<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <link rel="dns-prefetch" href="http://yoursite.com">
  <title>Pandas学习笔记 | 信平的小屋</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="1《pandas函数手册·zw汉化标注版》（pandas v0.17）zw量化开源·系列课件zw开源量化团队QQ群：533233771。作者：zw=智王+字王2016.01.18 字王 Git 项目总览：github.com/ziwang-com/,包括：字王 4k 云字库，zwPython、zwpy_lst Zw 量化 QQ 群：124134140 （AI 量化，足彩大数据、云字库、zwPy">
<meta property="og:type" content="article">
<meta property="og:title" content="Pandas学习笔记">
<meta property="og:url" content="http://yoursite.com/2017/04/06/Pandas学习笔记/index.html">
<meta property="og:site_name" content="信平的小屋">
<meta property="og:description" content="1《pandas函数手册·zw汉化标注版》（pandas v0.17）zw量化开源·系列课件zw开源量化团队QQ群：533233771。作者：zw=智王+字王2016.01.18 字王 Git 项目总览：github.com/ziwang-com/,包括：字王 4k 云字库，zwPython、zwpy_lst Zw 量化 QQ 群：124134140 （AI 量化，足彩大数据、云字库、zwPy">
<meta property="og:updated_time" content="2017-04-06T10:38:37.460Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Pandas学习笔记">
<meta name="twitter:description" content="1《pandas函数手册·zw汉化标注版》（pandas v0.17）zw量化开源·系列课件zw开源量化团队QQ群：533233771。作者：zw=智王+字王2016.01.18 字王 Git 项目总览：github.com/ziwang-com/,包括：字王 4k 云字库，zwPython、zwpy_lst Zw 量化 QQ 群：124134140 （AI 量化，足彩大数据、云字库、zwPy">
  
    <link rel="alternative" href="/atom.xml" title="信平的小屋" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" type="text/css" href="/./main.234bc0.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#a0cfe4,#e8c37e);
    }
  </style>
  

  

</head>

<body>
  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: #4d4d4d"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src="http://images.cnblogs.com/cnblogs_com/wangshuo1/859300/o_tangjie.bmp" class="js-avatar">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="/">王信平</a></h1>
		</hgroup>
		
		<p class="header-subtitle">念念不忘,必有回响,有一口气,点一盏灯。</p>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">主页</a></li>
	        
				<li><a href="/tags/随笔/">随笔</a></li>
	        
			</ul>
		</nav>
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">所有文章</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'friends')" href="javascript:void(0)">友链</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="#" title="github"><i class="icon-github"></i></a>
		        
					<a class="weibo" target="_blank" href="#" title="weibo"><i class="icon-weibo"></i></a>
		        
					<a class="rss" target="_blank" href="#" title="rss"><i class="icon-rss"></i></a>
		        
					<a class="zhihu" target="_blank" href="#" title="zhihu"><i class="icon-zhihu"></i></a>
		        
			</div>
		</nav>
	</header>		
</div>

    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #4d4d4d"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="http://images.cnblogs.com/cnblogs_com/wangshuo1/859300/o_tangjie.bmp" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author">王信平</h1>
			</hgroup>
			
			<p class="header-subtitle"><i class="icon icon-quo-left"></i>念念不忘,必有回响,有一口气,点一盏灯。<i class="icon icon-quo-right"></i></p>
			
			
			
				
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="#" title="github"><i class="icon-github"></i></a>
			        
						<a class="weibo" target="_blank" href="#" title="weibo"><i class="icon-weibo"></i></a>
			        
						<a class="rss" target="_blank" href="#" title="rss"><i class="icon-rss"></i></a>
			        
						<a class="zhihu" target="_blank" href="#" title="zhihu"><i class="icon-zhihu"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 50%">
				
				
					<li style="width: 50%"><a href="/">主页</a></li>
		        
					<li style="width: 50%"><a href="/tags/随笔/">随笔</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            <article id="post-Pandas学习笔记" class="article article-type-post " itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Pandas学习笔记
    </h1>
  

        
        <a href="/2017/04/06/Pandas学习笔记/" class="archive-article-date">
  	<time datetime="2017-04-06T10:38:20.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2017-04-06</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
				<!-- Table of Contents -->
				
	  
	  
        <p>1<br>《pandas函数手册·zw汉化标注版》<br>（pandas v0.17）<br>zw量化开源·系列课件<br>zw开源量化团队QQ群：533233771。<br>作者：zw=智王+字王<br>2016.01.18<br> 字王 Git 项目总览：github.com/ziwang-com/,<br>包括：字王 4k 云字库，zwPython、zwpy_lst<br> Zw 量化 QQ 群：124134140 （AI 量化，足彩大数据、云字库、zwPython）<br> zw 开源量化团队 QQ 群：533233771。<br> 技术 Blog：blog.sina.com.cn/zbrow （AI 量化、足彩大数据、字库）<br> www.cnblogs.com/ziwang/ （机器视觉）<br> 网盘下载：<a href="http://pan.baidu.com/s/1bnSqTxd" target="_blank" rel="external">http://pan.baidu.com/s/1bnSqTxd</a><br> zw 网站：<a href="http://www.ziwang.com" target="_blank" rel="external">http://www.ziwang.com</a><br>github，全球最大的极客创意平台，欢迎大家参与<br>2<br>前言………………………………………………………………………………………………………………………………………………………………………6<br>ZW 量化开源团队简介…………………………………………………………………………………………………………………………………………. 7<br>Categorical………………………………………………………………………………………………………………………………………………………….. 9<br>CategoricalIndex……………………………………………………………………………………………………………………………………………….. 24<br>DataFrame………………………………………………………………………………………………………………………………………………………… 46<br>DateOffset……………………………………………………………………………………………………………………………………………………….. 145<br>DatetimeIndex…………………………………………………………………………………………………………………………………………………. 148<br>ExcelFile………………………………………………………………………………………………………………………………………………………….. 170<br>ExcelWriter……………………………………………………………………………………………………………………………………………………….171<br>Expr…………………………………………………………………………………………………………………………………………………………………. 173<br>Float64Index……………………………………………………………………………………………………………………………………………………. 174<br>Grouper…………………………………………………………………………………………………………………………………………………………….192<br>HDFStore………………………………………………………………………………………………………………………………………………………… 194<br>Index…………………………………………………………………………………………………………………………………………………………………200<br>IndexSlice…………………………………………………………………………………………………………………………………………………………218<br>Int64Index…………………………………………………………………………………………………………………………………………………………219<br>LooseVersion……………………………………………………………………………………………………………………………………………………237<br>MultiIndex…………………………………………………………………………………………………………………………………………………………239<br>NaT…………………………………………………………………………………………………………………………………………………………………..262<br>Panel……………………………………………………………………………………………………………………………………………………………….. 266<br>Panel4D……………………………………………………………………………………………………………………………………………………………319<br>Period……………………………………………………………………………………………………………………………………………………………….370<br>PeriodIndex………………………………………………………………………………………………………………………………………………………375<br>Series……………………………………………………………………………………………………………………………………………………………….397<br>SparseArray……………………………………………………………………………………………………………………………………………………..470<br>SparseDataFrame…………………………………………………………………………………………………………………………………………… 505<br>SparseList……………………………………………………………………………………………………………………………………………………….. 603<br>SparsePanel……………………………………………………………………………………………………………………………………………………. 605<br>SparseSeries…………………………………………………………………………………………………………………………………………………… 655<br>SparseTimeSeries…………………………………………………………………………………………………………………………………………… 728<br>Term………………………………………………………………………………………………………………………………………………………………… 803<br>TimeGrouper…………………………………………………………………………………………………………………………………………………….805<br>TimeSeries………………………………………………………………………………………………………………………………………………………. 806<br>Timedelta………………………………………………………………………………………………………………………………………………………….882<br>TimedeltaIndex…………………………………………………………………………………………………………………………………………………886<br>Timestamp………………………………………………………………………………………………………………………………………………………..904<br>WidePanel………………………………………………………………………………………………………………………………………………………..910<br><strong>builtins</strong>………………………………………………………………………………………………………………………………………………………966<br><strong>cached</strong>…………………………………………………………………………………………………………………………………………………….. 968<br><strong>doc</strong>……………………………………………………………………………………………………………………………………………………………968<br><strong>docformat</strong>………………………………………………………………………………………………………………………………………………… 968<br><strong>file</strong>……………………………………………………………………………………………………………………………………………………………. 969<br><strong>loader</strong>………………………………………………………………………………………………………………………………………………………. 969<br><strong>name</strong>……………………………………………………………………………………………………………………………………………………….. 970<br><strong>package</strong>…………………………………………………………………………………………………………………………………………………… 972<br><strong>path</strong>…………………………………………………………………………………………………………………………………………………………..973<br><strong>spec</strong>………………………………………………………………………………………………………………………………………………………….976<br><strong>version</strong>…………………………………………………………………………………………………………………………………………………….. 977<br><strong>warningregistry</strong>………………………………………………………………………………………………………………………………………… 977<br>_np_version…………………………………………………………………………………………………………………………………………………….. 979<br>_np_version_under1p8……………………………………………………………………………………………………………………………………. 979<br>_np_version_under1p9……………………………………………………………………………………………………………………………………. 984<br>_period……………………………………………………………………………………………………………………………………………………………..988<br>_sparse……………………………………………………………………………………………………………………………………………………………. 994<br>_testing………………………………………………………………………………………………………………………………………………………….. 1000<br>_version………………………………………………………………………………………………………………………………………………………….1001<br>algos……………………………………………………………………………………………………………………………………………………………… 1001<br>3<br>bdate_range………………………………………………………………………………………………………………………………………………….. 1015<br>compat……………………………………………………………………………………………………………………………………………………………1015<br>computation…………………………………………………………………………………………………………………………………………………… 1020<br>concat……………………………………………………………………………………………………………………………………………………………. 1021<br>core……………………………………………………………………………………………………………………………………………………………….. 1022<br>crosstab………………………………………………………………………………………………………………………………………………………….1023<br>cut…………………………………………………………………………………………………………………………………………………………………..1024<br>date_range……………………………………………………………………………………………………………………………………………………..1025<br>datetime………………………………………………………………………………………………………………………………………………………….1026<br>datetools…………………………………………………………………………………………………………………………………………………………1029<br>describe_option………………………………………………………………………………………………………………………………………………1031<br>eval…………………………………………………………………………………………………………………………………………………………………1031<br>ewma…………………………………………………………………………………………………………………………………………………………….. 1033<br>ewmcorr………………………………………………………………………………………………………………………………………………………….1034<br>ewmcov…………………………………………………………………………………………………………………………………………………………. 1035<br>ewmstd………………………………………………………………………………………………………………………………………………………….. 1037<br>ewmvar………………………………………………………………………………………………………………………………………………………….. 1038<br>ewmvol………………………………………………………………………………………………………………………………………………………….. 1040<br>expanding_apply…………………………………………………………………………………………………………………………………………….1041<br>expanding_corr……………………………………………………………………………………………………………………………………………… 1042<br>expanding_corr_pairwise………………………………………………………………………………………………………………………………. 1042<br>expanding_count…………………………………………………………………………………………………………………………………………… 1043<br>expanding_cov………………………………………………………………………………………………………………………………………………. 1043<br>expanding_kurt……………………………………………………………………………………………………………………………………………….1044<br>expanding_max………………………………………………………………………………………………………………………………………………1045<br>expanding_mean…………………………………………………………………………………………………………………………………………… 1045<br>expanding_median………………………………………………………………………………………………………………………………………… 1046<br>expanding_min……………………………………………………………………………………………………………………………………………….1046<br>expanding_quantile……………………………………………………………………………………………………………………………………….. 1047<br>expanding_skew……………………………………………………………………………………………………………………………………………. 1047<br>expanding_std………………………………………………………………………………………………………………………………………………..1048<br>expanding_sum………………………………………………………………………………………………………………………………………………1048<br>expanding_var………………………………………………………………………………………………………………………………………………..1049<br>factorize………………………………………………………………………………………………………………………………………………………….1049<br>fama_macbeth………………………………………………………………………………………………………………………………………………. 1050<br>get_dummies………………………………………………………………………………………………………………………………………………….1050<br>get_option……………………………………………………………………………………………………………………………………………………… 1052<br>get_store……………………………………………………………………………………………………………………………………………………….. 1052<br>groupby…………………………………………………………………………………………………………………………………………………………..1052<br>hashtable………………………………………………………………………………………………………………………………………………………..1054<br>index……………………………………………………………………………………………………………………………………………………………… 1059<br>infer_freq……………………………………………………………………………………………………………………………………………………….. 1066<br>info………………………………………………………………………………………………………………………………………………………………….1067<br>io……………………………………………………………………………………………………………………………………………………………………. 1067<br>isnull……………………………………………………………………………………………………………………………………………………………….1068<br>json…………………………………………………………………………………………………………………………………………………………………1068<br>lib…………………………………………………………………………………………………………………………………………………………………… 1069<br>lreshape………………………………………………………………………………………………………………………………………………………….1081<br>match…………………………………………………………………………………………………………………………………………………………….. 1082<br>melt…………………………………………………………………………………………………………………………………………………………………1083<br>merge……………………………………………………………………………………………………………………………………………………………..1084<br>msgpack…………………………………………………………………………………………………………………………………………………………1086<br>notnull……………………………………………………………………………………………………………………………………………………………. 1090<br>offsets……………………………………………………………………………………………………………………………………………………………. 1090<br>ols………………………………………………………………………………………………………………………………………………………………….. 1160<br>option_context……………………………………………………………………………………………………………………………………………….. 1162<br>options…………………………………………………………………………………………………………………………………………………………… 1162<br>4<br>ordered_merge……………………………………………………………………………………………………………………………………………….1162<br>pandas…………………………………………………………………………………………………………………………………………………………… 1164<br>parser…………………………………………………………………………………………………………………………………………………………….. 1165<br>period_range…………………………………………………………………………………………………………………………………………………..1170<br>pivot………………………………………………………………………………………………………………………………………………………………..1170<br>pivot_table………………………………………………………………………………………………………………………………………………………1171<br>plot_params…………………………………………………………………………………………………………………………………………………… 1172<br>pnow……………………………………………………………………………………………………………………………………………………………….1174<br>qcut…………………………………………………………………………………………………………………………………………………………………1175<br>read_clipboard………………………………………………………………………………………………………………………………………………..1176<br>read_csv………………………………………………………………………………………………………………………………………………………… 1176<br>read_excel………………………………………………………………………………………………………………………………………………………1179<br>read_fwf…………………………………………………………………………………………………………………………………………………………. 1181<br>read_gbq……………………………………………………………………………………………………………………………………………………….. 1184<br>read_hdf………………………………………………………………………………………………………………………………………………………….1185<br>read_html………………………………………………………………………………………………………………………………………………………. 1185<br>read_json………………………………………………………………………………………………………………………………………………………..1188<br>read_msgpack………………………………………………………………………………………………………………………………………………..1189<br>read_pickle……………………………………………………………………………………………………………………………………………………..1190<br>read_sas…………………………………………………………………………………………………………………………………………………………1190<br>read_sql…………………………………………………………………………………………………………………………………………………………. 1191<br>read_sql_query……………………………………………………………………………………………………………………………………………….1192<br>read_sql_table………………………………………………………………………………………………………………………………………………..1193<br>read_stata……………………………………………………………………………………………………………………………………………………… 1194<br>read_table……………………………………………………………………………………………………………………………………………………… 1195<br>reset_option…………………………………………………………………………………………………………………………………………………… 1199<br>rolling_apply……………………………………………………………………………………………………………………………………………………1199<br>rolling_corr…………………………………………………………………………………………………………………………………………………….. 1200<br>rolling_corr_pairwise……………………………………………………………………………………………………………………………………… 1201<br>rolling_count………………………………………………………………………………………………………………………………………………….. 1202<br>rolling_cov………………………………………………………………………………………………………………………………………………………1202<br>rolling_kurt…………………………………………………………………………………………………………………………………………………….. 1203<br>rolling_max……………………………………………………………………………………………………………………………………………………..1204<br>rolling_mean………………………………………………………………………………………………………………………………………………….. 1205<br>rolling_median………………………………………………………………………………………………………………………………………………..1206<br>rolling_min………………………………………………………………………………………………………………………………………………………1207<br>rolling_quantile………………………………………………………………………………………………………………………………………………. 1207<br>rolling_skew……………………………………………………………………………………………………………………………………………………1208<br>rolling_std……………………………………………………………………………………………………………………………………………………….1209<br>rolling_sum……………………………………………………………………………………………………………………………………………………..1210<br>rolling_var……………………………………………………………………………………………………………………………………………………….1211<br>rolling_window………………………………………………………………………………………………………………………………………………..1211<br>scatter_matrix…………………………………………………………………………………………………………………………………………………1213<br>set_eng_float_format…………………………………………………………………………………………………………………………………….. 1213<br>set_option……………………………………………………………………………………………………………………………………………………….1214<br>show_versions………………………………………………………………………………………………………………………………………………. 1214<br>sparse……………………………………………………………………………………………………………………………………………………………. 1215<br>stats………………………………………………………………………………………………………………………………………………………………..1215<br>timedelta_range…………………………………………………………………………………………………………………………………………….. 1216<br>to_datetime……………………………………………………………………………………………………………………………………………………. 1216<br>to_msgpack…………………………………………………………………………………………………………………………………………………… 1218<br>to_numeric…………………………………………………………………………………………………………………………………………………….. 1218<br>to_pickle………………………………………………………………………………………………………………………………………………………… 1219<br>to_timedelta…………………………………………………………………………………………………………………………………………………… 1219<br>tools………………………………………………………………………………………………………………………………………………………………..1220<br>tseries……………………………………………………………………………………………………………………………………………………………. 1220<br>tslib…………………………………………………………………………………………………………………………………………………………………1221<br>5<br>unique……………………………………………………………………………………………………………………………………………………………. 1221<br>util…………………………………………………………………………………………………………………………………………………………………..1222<br>value_counts…………………………………………………………………………………………………………………………………………………. 1222<br>wide_to_long…………………………………………………………………………………………………………………………………………………. 1223<br>6<br>前言<br>自 2014 年，美国银行、美林证券的“石英”计划，以及摩根大通的“雅典娜”项目后。<br>Python 量化，已经势不可挡，连老牌的 matlab、和专业的统计语言 R，都一一惜败。<br>Python 量化， 除了原本深厚的科学计算底蕴： numPy， sciKit， 以及 AI 人工智能、 机器学习： scikit、 theano、 pyMC、<br>NLTK 等强大的生态系统外。<br>Pandas 潘达思（熊猫）数据分析模块，无疑是 Python 量化的刀锋所在。<br>pandas 问世不久，这两年 python 量化，发展十分火爆，相关资料非常缺乏，不光是中文，连英文文档，都不多<br>见。<br>作为开发必备的 pandas 函数手册，更是其中的，重中之重。<br>原本以为，不过是 174 个函数，zw 量化开源团队，每人十个函数，几天就 ok 了。<br>通过 zw 自行开发的百度电脑全文翻译软件，一个晚上，机器翻译版本，全部到位。<br>可一整理，洋洋洒洒，六千多页，即使配合“机译”版本辅助，也不是短期可以完成的。<br>浏览了一下，函数手册，大部分是标准的 API 接口，把其中的 5%关键词，人工翻译下，基本上能看懂，可以勉<br>强用于实际编程参考。<br>毕竟，函数手册，API 接口，无法就是参数、类型和返回值这些。<br>于是，便有了，这个《pandas 函数手册·zw 汉化标注版》<br>更多请浏览 zw 网站: <a href="http://ziwang.com" target="_blank" rel="external">http://ziwang.com</a><br>或技术 blog:<a href="http://blog.sina.com.cn/zbrow" target="_blank" rel="external">http://blog.sina.com.cn/zbrow</a><br>7<br>ZW量化开源团队简介<br>zw 开源量化团队 QQ 群号： 533233771<br>zw 开源量化团队，英文名称暂定：zwQTT：ziwang.com Quant Tearm，<br>zw 开源量化团队，是个免费的开源公益组织，专业从事国内外最新的金融、量化资料、软件、教程等各种相关资<br>源的引进、翻译、宣传、托管。<br>同时，在能力所及的范围内，进行相关的量化开源软件开发。<br>有关团队介绍，可参见：<br>《zw 开源量化团队·成立纪念》 <a href="http://ziwang.com/?p=214" target="_blank" rel="external">http://ziwang.com/?p=214</a><br>《zw 开源量化团队·约法三章》 <a href="http://ziwang.com/?p=212" target="_blank" rel="external">http://ziwang.com/?p=212</a><br>新人申请，请先浏览，以上文档，填写表格，再联系团队管理员。<br>更多请浏览 zw 网站:<a href="http://ziwang.com" target="_blank" rel="external">http://ziwang.com</a><br>或技术 blog:<a href="http://blog.sina.com.cn/zbrow" target="_blank" rel="external">http://blog.sina.com.cn/zbrow</a><br>附图：是 zw 开源量化团队，QQ 群首批成员截图纪念<br>8<br>9<br>Categorical<br>Categorical 模块所属：pandas.core.categorical:<br>类定义：Categorical(pandas.core.base.PandasObject)<br>| Represents a categorical variable in classic R / S-plus fashion<br>|<br>| <code>Categoricals</code> can only take on only a limited, and usually fixed, number<br>| of possible values (<code>categories</code>). In contrast to statistical categorical<br>| variables, a <code>Categorical</code> might have an order, but numerical operations<br>| (additions, divisions, …) are not possible.<br>|<br>| All values of the <code>Categorical</code> are either in <code>categories</code> or <code>np.nan</code>.<br>| Assigning values outside of <code>categories</code> will raise a <code>ValueError</code>. Order is<br>| defined by the order of the <code>categories</code>, not lexical order of the values.<br>|<br>| 【参数】<br>| ———-| values : list-like<br>| The values of the categorical. If categories are given, values not in categories will<br>| be replaced with NaN.<br>| categories : Index-like (unique), optional<br>| The unique categories for this categorical. If not given, the categories are assumed<br>| to be the unique values of values.<br>| ordered : boolean, (default False)<br>| Whether or not this categorical is treated as a ordered categorical. If not given,<br>| the resulting categorical will not be ordered.<br>|<br>| 【属性】<br>| ———-| categories : Index<br>| The categories of this categorical<br>| codes : ndarray<br>| The codes (integer positions, which point to the categories) of this categorical, read only.<br>| ordered : boolean<br>| Whether or not this Categorical is ordered.<br>|<br>| 【Raises 引发错误】<br>| ——| ValueError<br>| If the categories do not validate.<br>| TypeError<br>| If an explicit <code>ordered=True</code> is given but no <code>categories</code> and the <code>values</code> are<br>| not sortable.<br>|<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; from pandas import Categorical<br>| &gt;&gt;&gt; Categorical([1, 2, 3, 1, 2, 3])<br>| [1, 2, 3, 1, 2, 3]<br>10<br>| Categories (3, int64): [1 &lt; 2 &lt; 3]<br>|<br>| &gt;&gt;&gt; Categorical([‘a’, ‘b’, ‘c’, ‘a’, ‘b’, ‘c’])<br>| [a, b, c, a, b, c]<br>| Categories (3, object): [a &lt; b &lt; c]<br>|<br>| &gt;&gt;&gt; a = Categorical([‘a’,’b’,’c’,’a’,’b’,’c’], [‘c’, ‘b’, ‘a’], ordered=True)<br>| &gt;&gt;&gt; a.min()<br>| ‘c’<br>|<br>| 【方法排序】<br>| Categorical<br>| pandas.core.base.PandasObject<br>| pandas.core.base.StringMixin<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>array</strong>(self, dtype=None)<br>| The numpy array interface.<br>|<br>| 【返回值】<br>| ——-| values : numpy array<br>| A numpy array of either the specified dtype or, if dtype==None (default), the same<br>| dtype as categorical.categories.dtype<br>|<br>| <strong>eq</strong>(self, other)<br>|<br>| <strong>ge</strong>(self, other)<br>|<br>| <strong>getitem</strong>(self, key)<br>| Return an item.<br>|<br>| <strong>gt</strong>(self, other)<br>|<br>| <strong>init</strong>(self, values, categories=None, ordered=False, name=None, fastpath=False, levels=None)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>iter</strong>(self)<br>| Returns an Iterator over the values of this Categorical.<br>|<br>| <strong>le</strong>(self, other)<br>|<br>| <strong>len</strong>(self)<br>| The length of this Categorical.<br>|<br>| <strong>lt</strong>(self, other)<br>|<br>| <strong>ne</strong>(self, other)<br>|<br>| <strong>setitem</strong>(self, key, value)<br>| Item assignment.<br>|<br>|<br>| 【Raises 引发错误】<br>| ——<br>11<br>| ValueError<br>| If (one or more) Value is not in categories or if a assigned <code>Categorical</code> has not the<br>| same categories<br>|<br>| <strong>setstate</strong>(self, state)<br>| Necessary for making this object picklable<br>|<br>| <strong>unicode</strong>(self)<br>| Unicode representation.<br>|<br>| add_categories(self, new_categories, inplace=False)<br>| Add new categories.<br>|<br>| <code>new_categories</code> will be included at the last/highest place in the categories and will be<br>| unused directly after this call.<br>|<br>| 【Raises 引发错误】<br>| ——| ValueError<br>| If the new categories include old categories or do not validate as categories<br>|<br>| 【参数】<br>| ———-| new_categories : category or list-like of category<br>| The new categories to be included.<br>| inplace : boolean (default: False)<br>| Whether or not to add the categories inplace or return a copy of this categorical<br>| with added categories.<br>|<br>| 【返回值】<br>| ——-| cat : Categorical with new categories added or None if inplace.<br>|<br>| 【参见】<br>| ——–| rename_categories<br>| reorder_categories<br>| remove_categories<br>| remove_unused_categories<br>| set_categories<br>|<br>| argsort(self, ascending=True, <strong>kwargs)<br>| Implements ndarray.argsort.<br>|<br>| For internal compatibility with numpy arrays.<br>|<br>| Only ordered Categoricals can be argsorted!<br>|<br>| 【返回值】<br>| ——-| argsorted : numpy array<br>|<br>| as_ordered(self, inplace=False)<br>| Sets the Categorical to be ordered<br>|<br>| 【参数】<br>| ———-<br>12<br>| inplace : boolean (default: False)<br>| Whether or not to set the ordered attribute inplace or return a copy of this categorical<br>| with ordered set to True<br>|<br>| as_unordered(self, inplace=False)<br>| Sets the Categorical to be unordered<br>|<br>| 【参数】<br>| ———-| inplace : boolean (default: False)<br>| Whether or not to set the ordered attribute inplace or return a copy of this categorical<br>| with ordered set to False<br>|<br>| astype(self, dtype)<br>| coerce this type to another dtype<br>|<br>| check_for_ordered(self, op)<br>| assert that we are ordered<br>|<br>| copy(self)<br>| Copy constructor.<br>|<br>| describe(self)<br>| Describes this Categorical<br>|<br>| 【返回值】<br>| ——-| description: <code>DataFrame</code><br>| A dataframe with frequency and counts by category.<br>|<br>| dropna(self)<br>| Return the Categorical without null values.<br>|<br>| Both missing values (-1 in .codes) and NA as a category are detected.<br>| NA is removed from the categories if present.<br>|<br>| 【返回值】<br>| ——-| valid : Categorical<br>|<br>| equals(self, other)<br>| Returns True if categorical arrays are equal.<br>|<br>| 【参数】<br>| ———-| other : <code>Categorical</code><br>|<br>| 【返回值】<br>| ——-| are_equal : boolean<br>|<br>| fillna(self, value=None, method=None, limit=None)<br>| Fill NA/NaN values using the specified method.<br>|<br>| 【参数】<br>| ———-| method : {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default None<br>13<br>| Method to use for filling holes in reindexed Series<br>| pad / ffill: propagate last valid observation forward to next valid<br>| backfill / bfill: use NEXT valid observation to fill gap<br>| value : scalar<br>| Value to use to fill holes (e.g. 0)<br>| limit : int, default None<br>| (Not implemented yet for Categorical!)<br>| If method is specified, this is the maximum number of consecutive<br>| NaN values to forward/backward fill. In other words, if there is<br>| a gap with more than this number of consecutive NaNs, it will only<br>| be partially filled. If method is not specified, this is the<br>| maximum number of entries along the entire axis where NaNs will be<br>| filled.<br>|<br>| 【返回值】<br>| ——-| filled : Categorical with NA/NaN filled<br>|<br>| get_values(self)<br>| Return the values.<br>|<br>| For internal compatibility with pandas formatting.<br>|<br>| 【返回值】<br>| ——-| values : numpy array<br>| A numpy array of the same dtype as categorical.categories.dtype or<br>| Index if datetime / periods<br>|<br>| is_dtype_equal(self, other)<br>| Returns True if categoricals are the same dtype<br>| same categories, and same ordered<br>|<br>| 【参数】<br>| ———-| other : Categorical<br>|<br>| 【返回值】<br>| ——-| are_equal : boolean<br>|<br>| isnull(self)<br>| Detect missing values<br>|<br>| Both missing values (-1 in .codes) and NA as a category are detected.<br>|<br>| 【返回值】<br>| ——-| a boolean array of whether my values are null<br>|<br>| 【参见】<br>| ——–| pandas.isnull : pandas version<br>| Categorical.notnull : boolean inverse of Categorical.isnull<br>|<br>| max(self, numeric_only=None, </strong>kwargs)<br>| The maximum value of the object.<br>14<br>|<br>| Only ordered <code>Categoricals</code> have a maximum!<br>|<br>| 【Raises 引发错误】<br>| ——| TypeError<br>| If the <code>Categorical</code> is not <code>ordered</code>.<br>|<br>| 【返回值】<br>| ——-| max : the maximum of this <code>Categorical</code><br>|<br>| memory_usage(self, deep=False)<br>| Memory usage of my values<br>|<br>| 【参数】<br>| ———-| deep : bool<br>| Introspect the data deeply, interrogate<br>| <code>object</code> dtypes for system-level memory consumption<br>|<br>| 【返回值】<br>| ——-| bytes used<br>|<br>| 【注意】<br>| —–| Memory usage does not include memory consumed by elements that<br>| are not components of the array if deep=False<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.nbytes<br>|<br>| min(self, numeric_only=None, <strong>kwargs)<br>| The minimum value of the object.<br>|<br>| Only ordered <code>Categoricals</code> have a minimum!<br>|<br>| 【Raises 引发错误】<br>| ——| TypeError<br>| If the <code>Categorical</code> is not <code>ordered</code>.<br>|<br>| 【返回值】<br>| ——-| min : the minimum of this <code>Categorical</code><br>|<br>| mode(self)<br>| Returns the mode(s) of the Categorical.<br>|<br>| Empty if nothing occurs at least 2 times. Always returns <code>Categorical</code> even<br>| if only one value.<br>|<br>| 【返回值】<br>| ——-<br>15<br>| modes : <code>Categorical</code> (sorted)<br>|<br>| notnull(self)<br>| Reverse of isnull<br>|<br>| Both missing values (-1 in .codes) and NA as a category are detected as null.<br>|<br>| 【返回值】<br>| ——-| a boolean array of whether my values are not null<br>|<br>| 【参见】<br>| ——–| pandas.notnull : pandas version<br>| Categorical.isnull : boolean inverse of Categorical.notnull<br>|<br>| order(self, inplace=False, ascending=True, na_position=’last’)<br>| DEPRECATED: use :meth:<code>Categorical.sort_values</code><br>|<br>| Sorts the Category by category value returning a new Categorical by default.<br>|<br>| Only ordered Categoricals can be sorted!<br>|<br>| Categorical.sort is the equivalent but sorts the Categorical inplace.<br>|<br>| 【参数】<br>| ———-| inplace : boolean, default False<br>| Do operation in place.<br>| ascending : boolean, default True<br>| Sort ascending. Passing False sorts descending<br>| na_position : {‘first’, ‘last’} (optional, default=’last’)<br>| ‘first’ puts NaNs at the beginning<br>| ‘last’ puts NaNs at the end<br>|<br>| 【返回值】<br>| ——-| y : Category or None<br>|<br>| 【参见】<br>| ——–| Category.sort<br>|<br>| ravel(self, order=’C’)<br>| Return a flattened (numpy) array.<br>|<br>| For internal compatibility with numpy arrays.<br>|<br>| 【返回值】<br>| ——-| raveled : numpy array<br>|<br>| remove_categories(self, removals, inplace=False)<br>| Removes the specified categories.<br>|<br>| <code>removals</code> must be included in the old categories. Values which were in the removed<br>| categories will be set to NaN<br>16<br>|<br>| 【Raises 引发错误】<br>| ——| ValueError<br>| If the removals are not contained in the categories<br>|<br>| 【参数】<br>| ———-| removals : category or list of categories<br>| The categories which should be removed.<br>| inplace : boolean (default: False)<br>| Whether or not to remove the categories inplace or return a copy of this categorical<br>| with removed categories.<br>|<br>| 【返回值】<br>| ——-| cat : Categorical with removed categories or None if inplace.<br>|<br>| 【参见】<br>| ——–| rename_categories<br>| reorder_categories<br>| add_categories<br>| remove_unused_categories<br>| set_categories<br>|<br>| remove_unused_categories(self, inplace=False)<br>| Removes categories which are not used.<br>|<br>| 【参数】<br>| ———-| inplace : boolean (default: False)<br>| Whether or not to drop unused categories inplace or return a copy of this categorical<br>| with unused categories dropped.<br>|<br>| 【返回值】<br>| ——-| cat : Categorical with unused categories dropped or None if inplace.<br>|<br>| 【参见】<br>| ——–| rename_categories<br>| reorder_categories<br>| add_categories<br>| remove_categories<br>| set_categories<br>|<br>| rename_categories(self, new_categories, inplace=False)<br>| Renames categories.<br>|<br>| The new categories has to be a list-like object. All items must be unique and the number of<br>| items in the new categories must be the same as the number of items in the old categories.<br>|<br>| 【Raises 引发错误】<br>| ——| ValueError<br>17<br>| If the new categories do not have the same number of items than the current categories<br>| or do not validate as categories<br>|<br>| 【参数】<br>| ———-| new_categories : Index-like<br>| The renamed categories.<br>| inplace : boolean (default: False)<br>| Whether or not to rename the categories inplace or return a copy of this categorical<br>| with renamed categories.<br>|<br>| 【返回值】<br>| ——-| cat : Categorical with renamed categories added or None if inplace.<br>|<br>| 【参见】<br>| ——–| reorder_categories<br>| add_categories<br>| remove_categories<br>| remove_unused_categories<br>| set_categories<br>|<br>| reorder_categories(self, new_categories, ordered=None, inplace=False)<br>| Reorders categories as specified in new_categories.<br>|<br>| <code>new_categories</code> need to include all old categories and no new category items.<br>|<br>| 【Raises 引发错误】<br>| ——| ValueError<br>| If the new categories do not contain all old category items or any new ones<br>|<br>| 【参数】<br>| ———-| new_categories : Index-like<br>| The categories in new order.<br>| ordered : boolean, optional<br>| Whether or not the categorical is treated as a ordered categorical. If not given,<br>| do not change the ordered information.<br>| inplace : boolean (default: False)<br>| Whether or not to reorder the categories inplace or return a copy of this categorical<br>| with reordered categories.<br>|<br>| 【返回值】<br>| ——-| cat : Categorical with reordered categories or None if inplace.<br>|<br>| 【参见】<br>| ——–| rename_categories<br>| add_categories<br>| remove_categories<br>| remove_unused_categories<br>| set_categories<br>|<br>| repeat(self, repeats)<br>18<br>| Repeat elements of a Categorical.<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.repeat<br>|<br>| reshape(self, new_shape, </strong>kwargs)<br>| compat with .reshape<br>|<br>| searchsorted(self, v, side=’left’, sorter=None)<br>| Find indices where elements should be inserted to maintain order.<br>|<br>| Find the indices into a sorted Categorical <code>self</code> such that, if the<br>| corresponding elements in <code>v</code> were inserted before the indices, the<br>| order of <code>self</code> would be preserved.<br>|<br>| 【参数】<br>| ———-| v : array_like<br>| Array-like values or a scalar value, to insert/search for in <code>self</code>.<br>| side : {‘left’, ‘right’}, optional<br>| If ‘left’, the index of the first suitable location found is given.<br>| If ‘right’, return the last such index. If there is no suitable<br>| index, return either 0 or N (where N is the length of <code>a</code>).<br>| sorter : 1-D array_like, optional<br>| Optional array of integer indices that sort <code>self</code> into ascending<br>| order. They are typically the result of <code>np.argsort</code>.<br>|<br>| 【返回值】<br>| ——-| indices : array of ints<br>| Array of insertion points with the same shape as <code>v</code>.<br>|<br>| 【参见】<br>| ——–| Series.searchsorted<br>| numpy.searchsorted<br>|<br>| 【注意】<br>| —–| Binary search is used to find the required insertion points.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; x = pd.Categorical([‘apple’, ‘bread’, ‘bread’, ‘cheese’, ‘milk’ ])<br>| [apple, bread, bread, cheese, milk]<br>| Categories (4, object): [apple &lt; bread &lt; cheese &lt; milk]<br>| &gt;&gt;&gt; x.searchsorted(‘bread’)<br>| array([1]) # Note: an array, not a scalar<br>| &gt;&gt;&gt; x.searchsorted([‘bread’])<br>| array([1])<br>| &gt;&gt;&gt; x.searchsorted([‘bread’, ‘eggs’])<br>| array([1, 4])<br>| &gt;&gt;&gt; x.searchsorted([‘bread’, ‘eggs’], side=’right’)<br>| array([3, 4]) # eggs before milk<br>| &gt;&gt;&gt; x = pd.Categorical([‘apple’, ‘bread’, ‘bread’, ‘cheese’, ‘milk’, ‘donuts’ ])<br>| &gt;&gt;&gt; x.searchsorted([‘bread’, ‘eggs’], side=’right’, sorter=[0, 1, 2, 3, 5, 4])<br>19<br>| array([3, 5]) # eggs after donuts, after switching milk and donuts<br>|<br>| set_categories(self, new_categories, ordered=None, rename=False, inplace=False)<br>| Sets the categories to the specified new_categories.<br>|<br>| <code>new_categories</code> can include new categories (which will result in unused categories) or<br>| or remove old categories (which results in values set to NaN). If <code>rename==True</code>,<br>| the categories will simple be renamed (less or more items than in old categories will<br>| result in values set to NaN or in unused categories respectively).<br>|<br>| This method can be used to perform more than one action of adding, removing,<br>| and reordering simultaneously and is therefore faster than performing the individual steps<br>| via the more specialised methods.<br>|<br>| On the other hand this methods does not do checks (e.g., whether the old categories are<br>| included in the new categories on a reorder), which can result in surprising changes, for<br>| example when using special string dtypes on python3, which does not considers a S1 string<br>| equal to a single char python string.<br>|<br>| 【Raises 引发错误】<br>| ——| ValueError<br>| If new_categories does not validate as categories<br>|<br>| 【参数】<br>| ———-| new_categories : Index-like<br>| The categories in new order.<br>| ordered : boolean, (default: False)<br>| Whether or not the categorical is treated as a ordered categorical. If not given,<br>| do not change the ordered information.<br>| rename : boolean (default: False)<br>| Whether or not the new_categories should be considered as a rename of the old<br>| categories or as reordered categories.<br>| inplace : boolean (default: False)<br>| Whether or not to reorder the categories inplace or return a copy of this categorical<br>| with reordered categories.<br>|<br>| 【返回值】<br>| ——-| cat : Categorical with reordered categories or None if inplace.<br>|<br>| 【参见】<br>| ——–| rename_categories<br>| reorder_categories<br>| add_categories<br>| remove_categories<br>| remove_unused_categories<br>|<br>| set_ordered(self, value, inplace=False)<br>| Sets the ordered attribute to the boolean value<br>|<br>| 【参数】<br>| ———-| value : boolean to set whether this categorical is ordered (True) or not (False)<br>| inplace : boolean (default: False)<br>20<br>| Whether or not to set the ordered attribute inplace or return a copy of this categorical<br>| with ordered set to the value<br>|<br>| shift(self, periods)<br>| Shift Categorical by desired number of periods.<br>|<br>| 【参数】<br>| ———-| periods : int<br>| Number of periods to move, can be positive or negative<br>|<br>| 【返回值】<br>| ——-| shifted : Categorical<br>|<br>| sort(self, inplace=True, ascending=True, na_position=’last’)<br>| Sorts the Category inplace by category value.<br>|<br>| Only ordered Categoricals can be sorted!<br>|<br>| Catgorical.order is the equivalent but returns a new Categorical.<br>|<br>| 【参数】<br>| ———-| ascending : boolean, default True<br>| Sort ascending. Passing False sorts descending<br>| inplace : boolean, default False<br>| Do operation in place.<br>| na_position : {‘first’, ‘last’} (optional, default=’last’)<br>| ‘first’ puts NaNs at the beginning<br>| ‘last’ puts NaNs at the end<br>|<br>| 【返回值】<br>| ——-| y : Category or None<br>|<br>| 【参见】<br>| ——–| Category.sort_values<br>|<br>| sort_values(self, inplace=False, ascending=True, na_position=’last’)<br>| Sorts the Category by category value returning a new Categorical by default.<br>|<br>| Only ordered Categoricals can be sorted!<br>|<br>| Categorical.sort is the equivalent but sorts the Categorical inplace.<br>|<br>| 【参数】<br>| ———-| inplace : boolean, default False<br>| Do operation in place.<br>| ascending : boolean, default True<br>| Sort ascending. Passing False sorts descending<br>| na_position : {‘first’, ‘last’} (optional, default=’last’)<br>| ‘first’ puts NaNs at the beginning<br>| ‘last’ puts NaNs at the end<br>|<br>21<br>| 【返回值】<br>| ——-| y : Category or None<br>|<br>| 【参见】<br>| ——–| Category.sort<br>|<br>| take = take_nd(self, indexer, allow_fill=True, fill_value=None)<br>|<br>| take_nd(self, indexer, allow_fill=True, fill_value=None)<br>| Take the codes by the indexer, fill with the fill_value.<br>|<br>| For internal compatibility with numpy arrays.<br>|<br>| to_dense(self)<br>| Return my ‘dense’ representation<br>|<br>| For internal compatibility with numpy arrays.<br>|<br>| 【返回值】<br>| ——-| dense : array<br>|<br>| unique(self)<br>| Return the <code>Categorical</code> which <code>categories</code> and <code>codes</code> are unique.<br>| Unused categories are NOT returned.<br>|<br>| - unordered category: values and categories are sorted by appearance<br>| order.<br>| - ordered category: values are sorted by appearance order, categories<br>| keeps existing order.<br>|<br>| 【返回值】<br>| ——-| unique values : <code>Categorical</code><br>|<br>| value_counts(self, dropna=True)<br>| Returns a Series containing counts of each category.<br>|<br>| Every category will have an entry, even those with a count of 0.<br>|<br>| 【参数】<br>| ———-| dropna : boolean, default True<br>| Don’t include counts of NaN, even if NaN is a category.<br>|<br>| 【返回值】<br>| ——-| counts : Series<br>|<br>| view(self)<br>| Return a view of myself.<br>|<br>| For internal compatibility with numpy arrays.<br>|<br>| 【返回值】<br>22<br>| ——-| view : Categorical<br>| Returns <code>self</code>!<br>|<br>| ———————————————————————-| Class methods defined here:<br>|<br>| from_array(data, <strong>kwargs) from builtins.type<br>| Make a Categorical type from a single array-like object.<br>|<br>| For internal compatibility with numpy arrays.<br>|<br>| 【参数】<br>| ———-| data : array-like<br>| Can be an Index or array-like. The categories are assumed to be<br>| the unique values of <code>data</code>.<br>|<br>| from_codes(codes, categories, ordered=False, name=None) from builtins.type<br>| Make a Categorical type from codes and categories arrays.<br>|<br>| This constructor is useful if you already have codes and categories and so do not need the<br>| (computation intensive) factorization step, which is usually done on the constructor.<br>|<br>| If your data does not follow this convention, please use the normal constructor.<br>|<br>| 【参数】<br>| ———-| codes : array-like, integers<br>| An integer array, where each integer points to a category in categories or -1 for NaN<br>| categories : index-like<br>| The categories for the categorical. Items need to be unique.<br>| ordered : boolean, (default False)<br>| Whether or not this categorical is treated as a ordered categorical. If not given,<br>| the resulting categorical will be unordered.<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| T<br>|<br>| base<br>| compat, we are always our own object<br>|<br>| categories<br>| The categories of this categorical.<br>|<br>| Setting assigns new values to each category (effectively a rename of<br>| each individual category).<br>|<br>| The assigned value has to be a list-like object. All items must be unique and the number of items<br>| in the new categories must be the same as the number of items in the old categories.<br>|<br>| Assigning to <code>categories</code> is a inplace operation!<br>|<br>| 【Raises 引发错误】<br>| ——<br>23<br>| ValueError<br>| If the new categories do not validate as categories or if the number of new categories is<br>| unequal the number of old categories<br>|<br>| 【参见】<br>| ——–| rename_categories<br>| reorder_categories<br>| add_categories<br>| remove_categories<br>| remove_unused_categories<br>| set_categories<br>|<br>| codes<br>| The category codes of this categorical.<br>|<br>| Level codes are an array if integer which are the positions of the real<br>| values in the categories array.<br>|<br>| There is not setter, use the other categorical methods and the normal item setter to change<br>| values in the categorical.<br>|<br>| itemsize<br>|<br>| labels<br>| Get the category labels (deprecated).<br>|<br>| Deprecated, use .codes!<br>|<br>| levels<br>| Gets the levels (deprecated, use “categories”)<br>|<br>| nbytes<br>|<br>| ndim<br>|<br>| ordered<br>| Gets the ordered attribute<br>|<br>| shape<br>| Shape of the Categorical.<br>|<br>| For internal compatibility with numpy arrays.<br>|<br>| 【返回值】<br>| ——-| shape : tuple<br>|<br>| size<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| <strong>array_priority</strong> = 1000<br>|<br>| <strong>hash</strong> = None<br>|<br>24<br>| dtype = category<br>|<br>| ———————————————————————-| Methods inherited from pandas.core.base.PandasObject:<br>|<br>| <strong>dir</strong>(self)<br>| Provide method name lookup and completion<br>| Only provide ‘public’ methods<br>|<br>| ———————————————————————-| Methods inherited from pandas.core.base.StringMixin:<br>|<br>| <strong>bytes</strong>(self)<br>| Return a string representation for a particular object.<br>|<br>| Invoked by bytes(obj) in py3 only.<br>| Yields a bytestring in both py2/py3.<br>|<br>| <strong>repr</strong>(self)<br>| Return a string representation for a particular object.<br>|<br>| Yields Bytestring in Py2, Unicode String in py3.<br>|<br>| <strong>str</strong>(self)<br>| Return a string representation for a particular Object<br>|<br>| Invoked by str(df) in both py2/py3.<br>| Yields Bytestring in Py2, Unicode String in py3.<br>|<br>| ———————————————————————-| Data descriptors inherited from pandas.core.base.StringMixin:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>CategoricalIndex<br>CategoricalIndex 模块所属：pandas.core.index:<br>类定义：CategoricalIndex(Index, pandas.core.base.PandasDelegate)<br>| Immutable Index implementing an ordered, sliceable set. CategoricalIndex<br>| represents a sparsely populated Index with an underlying Categorical.<br>|<br>| .. versionadded:: 0.16.1<br>|<br>| 【参数】<br>| ———-<br>25<br>| data : array-like or Categorical, (1-dimensional)<br>| categories : optional, array-like<br>| categories for the CategoricalIndex<br>| ordered : boolean,<br>| designating if the categories are ordered<br>| copy : bool<br>| Make a copy of input ndarray<br>| name : object<br>| Name to be stored in the index<br>|<br>| 【方法排序】<br>| CategoricalIndex<br>| Index<br>| pandas.core.base.IndexOpsMixin<br>| pandas.core.strings.StringAccessorMixin<br>| pandas.core.base.PandasDelegate<br>| pandas.core.base.PandasObject<br>| pandas.core.base.StringMixin<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>abs</strong>(self, other=None)<br>|<br>| <strong>add</strong>(self, other=None)<br>|<br>| <strong>array</strong>(self, dtype=None)<br>| the array interface, return my values<br>|<br>| <strong>contains</strong>(self, key)<br>|<br>| <strong>eq</strong> = _evaluate_compare(self, other)<br>|<br>| <strong>floordiv</strong>(self, other=None)<br>|<br>| <strong>ge</strong> = _evaluate_compare(self, other)<br>|<br>| <strong>gt</strong> = _evaluate_compare(self, other)<br>|<br>| <strong>inv</strong>(self, other=None)<br>|<br>| <strong>le</strong> = _evaluate_compare(self, other)<br>|<br>| <strong>lt</strong> = _evaluate_compare(self, other)<br>|<br>| <strong>mul</strong>(self, other=None)<br>|<br>| <strong>ne</strong> = _evaluate_compare(self, other)<br>|<br>| <strong>neg</strong>(self, other=None)<br>|<br>| <strong>pos</strong>(self, other=None)<br>|<br>| <strong>radd</strong> = <strong>add</strong>(self, other=None)<br>|<br>| <strong>rfloordiv</strong> = <strong>floordiv</strong>(self, other=None)<br>|<br>26<br>| <strong>rmul</strong> = <strong>mul</strong>(self, other=None)<br>|<br>| <strong>rtruediv</strong> = <strong>truediv</strong>(self, other=None)<br>|<br>| <strong>sub</strong>(self, other=None)<br>|<br>| <strong>truediv</strong>(self, other=None)<br>|<br>| add_categories(self, *args, </strong>kwargs)<br>| Add new categories.<br>|<br>| <code>new_categories</code> will be included at the last/highest place in the categories and will be<br>| unused directly after this call.<br>|<br>| 【Raises 引发错误】<br>| ——| ValueError<br>| If the new categories include old categories or do not validate as categories<br>|<br>| 【参数】<br>| ———-| new_categories : category or list-like of category<br>| The new categories to be included.<br>| inplace : boolean (default: False)<br>| Whether or not to add the categories inplace or return a copy of this categorical<br>| with added categories.<br>|<br>| 【返回值】<br>| ——-| cat : Categorical with new categories added or None if inplace.<br>|<br>| 【参见】<br>| ——–| rename_categories<br>| reorder_categories<br>| remove_categories<br>| remove_unused_categories<br>| set_categories<br>|<br>| all(self, other=None)<br>|<br>| any(self, other=None)<br>|<br>| append(self, other)<br>| Append a collection of CategoricalIndex options together<br>|<br>| 【参数】<br>| ———-| other : Index or list/tuple of indices<br>|<br>| 【返回值】<br>| ——-| appended : Index<br>|<br>| 【Raises 引发错误】<br>| ——| ValueError if other is not in the categories<br>27<br>|<br>| argsort(self, <em>args, **kwargs)<br>| return an ndarray indexer of the underlying data<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.argsort<br>|<br>| as_ordered(self, </em>args, <strong>kwargs)<br>| Sets the Categorical to be ordered<br>|<br>| 【参数】<br>| ———-| inplace : boolean (default: False)<br>| Whether or not to set the ordered attribute inplace or return a copy of this categorical<br>| with ordered set to True<br>|<br>| as_unordered(self, *args, </strong>kwargs)<br>| Sets the Categorical to be unordered<br>|<br>| 【参数】<br>| ———-| inplace : boolean (default: False)<br>| Whether or not to set the ordered attribute inplace or return a copy of this categorical<br>| with ordered set to False<br>|<br>| delete(self, loc)<br>| Make new Index with passed location(-s) deleted<br>|<br>| 【返回值】<br>| ——-| new_index : Index<br>|<br>| duplicated(self, keep=’first’)<br>| Return boolean np.array denoting duplicate values<br>|<br>| 【参数】<br>| ———-| keep : {‘first’, ‘last’, False}, default ‘first’<br>| - <code>first</code> : Mark duplicates as <code>True</code> except for the first occurrence.<br>| - <code>last</code> : Mark duplicates as <code>True</code> except for the last occurrence.<br>| - False : Mark all duplicates as <code>True</code>.<br>| take_last : deprecated<br>|<br>| 【返回值】<br>| ——-| duplicated : np.array<br>|<br>| equals(self, other)<br>| Determines if two CategorialIndex objects contain the same elements.<br>|<br>| fillna(self, value, downcast=None)<br>| Fill NA/NaN values with the specified value<br>|<br>| 【参数】<br>| ———-| value : scalar<br>28<br>| Scalar value to use to fill holes (e.g. 0).<br>| This value cannot be a list-likes.<br>| downcast : dict, default is None<br>| a dict of item-&gt;dtype of what to downcast if possible,<br>| or the string ‘infer’ which will try to downcast to an appropriate<br>| equal type (e.g. float64 to int64 if possible)<br>|<br>| 【返回值】<br>| ——-| filled : Index<br>|<br>| get_indexer(self, target, method=None, limit=None, tolerance=None)<br>| Compute indexer and mask for new index given the current index. The<br>| indexer should be then used as an input to ndarray.take to align the<br>| current data to the new index. The mask determines whether labels are<br>| found or not in the current index<br>|<br>| 【参数】<br>| ———-| target : MultiIndex or Index (of tuples)<br>| method : {‘pad’, ‘ffill’, ‘backfill’, ‘bfill’}<br>| pad / ffill: propagate LAST valid observation forward to next valid<br>| backfill / bfill: use NEXT valid observation to fill gap<br>|<br>| 【注意】<br>| —–| This is a low-level method and probably should be used at your own risk<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; indexer, mask = index.get_indexer(new_index)<br>| &gt;&gt;&gt; new_values = cur_values.take(indexer)<br>| &gt;&gt;&gt; new_values[-mask] = np.nan<br>|<br>| 【返回值】<br>| ——-| (indexer, mask) : (ndarray, ndarray)<br>|<br>| get_indexer_non_unique(self, target)<br>| this is the same for a CategoricalIndex for get_indexer; the API returns the missing values as well<br>|<br>| get_loc(self, key, method=None)<br>| Get integer location for requested label<br>|<br>| 【参数】<br>| ———-| key : label<br>| method : {None}<br>| <em> default: exact matches only.<br>|<br>| 【返回值】<br>| ——-| loc : int if unique index, possibly slice or mask if not<br>|<br>| get_values(self)<br>| return the underlying data as an ndarray<br>|<br>29<br>| insert(self, loc, item)<br>| Make new Index inserting new item at location. Follows<br>| Python list.append semantics for negative values<br>|<br>| 【参数】<br>| ———-| loc : int<br>| item : object<br>|<br>| 【返回值】<br>| ——-| new_index : Index<br>|<br>| 【Raises 引发错误】<br>| ——| ValueError if the item is not in the categories<br>|<br>| max(self, </em>args, <strong>kwargs)<br>| The maximum value of the object.<br>|<br>| Only ordered <code>Categoricals</code> have a maximum!<br>|<br>| 【Raises 引发错误】<br>| ——| TypeError<br>| If the <code>Categorical</code> is not <code>ordered</code>.<br>|<br>| 【返回值】<br>| ——-| max : the maximum of this <code>Categorical</code><br>|<br>| min(self, *args, </strong>kwargs)<br>| The minimum value of the object.<br>|<br>| Only ordered <code>Categoricals</code> have a minimum!<br>|<br>| 【Raises 引发错误】<br>| ——| TypeError<br>| If the <code>Categorical</code> is not <code>ordered</code>.<br>|<br>| 【返回值】<br>| ——-| min : the minimum of this <code>Categorical</code><br>|<br>| reindex(self, target, method=None, level=None, limit=None, tolerance=None)<br>| Create index with target’s values (move/add/delete values as necessary)<br>|<br>| 【返回值】<br>| ——-| new_index : pd.Index<br>| Resulting index<br>| indexer : np.ndarray or None<br>| Indices of output values in original index<br>|<br>| remove_categories(self, <em>args, **kwargs)<br>30<br>| Removes the specified categories.<br>|<br>| <code>removals</code> must be included in the old categories. Values which were in the removed<br>| categories will be set to NaN<br>|<br>| 【Raises 引发错误】<br>| ——| ValueError<br>| If the removals are not contained in the categories<br>|<br>| 【参数】<br>| ———-| removals : category or list of categories<br>| The categories which should be removed.<br>| inplace : boolean (default: False)<br>| Whether or not to remove the categories inplace or return a copy of this categorical<br>| with removed categories.<br>|<br>| 【返回值】<br>| ——-| cat : Categorical with removed categories or None if inplace.<br>|<br>| 【参见】<br>| ——–| rename_categories<br>| reorder_categories<br>| add_categories<br>| remove_unused_categories<br>| set_categories<br>|<br>| remove_unused_categories(self, </em>args, <strong>kwargs)<br>| Removes categories which are not used.<br>|<br>| 【参数】<br>| ———-| inplace : boolean (default: False)<br>| Whether or not to drop unused categories inplace or return a copy of this categorical<br>| with unused categories dropped.<br>|<br>| 【返回值】<br>| ——-| cat : Categorical with unused categories dropped or None if inplace.<br>|<br>| 【参见】<br>| ——–| rename_categories<br>| reorder_categories<br>| add_categories<br>| remove_categories<br>| set_categories<br>|<br>| rename_categories(self, *args, </strong>kwargs)<br>| Renames categories.<br>|<br>| The new categories has to be a list-like object. All items must be unique and the number of<br>| items in the new categories must be the same as the number of items in the old categories.<br>|<br>31<br>| 【Raises 引发错误】<br>| ——| ValueError<br>| If the new categories do not have the same number of items than the current categories<br>| or do not validate as categories<br>|<br>| 【参数】<br>| ———-| new_categories : Index-like<br>| The renamed categories.<br>| inplace : boolean (default: False)<br>| Whether or not to rename the categories inplace or return a copy of this categorical<br>| with renamed categories.<br>|<br>| 【返回值】<br>| ——-| cat : Categorical with renamed categories added or None if inplace.<br>|<br>| 【参见】<br>| ——–| reorder_categories<br>| add_categories<br>| remove_categories<br>| remove_unused_categories<br>| set_categories<br>|<br>| reorder_categories(self, <em>args, **kwargs)<br>| Reorders categories as specified in new_categories.<br>|<br>| <code>new_categories</code> need to include all old categories and no new category items.<br>|<br>| 【Raises 引发错误】<br>| ——| ValueError<br>| If the new categories do not contain all old category items or any new ones<br>|<br>| 【参数】<br>| ———-| new_categories : Index-like<br>| The categories in new order.<br>| ordered : boolean, optional<br>| Whether or not the categorical is treated as a ordered categorical. If not given,<br>| do not change the ordered information.<br>| inplace : boolean (default: False)<br>| Whether or not to reorder the categories inplace or return a copy of this categorical<br>| with reordered categories.<br>|<br>| 【返回值】<br>| ——-| cat : Categorical with reordered categories or None if inplace.<br>|<br>| 【参见】<br>| ——–| rename_categories<br>| add_categories<br>| remove_categories<br>32<br>| remove_unused_categories<br>| set_categories<br>|<br>| set_categories(self, </em>args, <strong>kwargs)<br>| Sets the categories to the specified new_categories.<br>|<br>| <code>new_categories</code> can include new categories (which will result in unused categories) or<br>| or remove old categories (which results in values set to NaN). If <code>rename==True</code>,<br>| the categories will simple be renamed (less or more items than in old categories will<br>| result in values set to NaN or in unused categories respectively).<br>|<br>| This method can be used to perform more than one action of adding, removing,<br>| and reordering simultaneously and is therefore faster than performing the individual steps<br>| via the more specialised methods.<br>|<br>| On the other hand this methods does not do checks (e.g., whether the old categories are<br>| included in the new categories on a reorder), which can result in surprising changes, for<br>| example when using special string dtypes on python3, which does not considers a S1 string<br>| equal to a single char python string.<br>|<br>| 【Raises 引发错误】<br>| ——| ValueError<br>| If new_categories does not validate as categories<br>|<br>| 【参数】<br>| ———-| new_categories : Index-like<br>| The categories in new order.<br>| ordered : boolean, (default: False)<br>| Whether or not the categorical is treated as a ordered categorical. If not given,<br>| do not change the ordered information.<br>| rename : boolean (default: False)<br>| Whether or not the new_categories should be considered as a rename of the old<br>| categories or as reordered categories.<br>| inplace : boolean (default: False)<br>| Whether or not to reorder the categories inplace or return a copy of this categorical<br>| with reordered categories.<br>|<br>| 【返回值】<br>| ——-| cat : Categorical with reordered categories or None if inplace.<br>|<br>| 【参见】<br>| ——–| rename_categories<br>| reorder_categories<br>| add_categories<br>| remove_categories<br>| remove_unused_categories<br>|<br>| take(self, indexer, axis=0, allow_fill=True, fill_value=None)<br>| For internal compatibility with numpy arrays.<br>|<br>| # filling must always be None/nan here<br>| # but is passed thru internally<br>| assert isnull(fill_value)<br>33<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.take<br>|<br>| ———————————————————————-| Static methods defined here:<br>|<br>| <strong>new</strong>(cls, data=None, categories=None, ordered=None, dtype=None, copy=False, name=None, fastpath=False,
</strong>kwargs)<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| categories<br>|<br>| codes<br>|<br>| inferred_type<br>|<br>| is_unique<br>|<br>| ordered<br>|<br>| values<br>| return the underlying data, which is a Categorical<br>|<br>| ———————————————————————-| Methods inherited from Index:<br>|<br>| <strong>and</strong>(self, other)<br>|<br>| <strong>array_wrap</strong>(self, result, context=None)<br>| Gets called after a ufunc<br>|<br>| <strong>bool</strong> = <strong>nonzero</strong>(self)<br>|<br>| <strong>copy</strong> = copy(self, names=None, name=None, dtype=None, deep=False)<br>| Make a copy of this object. Name and dtype sets those attributes on<br>| the new object.<br>|<br>| 【参数】<br>| ———-| name : string, optional<br>| dtype : numpy dtype or pandas type<br>|<br>| 【返回值】<br>| ——-| copy : Index<br>|<br>| 【注意】<br>| —–| In most cases, there should be no functional difference from using<br>| <code>deep</code>, but if <code>deep</code> is passed it will attempt to deepcopy.<br>|<br>| <strong>deepcopy</strong>(self, memo={})<br>34<br>|<br>| <strong>getitem</strong>(self, key)<br>| Override numpy.ndarray’s <strong>getitem</strong> method to work as desired.<br>|<br>| This function adds lists and Series as valid boolean indexers<br>| (ndarrays only supports ndarray with dtype=bool).<br>|<br>| If resulting ndim != 1, plain ndarray is returned instead of<br>| corresponding <code>Index</code> subclass.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>iadd</strong> = <strong>add</strong>(self, other)<br>|<br>| <strong>iter</strong>(self)<br>|<br>| <strong>len</strong>(self)<br>| return the length of the Index<br>|<br>| <strong>nonzero</strong>(self)<br>|<br>| <strong>or</strong>(self, other)<br>|<br>| <strong>reduce</strong>(self)<br>| helper for pickle<br>|<br>| <strong>setitem</strong>(self, key, value)<br>|<br>| <strong>setstate</strong>(self, state)<br>| Necessary for making this object picklable<br>|<br>| <strong>unicode</strong>(self)<br>| Return a string representation for this object.<br>|<br>| Invoked by unicode(df) in py2 only. Yields a Unicode String in both<br>| py2/py3.<br>|<br>| <strong>xor</strong>(self, other)<br>|<br>| asof(self, label)<br>| For a sorted index, return the most recent label up to and including<br>| the passed label. Return NaN if not found.<br>|<br>| 【参见】<br>| ——–| get_loc : asof is a thin wrapper around get_loc with method=’pad’<br>|<br>| asof_locs(self, where, mask)<br>| where : array of timestamps<br>| mask : array of booleans where data is not NA<br>|<br>| astype(self, dtype)<br>|<br>| copy(self, names=None, name=None, dtype=None, deep=False)<br>| Make a copy of this object. Name and dtype sets those attributes on<br>| the new object.<br>35<br>|<br>| 【参数】<br>| ———-| name : string, optional<br>| dtype : numpy dtype or pandas type<br>|<br>| 【返回值】<br>| ——-| copy : Index<br>|<br>| 【注意】<br>| —–| In most cases, there should be no functional difference from using<br>| <code>deep</code>, but if <code>deep</code> is passed it will attempt to deepcopy.<br>|<br>| diff = wrapper(<em>args, <strong>kwargs)<br>|<br>| difference(self, other)<br>| Return a new Index with elements from the index that are not in <code>other</code>.<br>|<br>| This is the sorted set difference of two Index objects.<br>|<br>| 【参数】<br>| ———-| other : Index or array-like<br>|<br>| 【返回值】<br>| ——-| difference : Index<br>|<br>| 【示例】<br>| ——–|<br>| &gt;&gt;&gt; idx1 = pd.Index([1, 2, 3, 4])<br>| &gt;&gt;&gt; idx2 = pd.Index([3, 4, 5, 6])<br>| &gt;&gt;&gt; idx1.difference(idx2)<br>| Int64Index([1, 2], dtype=’int64’)<br>|<br>| drop(self, labels, errors=’raise’)<br>| Make new Index with passed list of labels deleted<br>|<br>| 【参数】<br>| ———-| labels : array-like<br>| errors : {‘ignore’, ‘raise’}, default ‘raise’<br>| If ‘ignore’, suppress error and existing labels are dropped.<br>|<br>| 【返回值】<br>| ——-| dropped : Index<br>|<br>| drop_duplicates(self, keep=’first’)<br>| Return Index with duplicate values removed<br>|<br>| 【参数】<br>| ———-<br>36<br>|<br>| keep : {‘first’, ‘last’, False}, default ‘first’<br>| - <code>first</code> : Drop duplicates except for the first occurrence.<br>| - <code>last</code> : Drop duplicates except for the last occurrence.<br>| - False : Drop all duplicates.<br>| take_last : deprecated<br>|<br>|<br>| 【返回值】<br>| ——-| deduplicated : Index<br>|<br>| format(self, name=False, formatter=None, </strong>kwargs)<br>| Render a string representation of the Index<br>|<br>| get_duplicates(self)<br>|<br>| get_indexer_for(self, target, **kwargs)<br>| guaranteed return of an indexer even when non-unique<br>|<br>| get_level_values(self, level)<br>| Return vector of label values for requested level, equal to the length<br>| of the index<br>|<br>| 【参数】<br>| ———-| level : int<br>|<br>| 【返回值】<br>| ——-| values : ndarray<br>|<br>| get_slice_bound(self, label, side, kind)<br>| Calculate slice bound that corresponds to given label.<br>|<br>| Returns leftmost (one-past-the-rightmost if <code>side==&#39;right&#39;</code>) position<br>| of given label.<br>|<br>| 【参数】<br>| ———-| label : object<br>| side : {‘left’, ‘right’}<br>| kind : string / None, the type of indexer<br>|<br>| get_value(self, series, key)<br>| Fast lookup of value from 1-dimensional ndarray. Only use this if you<br>| know what you’re doing<br>|<br>| groupby(self, to_groupby)<br>| Group the index labels by a given array of values.<br>|<br>| 【参数】<br>| ———-| to_groupby : array<br>| Values used to determine the groups.<br>|<br>| 【返回值】<br>37<br>| ——-| groups : dict<br>| {group name -&gt; group labels}<br>|<br>| holds<em>integer(self)<br>|<br>| identical(self, other)<br>| Similar to equals, but check that other comparable attributes are<br>| also equal<br>|<br>| intersection(self, other)<br>| Form the intersection of two Index objects.<br>|<br>| This returns a new Index with elements common to the index and <code>other</code>.<br>| Sortedness of the result is not guaranteed.<br>|<br>| 【参数】<br>| ———-| other : Index or array-like<br>|<br>| 【返回值】<br>| ——-| intersection : Index<br>|<br>| 【示例】<br>| ——–|<br>| &gt;&gt;&gt; idx1 = pd.Index([1, 2, 3, 4])<br>| &gt;&gt;&gt; idx2 = pd.Index([3, 4, 5, 6])<br>| &gt;&gt;&gt; idx1.intersection(idx2)<br>| Int64Index([3, 4], dtype=’int64’)<br>|<br>| is</em>(self, other)<br>| More flexible, faster check like <code>is</code> but that works through views<br>|<br>| Note: this is </em>not<em> the same as <code>Index.identical()</code>, which checks<br>| that metadata is also the same.<br>|<br>| 【参数】<br>| ———-| other : object<br>| other object to compare against.<br>|<br>| 【返回值】<br>| ——-| True if both have same underlying data, False otherwise : bool<br>|<br>| is_boolean(self)<br>|<br>| is_categorical(self)<br>|<br>| is_floating(self)<br>|<br>| is_integer(self)<br>|<br>| is_lexsorted_for_tuple(self, tup)<br>|<br>38<br>| is_mixed(self)<br>|<br>| is_numeric(self)<br>|<br>| is_object(self)<br>|<br>| is_type_compatible(self, kind)<br>|<br>| isin(self, values, level=None)<br>| Compute boolean array of whether each index value is found in the<br>| passed set of values.<br>|<br>| 【参数】<br>| ———-| values : set or sequence of values<br>| Sought values.<br>| level : str or int, optional<br>| Name or position of the index level to use (if the index is a<br>| MultiIndex).<br>|<br>| 【注意】<br>| —–| If <code>level</code> is specified:<br>|<br>| - if it is the name of one </em>and only one<em> index level, use that level;<br>| - otherwise it should be a number indicating level position.<br>|<br>| 【返回值】<br>| ——-| is_contained : ndarray (boolean dtype)<br>|<br>| join(self, other, how=’left’, level=None, return_indexers=False)<br>| </em>this is an internal non-public method<em><br>|<br>| Compute join_index and indexers to conform data<br>| structures to the new index.<br>|<br>| 【参数】<br>| ———-| other : Index<br>| how : {‘left’, ‘right’, ‘inner’, ‘outer’}<br>| level : int or level name, default None<br>| return_indexers : boolean, default False<br>|<br>| 【返回值】<br>| ——-| join_index, (left_indexer, right_indexer)<br>|<br>| map(self, mapper)<br>|<br>| order(self, return_indexer=False, ascending=True)<br>| Return sorted copy of Index<br>|<br>| DEPRECATED: use :meth:<code>Index.sort_values</code><br>|<br>| putmask(self, mask, value)<br>| return a new Index of the values set with the mask<br>39<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.putmask<br>|<br>| ravel(self, order=’C’)<br>| return an ndarray of the flattened values of the underlying data<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.ravel<br>|<br>| rename(self, name, inplace=False)<br>| Set new names on index. Defaults to returning new index.<br>|<br>| 【参数】<br>| ———-| name : str or list<br>| name to set<br>| inplace : bool<br>| if True, mutates in place<br>|<br>| 【返回值】<br>| ——-| new index (of same type and class…etc) [if inplace, returns None]<br>|<br>| repeat(self, n)<br>| return a new Index of the values repeated n times<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.repeat<br>|<br>| set_names(self, names, level=None, inplace=False)<br>| Set new names on index. Defaults to returning new index.<br>|<br>| 【参数】<br>| ———-| names : str or sequence<br>| name(s) to set<br>| level : int or level name, or sequence of int / level names (default None)<br>| If the index is a MultiIndex (hierarchical), level(s) to set (None for all levels)<br>| Otherwise level must be None<br>| inplace : bool<br>| if True, mutates in place<br>|<br>| 【返回值】<br>| ——-| new index (of same type and class…etc) [if inplace, returns None]<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; Index([1, 2, 3, 4]).set_names(‘foo’)<br>| Int64Index([1, 2, 3, 4], dtype=’int64’)<br>| &gt;&gt;&gt; Index([1, 2, 3, 4]).set_names([‘foo’])<br>| Int64Index([1, 2, 3, 4], dtype=’int64’)<br>40<br>| &gt;&gt;&gt; idx = MultiIndex.from_tuples([(1, u’one’), (1, u’two’),<br>| (2, u’one’), (2, u’two’)],<br>| names=[‘foo’, ‘bar’])<br>| &gt;&gt;&gt; idx.set_names([‘baz’, ‘quz’])<br>| MultiIndex(levels=[[1, 2], [u’one’, u’two’]],<br>| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],<br>| names=[u’baz’, u’quz’])<br>| &gt;&gt;&gt; idx.set_names(‘baz’, level=0)<br>| MultiIndex(levels=[[1, 2], [u’one’, u’two’]],<br>| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],<br>| names=[u’baz’, u’bar’])<br>|<br>| set_value(self, arr, key, value)<br>| Fast lookup of value from 1-dimensional ndarray. Only use this if you<br>| know what you’re doing<br>|<br>| shift(self, periods=1, freq=None)<br>| Shift Index containing datetime objects by input number of periods and<br>| DateOffset<br>|<br>| 【返回值】<br>| ——-| shifted : Index<br>|<br>| slice_indexer(self, start=None, end=None, step=None, kind=None)<br>| For an ordered Index, compute the slice indexer for input labels and<br>| step<br>|<br>| 【参数】<br>| ———-| start : label, default None<br>| If None, defaults to the beginning<br>| end : label, default None<br>| If None, defaults to the end<br>| step : int, default None<br>| kind : string, default None<br>|<br>| 【返回值】<br>| ——-| indexer : ndarray or slice<br>|<br>| 【注意】<br>| —–| This function assumes that the data is sorted, so use at your own peril<br>|<br>| slice_locs(self, start=None, end=None, step=None, kind=None)<br>| Compute slice locations for input labels.<br>|<br>| 【参数】<br>| ———-| start : label, default None<br>| If None, defaults to the beginning<br>| end : label, default None<br>| If None, defaults to the end<br>| step : int, defaults None<br>| If None, defaults to 1<br>| kind : string, defaults None<br>41<br>|<br>| 【返回值】<br>| ——-| start, end : int<br>|<br>| sort(self, </em>args, <strong>kwargs)<br>|<br>| sort_values(self, return_indexer=False, ascending=True)<br>| Return sorted copy of Index<br>|<br>| sortlevel(self, level=None, ascending=True, sort_remaining=None)<br>| For internal compatibility with with the Index API<br>|<br>| Sort the Index. This is for compat with MultiIndex<br>|<br>| 【参数】<br>| ———-| ascending : boolean, default True<br>| False to sort in descending order<br>|<br>| level, sort_remaining are compat paramaters<br>|<br>| 【返回值】<br>| ——-| sorted_index : Index<br>|<br>| summary(self, name=None)<br>|<br>| sym_diff(self, other, result_name=None)<br>| Compute the sorted symmetric difference of two Index objects.<br>|<br>| 【参数】<br>| ———-| other : Index or array-like<br>| result_name : str<br>|<br>| 【返回值】<br>| ——-| sym_diff : Index<br>|<br>| 【注意】<br>| —–| <code>sym_diff</code> contains elements that appear in either <code>idx1</code> or<br>| <code>idx2</code> but not both. Equivalent to the Index created by<br>| <code>(idx1 - idx2) + (idx2 - idx1)</code> with duplicates dropped.<br>|<br>| The sorting of a result containing <code>NaN</code> values is not guaranteed<br>| across Python versions. See GitHub issue #6444.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; idx1 = Index([1, 2, 3, 4])<br>| &gt;&gt;&gt; idx2 = Index([2, 3, 4, 5])<br>| &gt;&gt;&gt; idx1.sym_diff(idx2)<br>| Int64Index([1, 5], dtype=’int64’)<br>|<br>| You can also use the <code>^</code> operator:<br>42<br>|<br>| &gt;&gt;&gt; idx1 ^ idx2<br>| Int64Index([1, 5], dtype=’int64’)<br>|<br>| to_datetime(self, dayfirst=False)<br>| For an Index containing strings or datetime.datetime objects, attempt<br>| conversion to DatetimeIndex<br>|<br>| to_native_types(self, slicer=None, </strong>kwargs)<br>| slice and dice then format<br>|<br>| to_series(self, <strong>kwargs)<br>| Create a Series with both index and values equal to the index keys<br>| useful with map for returning an indexer based on an index<br>|<br>| 【返回值】<br>| ——-| Series : dtype will be based on the type of the Index values.<br>|<br>| tolist(self)<br>| return a list of the Index values<br>|<br>| union(self, other)<br>| Form the union of two Index objects and sorts if possible.<br>|<br>| 【参数】<br>| ———-| other : Index or array-like<br>|<br>| 【返回值】<br>| ——-| union : Index<br>|<br>| 【示例】<br>| ——–|<br>| &gt;&gt;&gt; idx1 = pd.Index([1, 2, 3, 4])<br>| &gt;&gt;&gt; idx2 = pd.Index([3, 4, 5, 6])<br>| &gt;&gt;&gt; idx1.union(idx2)<br>| Int64Index([1, 2, 3, 4, 5, 6], dtype=’int64’)<br>|<br>| view(self, cls=None)<br>|<br>| ———————————————————————-| Data descriptors inherited from Index:<br>|<br>| dtype<br>|<br>| dtype_str<br>|<br>| has_duplicates<br>|<br>| hasnans<br>|<br>| is_all_dates<br>|<br>| is_monotonic<br>43<br>| alias for is_monotonic_increasing (deprecated)<br>|<br>| is_monotonic_decreasing<br>| return if the index is monotonic decreasing (only equal or<br>| decreasing) values.<br>|<br>| is_monotonic_increasing<br>| return if the index is monotonic increasing (only equal or<br>| increasing) values.<br>|<br>| names<br>|<br>| nlevels<br>|<br>| ———————————————————————-| Data and other attributes inherited from Index:<br>|<br>| asi8 = None<br>|<br>| name = None<br>|<br>| ———————————————————————-| Methods inherited from pandas.core.base.IndexOpsMixin:<br>|<br>| argmax(self, axis=None)<br>| return a ndarray of the maximum argument indexer<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.argmax<br>|<br>| argmin(self, axis=None)<br>| return a ndarray of the minimum argument indexer<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.argmin<br>|<br>| factorize(self, sort=False, na_sentinel=-1)<br>| Encode the object as an enumerated type or categorical variable<br>|<br>| 【参数】<br>| ———-| sort : boolean, default False<br>| Sort by values<br>| na_sentinel: int, default -1<br>| Value to mark “not found”<br>|<br>| 【返回值】<br>| ——-| labels : the indexer to the original array<br>| uniques : the unique Index<br>|<br>| item(self)<br>| return the first element of the underlying data as a python scalar<br>|<br>| memory_usage(self, deep=False)<br>44<br>| Memory usage of my values<br>|<br>| 【参数】<br>| ———-| deep : bool<br>| Introspect the data deeply, interrogate<br>| <code>object</code> dtypes for system-level memory consumption<br>|<br>| 【返回值】<br>| ——-| bytes used<br>|<br>| 【注意】<br>| —–| Memory usage does not include memory consumed by elements that<br>| are not components of the array if deep=False<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.nbytes<br>|<br>| nunique(self, dropna=True)<br>| Return number of unique elements in the object.<br>|<br>| Excludes NA values by default.<br>|<br>| 【参数】<br>| ———-| dropna : boolean, default True<br>| Don’t include NaN in the count.<br>|<br>| 【返回值】<br>| ——-| nunique : int<br>|<br>| searchsorted(self, key, side=’left’)<br>| np.ndarray searchsorted compat<br>|<br>| transpose(self)<br>| return the transpose, which is by definition self<br>|<br>| unique(self)<br>| Return array of unique values in the object. Significantly faster than<br>| numpy.unique. Includes NA values.<br>|<br>| 【返回值】<br>| ——-| uniques : ndarray<br>|<br>| value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)<br>| Returns object containing counts of unique values.<br>|<br>| The resulting object will be in descending order so that the<br>| first element is the most frequently-occurring element.<br>| Excludes NA values by default.<br>|<br>45<br>| 【参数】<br>| ———-| normalize : boolean, default False<br>| If True then the object returned will contain the relative<br>| frequencies of the unique values.<br>| sort : boolean, default True<br>| Sort by values<br>| ascending : boolean, default False<br>| Sort in ascending order<br>| bins : integer, optional<br>| Rather than count values, group them into half-open bins,<br>| a convenience for pd.cut, only works with numeric data<br>| dropna : boolean, default True<br>| Don’t include counts of NaN.<br>|<br>| 【返回值】<br>| ——-| counts : Series<br>|<br>| ———————————————————————-| Data descriptors inherited from pandas.core.base.IndexOpsMixin:<br>|<br>| T<br>| return the transpose, which is by definition self<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| base<br>| return the base object if the memory of the underlying data is shared<br>|<br>| data<br>| return the data pointer of the underlying data<br>|<br>| flags<br>| return the ndarray.flags for the underlying data<br>|<br>| itemsize<br>| return the size of the dtype of the item of the underlying data<br>|<br>| nbytes<br>| return the number of bytes in the underlying data<br>|<br>| ndim<br>| return the number of dimensions of the underlying data, by definition 1<br>|<br>| shape<br>| return a tuple of the shape of the underlying data<br>|<br>| size<br>| return the number of elements in the underlying data<br>|<br>| strides<br>| return the strides of the underlying data<br>46<br>|<br>| ———————————————————————-| Data and other attributes inherited from pandas.core.base.IndexOpsMixin:<br>|<br>| <strong>array_priority</strong> = 1000<br>|<br>| ———————————————————————-| Data and other attributes inherited from pandas.core.strings.StringAccessorMixin:<br>|<br>| str = <class 'pandas.core.strings.stringmethods'=""><br>| Vectorized string functions for Series and Index. NAs stay NA unless<br>| handled otherwise by a particular method. Patterned after Python’s string<br>| methods, with some inspiration from R’s stringr package.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; s.str.split(‘<em>‘)<br>| &gt;&gt;&gt; s.str.replace(‘</em>‘, ‘’)<br>|<br>| ———————————————————————-| Methods inherited from pandas.core.base.PandasObject:<br>|<br>| <strong>dir</strong>(self)<br>| Provide method name lookup and completion<br>| Only provide ‘public’ methods<br>|<br>| ———————————————————————-| Methods inherited from pandas.core.base.StringMixin:<br>|<br>| <strong>bytes</strong>(self)<br>| Return a string representation for a particular object.<br>|<br>| Invoked by bytes(obj) in py3 only.<br>| Yields a bytestring in both py2/py3.<br>|<br>| <strong>repr</strong>(self)<br>| Return a string representation for a particular object.<br>|<br>| Yields Bytestring in Py2, Unicode String in py3.<br>|<br>| <strong>str</strong>(self)<br>| Return a string representation for a particular Object<br>|<br>| Invoked by str(df) in both py2/py3.<br>| Yields Bytestring in Py2, Unicode String in py3.<br>DataFrame<br>DataFrame 模块所属：pandas.core.frame:<br>47<br>类定义：DataFrame(pandas.core.generic.NDFrame)<br>| Two-dimensional size-mutable, potentially heterogeneous tabular data<br>| structure with labeled axes (rows and columns). Arithmetic operations<br>| align on both row and column labels. Can be thought of as a dict-like<br>| container for Series objects. The primary pandas data structure<br>|<br>| 【参数】<br>| ———-| data : numpy ndarray (structured or homogeneous), dict, or DataFrame<br>| Dict can contain Series, arrays, constants, or list-like objects<br>| index : Index or array-like<br>| Index to use for resulting frame. Will default to np.arange(n) if<br>| no indexing information part of input data and no index provided<br>| columns : Index or array-like<br>| Column labels to use for resulting frame. Will default to<br>| np.arange(n) if no column labels are provided<br>| dtype : dtype, default None<br>| Data type to force, otherwise infer<br>| copy : boolean, default False<br>| Copy data from inputs. Only affects DataFrame / 2d ndarray input<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; d = {‘col1’: ts1, ‘col2’: ts2}<br>| &gt;&gt;&gt; df = DataFrame(data=d, index=index)<br>| &gt;&gt;&gt; df2 = DataFrame(np.random.randn(10, 5))<br>| &gt;&gt;&gt; df3 = DataFrame(np.random.randn(10, 5),<br>| … columns=[‘a’, ‘b’, ‘c’, ‘d’, ‘e’])<br>|<br>|【参见】<br>| ——–| DataFrame.from_records : constructor from tuples, also record arrays<br>| DataFrame.from_dict : from dicts of Series, arrays, or dicts<br>| DataFrame.from_items : from sequence of (key, value) pairs<br>| pandas.read_csv, pandas.read_table, pandas.read_clipboard<br>|<br>| 【方法排序】<br>| DataFrame<br>| pandas.core.generic.NDFrame<br>| pandas.core.base.PandasObject<br>| pandas.core.base.StringMixin<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>add</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>add</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>48<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>and</strong>(self, other, axis=’columns’, level=None, fill_value=None)<br>| Binary operator <strong>and</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>div</strong> = <strong>truediv</strong>(self, other, axis=None, level=None, fill_value=None)<br>|<br>| <strong>eq</strong>(self, other)<br>| Wrapper for comparison method <strong>eq</strong><br>|<br>| <strong>floordiv</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>floordiv</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>49<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>ge</strong>(self, other)<br>| Wrapper for comparison method <strong>ge</strong><br>|<br>| <strong>getitem</strong>(self, key)<br>|<br>| <strong>gt</strong>(self, other)<br>| Wrapper for comparison method <strong>gt</strong><br>|<br>| <strong>iadd</strong> = f(self, other)<br>|<br>| <strong>imul</strong> = f(self, other)<br>|<br>| <strong>init</strong>(self, data=None, index=None, columns=None, dtype=None, copy=False)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>ipow</strong> = f(self, other)<br>|<br>| <strong>isub</strong> = f(self, other)<br>|<br>| <strong>itruediv</strong> = f(self, other)<br>|<br>| <strong>le</strong>(self, other)<br>| Wrapper for comparison method <strong>le</strong><br>|<br>| <strong>len</strong>(self)<br>| Returns length of info axis, but here we use the index<br>|<br>| <strong>lt</strong>(self, other)<br>| Wrapper for comparison method <strong>lt</strong><br>|<br>| <strong>mod</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>mod</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–<br>50<br>| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>mul</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>mul</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>ne</strong>(self, other)<br>| Wrapper for comparison method <strong>ne</strong><br>|<br>| <strong>or</strong>(self, other, axis=’columns’, level=None, fill_value=None)<br>| Binary operator <strong>or</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>51<br>| <strong>pow</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>pow</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>radd</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>radd</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>rand</strong>(self, other, axis=’columns’, level=None, fill_value=None)<br>| Binary operator <strong>rand</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>52<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>rdiv</strong> = <strong>rtruediv</strong>(self, other, axis=None, level=None, fill_value=None)<br>|<br>| <strong>rfloordiv</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>rfloordiv</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>rmod</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>rmod</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>53<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>rmul</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>rmul</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>ror</strong>(self, other, axis=’columns’, level=None, fill_value=None)<br>| Binary operator <strong>ror</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>54<br>| <strong>rpow</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>rpow</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>rsub</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>rsub</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>rtruediv</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>rtruediv</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>55<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>rxor</strong>(self, other, axis=’columns’, level=None, fill_value=None)<br>| Binary operator <strong>rxor</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>setitem</strong>(self, key, value)<br>|<br>| <strong>sub</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>sub</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>56<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>truediv</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>truediv</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>unicode</strong>(self)<br>| Return a string representation for a particular DataFrame<br>|<br>| Invoked by unicode(df) in py2 only. Yields a Unicode String in both<br>| py2/py3.<br>|<br>| <strong>xor</strong>(self, other, axis=’columns’, level=None, fill_value=None)<br>| Binary operator <strong>xor</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>57<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| add(self, other, axis=’columns’, level=None, fill_value=None)<br>| Addition of dataframe and other, element-wise (binary operator <code>add</code>).<br>|<br>| Equivalent to <code>dataframe + other</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.radd<br>|<br>| align(self, other, join=’outer’, axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0,<br>broadcast_axis=None)<br>| Align two object on their axes with the<br>| specified join method for each axis Index<br>|<br>| 【参数】<br>| ———-| other : DataFrame or Series<br>| join : {‘outer’, ‘inner’, ‘left’, ‘right’}, default ‘outer’<br>| axis : allowed axis of the other object, default None<br>| Align on index (0), columns (1), or both (None)<br>| level : int or level name, default None<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>| copy : boolean, default True<br>| Always returns new objects. If copy=False and no reindexing is<br>| required then original objects are returned.<br>| fill_value : scalar, default np.NaN<br>| Value to use for missing values. Defaults to NaN, but can be any<br>| “compatible” value<br>| method : str, default None<br>| limit : int, default None<br>58<br>| fill_axis : {0, 1, ‘index’, ‘columns’}, default 0<br>| Filling axis, method and limit<br>| broadcast_axis : {0, 1, ‘index’, ‘columns’}, default None<br>| Broadcast values along this axis, if aligning two objects of<br>| different dimensions<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【返回值】<br>| ——-| (left, right) : (DataFrame, type of other)<br>| Aligned objects<br>|<br>| all(self, axis=None, bool_only=None, skipna=None, level=None, </class></strong>kwargs)<br>| Return whether all elements are True over requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| bool_only : boolean, default None<br>| Include only boolean data. If None, will attempt to use everything,<br>| then use only boolean data<br>|<br>| 【返回值】<br>| ——-| all : Series or DataFrame (if level specified)<br>|<br>| any(self, axis=None, bool_only=None, skipna=None, level=None, <strong>kwargs)<br>| Return whether any element is True over requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| bool_only : boolean, default None<br>| Include only boolean data. If None, will attempt to use everything,<br>| then use only boolean data<br>|<br>| 【返回值】<br>| ——-| any : Series or DataFrame (if level specified)<br>|<br>| append(self, other, ignore_index=False, verify_integrity=False)<br>| Append rows of <code>other</code> to the end of this frame, returning a new<br>| object. Columns not in this frame are added as new columns.<br>|<br>59<br>| 【参数】<br>| ———-| other : DataFrame or Series/dict-like object, or list of these<br>| The data to append.<br>| ignore_index : boolean, default False<br>| If True, do not use the index labels.<br>| verify_integrity : boolean, default False<br>| If True, raise ValueError on creating index with duplicates.<br>|<br>| 【返回值】<br>| ——-| appended : DataFrame<br>|<br>| 【注意】<br>| —–| If a list of dict/series is passed and the keys are all contained in the<br>| DataFrame’s index, the order of the columns in the resulting DataFrame<br>| will be unchanged.<br>|<br>| 【参见】<br>| ——–| pandas.concat : General function to concatenate DataFrame, Series<br>| or Panel objects<br>|<br>| 【示例】<br>| ——–|<br>| &gt;&gt;&gt; df = pd.DataFrame([[1, 2], [3, 4]], columns=list(‘AB’))<br>| &gt;&gt;&gt; df<br>| A B<br>| 0 1 2<br>| 1 3 4<br>| &gt;&gt;&gt; df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list(‘AB’))<br>| &gt;&gt;&gt; df.append(df2)<br>| A B<br>| 0 1 2<br>| 1 3 4<br>| 0 5 6<br>| 1 7 8<br>|<br>| With <code>ignore_index</code> set to True:<br>|<br>| &gt;&gt;&gt; df.append(df2, ignore_index=True)<br>| A B<br>| 0 1 2<br>| 1 3 4<br>| 2 5 6<br>| 3 7 8<br>|<br>| apply(self, func, axis=0, broadcast=False, raw=False, reduce=None, args=(), </strong>kwds)<br>| Applies function along input axis of DataFrame.<br>|<br>| Objects passed to functions are Series objects having index<br>| either the DataFrame’s index (axis=0) or the columns (axis=1).<br>| Return type depends on whether passed function aggregates, or the<br>| reduce argument if the DataFrame is empty.<br>|<br>60<br>| 【参数】<br>| ———-| func : function<br>| Function to apply to each column/row<br>| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| <em> 0 or ‘index’: apply function to each column<br>| </em> 1 or ‘columns’: apply function to each row<br>| broadcast : boolean, default False<br>| For aggregation functions, return object of same size with values<br>| propagated<br>| raw : boolean, default False<br>| If False, convert each row or column into a Series. If raw=True the<br>| passed function will receive ndarray objects instead. If you are<br>| just applying a NumPy reduction function this will achieve much<br>| better performance<br>| reduce : boolean or None, default None<br>| Try to apply reduction procedures. If the DataFrame is empty,<br>| apply will use reduce to determine whether the result should be a<br>| Series or a DataFrame. If reduce is None (the default), apply’s<br>| return value will be guessed by calling func an empty Series (note:<br>| while guessing, exceptions raised by func will be ignored). If<br>| reduce is True a Series will always be returned, and if False a<br>| DataFrame will always be returned.<br>| args : tuple<br>| Positional arguments to pass to function in addition to the<br>| array/series<br>| Additional keyword arguments will be passed as keywords to the function<br>|<br>| 【注意】<br>| —–| In the current implementation apply calls func twice on the<br>| first column/row to decide whether it can take a fast or slow<br>| code path. This can lead to unexpected behavior if func has<br>| side-effects, as they will take effect twice for the first<br>| column/row.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df.apply(numpy.sqrt) # returns DataFrame<br>| &gt;&gt;&gt; df.apply(numpy.sum, axis=0) # equiv to df.sum(0)<br>| &gt;&gt;&gt; df.apply(numpy.sum, axis=1) # equiv to df.sum(1)<br>|<br>| 【参见】<br>| ——–| DataFrame.applymap: For elementwise operations<br>|<br>| 【返回值】<br>| ——-| applied : Series or DataFrame<br>|<br>| applymap(self, func)<br>| Apply a function to a DataFrame that is intended to operate<br>| elementwise, i.e. like doing map(func, series) for each series in the<br>| DataFrame<br>|<br>| 【参数】<br>| ———-<br>61<br>| func : function<br>| Python function, returns a single value from a single value<br>|<br>| 【返回值】<br>| ——-| applied : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.apply : For operations on rows/columns<br>|<br>| assign(self, <strong>kwargs)<br>| Assign new columns to a DataFrame, returning a new object<br>| (a copy) with all the original columns in addition to the new ones.<br>|<br>| .. versionadded:: 0.16.0<br>|<br>| 【参数】<br>| ———-| kwargs : keyword, value pairs<br>| keywords are the column names. If the values are<br>| callable, they are computed on the DataFrame and<br>| assigned to the new columns. If the values are<br>| not callable, (e.g. a Series, scalar, or array),<br>| they are simply assigned.<br>|<br>| 【返回值】<br>| ——-| df : DataFrame<br>| A new DataFrame with the new columns in addition to<br>| all the existing columns.<br>|<br>| 【注意】<br>| —–| Since <code>kwargs</code> is a dictionary, the order of your<br>| arguments may not be preserved. The make things predicatable,<br>| the columns are inserted in alphabetical order, at the end of<br>| your DataFrame. Assigning multiple columns within the same<br>| <code>assign</code> is possible, but you cannot reference other columns<br>| created within the same <code>assign</code> call.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df = DataFrame({‘A’: range(1, 11), ‘B’: np.random.randn(10)})<br>|<br>| Where the value is a callable, evaluated on <code>df</code>:<br>|<br>| &gt;&gt;&gt; df.assign(ln_A = lambda x: np.log(x.A))<br>| A B ln_A<br>| 0 1 0.426905 0.000000<br>| 1 2 -0.780949 0.693147<br>| 2 3 -0.418711 1.098612<br>| 3 4 -0.269708 1.386294<br>| 4 5 -0.274002 1.609438<br>| 5 6 -0.500792 1.791759<br>| 6 7 1.649697 1.945910<br>| 7 8 -1.495604 2.079442<br>62<br>| 8 9 0.549296 2.197225<br>| 9 10 -0.758542 2.302585<br>|<br>| Where the value already exists and is inserted:<br>|<br>| &gt;&gt;&gt; newcol = np.log(df[‘A’])<br>| &gt;&gt;&gt; df.assign(ln_A=newcol)<br>| A B ln_A<br>| 0 1 0.426905 0.000000<br>| 1 2 -0.780949 0.693147<br>| 2 3 -0.418711 1.098612<br>| 3 4 -0.269708 1.386294<br>| 4 5 -0.274002 1.609438<br>| 5 6 -0.500792 1.791759<br>| 6 7 1.649697 1.945910<br>| 7 8 -1.495604 2.079442<br>| 8 9 0.549296 2.197225<br>| 9 10 -0.758542 2.302585<br>|<br>| boxplot(self, column=None, by=None, ax=None, fontsize=None, rot=0, grid=True, figsize=None, layout=None,<br>return_type=None, </strong>kwds)<br>| Make a box plot from DataFrame column optionally grouped by some columns or<br>| other inputs<br>|<br>| 【参数】<br>| ———-| data : the pandas object holding the data<br>| column : column name or list of names, or vector<br>| Can be any valid input to groupby<br>| by : string or sequence<br>| Column in the DataFrame to group by<br>| ax : Matplotlib axes object, optional<br>| fontsize : int or string<br>| rot : label rotation angle<br>| figsize : A tuple (width, height) in inches<br>| grid : Setting this to True will show the grid<br>| layout : tuple (optional)<br>| (rows, columns) for the layout of the plot<br>| return_type : {‘axes’, ‘dict’, ‘both’}, default ‘dict’<br>| The kind of object to return. ‘dict’ returns a dictionary<br>| whose values are the matplotlib Lines of the boxplot;<br>| ‘axes’ returns the matplotlib axes the boxplot is drawn on;<br>| ‘both’ returns a namedtuple with the axes and dict.<br>|<br>| When grouping with <code>by</code>, a dict mapping columns to <code>return_type</code><br>| is returned.<br>|<br>| kwds : other plotting keyword arguments to be passed to matplotlib boxplot<br>| function<br>|<br>| 【返回值】<br>| ——-| lines : dict<br>| ax : matplotlib Axes<br>| (ax, lines): namedtuple<br>|<br>| 【注意】<br>63<br>| —–| Use <code>return_type=&#39;dict&#39;</code> when you want to tweak the appearance<br>| of the lines after plotting. In this case a dict containing the Lines<br>| making up the boxes, caps, fliers, medians, and whiskers is returned.<br>|<br>| combine(self, other, func, fill_value=None, overwrite=True)<br>| Add two DataFrame objects and do not propagate NaN values, so if for a<br>| (column, time) one frame is missing a value, it will default to the<br>| other frame’s value (which might be NaN as well)<br>|<br>| 【参数】<br>| ———-| other : DataFrame<br>| func : function<br>| fill_value : scalar value<br>| overwrite : boolean, default True<br>| If True then overwrite values for common keys in the calling frame<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| combineAdd(self, other)<br>| DEPRECATED. Use <code>DataFrame.add(other, fill_value=0.)</code> instead.<br>|<br>| Add two DataFrame objects and do not propagate<br>| NaN values, so if for a (column, time) one frame is missing a<br>| value, it will default to the other frame’s value (which might<br>| be NaN as well)<br>|<br>| 【参数】<br>| ———-| other : DataFrame<br>|<br>| 【返回值】<br>| ——-| DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.add<br>|<br>| combineMult(self, other)<br>| DEPRECATED. Use <code>DataFrame.mul(other, fill_value=1.)</code> instead.<br>|<br>| Multiply two DataFrame objects and do not propagate NaN values, so if<br>| for a (column, time) one frame is missing a value, it will default to<br>| the other frame’s value (which might be NaN as well)<br>|<br>| 【参数】<br>| ———-| other : DataFrame<br>|<br>| 【返回值】<br>| ——-| DataFrame<br>|<br>64<br>| 【参见】<br>| ——–| DataFrame.mul<br>|<br>| combine_first(self, other)<br>| Combine two DataFrame objects and default to non-null values in frame<br>| calling the method. Result index columns will be the union of the<br>| respective indexes and columns<br>|<br>| 【参数】<br>| ———-| other : DataFrame<br>|<br>| 【示例】<br>| ——–| a’s values prioritized, use values from b to fill holes:<br>|<br>| &gt;&gt;&gt; a.combine_first(b)<br>|<br>|<br>| 【返回值】<br>| ——-| combined : DataFrame<br>|<br>| compound(self, axis=None, skipna=None, level=None)<br>| Return the compound percentage of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| compounded : Series or DataFrame (if level specified)<br>|<br>| corr(self, method=’pearson’, min_periods=1)<br>| Compute pairwise correlation of columns, excluding NA/null values<br>|<br>| 【参数】<br>| ———-| method : {‘pearson’, ‘kendall’, ‘spearman’}<br>| <em> pearson : standard correlation coefficient<br>| </em> kendall : Kendall Tau correlation coefficient<br>| <em> spearman : Spearman rank correlation<br>| min_periods : int, optional<br>| Minimum number of observations required per pair of columns<br>| to have a valid result. Currently only available for pearson<br>| and spearman correlation<br>65<br>|<br>| 【返回值】<br>| ——-| y : DataFrame<br>|<br>| corrwith(self, other, axis=0, drop=False)<br>| Compute pairwise correlation between rows or columns of two DataFrame<br>| objects.<br>|<br>| 【参数】<br>| ———-| other : DataFrame<br>| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| 0 or ‘index’ to compute column-wise, 1 or ‘columns’ for row-wise<br>| drop : boolean, default False<br>| Drop missing indices from result, default returns union of all<br>|<br>| 【返回值】<br>| ——-| correls : Series<br>|<br>| count(self, axis=0, level=None, numeric_only=False)<br>| Return Series with number of non-NA/null observations over requested<br>| axis. Works with non-floating point data as well (detects NaN and None)<br>|<br>| 【参数】<br>| ———-| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| 0 or ‘index’ for row-wise, 1 or ‘columns’ for column-wise<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a DataFrame<br>| numeric_only : boolean, default False<br>| Include only float, int, boolean data<br>|<br>| 【返回值】<br>| ——-| count : Series (or DataFrame if level specified)<br>|<br>| cov(self, min_periods=None)<br>| Compute pairwise covariance of columns, excluding NA/null values<br>|<br>| 【参数】<br>| ———-| min_periods : int, optional<br>| Minimum number of observations required per pair of columns<br>| to have a valid result.<br>|<br>| 【返回值】<br>| ——-| y : DataFrame<br>|<br>| 【注意】<br>| —–| <code>y</code> contains the covariance matrix of the DataFrame’s time series.<br>| The covariance is normalized by N-1 (unbiased estimator).<br>66<br>|<br>| cummax = max(self, axis=None, dtype=None, out=None, skipna=True, <strong>kwargs)<br>| Return cumulative max over requested axis.<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>|<br>| 【返回值】<br>| ——-| max : Series<br>|<br>| cummin = min(self, axis=None, dtype=None, out=None, skipna=True, </strong>kwargs)<br>| Return cumulative min over requested axis.<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>|<br>| 【返回值】<br>| ——-| min : Series<br>|<br>| cumprod = prod(self, axis=None, dtype=None, out=None, skipna=True, <strong>kwargs)<br>| Return cumulative prod over requested axis.<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>|<br>| 【返回值】<br>| ——-| prod : Series<br>|<br>| cumsum = sum(self, axis=None, dtype=None, out=None, skipna=True, </strong>kwargs)<br>| Return cumulative sum over requested axis.<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>|<br>| 【返回值】<br>| ——-| sum : Series<br>67<br>|<br>| diff(self, periods=1, axis=0)<br>| 1st discrete difference of object<br>|<br>| 【参数】<br>| ———-| periods : int, default 1<br>| Periods to shift for forming difference<br>| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| Take difference over rows (0) or columns (1).<br>|<br>| .. versionadded: 0.16.1<br>|<br>| 【返回值】<br>| ——-| diffed : DataFrame<br>|<br>| div = truediv(self, other, axis=’columns’, level=None, fill_value=None)<br>|<br>| divide = truediv(self, other, axis=’columns’, level=None, fill_value=None)<br>|<br>| dot(self, other)<br>| Matrix multiplication with DataFrame or Series objects<br>|<br>| 【参数】<br>| ———-| other : DataFrame or Series<br>|<br>| 【返回值】<br>| ——-| dot_product : DataFrame or Series<br>|<br>| drop_duplicates(self, subset=None, keep=’first’, inplace=False)<br>| Return DataFrame with duplicate rows removed, optionally only<br>| considering certain columns<br>|<br>| 【参数】<br>| ———-| subset : column label or sequence of labels, optional<br>| Only consider certain columns for identifying duplicates, by<br>| default use all of the columns<br>| keep : {‘first’, ‘last’, False}, default ‘first’<br>| - <code>first</code> : Drop duplicates except for the first occurrence.<br>| - <code>last</code> : Drop duplicates except for the last occurrence.<br>| - False : Drop all duplicates.<br>| take_last : deprecated<br>| inplace : boolean, default False<br>| Whether to drop duplicates in place or to return a copy<br>| cols : kwargs only argument of subset [deprecated]<br>|<br>| 【返回值】<br>| ——-| deduplicated : DataFrame<br>|<br>| dropna(self, axis=0, how=’any’, thresh=None, subset=None, inplace=False)<br>| Return object with labels on given axis omitted where alternately any<br>| or all of the data are missing<br>68<br>|<br>| 【参数】<br>| ———-| axis : {0 or ‘index’, 1 or ‘columns’}, or tuple/list thereof<br>| Pass tuple or list to drop on multiple axes<br>| how : {‘any’, ‘all’}<br>| </em> any : if any NA values are present, drop that label<br>| <em> all : if all values are NA, drop that label<br>| thresh : int, default None<br>| int value : require that many non-NA values<br>| subset : array-like<br>| Labels along other axis to consider, e.g. if you are dropping rows<br>| these would be a list of columns to include<br>| inplace : boolean, default False<br>| If True, do operation inplace and return None.<br>|<br>| 【返回值】<br>| ——-| dropped : DataFrame<br>|<br>| duplicated(self, subset=None, keep=’first’)<br>| Return boolean Series denoting duplicate rows, optionally only<br>| considering certain columns<br>|<br>| 【参数】<br>| ———-| subset : column label or sequence of labels, optional<br>| Only consider certain columns for identifying duplicates, by<br>| default use all of the columns<br>| keep : {‘first’, ‘last’, False}, default ‘first’<br>| - <code>first</code> : Mark duplicates as <code>True</code> except for the<br>| first occurrence.<br>| - <code>last</code> : Mark duplicates as <code>True</code> except for the<br>| last occurrence.<br>| - False : Mark all duplicates as <code>True</code>.<br>| take_last : deprecated<br>| cols : kwargs only argument of subset [deprecated]<br>|<br>| 【返回值】<br>| ——-| duplicated : Series<br>|<br>| eq(self, other, axis=’columns’, level=None)<br>| Wrapper for flexible comparison methods eq<br>|<br>| eval(self, expr, <strong>kwargs)<br>| Evaluate an expression in the context of the calling DataFrame<br>| instance.<br>|<br>| 【参数】<br>| ———-| expr : string<br>| The expression string to evaluate.<br>| kwargs : dict<br>| See the documentation for :func:<code>~pandas.eval</code> for complete details<br>| on the keyword arguments accepted by<br>| :meth:<code>~pandas.DataFrame.query</code>.<br>69<br>|<br>| 【返回值】<br>| ——-| ret : ndarray, scalar, or pandas object<br>|<br>| 【参见】<br>| ——–| pandas.DataFrame.query<br>| pandas.eval<br>|<br>| 【注意】<br>| —–| For more details see the API documentation for :func:<code>~pandas.eval</code>.<br>| For detailed examples see :ref:<code>enhancing performance with eval
| &lt;enhancingperf.eval&gt;</code>.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; from numpy.random import randn<br>| &gt;&gt;&gt; from pandas import DataFrame<br>| &gt;&gt;&gt; df = DataFrame(randn(10, 2), columns=list(‘ab’))<br>| &gt;&gt;&gt; df.eval(‘a + b’)<br>| &gt;&gt;&gt; df.eval(‘c = a + b’)<br>|<br>| fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, </strong>kwargs)<br>| Fill NA/NaN values using the specified method<br>|<br>| 【参数】<br>| ———-| value : scalar, dict, Series, or DataFrame<br>| Value to use to fill holes (e.g. 0), alternately a dict/Series/DataFrame of<br>| values specifying which value to use for each index (for a Series) or<br>| column (for a DataFrame). (values not in the dict/Series/DataFrame will not be<br>| filled). This value cannot be a list.<br>| method : {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default None<br>| Method to use for filling holes in reindexed Series<br>| pad / ffill: propagate last valid observation forward to next valid<br>| backfill / bfill: use NEXT valid observation to fill gap<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| inplace : boolean, default False<br>| If True, fill in place. Note: this will modify any<br>| other views on this object, (e.g. a no-copy slice for a column in a<br>| DataFrame).<br>| limit : int, default None<br>| If method is specified, this is the maximum number of consecutive<br>| NaN values to forward/backward fill. In other words, if there is<br>| a gap with more than this number of consecutive NaNs, it will only<br>| be partially filled. If method is not specified, this is the<br>| maximum number of entries along the entire axis where NaNs will be<br>| filled.<br>| downcast : dict, default is None<br>| a dict of item-&gt;dtype of what to downcast if possible,<br>| or the string ‘infer’ which will try to downcast to an appropriate<br>| equal type (e.g. float64 to int64 if possible)<br>|<br>| 【参见】<br>| ——–<br>70<br>| reindex, asfreq<br>|<br>| 【返回值】<br>| ——-| filled : DataFrame<br>|<br>| first_valid_index(self)<br>| Return label for first non-NA/null value<br>|<br>| floordiv(self, other, axis=’columns’, level=None, fill_value=None)<br>| Integer division of dataframe and other, element-wise (binary operator <code>floordiv</code>).<br>|<br>| Equivalent to <code>dataframe // other</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.rfloordiv<br>|<br>| ge(self, other, axis=’columns’, level=None)<br>| Wrapper for flexible comparison methods ge<br>|<br>| get_value(self, index, col, takeable=False)<br>| Quickly retrieve single value at passed column and index<br>|<br>| 【参数】<br>| ———-| index : row label<br>| col : column label<br>| takeable : interpret the index/col as indexers, default False<br>|<br>| 【返回值】<br>| ——-| value : scalar value<br>|<br>| gt(self, other, axis=’columns’, level=None)<br>| Wrapper for flexible comparison methods gt<br>71<br>|<br>| hist = hist_frame(data, column=None, by=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None,<br>ax=None, sharex=False, sharey=False, figsize=None, layout=None, bins=10, <strong>kwds)<br>| Draw histogram of the DataFrame’s series using matplotlib / pylab.<br>|<br>| 【参数】<br>| ———-| data : DataFrame<br>| column : string or sequence<br>| If passed, will be used to limit data to a subset of columns<br>| by : object, optional<br>| If passed, then used to form histograms for separate groups<br>| grid : boolean, default True<br>| Whether to show axis grid lines<br>| xlabelsize : int, default None<br>| If specified changes the x-axis label size<br>| xrot : float, default None<br>| rotation of x axis labels<br>| ylabelsize : int, default None<br>| If specified changes the y-axis label size<br>| yrot : float, default None<br>| rotation of y axis labels<br>| ax : matplotlib axes object, default None<br>| sharex : boolean, default True if ax is None else False<br>| In case subplots=True, share x axis and set some x axis labels to<br>| invisible; defaults to True if ax is None otherwise False if an ax<br>| is passed in; Be aware, that passing in both an ax and sharex=True<br>| will alter all x axis labels for all subplots in a figure!<br>| sharey : boolean, default False<br>| In case subplots=True, share y axis and set some y axis labels to<br>| invisible<br>| figsize : tuple<br>| The size of the figure to create in inches by default<br>| layout: (optional) a tuple (rows, columns) for the layout of the histograms<br>| bins: integer, default 10<br>| Number of histogram bins to be used<br>| kwds : other plotting keyword arguments<br>| To be passed to hist function<br>|<br>| icol(self, i)<br>| DEPRECATED. Use <code>.iloc[:, i]</code> instead<br>|<br>| idxmax(self, axis=0, skipna=True)<br>| Return index of first occurrence of maximum over requested axis.<br>| NA/null values are excluded.<br>|<br>| 【参数】<br>| ———-| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| 0 or ‘index’ for row-wise, 1 or ‘columns’ for column-wise<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be first index.<br>|<br>| 【返回值】<br>| ——-| idxmax : Series<br>72<br>|<br>| 【注意】<br>| —–| This method is the DataFrame version of <code>ndarray.argmax</code>.<br>|<br>| 【参见】<br>| ——–| Series.idxmax<br>|<br>| idxmin(self, axis=0, skipna=True)<br>| Return index of first occurrence of minimum over requested axis.<br>| NA/null values are excluded.<br>|<br>| 【参数】<br>| ———-| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| 0 or ‘index’ for row-wise, 1 or ‘columns’ for column-wise<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>|<br>| 【返回值】<br>| ——-| idxmin : Series<br>|<br>| 【注意】<br>| —–| This method is the DataFrame version of <code>ndarray.argmin</code>.<br>|<br>| 【参见】<br>| ——–| Series.idxmin<br>|<br>| iget_value(self, i, j)<br>| DEPRECATED. Use <code>.iat[i, j]</code> instead<br>|<br>| info(self, verbose=None, buf=None, max_cols=None, memory_usage=None, null_counts=None)<br>| Concise summary of a DataFrame.<br>|<br>| 【参数】<br>| ———-| verbose : {None, True, False}, optional<br>| Whether to print the full summary.<br>| None follows the <code>display.max_info_columns</code> setting.<br>| True or False overrides the <code>display.max_info_columns</code> setting.<br>| buf : writable buffer, defaults to sys.stdout<br>| max_cols : int, default None<br>| Determines whether full summary or short summary is printed.<br>| None follows the <code>display.max_info_columns</code> setting.<br>| memory_usage : boolean/string, default None<br>| Specifies whether total memory usage of the DataFrame<br>| elements (including index) should be displayed. None follows<br>| the <code>display.memory_usage</code> setting. True or False overrides<br>| the <code>display.memory_usage</code> setting. A value of ‘deep’ is equivalent<br>| of True, with deep introspection. Memory usage is shown in<br>| human-readable units (base-2 representation).<br>| null_counts : boolean, default None<br>73<br>| Whether to show the non-null counts<br>| If None, then only show if the frame is smaller than max_info_rows and max_info_columns.<br>| If True, always show counts.<br>| If False, never show counts.<br>|<br>| insert(self, loc, column, value, allow_duplicates=False)<br>| Insert column into DataFrame at specified location.<br>|<br>| If <code>allow_duplicates</code> is False, raises Exception if column<br>| is already contained in the DataFrame.<br>|<br>| 【参数】<br>| ———-| loc : int<br>| Must have 0 &lt;= loc &lt;= len(columns)<br>| column : object<br>| value : int, Series, or array-like<br>|<br>| irow(self, i, copy=False)<br>| DEPRECATED. Use <code>.iloc[i]</code> instead<br>|<br>| isin(self, values)<br>| Return boolean DataFrame showing whether each element in the<br>| DataFrame is contained in values.<br>|<br>| 【参数】<br>| ———-| values : iterable, Series, DataFrame or dictionary<br>| The result will only be true at a location if all the<br>| labels match. If <code>values</code> is a Series, that’s the index. If<br>| <code>values</code> is a dictionary, the keys must be the column names,<br>| which must match. If <code>values</code> is a DataFrame,<br>| then both the index and column labels must match.<br>|<br>| 【返回值】<br>| ——-|<br>| DataFrame of booleans<br>|<br>| 【示例】<br>| ——–| When <code>values</code> is a list:<br>|<br>| &gt;&gt;&gt; df = DataFrame({‘A’: [1, 2, 3], ‘B’: [‘a’, ‘b’, ‘f’]})<br>| &gt;&gt;&gt; df.isin([1, 3, 12, ‘a’])<br>| A B<br>| 0 True True<br>| 1 False False<br>| 2 True False<br>|<br>| When <code>values</code> is a dict:<br>|<br>| &gt;&gt;&gt; df = DataFrame({‘A’: [1, 2, 3], ‘B’: [1, 4, 7]})<br>| &gt;&gt;&gt; df.isin({‘A’: [1, 3], ‘B’: [4, 7, 12]})<br>| A B<br>| 0 True False # Note that B didn’t match the 1 here.<br>| 1 False True<br>74<br>| 2 True True<br>|<br>| When <code>values</code> is a Series or DataFrame:<br>|<br>| &gt;&gt;&gt; df = DataFrame({‘A’: [1, 2, 3], ‘B’: [‘a’, ‘b’, ‘f’]})<br>| &gt;&gt;&gt; other = DataFrame({‘A’: [1, 3, 3, 2], ‘B’: [‘e’, ‘f’, ‘f’, ‘e’]})<br>| &gt;&gt;&gt; df.isin(other)<br>| A B<br>| 0 True False<br>| 1 False False # Column A in <code>other</code> has a 3, but not at index 1.<br>| 2 True True<br>|<br>| items = iteritems(self)<br>|<br>| iteritems(self)<br>| Iterator over (column name, Series) pairs.<br>|<br>| 【参见】<br>| ——–| iterrows : Iterate over the rows of a DataFrame as (index, Series) pairs.<br>| itertuples : Iterate over the rows of a DataFrame as namedtuples of the values.<br>|<br>| iterrows(self)<br>| Iterate over the rows of a DataFrame as (index, Series) pairs.<br>|<br>| 【注意】<br>| —–|<br>| 1. Because <code>iterrows</code> returns a Series for each row,<br>| it does </strong>not<strong> preserve dtypes across the rows (dtypes are<br>| preserved across columns for DataFrames). For example,<br>|<br>| &gt;&gt;&gt; df = pd.DataFrame([[1, 1.5]], columns=[‘int’, ‘float’])<br>| &gt;&gt;&gt; row = next(df.iterrows())[1]<br>| &gt;&gt;&gt; row<br>| int 1.0<br>| float 1.5<br>| Name: 0, dtype: float64<br>| &gt;&gt;&gt; print(row[‘int’].dtype)<br>| float64<br>| &gt;&gt;&gt; print(df[‘int’].dtype)<br>| int64<br>|<br>| To preserve dtypes while iterating over the rows, it is better<br>| to use :meth:<code>itertuples</code> which returns namedtuples of the values<br>| and which is generally faster as <code>iterrows</code>.<br>|<br>| 2. You should </strong>never modify** something you are iterating over.<br>| This is not guaranteed to work in all cases. Depending on the<br>| data types, the iterator returns a copy and not a view, and writing<br>| to it will have no effect.<br>|<br>| 【返回值】<br>| ——-| it : generator<br>| A generator that iterates over the rows of the frame.<br>|<br>75<br>| 【参见】<br>| ——–| itertuples : Iterate over the rows of a DataFrame as namedtuples of the values.<br>| iteritems : Iterate over (column name, Series) pairs.<br>|<br>| itertuples(self, index=True, name=’Pandas’)<br>| Iterate over the rows of DataFrame as namedtuples, with index value<br>| as first element of the tuple.<br>|<br>| 【参数】<br>| ———-| index : boolean, default True<br>| If True, return the index as the first element of the tuple.<br>| name : string, default “Pandas”<br>| The name of the returned namedtuples or None to return regular tuples.<br>|<br>| 【注意】<br>| —–| The columns names will be renamed to positional names if they are<br>| invalid Python identifiers, repeated, or start with an underscore.<br>| With a large number of columns (&gt;255), regular tuples are returned.<br>|<br>| 【参见】<br>| ——–| iterrows : Iterate over the rows of a DataFrame as (index, Series) pairs.<br>| iteritems : Iterate over (column name, Series) pairs.<br>|<br>| 【示例】<br>| ——–|<br>| &gt;&gt;&gt; df = pd.DataFrame({‘col1’: [1, 2], ‘col2’: [0.1, 0.2]}, index=[‘a’, ‘b’])<br>| &gt;&gt;&gt; df<br>| col1 col2<br>| a 1 0.1<br>| b 2 0.2<br>| &gt;&gt;&gt; for row in df.itertuples():<br>| … print(row)<br>| …<br>| Pandas(Index=’a’, col1=1, col2=0.10000000000000001)<br>| Pandas(Index=’b’, col1=2, col2=0.20000000000000001)<br>|<br>| join(self, other, on=None, how=’left’, lsuffix=’’, rsuffix=’’, sort=False)<br>| Join columns with other DataFrame either on index or on a key<br>| column. Efficiently Join multiple DataFrame objects by index at once by<br>| passing a list.<br>|<br>| 【参数】<br>| ———-| other : DataFrame, Series with name field set, or list of DataFrame<br>| Index should be similar to one of the columns in this one. If a<br>| Series is passed, its name attribute must be set, and that will be<br>| used as the column name in the resulting joined DataFrame<br>| on : column name, tuple/list of column names, or array-like<br>| Column(s) to use for joining, otherwise join on index. If multiples<br>| columns given, the passed DataFrame must have a MultiIndex. Can<br>| pass an array as the join key if not already contained in the<br>| calling DataFrame. Like an Excel VLOOKUP operation<br>76<br>| how : {‘left’, ‘right’, ‘outer’, ‘inner’}<br>| How to handle indexes of the two objects. Default: ‘left’<br>| for joining on index, None otherwise<br>|<br>| </em> left: use calling frame’s index<br>| <em> right: use input frame’s index<br>| </em> outer: form union of indexes<br>| <em> inner: use intersection of indexes<br>| lsuffix : string<br>| Suffix to use from left frame’s overlapping columns<br>| rsuffix : string<br>| Suffix to use from right frame’s overlapping columns<br>| sort : boolean, default False<br>| Order result DataFrame lexicographically by the join key. If False,<br>| preserves the index order of the calling (left) DataFrame<br>|<br>| 【注意】<br>| —–| on, lsuffix, and rsuffix options are not supported when passing a list<br>| of DataFrame objects<br>|<br>| 【返回值】<br>| ——-| joined : DataFrame<br>|<br>| kurt(self, axis=None, skipna=None, level=None, numeric_only=None, <strong>kwargs)<br>| Return unbiased kurtosis over requested axis using Fishers definition of<br>| kurtosis (kurtosis of normal == 0.0). Normalized by N-1<br>|<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| kurt : Series or DataFrame (if level specified)<br>|<br>| kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>|<br>| last_valid_index(self)<br>| Return label for last non-NA/null value<br>|<br>| le(self, other, axis=’columns’, level=None)<br>| Wrapper for flexible comparison methods le<br>|<br>| lookup(self, row_labels, col_labels)<br>| Label-based “fancy indexing” function for DataFrame.<br>77<br>| Given equal-length arrays of row and column labels, return an<br>| array of the values corresponding to each (row, col) pair.<br>|<br>| 【参数】<br>| ———-| row_labels : sequence<br>| The row labels to use for lookup<br>| col_labels : sequence<br>| The column labels to use for lookup<br>|<br>| 【注意】<br>| —–| Akin to::<br>|<br>| result = []<br>| for row, col in zip(row_labels, col_labels):<br>| result.append(df.get_value(row, col))<br>|<br>| 【示例】<br>| ——–| values : ndarray<br>| The found values<br>|<br>| lt(self, other, axis=’columns’, level=None)<br>| Wrapper for flexible comparison methods lt<br>|<br>| mad(self, axis=None, skipna=None, level=None)<br>| Return the mean absolute deviation of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| mad : Series or DataFrame (if level specified)<br>|<br>| max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)<br>| This method returns the maximum of the values in the object. If you<br>| want the </em>index<em> of the maximum, use <code>idxmax</code>. This is the<br>| equivalent of the <code>numpy.ndarray</code> method <code>argmax</code>.<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>78<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| max : Series or DataFrame (if level specified)<br>|<br>| mean(self, axis=None, skipna=None, level=None, numeric_only=None, <strong>kwargs)<br>| Return the mean of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| mean : Series or DataFrame (if level specified)<br>|<br>| median(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| Return the median of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| median : Series or DataFrame (if level specified)<br>|<br>| memory_usage(self, index=False, deep=False)<br>| Memory usage of DataFrame columns.<br>|<br>| 【参数】<br>| ———-| index : bool<br>79<br>| Specifies whether to include memory usage of DataFrame’s<br>| index in returned Series. If <code>index=True</code> (default is False)<br>| the first index of the Series is <code>Index</code>.<br>| deep : bool<br>| Introspect the data deeply, interrogate<br>| <code>object</code> dtypes for system-level memory consumption<br>|<br>| 【返回值】<br>| ——-| sizes : Series<br>| A series with column names as index and memory usage of<br>| columns with units of bytes.<br>|<br>| 【注意】<br>| —–| Memory usage does not include memory consumed by elements that<br>| are not components of the array if deep=False<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.nbytes<br>|<br>| merge(self, right, how=’inner’, on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False,<br>suffixes=(‘_x’, ‘_y’), copy=True, indicator=False)<br>| Merge DataFrame objects by performing a database-style join operation by<br>| columns or indexes.<br>|<br>| If joining columns on columns, the DataFrame indexes </em>will be<br>| ignored<em>. Otherwise if joining indexes on indexes or indexes on a column or<br>| columns, the index will be passed on.<br>|<br>| 【参数】<br>| ———-| right : DataFrame<br>| how : {‘left’, ‘right’, ‘outer’, ‘inner’}, default ‘inner’<br>| </em> left: use only keys from left frame (SQL: left outer join)<br>| <em> right: use only keys from right frame (SQL: right outer join)<br>| </em> outer: use union of keys from both frames (SQL: full outer join)<br>| <em> inner: use intersection of keys from both frames (SQL: inner join)<br>| on : label or list<br>| Field names to join on. Must be found in both DataFrames. If on is<br>| None and not merging on indexes, then it merges on the intersection of<br>| the columns by default.<br>| left_on : label or list, or array-like<br>| Field names to join on in left DataFrame. Can be a vector or list of<br>| vectors of the length of the DataFrame to use a particular vector as<br>| the join key instead of columns<br>| right_on : label or list, or array-like<br>| Field names to join on in right DataFrame or vector/list of vectors per<br>| left_on docs<br>| left_index : boolean, default False<br>| Use the index from the left DataFrame as the join key(s). If it is a<br>| MultiIndex, the number of keys in the other DataFrame (either the index<br>| or a number of columns) must match the number of levels<br>| right_index : boolean, default False<br>| Use the index from the right DataFrame as the join key. Same caveats as<br>| left_index<br>80<br>| sort : boolean, default False<br>| Sort the join keys lexicographically in the result DataFrame<br>| suffixes : 2-length sequence (tuple, list, …)<br>| Suffix to apply to overlapping column names in the left and right<br>| side, respectively<br>| copy : boolean, default True<br>| If False, do not copy data unnecessarily<br>| indicator : boolean or string, default False<br>| If True, adds a column to output DataFrame called “_merge” with<br>| information on the source of each row.<br>| If string, column with information on source of each row will be added to<br>| output DataFrame, and column will be named value of string.<br>| Information column is Categorical-type and takes on a value of “left_only”<br>| for observations whose merge key only appears in ‘left’ DataFrame,<br>| “right_only” for observations whose merge key only appears in ‘right’<br>| DataFrame, and “both” if the observation’s merge key is found in both.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【示例】<br>| ——–|<br>| &gt;&gt;&gt; A &gt;&gt;&gt; B<br>| lkey value rkey value<br>| 0 foo 1 0 foo 5<br>| 1 bar 2 1 bar 6<br>| 2 baz 3 2 qux 7<br>| 3 foo 4 3 bar 8<br>|<br>| &gt;&gt;&gt; merge(A, B, left_on=’lkey’, right_on=’rkey’, how=’outer’)<br>| lkey value_x rkey value_y<br>| 0 foo 1 foo 5<br>| 1 foo 4 foo 5<br>| 2 bar 2 bar 6<br>| 3 bar 2 bar 8<br>| 4 baz 3 NaN NaN<br>| 5 NaN NaN qux 7<br>|<br>| 【返回值】<br>| ——-| merged : DataFrame<br>| The output type will the be same as ‘left’, if it is a subclass<br>| of DataFrame.<br>|<br>| min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)<br>| This method returns the minimum of the values in the object. If you<br>| want the </em>index<em> of the minimum, use <code>idxmin</code>. This is the<br>| equivalent of the <code>numpy.ndarray</code> method <code>argmin</code>.<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>81<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| min : Series or DataFrame (if level specified)<br>|<br>| mod(self, other, axis=’columns’, level=None, fill_value=None)<br>| Modulo of dataframe and other, element-wise (binary operator <code>mod</code>).<br>|<br>| Equivalent to <code>dataframe % other</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.rmod<br>|<br>| mode(self, axis=0, numeric_only=False)<br>| Gets the mode(s) of each element along the axis selected. Empty if nothing<br>| has 2+ occurrences. Adds a row for each mode per label, fills in gaps<br>| with nan.<br>|<br>| Note that there could be multiple values returned for the selected<br>| axis (when more than one item share the maximum frequency), which is the<br>| reason why a dataframe is returned. If you want to impute missing values<br>| with the mode in a dataframe <code>df</code>, you can just do this:<br>| <code>df.fillna(df.mode().iloc[0])</code><br>|<br>| 【参数】<br>| ———-| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| </em> 0 or ‘index’ : get mode of each column<br>| <em> 1 or ‘columns’ : get mode of each row<br>| numeric_only : boolean, default False<br>| if True, only apply to numeric columns<br>82<br>|<br>| 【返回值】<br>| ——-| modes : DataFrame (sorted)<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df = pd.DataFrame({‘A’: [1, 2, 1, 2, 1, 2, 3]})<br>| &gt;&gt;&gt; df.mode()<br>| A<br>| 0 1<br>| 1 2<br>|<br>| mul(self, other, axis=’columns’, level=None, fill_value=None)<br>| Multiplication of dataframe and other, element-wise (binary operator <code>mul</code>).<br>|<br>| Equivalent to ``dataframe </em> other<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other : Series, DataFrame, or constant
| axis : {0, 1, &#39;index&#39;, &#39;columns&#39;}
| For Series input, axis to match Series index on
| fill_value : None or float value, default None
| Fill missing (NaN) values with this value. If both DataFrame locations are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【注意】
| -----| Mismatched indices will be unioned together
|
| 【返回值】
| -------| result : DataFrame
|
| 【参见】
| --------| DataFrame.rmul
|
| multiply = mul(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
|
| ne(self, other, axis=&#39;columns&#39;, level=None)
| Wrapper for flexible comparison methods ne
|
| nlargest(self, n, columns, keep=&#39;first&#39;)
| Get the rows of a DataFrame sorted by the `n` largest
| values of `columns`.
|
| .. versionadded:: 0.17.0
|
| 【参数】
| ----------| n : int
83
| Number of items to retrieve
| columns : list or str
| Column name or names to order by
| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| Where there are duplicate values:
| -</code>first<code>: take the first occurrence.
| -</code>last<code>: take the last occurrence.
|
| 【返回值】
| -------| DataFrame
|
| 【示例】
| --------| &gt;&gt;&gt; df = DataFrame({&#39;a&#39;: [1, 10, 8, 11, -1],
| ... &#39;b&#39;: list(&#39;abdce&#39;),
| ... &#39;c&#39;: [1.0, 2.0, np.nan, 3.0, 4.0]})
| &gt;&gt;&gt; df.nlargest(3, &#39;a&#39;)
| a b c
| 3 11 c 3
| 1 10 b 2
| 2 8 d NaN
|
| nsmallest(self, n, columns, keep=&#39;first&#39;)
| Get the rows of a DataFrame sorted by the `n` smallest
| values of `columns`.
|
| .. versionadded:: 0.17.0
|
| 【参数】
| ----------| n : int
| Number of items to retrieve
| columns : list or str
| Column name or names to order by
| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| Where there are duplicate values:
| -</code>first<code>: take the first occurrence.
| -</code>last<code>: take the last occurrence.
|
| 【返回值】
| -------| DataFrame
|
| 【示例】
| --------| &gt;&gt;&gt; df = DataFrame({&#39;a&#39;: [1, 10, 8, 11, -1],
| ... &#39;b&#39;: list(&#39;abdce&#39;),
| ... &#39;c&#39;: [1.0, 2.0, np.nan, 3.0, 4.0]})
| &gt;&gt;&gt; df.nsmallest(3, &#39;a&#39;)
| a b c
| 4 -1 e 4
| 0 1 a 1
| 2 8 d NaN
|
| pivot(self, index=None, columns=None, values=None)
| Reshape data (produce a &quot;pivot&quot; table) based on column values. Uses
84
| unique values from index / columns to form axes and return either
| DataFrame or Panel, depending on whether you request a single value
| column (DataFrame) or all columns (Panel)
|
| 【参数】
| ----------| index : string or object, optional
| Column name to use to make new frame&#39;s index. If None, uses
| existing index.
| columns : string or object
| Column name to use to make new frame&#39;s columns
| values : string or object, optional
| Column name to use for populating new frame&#39;s values
|
| 【注意】
| -----| For finer-tuned control, see hierarchical indexing documentation along
| with the related stack/unstack methods
|
| 【示例】
| --------| &gt;&gt;&gt; df
| foo bar baz
| 0 one A 1.
| 1 one B 2.
| 2 one C 3.
| 3 two A 4.
| 4 two B 5.
| 5 two C 6.
|
| &gt;&gt;&gt; df.pivot(&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;)
| A B C
| one 1 2 3
| two 4 5 6
|
| &gt;&gt;&gt; df.pivot(&#39;foo&#39;, &#39;bar&#39;)[&#39;baz&#39;]
| A B C
| one 1 2 3
| two 4 5 6
|
| 【返回值】
| -------| pivoted : DataFrame
| If no values column specified, will have hierarchically indexed
| columns
|
| pivot_table(data, values=None, index=None, columns=None, aggfunc=&#39;mean&#39;, fill_value=None, margins=False,
dropna=True, margins_name=&#39;All&#39;)
| Create a spreadsheet-style pivot table as a DataFrame. The levels in the
| pivot table will be stored in MultiIndex objects (hierarchical indexes) on
| the index and columns of the result DataFrame
|
| 【参数】
| ----------| data : DataFrame
| values : column to aggregate, optional
| index : a column, Grouper, array which has the same length as data, or list of them.
85
| Keys to group by on the pivot table index.
| If an array is passed, it is being used as the same manner as column values.
| columns : a column, Grouper, array which has the same length as data, or list of them.
| Keys to group by on the pivot table column.
| If an array is passed, it is being used as the same manner as column values.
| aggfunc : function, default numpy.mean, or list of functions
| If list of functions passed, the resulting pivot table will have
| hierarchical columns whose top level are the function names (inferred
| from the function objects themselves)
| fill_value : scalar, default None
| Value to replace missing values with
| margins : boolean, default False
| Add all row / columns (e.g. for subtotal / grand totals)
| dropna : boolean, default True
| Do not include columns whose entries are all NaN
| margins_name : string, default &#39;All&#39;
| Name of the row / column that will contain the totals
| when margins is True.
|
| 【示例】
| --------| &gt;&gt;&gt; df
| A B C D
| 0 foo one small 1
| 1 foo one large 2
| 2 foo one large 2
| 3 foo two small 3
| 4 foo two small 3
| 5 bar one large 4
| 6 bar one small 5
| 7 bar two small 6
| 8 bar two large 7
|
| &gt;&gt;&gt; table = pivot_table(df, values=&#39;D&#39;, index=[&#39;A&#39;, &#39;B&#39;],
| ... columns=[&#39;C&#39;], aggfunc=np.sum)
| &gt;&gt;&gt; table
| small large
| foo one 1 4
| two 6 NaN
| bar one 5 4
| two 6 7
|
| 【返回值】
| -------| table : DataFrame
|
| pow(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
| Exponential power of dataframe and other, element-wise (binary operator `pow`).
|
| Equivalent to</code>dataframe <strong> other``, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>86<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.rpow<br>|<br>| prod(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| Return the product of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| prod : Series or DataFrame (if level specified)<br>|<br>| product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, <strong>kwargs)<br>|<br>| quantile(self, q=0.5, axis=0, numeric_only=True)<br>| Return values at the given quantile over requested axis, a la<br>| numpy.percentile.<br>|<br>| 【参数】<br>| ———-| q : float or array-like, default 0.5 (50% quantile)<br>| 0 &lt;= q &lt;= 1, the quantile(s) to compute<br>| axis : {0, 1, ‘index’, ‘columns’} (default 0)<br>| 0 or ‘index’ for row-wise, 1 or ‘columns’ for column-wise<br>|<br>|<br>| 【返回值】<br>| ——-| quantiles : Series or DataFrame<br>| If <code>q</code> is an array, a DataFrame will be returned where the<br>87<br>| index is <code>q</code>, the columns are the columns of self, and the<br>| values are the quantiles.<br>| If <code>q</code> is a float, a Series will be returned where the<br>| index is the columns of self and the values are the quantiles.<br>|<br>| 【示例】<br>| ——–|<br>| &gt;&gt;&gt; df = DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),<br>| columns=[‘a’, ‘b’])<br>| &gt;&gt;&gt; df.quantile(.1)<br>| a 1.3<br>| b 3.7<br>| dtype: float64<br>| &gt;&gt;&gt; df.quantile([.1, .5])<br>| a b<br>| 0.1 1.3 3.7<br>| 0.5 2.5 55.0<br>|<br>| query(self, expr, </strong>kwargs)<br>| Query the columns of a frame with a boolean expression.<br>|<br>| .. versionadded:: 0.13<br>|<br>| 【参数】<br>| ———-| expr : string<br>| The query string to evaluate. You can refer to variables<br>| in the environment by prefixing them with an ‘@’ character like<br>| <code>@a + b</code>.<br>| kwargs : dict<br>| See the documentation for :func:<code>pandas.eval</code> for complete details<br>| on the keyword arguments accepted by :meth:<code>DataFrame.query</code>.<br>|<br>| 【返回值】<br>| ——-| q : DataFrame<br>|<br>| 【注意】<br>| —–| The result of the evaluation of this expression is first passed to<br>| :attr:<code>DataFrame.loc</code> and if that fails because of a<br>| multidimensional key (e.g., a DataFrame) then the result will be passed<br>| to :meth:<code>DataFrame.__getitem__</code>.<br>|<br>| This method uses the top-level :func:<code>pandas.eval</code> function to<br>| evaluate the passed query.<br>|<br>| The :meth:<code>~pandas.DataFrame.query</code> method uses a slightly<br>| modified Python syntax by default. For example, the <code>&amp;</code> and <code>|</code><br>| (bitwise) operators have the precedence of their boolean cousins,<br>| :keyword:<code>and</code> and :keyword:<code>or</code>. This <em>is</em> syntactically valid Python,<br>| however the semantics are different.<br>|<br>| You can change the semantics of the expression by passing the keyword<br>| argument <code>parser=&#39;python&#39;</code>. This enforces the same semantics as<br>| evaluation in Python space. Likewise, you can pass <code>engine=&#39;python&#39;</code><br>88<br>| to evaluate an expression using Python itself as a backend. This is not<br>| recommended as it is inefficient compared to using <code>numexpr</code> as the<br>| engine.<br>|<br>| The :attr:<code>DataFrame.index</code> and<br>| :attr:<code>DataFrame.columns</code> attributes of the<br>| :class:<code>~pandas.DataFrame</code> instance are placed in the query namespace<br>| by default, which allows you to treat both the index and columns of the<br>| frame as a column in the frame.<br>| The identifier <code>index</code> is used for the frame index; you can also<br>| use the name of the index to identify it in a query.<br>|<br>| For further details and examples see the <code>query</code> documentation in<br>| :ref:<code>indexing &lt;indexing.query&gt;</code>.<br>|<br>| 【参见】<br>| ——–| pandas.eval<br>| DataFrame.eval<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; from numpy.random import randn<br>| &gt;&gt;&gt; from pandas import DataFrame<br>| &gt;&gt;&gt; df = DataFrame(randn(10, 2), columns=list(‘ab’))<br>| &gt;&gt;&gt; df.query(‘a &gt; b’)<br>| &gt;&gt;&gt; df[df.a &gt; df.b] # same result as the previous expression<br>|<br>| radd(self, other, axis=’columns’, level=None, fill_value=None)<br>| Addition of dataframe and other, element-wise (binary operator <code>radd</code>).<br>|<br>| Equivalent to <code>other + dataframe</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.add<br>89<br>|<br>| rank(self, axis=0, numeric_only=None, method=’average’, na_option=’keep’, ascending=True, pct=False)<br>| Compute numerical data ranks (1 through n) along axis. Equal values are<br>| assigned a rank that is the average of the ranks of those values<br>|<br>| 【参数】<br>| ———-| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| Ranks over columns (0) or rows (1)<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data<br>| method : {‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}<br>| <em> average: average rank of group<br>| </em> min: lowest rank in group<br>| <em> max: highest rank in group<br>| </em> first: ranks assigned in order they appear in the array<br>| <em> dense: like ‘min’, but rank always increases by 1 between groups<br>| na_option : {‘keep’, ‘top’, ‘bottom’}<br>| </em> keep: leave NA values where they are<br>| <em> top: smallest rank if ascending<br>| </em> bottom: smallest rank if descending<br>| ascending : boolean, default True<br>| False for ranks by high (1) to low (N)<br>| pct : boolean, default False<br>| Computes percentage rank of data<br>|<br>| 【返回值】<br>| ——-| ranks : DataFrame<br>|<br>| rdiv = rtruediv(self, other, axis=’columns’, level=None, fill_value=None)<br>|<br>| reindex(self, index=None, columns=None, <strong>kwargs)<br>| Conform DataFrame to new index with optional filling logic, placing<br>| NA/NaN in locations having no value in the previous index. A new object<br>| is produced unless the new index is equivalent to the current one and<br>| copy=False<br>|<br>| 【参数】<br>| ———-| index, columns : array-like, optional (can be specified in order, or as<br>| keywords)<br>| New labels / index to conform to. Preferably an Index object to<br>| avoid duplicating data<br>| method : {None, ‘backfill’/‘bfill’, ‘pad’/‘ffill’, ‘nearest’}, optional<br>| method to use for filling holes in reindexed DataFrame.<br>| Please note: this is only applicable to DataFrames/Series with a<br>| monotonically increasing/decreasing index.<br>| <em> default: don’t fill gaps<br>| </em> pad / ffill: propagate last valid observation forward to next valid<br>| <em> backfill / bfill: use next valid observation to fill gap<br>| </em> nearest: use nearest valid observations to fill gap<br>| copy : boolean, default True<br>| Return a new object, even if the passed indexes are the same<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>90<br>| fill_value : scalar, default np.NaN<br>| Value to use for missing values. Defaults to NaN, but can be any<br>| “compatible” value<br>| limit : int, default None<br>| Maximum number of consecutive elements to forward or backward fill<br>| tolerance : optional<br>| Maximum distance between original and new labels for inexact<br>| matches. The values of the index at the matching locations most<br>| satisfy the equation <code>abs(index[indexer] - target) &lt;= tolerance</code>.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【示例】<br>| ——–|<br>| Create a dataframe with some fictional data.<br>|<br>| &gt;&gt;&gt; index = [‘Firefox’, ‘Chrome’, ‘Safari’, ‘IE10’, ‘Konqueror’]<br>| &gt;&gt;&gt; df = pd.DataFrame({<br>| … ‘http_status’: [200,200,404,404,301],<br>| … ‘response_time’: [0.04, 0.02, 0.07, 0.08, 1.0]},<br>| … index=index)<br>| &gt;&gt;&gt; df<br>| http_status response_time<br>| Firefox 200 0.04<br>| Chrome 200 0.02<br>| Safari 404 0.07<br>| IE10 404 0.08<br>| Konqueror 301 1.00<br>|<br>| Create a new index and reindex the dataframe. By default<br>| values in the new index that do not have corresponding<br>| records in the dataframe are assigned <code>NaN</code>.<br>|<br>| &gt;&gt;&gt; new_index= [‘Safari’, ‘Iceweasel’, ‘Comodo Dragon’, ‘IE10’,<br>| … ‘Chrome’]<br>| &gt;&gt;&gt; df.reindex(new_index)<br>| http_status response_time<br>| Safari 404 0.07<br>| Iceweasel NaN NaN<br>| Comodo Dragon NaN NaN<br>| IE10 404 0.08<br>| Chrome 200 0.02<br>|<br>| We can fill in the missing values by passing a value to<br>| the keyword <code>fill_value</code>. Because the index is not monotonically<br>| increasing or decreasing, we cannot use arguments to the keyword<br>| <code>method</code> to fill the <code>NaN</code> values.<br>|<br>| &gt;&gt;&gt; df.reindex(new_index, fill_value=0)<br>| http_status response_time<br>| Safari 404 0.07<br>| Iceweasel 0 0.00<br>| Comodo Dragon 0 0.00<br>| IE10 404 0.08<br>| Chrome 200 0.02<br>|<br>91<br>| &gt;&gt;&gt; df.reindex(new_index, fill_value=’missing’)<br>| http_status response_time<br>| Safari 404 0.07<br>| Iceweasel missing missing<br>| Comodo Dragon missing missing<br>| IE10 404 0.08<br>| Chrome 200 0.02<br>|<br>| To further illustrate the filling functionality in<br>| <code>reindex</code>, we will create a dataframe with a<br>| monotonically increasing index (for example, a sequence<br>| of dates).<br>|<br>| &gt;&gt;&gt; date_index = pd.date_range(‘1/1/2010’, periods=6, freq=’D’)<br>| &gt;&gt;&gt; df2 = pd.DataFrame({“prices”: [100, 101, np.nan, 100, 89, 88]},<br>| index=date_index)<br>| &gt;&gt;&gt; df2<br>| prices<br>| 2010-01-01 100<br>| 2010-01-02 101<br>| 2010-01-03 NaN<br>| 2010-01-04 100<br>| 2010-01-05 89<br>| 2010-01-06 88<br>|<br>| Suppose we decide to expand the dataframe to cover a wider<br>| date range.<br>|<br>| &gt;&gt;&gt; date_index2 = pd.date_range(‘12/29/2009’, periods=10, freq=’D’)<br>| &gt;&gt;&gt; df2.reindex(date_index2)<br>| prices<br>| 2009-12-29 NaN<br>| 2009-12-30 NaN<br>| 2009-12-31 NaN<br>| 2010-01-01 100<br>| 2010-01-02 101<br>| 2010-01-03 NaN<br>| 2010-01-04 100<br>| 2010-01-05 89<br>| 2010-01-06 88<br>| 2010-01-07 NaN<br>|<br>| The index entries that did not have a value in the original data frame<br>| (for example, ‘2009-12-29’) are by default filled with <code>NaN</code>.<br>| If desired, we can fill in the missing values using one of several<br>| options.<br>|<br>| For example, to backpropagate the last valid value to fill the <code>NaN</code><br>| values, pass <code>bfill</code> as an argument to the <code>method</code> keyword.<br>|<br>| &gt;&gt;&gt; df2.reindex(date_index2, method=’bfill’)<br>| prices<br>| 2009-12-29 100<br>| 2009-12-30 100<br>| 2009-12-31 100<br>| 2010-01-01 100<br>| 2010-01-02 101<br>92<br>| 2010-01-03 NaN<br>| 2010-01-04 100<br>| 2010-01-05 89<br>| 2010-01-06 88<br>| 2010-01-07 NaN<br>|<br>| Please note that the <code>NaN</code> value present in the original dataframe<br>| (at index value 2010-01-03) will not be filled by any of the<br>| value propagation schemes. This is because filling while reindexing<br>| does not look at dataframe values, but only compares the original and<br>| desired indexes. If you do want to fill in the <code>NaN</code> values present<br>| in the original dataframe, use the <code>fillna()</code> method.<br>|<br>| 【返回值】<br>| ——-| reindexed : DataFrame<br>|<br>| reindex_axis(self, labels, axis=0, method=None, level=None, copy=True, limit=None, fill_value=nan)<br>| Conform input object to new index with optional filling logic,<br>| placing NA/NaN in locations having no value in the previous index. A<br>| new object is produced unless the new index is equivalent to the<br>| current one and copy=False<br>|<br>| 【参数】<br>| ———-| labels : array-like<br>| New labels / index to conform to. Preferably an Index object to<br>| avoid duplicating data<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| method : {None, ‘backfill’/‘bfill’, ‘pad’/‘ffill’, ‘nearest’}, optional<br>| Method to use for filling holes in reindexed DataFrame:<br>| <em> default: don’t fill gaps<br>| </em> pad / ffill: propagate last valid observation forward to next valid<br>| <em> backfill / bfill: use next valid observation to fill gap<br>| </em> nearest: use nearest valid observations to fill gap<br>| copy : boolean, default True<br>| Return a new object, even if the passed indexes are the same<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>| limit : int, default None<br>| Maximum number of consecutive elements to forward or backward fill<br>| tolerance : optional<br>| Maximum distance between original and new labels for inexact<br>| matches. The values of the index at the matching locations most<br>| satisfy the equation <code>abs(index[indexer] - target) &lt;= tolerance</code>.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df.reindex_axis([‘A’, ‘B’, ‘C’], axis=1)<br>|<br>| 【参见】<br>| ——–| reindex, reindex_like<br>|<br>93<br>| 【返回值】<br>| ——-| reindexed : DataFrame<br>|<br>| rename(self, index=None, columns=None, </strong>kwargs)<br>| Alter axes input function or functions. Function / dict values must be<br>| unique (1-to-1). Labels not contained in a dict / Series will be left<br>| as-is.<br>|<br>| 【参数】<br>| ———-| index, columns : dict-like or function, optional<br>| Transformation to apply to that axis values<br>|<br>| copy : boolean, default True<br>| Also copy underlying data<br>| inplace : boolean, default False<br>| Whether to return a new DataFrame. If True then value of copy is<br>| ignored.<br>|<br>| 【返回值】<br>| ——-| renamed : DataFrame (new object)<br>|<br>| reorder_levels(self, order, axis=0)<br>| Rearrange index levels using input order.<br>| May not drop or duplicate levels<br>|<br>| 【参数】<br>| ———-| order : list of int or list of str<br>| List representing new level order. Reference level by number<br>| (position) or by key (label).<br>| axis : int<br>| Where to reorder levels.<br>|<br>| 【返回值】<br>| ——-| type of caller (new object)<br>|<br>| reset_index(self, level=None, drop=False, inplace=False, col_level=0, col_fill=’’)<br>| For DataFrame with multi-level index, return new DataFrame with<br>| labeling information in the columns under the index names, defaulting<br>| to ‘level_0’, ‘level_1’, etc. if any are None. For a standard index,<br>| the index name will be used (if set), otherwise a default ‘index’ or<br>| ‘level_0’ (if ‘index’ is already taken) will be used.<br>|<br>| 【参数】<br>| ———-| level : int, str, tuple, or list, default None<br>| Only remove the given levels from the index. Removes all levels by<br>| default<br>| drop : boolean, default False<br>| Do not try to insert index into dataframe columns. This resets<br>| the index to the default integer index.<br>| inplace : boolean, default False<br>| Modify the DataFrame in place (do not create a new object)<br>94<br>| col_level : int or str, default 0<br>| If the columns have multiple levels, determines which level the<br>| labels are inserted into. By default it is inserted into the first<br>| level.<br>| col_fill : object, default ‘’<br>| If the columns have multiple levels, determines how the other<br>| levels are named. If None then the index name is repeated.<br>|<br>| 【返回值】<br>| ——-| resetted : DataFrame<br>|<br>| rfloordiv(self, other, axis=’columns’, level=None, fill_value=None)<br>| Integer division of dataframe and other, element-wise (binary operator <code>rfloordiv</code>).<br>|<br>| Equivalent to <code>other // dataframe</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.floordiv<br>|<br>| rmod(self, other, axis=’columns’, level=None, fill_value=None)<br>| Modulo of dataframe and other, element-wise (binary operator <code>rmod</code>).<br>|<br>| Equivalent to <code>other % dataframe</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>95<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.mod<br>|<br>| rmul(self, other, axis=’columns’, level=None, fill_value=None)<br>| Multiplication of dataframe and other, element-wise (binary operator <code>rmul</code>).<br>|<br>| Equivalent to <code>other * dataframe</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.mul<br>|<br>| round(self, decimals=0, out=None)<br>| Round a DataFrame to a variable number of decimal places.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| decimals : int, dict, Series<br>| Number of decimal places to round each column to. If an int is<br>| given, round each column to the same number of places.<br>| Otherwise dict and Series round to variable numbers of places.<br>96<br>| Column names should be in the keys if <code>decimals</code> is a<br>| dict-like, or in the index if <code>decimals</code> is a Series. Any<br>| columns not included in <code>decimals</code> will be left as is. Elements<br>| of <code>decimals</code> which are not columns of the input will be<br>| ignored.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df = pd.DataFrame(np.random.random([3, 3]),<br>| … columns=[‘A’, ‘B’, ‘C’], index=[‘first’, ‘second’, ‘third’])<br>| &gt;&gt;&gt; df<br>| A B C<br>| first 0.028208 0.992815 0.173891<br>| second 0.038683 0.645646 0.577595<br>| third 0.877076 0.149370 0.491027<br>| &gt;&gt;&gt; df.round(2)<br>| A B C<br>| first 0.03 0.99 0.17<br>| second 0.04 0.65 0.58<br>| third 0.88 0.15 0.49<br>| &gt;&gt;&gt; df.round({‘A’: 1, ‘C’: 2})<br>| A B C<br>| first 0.0 0.992815 0.17<br>| second 0.0 0.645646 0.58<br>| third 0.9 0.149370 0.49<br>| &gt;&gt;&gt; decimals = pd.Series([1, 0, 2], index=[‘A’, ‘B’, ‘C’])<br>| &gt;&gt;&gt; df.round(decimals)<br>| A B C<br>| first 0.0 1 0.17<br>| second 0.0 1 0.58<br>| third 0.9 0 0.49<br>|<br>| 【返回值】<br>| ——-| DataFrame object<br>|<br>| rpow(self, other, axis=’columns’, level=None, fill_value=None)<br>| Exponential power of dataframe and other, element-wise (binary operator <code>rpow</code>).<br>|<br>| Equivalent to <code>other ** dataframe</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>97<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.pow<br>|<br>| rsub(self, other, axis=’columns’, level=None, fill_value=None)<br>| Subtraction of dataframe and other, element-wise (binary operator <code>rsub</code>).<br>|<br>| Equivalent to <code>other - dataframe</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.sub<br>|<br>| rtruediv(self, other, axis=’columns’, level=None, fill_value=None)<br>| Floating division of dataframe and other, element-wise (binary operator <code>rtruediv</code>).<br>|<br>| Equivalent to <code>other / dataframe</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>98<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.truediv<br>|<br>| select_dtypes(self, include=None, exclude=None)<br>| Return a subset of a DataFrame including/excluding columns based on<br>| their <code>dtype</code>.<br>|<br>| 【参数】<br>| ———-| include, exclude : list-like<br>| A list of dtypes or strings to be included/excluded. You must pass<br>| in a non-empty sequence for at least one of these.<br>|<br>| 【Raises 引发错误】<br>| ——| ValueError<br>| <em> If both of <code>include</code> and <code>exclude</code> are empty<br>| </em> If <code>include</code> and <code>exclude</code> have overlapping elements<br>| <em> If any kind of string dtype is passed in.<br>| TypeError<br>| </em> If either of <code>include</code> or <code>exclude</code> is not a sequence<br>|<br>| 【返回值】<br>| ——-| subset : DataFrame<br>| The subset of the frame including the dtypes in <code>include</code> and<br>| excluding the dtypes in <code>exclude</code>.<br>|<br>| 【注意】<br>| —–| <em> To select all </em>numeric<em> types use the numpy dtype <code>numpy.number</code><br>| </em> To select strings you must use the <code>object</code> dtype, but note that<br>| this will return <em>all</em> object dtype columns<br>| <em> See the <code>numpy dtype hierarchy
| &lt;http://docs.scipy.org/doc/numpy/reference/arrays.scalars.html&gt;</code>__<br>| </em> To select Pandas categorical dtypes, use ‘category’<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df = pd.DataFrame({‘a’: np.random.randn(6).astype(‘f4’),<br>| … ‘b’: [True, False] <em> 3,<br>| … ‘c’: [1.0, 2.0] </em> 3})<br>| &gt;&gt;&gt; df<br>| a b c<br>| 0 0.3962 True 1<br>| 1 0.1459 False 2<br>| 2 0.2623 True 1<br>99<br>| 3 0.0764 False 2<br>| 4 -0.9703 True 1<br>| 5 -1.2094 False 2<br>| &gt;&gt;&gt; df.select_dtypes(include=[‘float64’])<br>| c<br>| 0 1<br>| 1 2<br>| 2 1<br>| 3 2<br>| 4 1<br>| 5 2<br>| &gt;&gt;&gt; df.select_dtypes(exclude=[‘floating’])<br>| b<br>| 0 True<br>| 1 False<br>| 2 True<br>| 3 False<br>| 4 True<br>| 5 False<br>|<br>| sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, <strong>kwargs)<br>| Return unbiased standard error of the mean over requested axis.<br>|<br>| Normalized by N-1 by default. This can be changed using the ddof argument<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| ddof : int, default 1<br>| degrees of freedom<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| sem : Series or DataFrame (if level specified)<br>|<br>| set_index(self, keys, drop=True, append=False, inplace=False, verify_integrity=False)<br>| Set the DataFrame index (row labels) using one or more existing<br>| columns. By default yields a new object.<br>|<br>| 【参数】<br>| ———-| keys : column label or list of column labels / arrays<br>| drop : boolean, default True<br>| Delete columns to be used as the new index<br>| append : boolean, default False<br>| Whether to append columns to existing index<br>| inplace : boolean, default False<br>| Modify the DataFrame in place (do not create a new object)<br>100<br>| verify_integrity : boolean, default False<br>| Check the new index for duplicates. Otherwise defer the check until<br>| necessary. Setting to False will improve the performance of this<br>| method<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; indexed_df = df.set_index([‘A’, ‘B’])<br>| &gt;&gt;&gt; indexed_df2 = df.set_index([‘A’, [0, 1, 2, 0, 1, 2]])<br>| &gt;&gt;&gt; indexed_df3 = df.set_index([[0, 1, 2, 0, 1, 2]])<br>|<br>| 【返回值】<br>| ——-| dataframe : DataFrame<br>|<br>| set_value(self, index, col, value, takeable=False)<br>| Put single value at passed column and index<br>|<br>| 【参数】<br>| ———-| index : row label<br>| col : column label<br>| value : scalar value<br>| takeable : interpret the index/col as indexers, default False<br>|<br>| 【返回值】<br>| ——-| frame : DataFrame<br>| If label pair is contained, will be reference to calling DataFrame,<br>| otherwise a new object<br>|<br>| shift(self, periods=1, freq=None, axis=0)<br>| Shift index by desired number of periods with an optional time freq<br>|<br>| 【参数】<br>| ———-| periods : int<br>| Number of periods to move, can be positive or negative<br>| freq : DateOffset, timedelta, or time rule string, optional<br>| Increment to use from datetools module or time rule (e.g. ‘EOM’).<br>| See Notes.<br>| axis : {0, 1, ‘index’, ‘columns’}<br>|<br>| 【注意】<br>| —–| If freq is specified then the index values are shifted but the data<br>| is not realigned. That is, use freq if you would like to extend the<br>| index when shifting and preserve the original data.<br>|<br>| 【返回值】<br>| ——-| shifted : DataFrame<br>|<br>| skew(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| Return unbiased skew over requested axis<br>| Normalized by N-1<br>|<br>101<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| skew : Series or DataFrame (if level specified)<br>|<br>| sort(self, columns=None, axis=0, ascending=True, inplace=False, kind=’quicksort’, na_position=’last’)<br>| DEPRECATED: use :meth:<code>DataFrame.sort_values</code><br>|<br>| Sort DataFrame either by labels (along either axis) or by the values in<br>| column(s)<br>|<br>| 【参数】<br>| ———-| columns : object<br>| Column name(s) in frame. Accepts a column name or a list<br>| for a nested sort. A tuple will be interpreted as the<br>| levels of a multi-index.<br>| ascending : boolean or list, default True<br>| Sort ascending vs. descending. Specify list for multiple sort<br>| orders<br>| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| Sort index/rows versus columns<br>| inplace : boolean, default False<br>| Sort the DataFrame without creating a new instance<br>| kind : {‘quicksort’, ‘mergesort’, ‘heapsort’}, optional<br>| This option is only applied when sorting on a single column or label.<br>| na_position : {‘first’, ‘last’} (optional, default=’last’)<br>| ‘first’ puts NaNs at the beginning<br>| ‘last’ puts NaNs at the end<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; result = df.sort([‘A’, ‘B’], ascending=[1, 0])<br>|<br>| 【返回值】<br>| ——-| sorted : DataFrame<br>|<br>| sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind=’quicksort’, na_position=’last’,<br>sort_remaining=True, by=None)<br>| Sort object by labels (along an axis)<br>|<br>| 【参数】<br>| ———-| axis : index, columns to direct sorting<br>102<br>| level : int or level name or list of ints or list of level names<br>| if not None, sort on values in specified index level(s)<br>| ascending : boolean, default True<br>| Sort ascending vs. descending<br>| inplace : bool<br>| if True, perform operation in-place<br>| kind : {<code>quicksort</code>, <code>mergesort</code>, <code>heapsort</code>}<br>| Choice of sorting algorithm. 参见：ndarray.np.sort for more information.<br>| <code>mergesort</code> is the only stable algorithm. For DataFrames, this option is<br>| only applied when sorting on a single column or label.<br>| na_position : {‘first’, ‘last’}<br>| <code>first</code> puts NaNs at the beginning, <code>last</code> puts NaNs at the end<br>| sort_remaining : bool<br>| if true and sorting by level and index is multilevel, sort by other levels<br>| too (in order) after sorting by specified level<br>|<br>| 【返回值】<br>| ——-| sorted_obj : DataFrame<br>|<br>| sort_values(self, by, axis=0, ascending=True, inplace=False, kind=’quicksort’, na_position=’last’)<br>| Sort by the values along either axis<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| by : string name or list of names which refer to the axis items<br>| axis : index, columns to direct sorting<br>| ascending : bool or list of bool<br>| Sort ascending vs. descending. Specify list for multiple sort orders.<br>| If this is a list of bools, must match the length of the by<br>| inplace : bool<br>| if True, perform operation in-place<br>| kind : {<code>quicksort</code>, <code>mergesort</code>, <code>heapsort</code>}<br>| Choice of sorting algorithm. 参见：ndarray.np.sort for more information.<br>| <code>mergesort</code> is the only stable algorithm. For DataFrames, this option is<br>| only applied when sorting on a single column or label.<br>| na_position : {‘first’, ‘last’}<br>| <code>first</code> puts NaNs at the beginning, <code>last</code> puts NaNs at the end<br>|<br>| 【返回值】<br>| ——-| sorted_obj : DataFrame<br>|<br>| sortlevel(self, level=0, axis=0, ascending=True, inplace=False, sort_remaining=True)<br>| Sort multilevel index by chosen axis and primary level. Data will be<br>| lexicographically sorted by the chosen level followed by the other<br>| levels (in order)<br>|<br>| 【参数】<br>| ———-| level : int<br>| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| ascending : boolean, default True<br>| inplace : boolean, default False<br>| Sort the DataFrame without creating a new instance<br>103<br>| sort_remaining : boolean, default True<br>| Sort by the other levels too.<br>|<br>| 【返回值】<br>| ——-| sorted : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.sort_index(level=…)<br>|<br>| stack(self, level=-1, dropna=True)<br>| Pivot a level of the (possibly hierarchical) column labels, returning a<br>| DataFrame (or Series in the case of an object with a single level of<br>| column labels) having a hierarchical index with a new inner-most level<br>| of row labels.<br>| The level involved will automatically get sorted.<br>|<br>| 【参数】<br>| ———-| level : int, string, or list of these, default last level<br>| Level(s) to stack, can pass level name<br>| dropna : boolean, default True<br>| Whether to drop rows in the resulting Frame/Series with no valid<br>| values<br>|<br>| 【示例】<br>| ———-| &gt;&gt;&gt; s<br>| a b<br>| one 1. 2.<br>| two 3. 4.<br>|<br>| &gt;&gt;&gt; s.stack()<br>| one a 1<br>| b 2<br>| two a 3<br>| b 4<br>|<br>| 【返回值】<br>| ——-| stacked : DataFrame or Series<br>|<br>| std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, <strong>kwargs)<br>| Return unbiased standard deviation over requested axis.<br>|<br>| Normalized by N-1 by default. This can be changed using the ddof argument<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>104<br>| ddof : int, default 1<br>| degrees of freedom<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| std : Series or DataFrame (if level specified)<br>|<br>| sub(self, other, axis=’columns’, level=None, fill_value=None)<br>| Subtraction of dataframe and other, element-wise (binary operator <code>sub</code>).<br>|<br>| Equivalent to <code>dataframe - other</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.rsub<br>|<br>| subtract = sub(self, other, axis=’columns’, level=None, fill_value=None)<br>|<br>| sum(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| Return the sum of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>105<br>|<br>| 【返回值】<br>| ——-| sum : Series or DataFrame (if level specified)<br>|<br>| swaplevel(self, i, j, axis=0)<br>| Swap levels i and j in a MultiIndex on a particular axis<br>|<br>| 【参数】<br>| ———-| i, j : int, string (can be mixed)<br>| Level of index to be swapped. Can pass level name as string.<br>|<br>| 【返回值】<br>| ——-| swapped : type of caller (new object)<br>|<br>| to_csv(self, path_or_buf=None, sep=’,’, na_rep=’’, float_format=None, columns=None, header=True, index=True,<br>index_label=None, mode=’w’, encoding=None, compression=None, quoting=None, quotechar=’”‘, line_terminator=’\n’,<br>chunksize=None, tupleize_cols=False, date_format=None, doublequote=True, escapechar=None, decimal=’.’, <strong>kwds)<br>| Write DataFrame to a comma-separated values (csv) file<br>|<br>| 【参数】<br>| ———-| path_or_buf : string or file handle, default None<br>| File path or object, if None is provided the result is returned as<br>| a string.<br>| sep : character, default ‘,’<br>| Field delimiter for the output file.<br>| na_rep : string, default ‘’<br>| Missing data representation<br>| float_format : string, default None<br>| Format string for floating point numbers<br>| columns : sequence, optional<br>| Columns to write<br>| header : boolean or list of string, default True<br>| Write out column names. If a list of string is given it is assumed<br>| to be aliases for the column names<br>| index : boolean, default True<br>| Write row names (index)<br>| index_label : string or sequence, or False, default None<br>| Column label for index column(s) if desired. If None is given, and<br>| <code>header</code> and <code>index</code> are True, then the index names are used. A<br>| sequence should be given if the DataFrame uses MultiIndex. If<br>| False do not print fields for index names. Use index_label=False<br>| for easier importing in R<br>| nanRep : None<br>| deprecated, use na_rep<br>| mode : str<br>| Python write mode, default ‘w’<br>| encoding : string, optional<br>| A string representing the encoding to use in the output file,<br>| defaults to ‘ascii’ on Python 2 and ‘utf-8’ on Python 3.<br>| compression : string, optional<br>| a string representing the compression to use in the output file,<br>| allowed values are ‘gzip’, ‘bz2’,<br>| only used when the first argument is a filename<br>106<br>| line_terminator : string, default ‘\n’<br>| The newline character or character sequence to use in the output<br>| file<br>| quoting : optional constant from csv module<br>| defaults to csv.QUOTE_MINIMAL<br>| quotechar : string (length 1), default ‘“‘<br>| character used to quote fields<br>| doublequote : boolean, default True<br>| Control quoting of <code>quotechar</code> inside a field<br>| escapechar : string (length 1), default None<br>| character used to escape <code>sep</code> and <code>quotechar</code> when appropriate<br>| chunksize : int or None<br>| rows to write at a time<br>| tupleize_cols : boolean, default False<br>| write multi_index columns as a list of tuples (if True)<br>| or new (expanded format) if False)<br>| date_format : string, default None<br>| Format string for datetime objects<br>| decimal: string, default ‘.’<br>| Character recognized as decimal separator. E.g. use ‘,’ for European data<br>|<br>| .. versionadded:: 0.16.0<br>|<br>| to_dict(self, orient=’dict’)<br>| Convert DataFrame to dictionary.<br>|<br>| 【参数】<br>| ———-| orient : str {‘dict’, ‘list’, ‘series’, ‘split’, ‘records’, ‘index’}<br>| Determines the type of the values of the dictionary.<br>|<br>| - dict (default) : dict like {column -&gt; {index -&gt; value}}<br>| - list : dict like {column -&gt; [values]}<br>| - series : dict like {column -&gt; Series(values)}<br>| - split : dict like<br>| {index -&gt; [index], columns -&gt; [columns], data -&gt; [values]}<br>| - records : list like<br>| [{column -&gt; value}, … , {column -&gt; value}]<br>| - index : dict like {index -&gt; {column -&gt; value}}<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| Abbreviations are allowed. <code>s</code> indicates <code>series</code> and <code>sp</code><br>| indicates <code>split</code>.<br>|<br>| 【返回值】<br>| ——-| result : dict like {column -&gt; {index -&gt; value}}<br>|<br>| to_excel(self, excel_writer, sheet_name=’Sheet1’, na_rep=’’, float_format=None, columns=None, header=True, index=True,<br>index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep=’inf’, verbose=True)<br>| Write DataFrame to a excel sheet<br>|<br>| 【参数】<br>| ———-| excel_writer : string or ExcelWriter object<br>| File path or existing ExcelWriter<br>107<br>| sheet_name : string, default ‘Sheet1’<br>| Name of sheet which will contain DataFrame<br>| na_rep : string, default ‘’<br>| Missing data representation<br>| float_format : string, default None<br>| Format string for floating point numbers<br>| columns : sequence, optional<br>| Columns to write<br>| header : boolean or list of string, default True<br>| Write out column names. If a list of string is given it is<br>| assumed to be aliases for the column names<br>| index : boolean, default True<br>| Write row names (index)<br>| index_label : string or sequence, default None<br>| Column label for index column(s) if desired. If None is given, and<br>| <code>header</code> and <code>index</code> are True, then the index names are used. A<br>| sequence should be given if the DataFrame uses MultiIndex.<br>| startrow :<br>| upper left cell row to dump data frame<br>| startcol :<br>| upper left cell column to dump data frame<br>| engine : string, default None<br>| write engine to use - you can also set this via the options<br>| <code>io.excel.xlsx.writer</code>, <code>io.excel.xls.writer</code>, and<br>| <code>io.excel.xlsm.writer</code>.<br>| merge_cells : boolean, default True<br>| Write MultiIndex and Hierarchical Rows as merged cells.<br>| encoding: string, default None<br>| encoding of the resulting excel file. Only necessary for xlwt,<br>| other writers support unicode natively.<br>| inf_rep : string, default ‘inf’<br>| Representation for infinity (there is no native representation for<br>| infinity in Excel)<br>|<br>| 【注意】<br>| —–| If passing an existing ExcelWriter object, then the sheet will be added<br>| to the existing workbook. This can be used to save different<br>| DataFrames to one workbook:<br>|<br>| &gt;&gt;&gt; writer = ExcelWriter(‘output.xlsx’)<br>| &gt;&gt;&gt; df1.to_excel(writer,’Sheet1’)<br>| &gt;&gt;&gt; df2.to_excel(writer,’Sheet2’)<br>| &gt;&gt;&gt; writer.save()<br>|<br>| For compatibility with to_csv, to_excel serializes lists and dicts to<br>| strings before writing.<br>|<br>| to_gbq(self, destination_table, project_id, chunksize=10000, verbose=True, reauth=False, if_exists=’fail’)<br>| Write a DataFrame to a Google BigQuery table.<br>|<br>| THIS IS AN EXPERIMENTAL LIBRARY<br>|<br>| 【参数】<br>| ———-| dataframe : DataFrame<br>| DataFrame to be written<br>108<br>| destination_table : string<br>| Name of table to be written, in the form ‘dataset.tablename’<br>| project_id : str<br>| Google BigQuery Account project ID.<br>| chunksize : int (default 10000)<br>| Number of rows to be inserted in each chunk from the dataframe.<br>| verbose : boolean (default True)<br>| Show percentage complete<br>| reauth : boolean (default False)<br>| Force Google BigQuery to reauthenticate the user. This is useful<br>| if multiple accounts are used.<br>| if_exists : {‘fail’, ‘replace’, ‘append’}, default ‘fail’<br>| ‘fail’: If table exists, do nothing.<br>| ‘replace’: If table exists, drop it, recreate it, and insert data.<br>| ‘append’: If table exists, insert data. Create if does not exist.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| to_html(self, buf=None, columns=None, col_space=None, colSpace=None, header=True, index=True, na_rep=’NaN’,<br>formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, bold_rows=True, classes=None,<br>escape=True, max_rows=None, max_cols=None, show_dimensions=False, notebook=False)<br>| Render a DataFrame as an HTML table.<br>|<br>| <code>to_html</code>-specific options:<br>|<br>| bold_rows : boolean, default True<br>| Make the row labels bold in the output<br>| classes : str or list or tuple, default None<br>| CSS class(es) to apply to the resulting html table<br>| escape : boolean, default True<br>| Convert the characters &lt;, &gt;, and &amp; to HTML-safe sequences.=<br>| max_rows : int, optional<br>| Maximum number of rows to show before truncating. If None, show<br>| all.<br>| max_cols : int, optional<br>| Maximum number of columns to show before truncating. If None, show<br>| all.<br>|<br>|<br>| 【参数】<br>| ———-| buf : StringIO-like, optional<br>| buffer to write to<br>| columns : sequence, optional<br>| the subset of columns to write; default None writes all columns<br>| col_space : int, optional<br>| the minimum width of each column<br>| header : bool, optional<br>| whether to print column labels, default True<br>| index : bool, optional<br>| whether to print index (row) labels, default True<br>| na_rep : string, optional<br>| string representation of NAN to use, default ‘NaN’<br>| formatters : list or dict of one-parameter functions, optional<br>| formatter functions to apply to columns’ elements by position or name,<br>| default None. The result of each function must be a unicode string.<br>| List must be of length equal to the number of columns.<br>109<br>| float_format : one-parameter function, optional<br>| formatter function to apply to columns’ elements if they are floats,<br>| default None. The result of this function must be a unicode string.<br>| sparsify : bool, optional<br>| Set to False for a DataFrame with a hierarchical index to print every<br>| multiindex key at each row, default True<br>| index_names : bool, optional<br>| Prints the names of the indexes, default True<br>| justify : {‘left’, ‘right’}, default None<br>| Left or right-justify the column labels. If None uses the option from<br>| the print configuration (controlled by set_option), ‘right’ out<br>| of the box.<br>|<br>| 【返回值】<br>| ——-| formatted : string (or unicode, depending on data and options)<br>|<br>| to_latex(self, buf=None, columns=None, col_space=None, colSpace=None, header=True, index=True, na_rep=’NaN’,<br>formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=True, column_format=None,<br>longtable=False, escape=True)<br>| Render a DataFrame to a tabular environment table. You can splice<br>| this into a LaTeX document. Requires \usepackage{booktabs}.<br>|<br>| <code>to_latex</code>-specific options:<br>|<br>| bold_rows : boolean, default True<br>| Make the row labels bold in the output<br>| column_format : str, default None<br>| The columns format as specified in <code>LaTeX table format
| &lt;https://en.wikibooks.org/wiki/LaTeX/Tables&gt;</code>__ e.g ‘rcl’ for 3 columns<br>| longtable : boolean, default False<br>| Use a longtable environment instead of tabular. Requires adding<br>| a \usepackage{longtable} to your LaTeX preamble.<br>| escape : boolean, default True<br>| When set to False prevents from escaping latex special<br>| characters in column names.<br>|<br>|<br>| 【参数】<br>| ———-| buf : StringIO-like, optional<br>| buffer to write to<br>| columns : sequence, optional<br>| the subset of columns to write; default None writes all columns<br>| col_space : int, optional<br>| the minimum width of each column<br>| header : bool, optional<br>| whether to print column labels, default True<br>| index : bool, optional<br>| whether to print index (row) labels, default True<br>| na_rep : string, optional<br>| string representation of NAN to use, default ‘NaN’<br>| formatters : list or dict of one-parameter functions, optional<br>| formatter functions to apply to columns’ elements by position or name,<br>| default None. The result of each function must be a unicode string.<br>| List must be of length equal to the number of columns.<br>| float_format : one-parameter function, optional<br>110<br>| formatter function to apply to columns’ elements if they are floats,<br>| default None. The result of this function must be a unicode string.<br>| sparsify : bool, optional<br>| Set to False for a DataFrame with a hierarchical index to print every<br>| multiindex key at each row, default True<br>| index_names : bool, optional<br>| Prints the names of the indexes, default True<br>|<br>| 【返回值】<br>| ——-| formatted : string (or unicode, depending on data and options)<br>|<br>| to_panel(self)<br>| Transform long (stacked) format (DataFrame) into wide (3D, Panel)<br>| format.<br>|<br>| Currently the index of the DataFrame must be a 2-level MultiIndex. This<br>| may be generalized later<br>|<br>| 【返回值】<br>| ——-| panel : Panel<br>|<br>| to_period(self, freq=None, axis=0, copy=True)<br>| Convert DataFrame from DatetimeIndex to PeriodIndex with desired<br>| frequency (inferred from index if not passed)<br>|<br>| 【参数】<br>| ———-| freq : string, default<br>| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| The axis to convert (the index by default)<br>| copy : boolean, default True<br>| If False then underlying input data is not copied<br>|<br>| 【返回值】<br>| ——-| ts : TimeSeries with PeriodIndex<br>|<br>| to_records(self, index=True, convert_datetime64=True)<br>| Convert DataFrame to record array. Index will be put in the<br>| ‘index’ field of the record array if requested<br>|<br>| 【参数】<br>| ———-| index : boolean, default True<br>| Include index in resulting record array, stored in ‘index’ field<br>| convert_datetime64 : boolean, default True<br>| Whether to convert the index to datetime.datetime if it is a<br>| DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : recarray<br>|<br>| to_sparse(self, fill_value=None, kind=’block’)<br>| Convert to SparseDataFrame<br>111<br>|<br>| 【参数】<br>| ———-| fill_value : float, default NaN<br>| kind : {‘block’, ‘integer’}<br>|<br>| 【返回值】<br>| ——-| y : SparseDataFrame<br>|<br>| to_stata(self, fname, convert_dates=None, write_index=True, encoding=’latin-1’, byteorder=None, time_stamp=None,<br>data_label=None)<br>| A class for writing Stata binary dta files from array-like objects<br>|<br>| 【参数】<br>| ———-| fname : file path or buffer<br>| Where to save the dta file.<br>| convert_dates : dict<br>| Dictionary mapping column of datetime types to the stata internal<br>| format that you want to use for the dates. Options are<br>| ‘tc’, ‘td’, ‘tm’, ‘tw’, ‘th’, ‘tq’, ‘ty’. Column can be either a<br>| number or a name.<br>| encoding : str<br>| Default is latin-1. Note that Stata does not support unicode.<br>| byteorder : str<br>| Can be “&gt;”, “&lt;”, “little”, or “big”. The default is None which uses<br>| <code>sys.byteorder</code><br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; writer = StataWriter(‘./data_file.dta’, data)<br>| &gt;&gt;&gt; writer.write_file()<br>|<br>| Or with dates<br>|<br>| &gt;&gt;&gt; writer = StataWriter(‘./date_data_file.dta’, data, {2 : ‘tw’})<br>| &gt;&gt;&gt; writer.write_file()<br>|<br>| to_string(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep=’NaN’, formatters=None,<br>float_format=None, sparsify=None, index_names=True, justify=None, line_width=None, max_rows=None, max_cols=None,<br>show_dimensions=False)<br>| Render a DataFrame to a console-friendly tabular output.<br>|<br>| 【参数】<br>| ———-| buf : StringIO-like, optional<br>| buffer to write to<br>| columns : sequence, optional<br>| the subset of columns to write; default None writes all columns<br>| col_space : int, optional<br>| the minimum width of each column<br>| header : bool, optional<br>| whether to print column labels, default True<br>| index : bool, optional<br>| whether to print index (row) labels, default True<br>| na_rep : string, optional<br>112<br>| string representation of NAN to use, default ‘NaN’<br>| formatters : list or dict of one-parameter functions, optional<br>| formatter functions to apply to columns’ elements by position or name,<br>| default None. The result of each function must be a unicode string.<br>| List must be of length equal to the number of columns.<br>| float_format : one-parameter function, optional<br>| formatter function to apply to columns’ elements if they are floats,<br>| default None. The result of this function must be a unicode string.<br>| sparsify : bool, optional<br>| Set to False for a DataFrame with a hierarchical index to print every<br>| multiindex key at each row, default True<br>| index_names : bool, optional<br>| Prints the names of the indexes, default True<br>| justify : {‘left’, ‘right’}, default None<br>| Left or right-justify the column labels. If None uses the option from<br>| the print configuration (controlled by set_option), ‘right’ out<br>| of the box.<br>|<br>| 【返回值】<br>| ——-| formatted : string (or unicode, depending on data and options)<br>|<br>| to_timestamp(self, freq=None, how=’start’, axis=0, copy=True)<br>| Cast to DatetimeIndex of timestamps, at <em>beginning</em> of period<br>|<br>| 【参数】<br>| ———-| freq : string, default frequency of PeriodIndex<br>| Desired frequency<br>| how : {‘s’, ‘e’, ‘start’, ‘end’}<br>| Convention for converting period to timestamp; start of period<br>| vs. end<br>| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| The axis to convert (the index by default)<br>| copy : boolean, default True<br>| If false then underlying input data is not copied<br>|<br>| 【返回值】<br>| ——-| df : DataFrame with DatetimeIndex<br>|<br>| to_wide = wrapper(*args, </strong>kwargs)<br>|<br>| transpose(self)<br>| Transpose index and columns<br>|<br>| truediv(self, other, axis=’columns’, level=None, fill_value=None)<br>| Floating division of dataframe and other, element-wise (binary operator <code>truediv</code>).<br>|<br>| Equivalent to <code>dataframe / other</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>113<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.rtruediv<br>|<br>| unstack(self, level=-1)<br>| Pivot a level of the (necessarily hierarchical) index labels, returning<br>| a DataFrame having a new level of column labels whose inner-most level<br>| consists of the pivoted index labels. If the index is not a MultiIndex,<br>| the output will be a Series (the analogue of stack when the columns are<br>| not a MultiIndex).<br>| The level involved will automatically get sorted.<br>|<br>| 【参数】<br>| ———-| level : int, string, or list of these, default -1 (last level)<br>| Level(s) of index to unstack, can pass level name<br>|<br>| 【参见】<br>| ——–| DataFrame.pivot : Pivot a table based on column values.<br>| DataFrame.stack : Pivot a level of the column labels (inverse operation<br>| from <code>unstack</code>).<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; index = pd.MultiIndex.from_tuples([(‘one’, ‘a’), (‘one’, ‘b’),<br>| … (‘two’, ‘a’), (‘two’, ‘b’)])<br>| &gt;&gt;&gt; s = pd.Series(np.arange(1.0, 5.0), index=index)<br>| &gt;&gt;&gt; s<br>| one a 1<br>| b 2<br>| two a 3<br>| b 4<br>| dtype: float64<br>|<br>| &gt;&gt;&gt; s.unstack(level=-1)<br>| a b<br>| one 1 2<br>| two 3 4<br>|<br>| &gt;&gt;&gt; s.unstack(level=0)<br>| one two<br>114<br>| a 1 3<br>| b 2 4<br>|<br>| &gt;&gt;&gt; df = s.unstack(level=0)<br>| &gt;&gt;&gt; df.unstack()<br>| one a 1.<br>| b 3.<br>| two a 2.<br>| b 4.<br>|<br>| 【返回值】<br>| ——-| unstacked : DataFrame or Series<br>|<br>| update(self, other, join=’left’, overwrite=True, filter_func=None, raise_conflict=False)<br>| Modify DataFrame in place using non-NA values from passed<br>| DataFrame. Aligns on indices<br>|<br>| 【参数】<br>| ———-| other : DataFrame, or object coercible into a DataFrame<br>| join : {‘left’}, default ‘left’<br>| overwrite : boolean, default True<br>| If True then overwrite values for common keys in the calling frame<br>| filter_func : callable(1d-array) -&gt; 1d-array<boolean>, default None<br>| Can choose to replace values other than NA. Return True for values<br>| that should be updated<br>| raise_conflict : boolean<br>| If True, will raise an error if the DataFrame and other both<br>| contain data in the same place.<br>|<br>| var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, <strong>kwargs)<br>| Return unbiased variance over requested axis.<br>|<br>| Normalized by N-1 by default. This can be changed using the ddof argument<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| ddof : int, default 1<br>| degrees of freedom<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| var : Series or DataFrame (if level specified)<br>|<br>| ———————————————————————-| Class methods defined here:<br>115<br>|<br>| from_csv(path, header=0, sep=’,’, index_col=0, parse_dates=True, encoding=None, tupleize_cols=False,<br>infer_datetime_format=False) from builtins.type<br>| Read CSV file (DISCOURAGED, please use :func:<code>pandas.read_csv</code> instead).<br>|<br>| It is preferable to use the more powerful :func:<code>pandas.read_csv</code><br>| for most general purposes, but <code>from_csv</code> makes for an easy<br>| roundtrip to and from a file (the exact counterpart of<br>| <code>to_csv</code>), especially with a DataFrame of time series data.<br>|<br>| This method only differs from the preferred :func:<code>pandas.read_csv</code><br>| in some defaults:<br>|<br>| - <code>index_col</code> is <code>0</code> instead of <code>None</code> (take first column as index<br>| by default)<br>| - <code>parse_dates</code> is <code>True</code> instead of <code>False</code> (try parsing the index<br>| as datetime by default)<br>|<br>| So a <code>pd.DataFrame.from_csv(path)</code> can be replaced by<br>| <code>pd.read_csv(path, index_col=0, parse_dates=True)</code>.<br>|<br>| 【参数】<br>| ———-| path : string file path or file handle / StringIO<br>| header : int, default 0<br>| Row to use as header (skip prior rows)<br>| sep : string, default ‘,’<br>| Field delimiter<br>| index_col : int or sequence, default 0<br>| Column to use for index. If a sequence is given, a MultiIndex<br>| is used. Different default from read_table<br>| parse_dates : boolean, default True<br>| Parse dates. Different default from read_table<br>| tupleize_cols : boolean, default False<br>| write multi_index columns as a list of tuples (if True)<br>| or new (expanded format) if False)<br>| infer_datetime_format: boolean, default False<br>| If True and <code>parse_dates</code> is True for a column, try to infer the<br>| datetime format based on the first datetime string. If the format<br>| can be inferred, there often will be a large parsing speed-up.<br>|<br>| 【参见】<br>| ——–| pandas.read_csv<br>|<br>| 【返回值】<br>| ——-| y : DataFrame<br>|<br>| from_dict(data, orient=’columns’, dtype=None) from builtins.type<br>| Construct DataFrame from dict of array-like or dicts<br>|<br>| 【参数】<br>| ———-| data : dict<br>| {field : array-like} or {field : dict}<br>| orient : {‘columns’, ‘index’}, default ‘columns’<br>116<br>| The “orientation” of the data. If the keys of the passed dict<br>| should be the columns of the resulting DataFrame, pass ‘columns’<br>| (default). Otherwise if the keys should be rows, pass ‘index’.<br>| dtype : dtype, default None<br>| Data type to force, otherwise infer<br>|<br>| 【返回值】<br>| ——-| DataFrame<br>|<br>| from_items(items, columns=None, orient=’columns’) from builtins.type<br>| Convert (key, value) pairs to DataFrame. The keys will be the axis<br>| index (usually the columns, but depends on the specified<br>| orientation). The values should be arrays or Series.<br>|<br>| 【参数】<br>| ———-| items : sequence of (key, value) pairs<br>| Values should be arrays or Series.<br>| columns : sequence of column labels, optional<br>| Must be passed if orient=’index’.<br>| orient : {‘columns’, ‘index’}, default ‘columns’<br>| The “orientation” of the data. If the keys of the<br>| input correspond to column labels, pass ‘columns’<br>| (default). Otherwise if the keys correspond to the index,<br>| pass ‘index’.<br>|<br>| 【返回值】<br>| ——-| frame : DataFrame<br>|<br>| from_records(data, index=None, exclude=None, columns=None, coerce_float=False, nrows=None) from builtins.type<br>| Convert structured or record ndarray to DataFrame<br>|<br>| 【参数】<br>| ———-| data : ndarray (structured dtype), list of tuples, dict, or DataFrame<br>| index : string, list of fields, array-like<br>| Field of array to use as the index, alternately a specific set of<br>| input labels to use<br>| exclude : sequence, default None<br>| Columns or fields to exclude<br>| columns : sequence, default None<br>| Column names to use. If the passed data do not have names<br>| associated with them, this argument provides names for the<br>| columns. Otherwise this argument indicates the order of the columns<br>| in the result (any names not found in the data will become all-NA<br>| columns)<br>| coerce_float : boolean, default False<br>| Attempt to convert values to non-string, non-numeric objects (like<br>| decimal.Decimal) to floating point, useful for SQL result sets<br>|<br>| 【返回值】<br>| ——-| df : DataFrame<br>|<br>| ———————————————————————-<br>117<br>| Data descriptors defined here:<br>|<br>| T<br>| Transpose index and columns<br>|<br>| axes<br>| Return a list with the row axis labels and column axis labels as the<br>| only members. They are returned in that order.<br>|<br>| columns<br>|<br>| index<br>|<br>| shape<br>| Return a tuple representing the dimensionality of the DataFrame.<br>|<br>| style<br>| Property returning a Styler object containing methods for<br>| building a styled HTML representation fo the DataFrame.<br>|<br>| 【参见】<br>| ——–| pandas.core.Styler<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| plot = <class 'pandas.tools.plotting.frameplotmethods'=""><br>| DataFrame plotting accessor and method<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df.plot.line()<br>| &gt;&gt;&gt; df.plot.scatter(‘x’, ‘y’)<br>| &gt;&gt;&gt; df.plot.hexbin()<br>|<br>| These plotting methods can also be accessed by calling the accessor as a<br>| method with the <code>kind</code> argument:<br>| <code>df.plot(kind=&#39;line&#39;)</code> is equivalent to <code>df.plot.line()</code><br>|<br>| ———————————————————————-| Methods inherited from pandas.core.generic.NDFrame:<br>|<br>| <strong>abs</strong>(self)<br>|<br>| <strong>array</strong>(self, dtype=None)<br>|<br>| <strong>array_wrap</strong>(self, result, context=None)<br>|<br>| <strong>bool</strong> = <strong>nonzero</strong>(self)<br>|<br>| <strong>contains</strong>(self, key)<br>| True if the key is in the info axis<br>|<br>| <strong>delitem</strong>(self, key)<br>| Delete item<br>|<br>118<br>| <strong>finalize</strong>(self, other, method=None, </class></strong>kwargs)<br>| propagate metadata from other to self<br>|<br>| 【参数】<br>| ———-| other : the object from which to get the attributes that we are going<br>| to propagate<br>| method : optional, a passed method name ; possibly to take different<br>| types of propagation actions based on this<br>|<br>| <strong>getattr</strong>(self, name)<br>| After regular attribute access, try looking up the name<br>| This allows simpler access to columns for interactive use.<br>|<br>| <strong>getstate</strong>(self)<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>invert</strong>(self)<br>|<br>| <strong>iter</strong>(self)<br>| Iterate over infor axis<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>nonzero</strong>(self)<br>|<br>| <strong>setattr</strong>(self, name, value)<br>| After regular attribute access, try setting the name<br>| This allows simpler access to columns for interactive use.<br>|<br>| <strong>setstate</strong>(self, state)<br>|<br>| abs(self)<br>| Return an object with absolute value taken. Only applicable to objects<br>| that are all numeric<br>|<br>| 【返回值】<br>| ——-| abs: type of caller<br>|<br>| add_prefix(self, prefix)<br>| Concatenate prefix string with panel items names.<br>|<br>| 【参数】<br>| ———-| prefix : string<br>|<br>| 【返回值】<br>| ——-| with_prefix : type of caller<br>|<br>| add_suffix(self, suffix)<br>| Concatenate suffix string with panel items names<br>|<br>| 【参数】<br>119<br>| ———-| suffix : string<br>|<br>| 【返回值】<br>| ——-| with_suffix : type of caller<br>|<br>| as_blocks(self, copy=True)<br>| Convert the frame to a dict of dtype -&gt; Constructor Types that each has<br>| a homogeneous dtype.<br>|<br>| NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in<br>| as_matrix)<br>|<br>| 【参数】<br>| ———-| copy : boolean, default True<br>|<br>| .. versionadded: 0.16.1<br>|<br>| 【返回值】<br>| ——-| values : a dict of dtype -&gt; Constructor Types<br>|<br>| as_matrix(self, columns=None)<br>| Convert the frame to its Numpy-array representation.<br>|<br>| 【参数】<br>| ———-| columns: list, optional, default:None<br>| If None, return all columns, otherwise, returns specified columns.<br>|<br>| 【返回值】<br>| ——-| values : ndarray<br>| If the caller is heterogeneous and contains booleans or objects,<br>| the result will be of dtype=object. See Notes.<br>|<br>|<br>| 【注意】<br>| —–| Return is NOT a Numpy-matrix, rather, a Numpy-array.<br>|<br>| The dtype will be a lower-common-denominator dtype (implicit<br>| upcasting); that is to say if the dtypes (even of numeric types)<br>| are mixed, the one that accommodates all will be chosen. Use this<br>| with care if you are not dealing with the blocks.<br>|<br>| e.g. If the dtypes are float16 and float32, dtype will be upcast to<br>| float32. If dtypes are int32 and uint8, dtype will be upcase to<br>| int32.<br>|<br>| This method is provided for backwards compatibility. Generally,<br>| it is recommended to use ‘.values’.<br>|<br>| 【参见】<br>| ——–<br>120<br>| pandas.DataFrame.values<br>|<br>| asfreq(self, freq, method=None, how=None, normalize=False)<br>| Convert all TimeSeries inside to specified frequency using DateOffset<br>| objects. Optionally provide fill method to pad/backfill missing values.<br>|<br>| 【参数】<br>| ———-| freq : DateOffset object, or string<br>| method : {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}<br>| Method to use for filling holes in reindexed Series<br>| pad / ffill: propagate last valid observation forward to next valid<br>| backfill / bfill: use NEXT valid observation to fill method<br>| how : {‘start’, ‘end’}, default end<br>| For PeriodIndex only, see PeriodIndex.asfreq<br>| normalize : bool, default False<br>| Whether to reset output index to midnight<br>|<br>| 【返回值】<br>| ——-| converted : type of caller<br>|<br>| astype(self, dtype, copy=True, raise_on_error=True, <strong>kwargs)<br>| Cast object to input numpy.dtype<br>| Return a copy when copy = True (be really careful with this!)<br>|<br>| 【参数】<br>| ———-| dtype : numpy.dtype or Python type<br>| raise_on_error : raise on invalid input<br>| kwargs : keyword arguments to pass on to the constructor<br>|<br>| 【返回值】<br>| ——-| casted : type of caller<br>|<br>| at_time(self, time, asof=False)<br>| Select values at particular time of day (e.g. 9:30AM)<br>|<br>| 【参数】<br>| ———-| time : datetime.time or string<br>|<br>| 【返回值】<br>| ——-| values_at_time : type of caller<br>|<br>| between_time(self, start_time, end_time, include_start=True, include_end=True)<br>| Select values between particular times of the day (e.g., 9:00-9:30 AM)<br>|<br>| 【参数】<br>| ———-| start_time : datetime.time or string<br>| end_time : datetime.time or string<br>| include_start : boolean, default True<br>| include_end : boolean, default True<br>|<br>121<br>| 【返回值】<br>| ——-| values_between_time : type of caller<br>|<br>| bfill(self, axis=None, inplace=False, limit=None, downcast=None)<br>| Synonym for NDFrame.fillna(method=’bfill’)<br>|<br>| bool(self)<br>| Return the bool of a single element PandasObject<br>| This must be a boolean scalar value, either True or False<br>|<br>| Raise a ValueError if the PandasObject does not have exactly<br>| 1 element, or that element is not boolean<br>|<br>| clip(self, lower=None, upper=None, out=None, axis=None)<br>| Trim values at input threshold(s)<br>|<br>| 【参数】<br>| ———-| lower : float or array_like, default None<br>| upper : float or array_like, default None<br>| axis : int or string axis name, optional<br>| Align object with lower and upper along the given axis.<br>|<br>| 【返回值】<br>| ——-| clipped : Series<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df<br>| 0 1<br>| 0 0.335232 -1.256177<br>| 1 -1.367855 0.746646<br>| 2 0.027753 -1.176076<br>| 3 0.230930 -0.679613<br>| 4 1.261967 0.570967<br>| &gt;&gt;&gt; df.clip(-1.0, 0.5)<br>| 0 1<br>| 0 0.335232 -1.000000<br>| 1 -1.000000 0.500000<br>| 2 0.027753 -1.000000<br>| 3 0.230930 -0.679613<br>| 4 0.500000 0.500000<br>| &gt;&gt;&gt; t<br>| 0 -0.3<br>| 1 -0.2<br>| 2 -0.1<br>| 3 0.0<br>| 4 0.1<br>| dtype: float64<br>| &gt;&gt;&gt; df.clip(t, t + 1, axis=0)<br>| 0 1<br>| 0 0.335232 -0.300000<br>| 1 -0.200000 0.746646<br>| 2 0.027753 -0.100000<br>| 3 0.230930 0.000000<br>122<br>| 4 1.100000 0.570967<br>|<br>| clip_lower(self, threshold, axis=None)<br>| Return copy of the input with values below given value(s) truncated<br>|<br>| 【参数】<br>| ———-| threshold : float or array_like<br>| axis : int or string axis name, optional<br>| Align object with threshold along the given axis.<br>|<br>| 【参见】<br>| ——–| clip<br>|<br>| 【返回值】<br>| ——-| clipped : same type as input<br>|<br>| clip_upper(self, threshold, axis=None)<br>| Return copy of input with values above given value(s) truncated<br>|<br>| 【参数】<br>| ———-| threshold : float or array_like<br>| axis : int or string axis name, optional<br>| Align object with threshold along the given axis.<br>|<br>| 【参见】<br>| ——–| clip<br>|<br>| 【返回值】<br>| ——-| clipped : same type as input<br>|<br>| consolidate(self, inplace=False)<br>| Compute NDFrame with “consolidated” internals (data of each dtype<br>| grouped together in a single ndarray). Mainly an internal API function,<br>| but available here to the savvy user<br>|<br>| 【参数】<br>| ———-| inplace : boolean, default False<br>| If False return new object, otherwise modify existing object<br>|<br>| 【返回值】<br>| ——-| consolidated : type of caller<br>|<br>| convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)<br>| Attempt to infer better dtype for object columns<br>|<br>| 【参数】<br>| ———-| convert_dates : boolean, default True<br>123<br>| If True, convert to date where possible. If ‘coerce’, force<br>| conversion, with unconvertible values becoming NaT.<br>| convert_numeric : boolean, default False<br>| If True, attempt to coerce to numbers (including strings), with<br>| unconvertible values becoming NaN.<br>| convert_timedeltas : boolean, default True<br>| If True, convert to timedelta where possible. If ‘coerce’, force<br>| conversion, with unconvertible values becoming NaT.<br>| copy : boolean, default True<br>| If True, return a copy even if no copy is necessary (e.g. no<br>| conversion was done). Note: This is meant for internal use, and<br>| should not be confused with inplace.<br>|<br>| 【返回值】<br>| ——-| converted : same as input object<br>|<br>| copy(self, deep=True)<br>| Make a copy of this object<br>|<br>| 【参数】<br>| ———-| deep : boolean or string, default True<br>| Make a deep copy, i.e. also copy data<br>|<br>| 【返回值】<br>| ——-| copy : type of caller<br>|<br>| describe(self, percentiles=None, include=None, exclude=None)<br>| Generate various summary statistics, excluding NaN values.<br>|<br>| 【参数】<br>| ———-| percentiles : array-like, optional<br>| The percentiles to include in the output. Should all<br>| be in the interval [0, 1]. By default <code>percentiles</code> is<br>| [.25, .5, .75], returning the 25th, 50th, and 75th percentiles.<br>| include, exclude : list-like, ‘all’, or None (default)<br>| Specify the form of the returned result. Either:<br>|<br>| - None to both (default). The result will include only numeric-typed<br>| columns or, if none are, only categorical columns.<br>| - A list of dtypes or strings to be included/excluded.<br>| To select all numeric types use numpy numpy.number. To select<br>| categorical objects use type object. 参见：the select_dtypes<br>| documentation. eg. df.describe(include=[‘O’])<br>| - If include is the string ‘all’, the output column-set will<br>| match the input one.<br>|<br>| 【返回值】<br>| ——-| summary: NDFrame of summary statistics<br>|<br>| 【注意】<br>| —–| The output DataFrame index depends on the requested dtypes:<br>124<br>|<br>| For numeric dtypes, it will include: count, mean, std, min,<br>| max, and lower, 50, and upper percentiles.<br>|<br>| For object dtypes (e.g. timestamps or strings), the index<br>| will include the count, unique, most common, and frequency of the<br>| most common. Timestamps also include the first and last items.<br>|<br>| For mixed dtypes, the index will be the union of the corresponding<br>| output types. Non-applicable entries will be filled with NaN.<br>| Note that mixed-dtype outputs can only be returned from mixed-dtype<br>| inputs and appropriate use of the include/exclude arguments.<br>|<br>| If multiple values have the highest count, then the<br>| <code>count</code> and <code>most common</code> pair will be arbitrarily chosen from<br>| among those with the highest count.<br>|<br>| The include, exclude arguments are ignored for Series.<br>|<br>| 【参见】<br>| ——–| DataFrame.select_dtypes<br>|<br>| drop(self, labels, axis=0, level=None, inplace=False, errors=’raise’)<br>| Return new object with labels in requested axis removed<br>|<br>| 【参数】<br>| ———-| labels : single label or list-like<br>| axis : int or axis name<br>| level : int or level name, default None<br>| For MultiIndex<br>| inplace : bool, default False<br>| If True, do operation inplace and return None.<br>| errors : {‘ignore’, ‘raise’}, default ‘raise’<br>| If ‘ignore’, suppress error and existing labels are dropped.<br>|<br>| .. versionadded:: 0.16.1<br>|<br>| 【返回值】<br>| ——-| dropped : type of caller<br>|<br>| equals(self, other)<br>| Determines if two NDFrame objects contain the same elements. NaNs in the<br>| same location are considered equal.<br>|<br>| ffill(self, axis=None, inplace=False, limit=None, downcast=None)<br>| Synonym for NDFrame.fillna(method=’ffill’)<br>|<br>| filter(self, items=None, like=None, regex=None, axis=None)<br>| Restrict the info axis to set of items or wildcard<br>|<br>| 【参数】<br>| ———-| items : list-like<br>| List of info axis to restrict to (must not all be present)<br>125<br>| like : string<br>| Keep info axis where “arg in col == True”<br>| regex : string (regular expression)<br>| Keep info axis with re.search(regex, col) == True<br>| axis : int or None<br>| The axis to filter on. By default this is the info axis. The “info<br>| axis” is the axis that is used when indexing with <code>[]</code>. For<br>| example, <code>df = DataFrame({&#39;a&#39;: [1, 2, 3, 4]]}); df[&#39;a&#39;]</code>. So,<br>| the <code>DataFrame</code> columns are the info axis.<br>|<br>| 【注意】<br>| —–| Arguments are mutually exclusive, but this is not checked for<br>|<br>| first(self, offset)<br>| Convenience method for subsetting initial periods of time series data<br>| based on a date offset<br>|<br>| 【参数】<br>| ———-| offset : string, DateOffset, dateutil.relativedelta<br>|<br>| 【示例】<br>| ——–| ts.last(‘10D’) -&gt; First 10 days<br>|<br>| 【返回值】<br>| ——-| subset : type of caller<br>|<br>| get(self, key, default=None)<br>| Get item from object for given key (DataFrame column, Panel slice,<br>| etc.). Returns default value if not found<br>|<br>| 【参数】<br>| ———-| key : object<br>|<br>| 【返回值】<br>| ——-| value : type of items contained in object<br>|<br>| get_dtype_counts(self)<br>| Return the counts of dtypes in this object<br>|<br>| get_ftype_counts(self)<br>| Return the counts of ftypes in this object<br>|<br>| get_values(self)<br>| same as values (but handles sparseness conversions)<br>|<br>| groupby(self, by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False)<br>| Group series using mapper (dict or key function, apply given function<br>| to group, return result as series) or by a series of columns<br>|<br>| 【参数】<br>| ———-<br>126<br>| by : mapping function / list of functions, dict, Series, or tuple /<br>| list of column names.<br>| Called on each element of the object index to determine the groups.<br>| If a dict or Series is passed, the Series or dict VALUES will be<br>| used to determine the groups<br>| axis : int, default 0<br>| level : int, level name, or sequence of such, default None<br>| If the axis is a MultiIndex (hierarchical), group by a particular<br>| level or levels<br>| as_index : boolean, default True<br>| For aggregated output, return object with group labels as the<br>| index. Only relevant for DataFrame input. as_index=False is<br>| effectively “SQL-style” grouped output<br>| sort : boolean, default True<br>| Sort group keys. Get better performance by turning this off.<br>| Note this does not influence the order of observations within each group.<br>| groupby preserves the order of rows within each group.<br>| group_keys : boolean, default True<br>| When calling apply, add group keys to index to identify pieces<br>| squeeze : boolean, default False<br>| reduce the dimensionality of the return type if possible,<br>| otherwise return a consistent type<br>|<br>| 【示例】<br>| ——–| DataFrame results<br>|<br>| &gt;&gt;&gt; data.groupby(func, axis=0).mean()<br>| &gt;&gt;&gt; data.groupby([‘col1’, ‘col2’])[‘col3’].mean()<br>|<br>| DataFrame with hierarchical index<br>|<br>| &gt;&gt;&gt; data.groupby([‘col1’, ‘col2’]).mean()<br>|<br>| 【返回值】<br>| ——-| GroupBy object<br>|<br>| head(self, n=5)<br>| Returns first n rows<br>|<br>| interpolate(self, method=’linear’, axis=0, limit=None, inplace=False, limit_direction=’forward’, downcast=None, </strong>kwargs)<br>| Interpolate values according to different methods.<br>|<br>| Please note that only <code>method=&#39;linear&#39;</code> is supported for DataFrames/Series<br>| with a MultiIndex.<br>|<br>| 【参数】<br>| ———-| method : {‘linear’, ‘time’, ‘index’, ‘values’, ‘nearest’, ‘zero’,<br>| ‘slinear’, ‘quadratic’, ‘cubic’, ‘barycentric’, ‘krogh’,<br>| ‘polynomial’, ‘spline’ ‘piecewise_polynomial’, ‘pchip’}<br>|<br>| <em> ‘linear’: ignore the index and treat the values as equally<br>| spaced. This is the only method supported on MultiIndexes.<br>| default<br>| </em> ‘time’: interpolation works on daily and higher resolution<br>127<br>| data to interpolate given length of interval<br>| <em> ‘index’, ‘values’: use the actual numerical values of the index<br>| </em> ‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’,<br>| ‘barycentric’, ‘polynomial’ is passed to<br>| <code>scipy.interpolate.interp1d</code>. Both ‘polynomial’ and ‘spline’<br>| require that you also specify an <code>order</code> (int),<br>| e.g. df.interpolate(method=’polynomial’, order=4).<br>| These use the actual numerical values of the index.<br>| <em> ‘krogh’, ‘piecewise_polynomial’, ‘spline’, and ‘pchip’ are all<br>| wrappers around the scipy interpolation methods of similar<br>| names. These use the actual numerical values of the index. See<br>| the scipy documentation for more on their behavior<br>| <code>here &lt;http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation&gt;</code><strong><br>| <code>and here &lt;http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html&gt;</code></strong><br>|<br>| axis : {0, 1}, default 0<br>| </em> 0: fill column-by-column<br>| <em> 1: fill row-by-row<br>| limit : int, default None.<br>| Maximum number of consecutive NaNs to fill.<br>| limit_direction : {‘forward’, ‘backward’, ‘both’}, defaults to ‘forward’<br>| If limit is specified, consecutive NaNs will be filled in this<br>| direction.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| inplace : bool, default False<br>| Update the NDFrame in place if possible.<br>| downcast : optional, ‘infer’ or None, defaults to None<br>| Downcast dtypes if possible.<br>| kwargs : keyword arguments to pass on to the interpolating function.<br>|<br>| 【返回值】<br>| ——-| Series or DataFrame of same shape interpolated at the NaNs<br>|<br>| 【参见】<br>| ——–| reindex, replace, fillna<br>|<br>| 【示例】<br>| ——–|<br>| Filling in NaNs<br>|<br>| &gt;&gt;&gt; s = pd.Series([0, 1, np.nan, 3])<br>| &gt;&gt;&gt; s.interpolate()<br>| 0 0<br>| 1 1<br>| 2 2<br>| 3 3<br>| dtype: float64<br>|<br>| isnull(self)<br>| Return a boolean same-sized object indicating if the values are null<br>|<br>| 【参见】<br>128<br>| ——–| notnull : boolean inverse of isnull<br>|<br>| iterkv(self, </em>args, <strong>kwargs)<br>| iteritems alias used to get around 2to3. Deprecated<br>|<br>| keys(self)<br>| Get the ‘info axis’ (see Indexing for more)<br>|<br>| This is index for Series, columns for DataFrame and major_axis for<br>| Panel.<br>|<br>| last(self, offset)<br>| Convenience method for subsetting final periods of time series data<br>| based on a date offset<br>|<br>| 【参数】<br>| ———-| offset : string, DateOffset, dateutil.relativedelta<br>|<br>| 【示例】<br>| ——–| ts.last(‘5M’) -&gt; Last 5 months<br>|<br>| 【返回值】<br>| ——-| subset : type of caller<br>|<br>| mask(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)<br>| Return an object of same shape as self and whose corresponding<br>| entries are from self where cond is False and otherwise are from other.<br>|<br>| 【参数】<br>| ———-| cond : boolean NDFrame or array<br>| other : scalar or NDFrame<br>| inplace : boolean, default False<br>| Whether to perform the operation in place on the data<br>| axis : alignment axis if needed, default None<br>| level : alignment level if needed, default None<br>| try_cast : boolean, default False<br>| try to cast the result back to the input type (if possible),<br>| raise_on_error : boolean, default True<br>| Whether to raise on invalid data types (e.g. trying to where on<br>| strings)<br>|<br>| 【返回值】<br>| ——-| wh : same type as caller<br>|<br>| notnull(self)<br>| Return a boolean same-sized object indicating if the values are<br>| not null<br>|<br>| 【参见】<br>| ——–| isnull : boolean inverse of notnull<br>129<br>|<br>| pct_change(self, periods=1, fill_method=’pad’, limit=None, freq=None, </strong>kwargs)<br>| Percent change over given number of periods.<br>|<br>| 【参数】<br>| ———-| periods : int, default 1<br>| Periods to shift for forming percent change<br>| fill_method : str, default ‘pad’<br>| How to handle NAs before computing percent changes<br>| limit : int, default None<br>| The number of consecutive NAs to fill before stopping<br>| freq : DateOffset, timedelta, or offset alias string, optional<br>| Increment to use from time series API (e.g. ‘M’ or BDay())<br>|<br>| 【返回值】<br>| ——-| chg : NDFrame<br>|<br>| 【注意】<br>| —–|<br>| By default, the percentage change is calculated along the stat<br>| axis: 0, or <code>Index</code>, for <code>DataFrame</code> and 1, or <code>minor</code> for<br>| <code>Panel</code>. You can change this with the <code>axis</code> keyword argument.<br>|<br>| pipe(self, func, <em>args, **kwargs)<br>| Apply func(self, \</em>args, **kwargs)<br>|<br>| .. versionadded:: 0.16.2<br>|<br>| 【参数】<br>| ———-| func : function<br>| function to apply to the NDFrame.<br>| <code>args</code>, and <code>kwargs</code> are passed into <code>func</code>.<br>| Alternatively a <code>(callable, data_keyword)</code> tuple where<br>| <code>data_keyword</code> is a string indicating the keyword of<br>| <code>callable</code> that expects the NDFrame.<br>| args : positional arguments passed into <code>func</code>.<br>| kwargs : a dictionary of keyword arguments passed into <code>func</code>.<br>|<br>| 【返回值】<br>| ——-| object : the return type of <code>func</code>.<br>|<br>| 【注意】<br>| —–|<br>| Use <code>.pipe</code> when chaining together functions that expect<br>| on Series or DataFrames. Instead of writing<br>|<br>| &gt;&gt;&gt; f(g(h(df), arg1=a), arg2=b, arg3=c)<br>|<br>| You can write<br>|<br>| &gt;&gt;&gt; (df.pipe(h)<br>130<br>| … .pipe(g, arg1=a)<br>| … .pipe(f, arg2=b, arg3=c)<br>| … )<br>|<br>| If you have a function that takes the data as (say) the second<br>| argument, pass a tuple indicating which keyword expects the<br>| data. For example, suppose <code>f</code> takes its data as <code>arg2</code>:<br>|<br>| &gt;&gt;&gt; (df.pipe(h)<br>| … .pipe(g, arg1=a)<br>| … .pipe((f, ‘arg2’), arg1=a, arg3=c)<br>| … )<br>|<br>| 【参见】<br>| ——–| pandas.DataFrame.apply<br>| pandas.DataFrame.applymap<br>| pandas.Series.map<br>|<br>| pop(self, item)<br>| Return item and drop from frame. Raise KeyError if not found.<br>|<br>| reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)<br>| return an object with matching indicies to myself<br>|<br>| 【参数】<br>| ———-| other : Object<br>| method : string or None<br>| copy : boolean, default True<br>| limit : int, default None<br>| Maximum number of consecutive labels to fill for inexact matches.<br>| tolerance : optional<br>| Maximum distance between labels of the other object and this<br>| object for inexact matches.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【注意】<br>| —–| Like calling s.reindex(index=other.index, columns=other.columns,<br>| method=…)<br>|<br>| 【返回值】<br>| ——-| reindexed : same as input<br>|<br>| rename_axis(self, mapper, axis=0, copy=True, inplace=False)<br>| Alter index and / or columns using input function or functions.<br>| Function / dict values must be unique (1-to-1). Labels not contained in<br>| a dict / Series will be left as-is.<br>|<br>| 【参数】<br>| ———-| mapper : dict-like or function, optional<br>| axis : int or string, default 0<br>| copy : boolean, default True<br>131<br>| Also copy underlying data<br>| inplace : boolean, default False<br>|<br>| 【返回值】<br>| ——-| renamed : type of caller<br>|<br>| replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method=’pad’, axis=None)<br>| Replace values given in ‘to_replace’ with ‘value’.<br>|<br>| 【参数】<br>| ———-| to_replace : str, regex, list, dict, Series, numeric, or None<br>|<br>| <em> str or regex:<br>|<br>| - str: string exactly matching <code>to_replace</code> will be replaced<br>| with <code>value</code><br>| - regex: regexs matching <code>to_replace</code> will be replaced with<br>| <code>value</code><br>|<br>| </em> list of str, regex, or numeric:<br>|<br>| - First, if <code>to_replace</code> and <code>value</code> are both lists, they<br>| <strong>must</strong> be the same length.<br>| - Second, if <code>regex=True</code> then all of the strings in <strong>both</strong><br>| lists will be interpreted as regexs otherwise they will match<br>| directly. This doesn’t matter much for <code>value</code> since there<br>| are only a few possible substitution regexes you can use.<br>| - str and regex rules apply as above.<br>|<br>| <em> dict:<br>|<br>| - Nested dictionaries, e.g., {‘a’: {‘b’: nan}}, are read as<br>| follows: look in column ‘a’ for the value ‘b’ and replace it<br>| with nan. You can nest regular expressions as well. Note that<br>| column names (the top-level dictionary keys in a nested<br>| dictionary) <strong>cannot</strong> be regular expressions.<br>| - Keys map to column names and values map to substitution<br>| values. You can treat this as a special case of passing two<br>| lists except that you are specifying the column to search in.<br>|<br>| </em> None:<br>|<br>| - This means that the <code>regex</code> argument must be a string,<br>| compiled regular expression, or list, dict, ndarray or Series<br>| of such elements. If <code>value</code> is also <code>None</code> then this<br>| <strong>must</strong> be a nested dictionary or <code>Series</code>.<br>|<br>| See the examples section for examples of each of these.<br>| value : scalar, dict, list, str, regex, default None<br>| Value to use to fill holes (e.g. 0), alternately a dict of values<br>| specifying which value to use for each column (columns not in the<br>| dict will not be filled). Regular expressions, strings and lists or<br>| dicts of such objects are also allowed.<br>| inplace : boolean, default False<br>| If True, in place. Note: this will modify any<br>132<br>| other views on this object (e.g. a column form a DataFrame).<br>| Returns the caller if this is True.<br>| limit : int, default None<br>| Maximum size gap to forward or backward fill<br>| regex : bool or same types as <code>to_replace</code>, default False<br>| Whether to interpret <code>to_replace</code> and/or <code>value</code> as regular<br>| expressions. If this is <code>True</code> then <code>to_replace</code> <em>must</em> be a<br>| string. Otherwise, <code>to_replace</code> must be <code>None</code> because this<br>| parameter will be interpreted as a regular expression or a list,<br>| dict, or array of regular expressions.<br>| method : string, optional, {‘pad’, ‘ffill’, ‘bfill’}<br>| The method to use when for replacement, when <code>to_replace</code> is a<br>| <code>list</code>.<br>|<br>| 【参见】<br>| ——–| NDFrame.reindex<br>| NDFrame.asfreq<br>| NDFrame.fillna<br>|<br>| 【返回值】<br>| ——-| filled : NDFrame<br>|<br>| 【Raises 引发错误】<br>| ——| AssertionError<br>| <em> If <code>regex</code> is not a <code>bool</code> and <code>to_replace</code> is not <code>None</code>.<br>| TypeError<br>| </em> If <code>to_replace</code> is a <code>dict</code> and <code>value</code> is not a <code>list</code>,<br>| <code>dict</code>, <code>ndarray</code>, or <code>Series</code><br>| <em> If <code>to_replace</code> is <code>None</code> and <code>regex</code> is not compilable into a<br>| regular expression or is a list, dict, ndarray, or Series.<br>| ValueError<br>| </em> If <code>to_replace</code> and <code>value</code> are <code>list</code> s or <code>ndarray</code> s, but<br>| they are not the same length.<br>|<br>| 【注意】<br>| —–| <em> Regex substitution is performed under the hood with <code>re.sub</code>. The<br>| rules for substitution for <code>re.sub</code> are the same.<br>| </em> Regular expressions will only substitute on strings, meaning you<br>| cannot provide, for example, a regular expression matching floating<br>| point numbers and expect the columns in your frame that have a<br>| numeric dtype to be matched. However, if those floating point numbers<br>| <em>are</em> strings, then you can do this.<br>| <em> This method has </em>a lot<em> of options. You are encouraged to experiment<br>| and play with this method to gain intuition about how it works.<br>|<br>| resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention=’start’, kind=None,<br>loffset=None, limit=None, base=0)<br>| Convenience method for frequency conversion and resampling of regular<br>| time-series data.<br>|<br>| 【参数】<br>| ———-| rule : string<br>133<br>| the offset string or object representing target conversion<br>| how : string<br>| method for down- or re-sampling, default to ‘mean’ for<br>| downsampling<br>| axis : int, optional, default 0<br>| fill_method : string, default None<br>| fill_method for upsampling<br>| closed : {‘right’, ‘left’}<br>| Which side of bin interval is closed<br>| label : {‘right’, ‘left’}<br>| Which bin edge label to label bucket with<br>| convention : {‘start’, ‘end’, ‘s’, ‘e’}<br>| kind : “period”/“timestamp”<br>| loffset : timedelta<br>| Adjust the resampled time labels<br>| limit : int, default None<br>| Maximum size gap to when reindexing with fill_method<br>| base : int, default 0<br>| For frequencies that evenly subdivide 1 day, the “origin” of the<br>| aggregated intervals. For example, for ‘5min’ frequency, base could<br>| range from 0 through 4. Defaults to 0<br>|<br>|<br>| 【示例】<br>| ——–|<br>| Start by creating a series with 9 one minute timestamps.<br>|<br>| &gt;&gt;&gt; index = pd.date_range(‘1/1/2000’, periods=9, freq=’T’)<br>| &gt;&gt;&gt; series = pd.Series(range(9), index=index)<br>| &gt;&gt;&gt; series<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:01:00 1<br>| 2000-01-01 00:02:00 2<br>| 2000-01-01 00:03:00 3<br>| 2000-01-01 00:04:00 4<br>| 2000-01-01 00:05:00 5<br>| 2000-01-01 00:06:00 6<br>| 2000-01-01 00:07:00 7<br>| 2000-01-01 00:08:00 8<br>| Freq: T, dtype: int64<br>|<br>| Downsample the series into 3 minute bins and sum the values<br>| of the timestamps falling into a bin.<br>|<br>| &gt;&gt;&gt; series.resample(‘3T’, how=’sum’)<br>| 2000-01-01 00:00:00 3<br>| 2000-01-01 00:03:00 12<br>| 2000-01-01 00:06:00 21<br>| Freq: 3T, dtype: int64<br>|<br>| Downsample the series into 3 minute bins as above, but label each<br>| bin using the right edge instead of the left. Please note that the<br>| value in the bucket used as the label is not included in the bucket,<br>| which it labels. For example, in the original series the<br>| bucket <code>2000-01-01 00:03:00</code> contains the value 3, but the summed<br>| value in the resampled bucket with the label<code>2000-01-01 00:03:00</code><br>134<br>| does not include 3 (if it did, the summed value would be 6, not 3).<br>| To include this value close the right side of the bin interval as<br>| illustrated in the example below this one.<br>|<br>| &gt;&gt;&gt; series.resample(‘3T’, how=’sum’, label=’right’)<br>| 2000-01-01 00:03:00 3<br>| 2000-01-01 00:06:00 12<br>| 2000-01-01 00:09:00 21<br>| Freq: 3T, dtype: int64<br>|<br>| Downsample the series into 3 minute bins as above, but close the right<br>| side of the bin interval.<br>|<br>| &gt;&gt;&gt; series.resample(‘3T’, how=’sum’, label=’right’, closed=’right’)<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:03:00 6<br>| 2000-01-01 00:06:00 15<br>| 2000-01-01 00:09:00 15<br>| Freq: 3T, dtype: int64<br>|<br>| Upsample the series into 30 second bins.<br>|<br>| &gt;&gt;&gt; series.resample(‘30S’)[0:5] #select first 5 rows<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:00:30 NaN<br>| 2000-01-01 00:01:00 1<br>| 2000-01-01 00:01:30 NaN<br>| 2000-01-01 00:02:00 2<br>| Freq: 30S, dtype: float64<br>|<br>| Upsample the series into 30 second bins and fill the <code>NaN</code><br>| values using the <code>pad</code> method.<br>|<br>| &gt;&gt;&gt; series.resample(‘30S’, fill_method=’pad’)[0:5]<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:00:30 0<br>| 2000-01-01 00:01:00 1<br>| 2000-01-01 00:01:30 1<br>| 2000-01-01 00:02:00 2<br>| Freq: 30S, dtype: int64<br>|<br>| Upsample the series into 30 second bins and fill the<br>| <code>NaN</code> values using the <code>bfill</code> method.<br>|<br>| &gt;&gt;&gt; series.resample(‘30S’, fill_method=’bfill’)[0:5]<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:00:30 1<br>| 2000-01-01 00:01:00 1<br>| 2000-01-01 00:01:30 2<br>| 2000-01-01 00:02:00 2<br>| Freq: 30S, dtype: int64<br>|<br>| Pass a custom function to <code>how</code>.<br>|<br>| &gt;&gt;&gt; def custom_resampler(array_like):<br>| … return np.sum(array_like)+5<br>|<br>135<br>| &gt;&gt;&gt; series.resample(‘3T’, how=custom_resampler)<br>| 2000-01-01 00:00:00 8<br>| 2000-01-01 00:03:00 17<br>| 2000-01-01 00:06:00 26<br>| Freq: 3T, dtype: int64<br>|<br>| sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)<br>| Returns a random sample of items from an axis of object.<br>|<br>| .. versionadded:: 0.16.1<br>|<br>| 【参数】<br>| ———-| n : int, optional<br>| Number of items from axis to return. Cannot be used with <code>frac</code>.<br>| Default = 1 if <code>frac</code> = None.<br>| frac : float, optional<br>| Fraction of axis items to return. Cannot be used with <code>n</code>.<br>| replace : boolean, optional<br>| Sample with or without replacement. Default = False.<br>| weights : str or ndarray-like, optional<br>| Default ‘None’ results in equal probability weighting.<br>| If passed a Series, will align with target object on index. Index<br>| values in weights not found in sampled object will be ignored and<br>| index values in sampled object not in weights will be assigned<br>| weights of zero.<br>| If called on a DataFrame, will accept the name of a column<br>| when axis = 0.<br>| Unless weights are a Series, weights must be same length as axis<br>| being sampled.<br>| If weights do not sum to 1, they will be normalized to sum to 1.<br>| Missing values in the weights column will be treated as zero.<br>| inf and -inf values not allowed.<br>| random_state : int or numpy.random.RandomState, optional<br>| Seed for the random number generator (if int), or numpy RandomState<br>| object.<br>| axis : int or string, optional<br>| Axis to sample. Accepts axis number or name. Default is stat axis<br>| for given data type (0 for Series and DataFrames, 1 for Panels).<br>|<br>| 【返回值】<br>| ——-| A new object of same type as caller.<br>|<br>| select(self, crit, axis=0)<br>| Return data corresponding to axis labels matching criteria<br>|<br>| 【参数】<br>| ———-| crit : function<br>| To be called on each index (label). Should return True or False<br>| axis : int<br>|<br>| 【返回值】<br>| ——-| selection : type of caller<br>|<br>136<br>| set_axis(self, axis, labels)<br>| public verson of axis assignment<br>|<br>| slice_shift(self, periods=1, axis=0)<br>| Equivalent to <code>shift</code> without copying data. The shifted data will<br>| not include the dropped periods and the shifted axis will be smaller<br>| than the original.<br>|<br>| 【参数】<br>| ———-| periods : int<br>| Number of periods to move, can be positive or negative<br>|<br>| 【注意】<br>| —–| While the <code>slice_shift</code> is faster than <code>shift</code>, you may pay for it<br>| later during alignment.<br>|<br>| 【返回值】<br>| ——-| shifted : same type as caller<br>|<br>| squeeze(self)<br>| squeeze length 1 dimensions<br>|<br>| swapaxes(self, axis1, axis2, copy=True)<br>| Interchange axes and swap values axes appropriately<br>|<br>| 【返回值】<br>| ——-| y : same as input<br>|<br>| tail(self, n=5)<br>| Returns last n rows<br>|<br>| take(self, indices, axis=0, convert=True, is_copy=True)<br>| Analogous to ndarray.take<br>|<br>| 【参数】<br>| ———-| indices : list / array of ints<br>| axis : int, default 0<br>| convert : translate neg to pos indices (default)<br>| is_copy : mark the returned frame as a copy<br>|<br>| 【返回值】<br>| ——-| taken : type of caller<br>|<br>| to_clipboard(self, excel=None, sep=None, <strong>kwargs)<br>| Attempt to write text representation of object to the system clipboard<br>| This can be pasted into Excel, for example.<br>|<br>| 【参数】<br>| ———-| excel : boolean, defaults to True<br>| if True, use the provided separator, writing in a csv<br>137<br>| format for allowing easy pasting into excel.<br>| if False, write a string representation of the object<br>| to the clipboard<br>| sep : optional, defaults to tab<br>| other keywords are passed to to_csv<br>|<br>| 【注意】<br>| —–| Requirements for your platform<br>| - Linux: xclip, or xsel (with gtk or PyQt4 modules)<br>| - Windows: none<br>| - OS X: none<br>|<br>| to_dense(self)<br>| Return dense representation of NDFrame (as opposed to sparse)<br>|<br>| to_hdf(self, path_or_buf, key, </strong>kwargs)<br>| activate the HDFStore<br>|<br>| 【参数】<br>| ———-| path_or_buf : the path (string) or HDFStore object<br>| key : string<br>| indentifier for the group in the store<br>| mode : optional, {‘a’, ‘w’, ‘r’, ‘r+’}, default ‘a’<br>|<br>| <code>&#39;r&#39;</code><br>| Read-only; no data can be modified.<br>| <code>&#39;w&#39;</code><br>| Write; a new file is created (an existing file with the same<br>| name would be deleted).<br>| <code>&#39;a&#39;</code><br>| Append; an existing file is opened for reading and writing,<br>| and if the file does not exist it is created.<br>| <code>&#39;r+&#39;</code><br>| It is similar to <code>&#39;a&#39;</code>, but the file must already exist.<br>| format : ‘fixed(f)|table(t)’, default is ‘fixed’<br>| fixed(f) : Fixed format<br>| Fast writing/reading. Not-appendable, nor searchable<br>| table(t) : Table format<br>| Write as a PyTables Table structure which may perform<br>| worse but allow more flexible operations like searching<br>| / selecting subsets of the data<br>| append : boolean, default False<br>| For Table formats, append the input data to the existing<br>| complevel : int, 1-9, default 0<br>| If a complib is specified compression will be applied<br>| where possible<br>| complib : {‘zlib’, ‘bzip2’, ‘lzo’, ‘blosc’, None}, default None<br>| If complevel is &gt; 0 apply compression to objects written<br>| in the store wherever possible<br>| fletcher32 : bool, default False<br>| If applying compression use the fletcher32 checksum<br>| dropna : boolean, default False.<br>| If true, ALL nan rows will not be written to store.<br>|<br>| to_json(self, path_or_buf=None, orient=None, date_format=’epoch’, double_precision=10, force_ascii=True, date_unit=’ms’,<br>138<br>default_handler=None)<br>| Convert the object to a JSON string.<br>|<br>| Note NaN’s and None will be converted to null and datetime objects<br>| will be converted to UNIX timestamps.<br>|<br>| 【参数】<br>| ———-| path_or_buf : the path or buffer to write the result string<br>| if this is None, return a StringIO of the converted string<br>| orient : string<br>|<br>| </em> Series<br>|<br>| - default is ‘index’<br>| - allowed values are: {‘split’,’records’,’index’}<br>|<br>| <em> DataFrame<br>|<br>| - default is ‘columns’<br>| - allowed values are:<br>| {‘split’,’records’,’index’,’columns’,’values’}<br>|<br>| </em> The format of the JSON string<br>|<br>| - split : dict like<br>| {index -&gt; [index], columns -&gt; [columns], data -&gt; [values]}<br>| - records : list like<br>| [{column -&gt; value}, … , {column -&gt; value}]<br>| - index : dict like {index -&gt; {column -&gt; value}}<br>| - columns : dict like {column -&gt; {index -&gt; value}}<br>| - values : just the values array<br>|<br>| date_format : {‘epoch’, ‘iso’}<br>| Type of date conversion. <code>epoch</code> = epoch milliseconds,<br>| <code>iso`` = ISO8601, default is epoch.
| double_precision : The number of decimal places to use when encoding
| floating point values, default 10.
| force_ascii : force encoded string to be ASCII, default True.
| date_unit : string, default &#39;ms&#39; (milliseconds)
| The time unit to encode to, governs timestamp and ISO8601
| precision. One of &#39;s&#39;, &#39;ms&#39;, &#39;us&#39;, &#39;ns&#39; for second, millisecond,
| microsecond, and nanosecond respectively.
| default_handler : callable, default None
| Handler to call if object cannot otherwise be converted to a
| suitable format for JSON. Should receive a single argument which is
| the object to convert and return a serialisable object.
|
| 【返回值】
| -------| same type as input object with filtered info axis
|
| to_msgpack(self, path_or_buf=None, **kwargs)
| msgpack (serialize) object to input file path
|
| THIS IS AN EXPERIMENTAL LIBRARY and the storage format
| may not be stable until a future release.
139
|
| 【参数】
| ----------| path : string File path, buffer-like, or None
| if None, return generated string
| append : boolean whether to append to an existing msgpack
| (default is False)
| compress : type of compressor (zlib or blosc), default to None (no
| compression)
|
| to_pickle(self, path)
| Pickle (serialize) object to input file path
|
| 【参数】
| ----------| path : string
| File path
|
| to_sql(self, name, con, flavor=&#39;sqlite&#39;, schema=None, if_exists=&#39;fail&#39;, index=True, index_label=None, chunksize=None,
dtype=None)
| Write records stored in a DataFrame to a SQL database.
|
| 【参数】
| ----------| name : string
| Name of SQL table
| con : SQLAlchemy engine or DBAPI2 connection (legacy mode)
| Using SQLAlchemy makes it possible to use any DB supported by that
| library.
| If a DBAPI2 object, only sqlite3 is supported.
| flavor : {&#39;sqlite&#39;, &#39;mysql&#39;}, default &#39;sqlite&#39;
| The flavor of SQL to use. Ignored when using SQLAlchemy engine.
| &#39;mysql&#39; is deprecated and will be removed in future versions, but it
| will be further supported through SQLAlchemy engines.
| schema : string, default None
| Specify the schema (if database flavor supports this). If None, use
| default schema.
| if_exists : {&#39;fail&#39;, &#39;replace&#39;, &#39;append&#39;}, default &#39;fail&#39;
| - fail: If table exists, do nothing.
| - replace: If table exists, drop it, recreate it, and insert data.
| - append: If table exists, insert data. Create if does not exist.
| index : boolean, default True
| Write DataFrame index as a column.
| index_label : string or sequence, default None
| Column label for index column(s). If None is given (default) and
|</code>index<code>is True, then the index names are used.
| A sequence should be given if the DataFrame uses MultiIndex.
| chunksize : int, default None
| If not None, then rows will be written in batches of this size at a
| time. If None, all rows will be written at once.
| dtype : dict of column name to SQL type, default None
| Optional specifying the datatype for columns. The SQL type should
| be a SQLAlchemy type, or a string for sqlite3 fallback connection.
|
| truncate(self, before=None, after=None, axis=None, copy=True)
| Truncates a sorted NDFrame before and/or after some particular
| dates.
140
|
| 【参数】
| ----------| before : date
| Truncate before date
| after : date
| Truncate after date
| axis : the truncation axis, defaults to the stat axis
| copy : boolean, default is True,
| return a copy of the truncated section
|
| 【返回值】
| -------| truncated : type of caller
|
| tshift(self, periods=1, freq=None, axis=0)
| Shift the time index, using the index&#39;s frequency if available
|
| 【参数】
| ----------| periods : int
| Number of periods to move, can be positive or negative
| freq : DateOffset, timedelta, or time rule string, default None
| Increment to use from datetools module or time rule (e.g. &#39;EOM&#39;)
| axis : int or basestring
| Corresponds to the axis that contains the Index
|
| 【注意】
| -----| If freq is not specified then tries to use the freq or inferred_freq
| attributes of the index. If neither of those attributes exist, a
| ValueError is thrown
|
| 【返回值】
| -------| shifted : NDFrame
|
| tz_convert(self, tz, axis=0, level=None, copy=True)
| Convert tz-aware axis to target time zone.
|
| 【参数】
| ----------| tz : string or pytz.timezone object
| axis : the axis to convert
| level : int, str, default None
| If axis ia a MultiIndex, convert a specific level. Otherwise
| must be None
| copy : boolean, default True
| Also make a copy of the underlying data
|
| 【返回值】
| -------|
| 【Raises 引发错误】
| ------| TypeError
141
| If the axis is tz-naive.
|
| tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous=&#39;raise&#39;)
| Localize tz-naive TimeSeries to target time zone
|
| 【参数】
| ----------| tz : string or pytz.timezone object
| axis : the axis to localize
| level : int, str, default None
| If axis ia a MultiIndex, localize a specific level. Otherwise
| must be None
| copy : boolean, default True
| Also make a copy of the underlying data
| ambiguous : &#39;infer&#39;, bool-ndarray, &#39;NaT&#39;, default &#39;raise&#39;
| - &#39;infer&#39; will attempt to infer fall dst-transition hours based on order
| - bool-ndarray where True signifies a DST time, False designates
| a non-DST time (note that this flag is only applicable for ambiguous times)
| - &#39;NaT&#39; will return NaT where there are ambiguous times
| - &#39;raise&#39; will raise an AmbiguousTimeError if there are ambiguous times
| infer_dst : boolean, default False (DEPRECATED)
| Attempt to infer fall dst-transition hours based on order
|
| 【返回值】
| -------|
| 【Raises 引发错误】
| ------| TypeError
| If the TimeSeries is tz-aware and tz is not None.
|
| where(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)
| Return an object of same shape as self and whose corresponding
| entries are from self where cond is True and otherwise are from other.
|
| 【参数】
| ----------| cond : boolean NDFrame or array
| other : scalar or NDFrame
| inplace : boolean, default False
| Whether to perform the operation in place on the data
| axis : alignment axis if needed, default None
| level : alignment level if needed, default None
| try_cast : boolean, default False
| try to cast the result back to the input type (if possible),
| raise_on_error : boolean, default True
| Whether to raise on invalid data types (e.g. trying to where on
| strings)
|
| 【返回值】
| -------| wh : same type as caller
|
| xs(self, key, axis=0, level=None, copy=None, drop_level=True)
| Returns a cross-section (row(s) or column(s)) from the Series/DataFrame.
| Defaults to cross-section on the rows (axis=0).
|
142
| 【参数】
| ----------| key : object
| Some label contained in the index, or partially in a MultiIndex
| axis : int, default 0
| Axis to retrieve cross-section on
| level : object, defaults to first n levels (n=1 or len(key))
| In case of a key partially contained in a MultiIndex, indicate
| which levels are used. Levels can be referred by label or position.
| copy : boolean [deprecated]
| Whether to make a copy of the data
| drop_level : boolean, default True
| If False, returns object with same levels as self.
|
| 【示例】
| --------| &gt;&gt;&gt; df
| A B C
| a 4 5 2
| b 4 0 9
| c 9 7 3
| &gt;&gt;&gt; df.xs(&#39;a&#39;)
| A 4
| B 5
| C 2
| Name: a
| &gt;&gt;&gt; df.xs(&#39;C&#39;, axis=1)
| a 2
| b 9
| c 3
| Name: C
|
| &gt;&gt;&gt; df
| A B C D
| first second third
| bar one 1 4 1 8 9
| two 1 7 5 5 0
| baz one 1 6 6 8 0
| three 2 5 3 5 3
| &gt;&gt;&gt; df.xs((&#39;baz&#39;, &#39;three&#39;))
| A B C D
| third
| 2 5 3 5 3
| &gt;&gt;&gt; df.xs(&#39;one&#39;, level=1)
| A B C D
| first third
| bar 1 4 1 8 9
| baz 1 6 6 8 0
| &gt;&gt;&gt; df.xs((&#39;baz&#39;, 2), level=[0, &#39;third&#39;])
| A B C D
| second
| three 5 3 5 3
|
| 【返回值】
| -------| xs : Series or DataFrame
|
143
| 【注意】
| -----| xs is only for getting, not setting values.
|
| MultiIndex Slicers is a generic way to get/set values on any level or levels
| it is a superset of xs functionality, see :ref:</code>MultiIndex Slicers <advanced.mi_slicers><code>|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.generic.NDFrame:
|
| at
| Fast label-based scalar accessor
|
| Similarly to ``loc``, ``at`` provides **label** based scalar lookups.
| You can also set using these indexers.
|
| blocks
| Internal property, property synonym for as_blocks()
|
| dtypes
| Return the dtypes in this object
|
| empty
| True if NDFrame is entirely empty [no items]
|
| ftypes
| Return the ftypes (indication of sparse/dense and dtype)
| in this object.
|
| iat
| Fast integer location scalar accessor.
|
| Similarly to ``iloc``, ``iat`` provides **integer** based lookups.
| You can also set using these indexers.
|
| iloc
| Purely integer-location based indexing for selection by position.
|
| ``.iloc[]`` is primarily integer position based (from ``0`` to
| ``length-1`` of the axis), but may also be used with a boolean
| array.
|
| Allowed inputs are:
|
| - An integer, e.g. ``5``.
| - A list or array of integers, e.g. ``[4, 3, 0]``.
| - A slice object with ints, e.g. ``1:7``.
| - A boolean array.
|
| ``.iloc`` will raise ``IndexError`` if a requested indexer is
| out-of-bounds, except *slice* indexers which allow out-of-bounds
| indexing (this conforms with python/numpy *slice* semantics).
|
| See more at :ref:</code>Selection by Position <indexing.integer><code>|
| ix
| A primarily label-location based indexer, with integer position
144
| fallback.
|
| ``.ix[]`` supports mixed integer and label based access. It is
| primarily label based, but will fall back to integer positional
| access unless the corresponding axis is of integer type.
|
| ``.ix`` is the most general indexer and will support any of the
| inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating
| point label schemes. ``.ix`` is exceptionally useful when dealing
| with mixed positional and label based hierachical indexes.
|
| However, when an axis is integer based, ONLY label based access
| and not positional access is supported. Thus, in such cases, it&#39;s
| usually better to be explicit and use ``.iloc`` or ``.loc``.
|
| See more at :ref:</code>Advanced Indexing <advanced><code>.
|
| loc
| Purely label-location based indexer for selection by label.
|
| ``.loc[]`` is primarily label based, but may also be used with a
| boolean array.
|
| Allowed inputs are:
|
| - A single label, e.g. ``5`` or ``&#39;a&#39;``, (note that ``5`` is
| interpreted as a *label* of the index, and **never** as an
| integer position along the index).
| - A list or array of labels, e.g. ``[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]``.
| - A slice object with labels, e.g. ``&#39;a&#39;:&#39;f&#39;`` (note that contrary
| to usual python slices, **both** the start and the stop are included!).
| - A boolean array.
|
| ``.loc`` will raise a ``KeyError`` when the items are not found.
|
| See more at :ref:</code>Selection by Label <indexing.label><code>|
| ndim
| Number of axes / array dimensions
|
| size
| number of elements in the NDFrame
|
| values
| Numpy representation of NDFrame
|
| 【注意】
| -----| The dtype will be a lower-common-denominator dtype (implicit
| upcasting); that is to say if the dtypes (even of numeric types)
| are mixed, the one that accommodates all will be chosen. Use this
| with care if you are not dealing with the blocks.
|
| e.g. If the dtypes are float16 and float32, dtype will be upcast to
| float32. If dtypes are int32 and uint8, dtype will be upcase to
| int32.
|
145
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.generic.NDFrame:
|
| is_copy = None
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.PandasObject:
|
| __dir__(self)
| Provide method name lookup and completion
| Only provide &#39;public&#39; methods
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
| Return a string representation for a particular object.
|
| Invoked by bytes(obj) in py3 only.
| Yields a bytestring in both py2/py3.
|
| __repr__(self)
| Return a string representation for a particular object.
|
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.base.StringMixin:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
DateOffset
DateOffset 模块所属：pandas.tseries.offsets:
类定义：DateOffset(builtins.object)
| Standard kind of date increment used for a date range.
|
| Works exactly like relativedelta in terms of the keyword args you
| pass in, use of the keyword n is discouraged-- you would be better
146
| off specifying n in the keywords you use, but regardless it is
| there for you. n is needed for DateOffset subclasses.
|
| DateOffets work as follows. Each offset specify a set of dates
| that conform to the DateOffset. For example, Bday defines this
| set to be the set of dates that are weekdays (M-F). To test if a
| date is in the set of a DateOffset dateOffset we can use the
| onOffset method: dateOffset.onOffset(date).
|
| If a date is not on a valid date, the rollback and rollforward
| methods can be used to roll the date to the nearest valid date
| before/after the date.
|
| DateOffsets can be created to move dates forward a given number of
| valid dates. For example, Bday(2) can be added to a date to move
| it two business days forward. If the date does not start on a
| valid date, first it is moved to a valid date. Thus psedo code
| is:
|
| def __add__(date):
| date = rollback(date) # does nothing if date is valid
| return date + &lt;n number of periods&gt;
|
| When a date offset is created for a negitive number of periods,
| the date is first rolled forward. The pseudo code is:
|
| def __add__(date):
| date = rollforward(date) # does nothing is date is valid
| return date + &lt;n number of periods&gt;
|
| Zero presents a problem. Should it roll forward or back? We
| arbitrarily have it rollforward:
|
| date + BDay(0) == BDay.rollforward(date)
|
| Since 0 is a bit weird, we suggest avoiding its use.
|
| 【方法定义】
|
| __add__(self, other)
|
| __call__(self, other)
| Call self as a function.
|
| __eq__(self, other)
| Return self==value.
|
| __hash__(self)
| Return hash(self).
|
| __init__(self, n=1, normalize=False, **kwds)
| Initialize self. See help(type(self)) for accurate signature.
|
| __mul__(self, someInt)
|
| __ne__(self, other)
| Return self!=value.
147
|
| __neg__(self)
|
| __radd__(self, other)
|
| __repr__(self)
| Return repr(self).
|
| __rmul__(self, someInt)
|
| __rsub__(self, other)
|
| __sub__(self, other)
|
| apply(self, other)
|
| apply_index(self, i)
| Vectorized apply of DateOffset to DatetimeIndex,
| raises NotImplentedError for offsets without a
| vectorized implementation
|
| .. versionadded:: 0.17.0
|
| 【参数】
| ----------| i : DatetimeIndex
|
| 【返回值】
| -------| y : DatetimeIndex
|
| copy(self)
|
| isAnchored(self)
|
| onOffset(self, dt)
|
| rollback(self, dt)
| Roll provided date backward to next offset only if not on offset
|
| rollforward(self, dt)
| Roll provided date forward to next offset only if not on offset
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
|
| freqstr
|
| name
|
| rule_code
148
|
| ----------------------------------------------------------------------| 其他数据、属性定义：
|
| normalize = False
DatetimeIndex
DatetimeIndex 模块所属：pandas.tseries.index:
类 定 义 ： DatetimeIndex(pandas.tseries.base.DatelikeOps, pandas.tseries.base.DatetimeIndexOpsMixin,
pandas.core.index.Int64Index)
| Immutable ndarray of datetime64 data, represented internally as int64, and
| which can be boxed to Timestamp objects that are subclasses of datetime and
| carry metadata such as frequency information.
|
| 【参数】
| ----------| data : array-like (1-dimensional), optional
| Optional datetime-like data to construct index with
| copy : bool
| Make a copy of input ndarray
| freq : string or pandas offset object, optional
| One of pandas date offset strings or corresponding objects
| start : starting value, datetime-like, optional
| If data is None, start is used as the start point in generating regular
| timestamp data.
| periods : int, optional, &gt; 0
| Number of periods to generate, if generating index. Takes precedence
| over end argument
| end : end time, datetime-like, optional
| If periods is none, generated index will extend to first conforming
| time on or just past end argument
| closed : string or None, default None
| Make the interval closed with respect to the given frequency to
| the &#39;left&#39;, &#39;right&#39;, or both sides (None)
| tz : pytz.timezone or dateutil.tz.tzfile
| ambiguous : &#39;infer&#39;, bool-ndarray, &#39;NaT&#39;, default &#39;raise&#39;
| - &#39;infer&#39; will attempt to infer fall dst-transition hours based on order
| - bool-ndarray where True signifies a DST time, False signifies
| a non-DST time (note that this flag is only applicable for ambiguous times)
| - &#39;NaT&#39; will return NaT where there are ambiguous times
| - &#39;raise&#39; will raise an AmbiguousTimeError if there are ambiguous times
| infer_dst : boolean, default False (DEPRECATED)
| Attempt to infer fall dst-transition hours based on order
| name : object
| Name to be stored in the index
|
| 【方法排序】
| DatetimeIndex
149
| pandas.tseries.base.DatelikeOps
| pandas.tseries.base.DatetimeIndexOpsMixin
| pandas.core.index.Int64Index
| pandas.core.index.NumericIndex
| pandas.core.index.Index
| pandas.core.base.IndexOpsMixin
| pandas.core.strings.StringAccessorMixin
| pandas.core.base.PandasObject
| pandas.core.base.StringMixin
| 【内置对象】
|
| 【方法定义】
|
| __abs__(self, other=None)
|
| __add__(self, other)
|
| __eq__ = wrapper(self, other)
|
| __floordiv__(self, other=None)
|
| __ge__ = wrapper(self, other)
|
| __gt__ = wrapper(self, other)
|
| __iadd__ = __add__(self, other)
|
| __inv__(self, other=None)
|
| __isub__ = __sub__(self, other)
|
| __iter__(self)
| Return an iterator over the boxed values
|
| 【返回值】
| -------| Timestamps : ndarray
|
| __le__ = wrapper(self, other)
|
| __lt__ = wrapper(self, other)
|
| __mul__(self, other=None)
|
| __ne__ = wrapper(self, other)
|
| __neg__(self, other=None)
|
| __pos__(self, other=None)
|
| __radd__ = __add__(self, other)
|
| __reduce__(self)
| helper for pickle
|
| __rfloordiv__ = __floordiv__(self, other=None)
|
150
| __rmul__ = __mul__(self, other=None)
|
| __rsub__(self, other)
|
| __rtruediv__ = __truediv__(self, other=None)
|
| __setstate__(self, state)
| Necessary for making this object picklable
|
| __sub__(self, other)
|
| __truediv__(self, other=None)
|
| all(self, other=None)
|
| any(self, other=None)
|
| append(self, other)
| Append a collection of Index options together
|
| 【参数】
| ----------| other : Index or list/tuple of indices
|
| 【返回值】
| -------| appended : Index
|
| astype(self, dtype)
|
| delete(self, loc)
| Make a new DatetimeIndex with passed location(s) deleted.
|
| 【参数】
| ----------| loc: int, slice or array of ints
| Indicate which sub-arrays to remove.
|
| 【返回值】
| -------| new_index : DatetimeIndex
|
| equals(self, other)
| Determines if two Index objects contain the same elements.
|
| get_loc(self, key, method=None, tolerance=None)
| Get integer location for requested label
|
| 【返回值】
| -------| loc : int
|
| get_value(self, series, key)
| Fast lookup of value from 1-dimensional ndarray. Only use this if you
| know what you&#39;re doing
|
| get_value_maybe_box(self, series, key)
151
|
| indexer_at_time(self, time, asof=False)
| Select values at particular time of day (e.g. 9:30AM)
|
| 【参数】
| ----------| time : datetime.time or string
|
| 【返回值】
| -------| values_at_time : TimeSeries
|
| indexer_between_time(self, start_time, end_time, include_start=True, include_end=True)
| Select values between particular times of day (e.g., 9:00-9:30AM)
|
| 【参数】
| ----------| start_time : datetime.time or string
| end_time : datetime.time or string
| include_start : boolean, default True
| include_end : boolean, default True
| tz : string or pytz.timezone or dateutil.tz.tzfile, default None
|
| 【返回值】
| -------| values_between_time : TimeSeries
|
| insert(self, loc, item)
| Make new Index inserting new item at location
|
| 【参数】
| ----------| loc : int
| item : object
| if not either a Python datetime or a numpy integer-like, returned
| Index dtype will be object rather than datetime.
|
| 【返回值】
| -------| new_index : Index
|
| intersection(self, other)
| Specialized intersection for DatetimeIndex objects. May be much faster
| than Index.intersection
|
| 【参数】
| ----------| other : DatetimeIndex or array-like
|
| 【返回值】
| -------| y : Index or DatetimeIndex
|
| is_type_compatible(self, typ)
|
| join(self, other, how=&#39;left&#39;, level=None, return_indexers=False)
152
| See Index.join
|
| normalize(self)
| Return DatetimeIndex with times to midnight. Length is unaltered
|
| 【返回值】
| -------| normalized : DatetimeIndex
|
| searchsorted(self, key, side=&#39;left&#39;)
| np.ndarray searchsorted compat
|
| slice_indexer(self, start=None, end=None, step=None, kind=None)
| Return indexer for specified label slice.
| Index.slice_indexer, customized to handle time slicing.
|
| In addition to functionality provided by Index.slice_indexer, does the
| following:
|
| - if both</code>start<code>and</code>end<code>are instances of</code>datetime.time<code>, it
| invokes</code>indexer_between_time<code>| - if</code>start<code>and</code>end<code>are both either string or None perform
| value-based selection in non-monotonic cases.
|
| snap(self, freq=&#39;S&#39;)
| Snap time stamps to nearest occurring frequency
|
| to_datetime(self, dayfirst=False)
| For an Index containing strings or datetime.datetime objects, attempt
| conversion to DatetimeIndex
|
| to_julian_date(self)
| Convert DatetimeIndex to Float64Index of Julian Dates.
| 0 Julian date is noon January 1, 4713 BC.
| http://en.wikipedia.org/wiki/Julian_day
|
| to_period(self, freq=None)
| Cast to PeriodIndex at a particular frequency
|
| to_perioddelta(self, freq)
| Calcuates TimedeltaIndex of difference between index
| values and index converted to PeriodIndex at specified
| freq. Used for vectorized offsets
|
| .. versionadded:: 0.17.0
|
| 【参数】
| ----------| freq : Period frequency
|
| 【返回值】
| -------| y : TimedeltaIndex
|
| to_pydatetime(self)
| Return DatetimeIndex as object ndarray of datetime.datetime objects
|
153
| 【返回值】
| -------| datetimes : ndarray
|
| to_series(self, keep_tz=False)
| Create a Series with both index and values equal to the index keys
| useful with map for returning an indexer based on an index
|
| 【参数】
| ----------| keep_tz : optional, defaults False.
| return the data keeping the timezone.
|
| If keep_tz is True:
|
| If the timezone is not set, the resulting
| Series will have a datetime64[ns] dtype.
|
| Otherwise the Series will have an datetime64[ns, tz] dtype; the
| tz will be preserved.
|
| If keep_tz is False:
|
| Series will have a datetime64[ns] dtype. TZ aware
| objects will have the tz removed.
|
| 【返回值】
| -------| Series
|
| tz_convert(self, tz)
| Convert tz-aware DatetimeIndex from one time zone to another (using pytz/dateutil)
|
| 【参数】
| ----------| tz : string, pytz.timezone, dateutil.tz.tzfile or None
| Time zone for time. Corresponding timestamps would be converted to
| time zone of the TimeSeries.
| None will remove timezone holding UTC time.
|
| 【返回值】
| -------| normalized : DatetimeIndex
|
| 【Raises 引发错误】
| ------| TypeError
| If DatetimeIndex is tz-naive.
|
| tz_localize(self, tz, ambiguous=&#39;raise&#39;)
| Localize tz-naive DatetimeIndex to given time zone (using pytz/dateutil),
| or remove timezone from tz-aware DatetimeIndex
|
| 【参数】
| ----------| tz : string, pytz.timezone, dateutil.tz.tzfile or None
| Time zone for time. Corresponding timestamps would be converted to
154
| time zone of the TimeSeries.
| None will remove timezone holding local time.
| ambiguous : &#39;infer&#39;, bool-ndarray, &#39;NaT&#39;, default &#39;raise&#39;
| - &#39;infer&#39; will attempt to infer fall dst-transition hours based on order
| - bool-ndarray where True signifies a DST time, False signifies
| a non-DST time (note that this flag is only applicable for ambiguous times)
| - &#39;NaT&#39; will return NaT where there are ambiguous times
| - &#39;raise&#39; will raise an AmbiguousTimeError if there are ambiguous times
| infer_dst : boolean, default False (DEPRECATED)
| Attempt to infer fall dst-transition hours based on order
|
| 【返回值】
| -------| localized : DatetimeIndex
|
| 【Raises 引发错误】
| ------| TypeError
| If the DatetimeIndex is tz-aware and tz is not None.
|
| union(self, other)
| Specialized union for DatetimeIndex objects. If combine
| overlapping ranges with the same DateOffset, will be much
| faster than Index.union
|
| 【参数】
| ----------| other : DatetimeIndex or array-like
|
| 【返回值】
| -------| y : Index or DatetimeIndex
|
| union_many(self, others)
| A bit of a hack to accelerate unioning a collection of indexes
|
| ----------------------------------------------------------------------| Static methods defined here:
|
| __new__(cls, data=None, freq=None, start=None, end=None, periods=None, copy=False, name=None, tz=None,
verify_integrity=True, normalize=False, closed=None, ambiguous=&#39;raise&#39;, dtype=None, **kwargs)
| Create and return a new object. See help(type) for accurate signature.
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| date
| Returns numpy array of datetime.date. The date part of the Timestamps.
|
| day
| The days of the datetime
|
| dayofweek
| The day of the week with Monday=0, Sunday=6
|
| dayofyear
| The ordinal day of the year
155
|
| days_in_month
| The number of days in the month
|
| .. versionadded:: 0.16.0
|
| daysinmonth
| The number of days in the month
|
| .. versionadded:: 0.16.0
|
| dtype
|
| freq
| get/set the frequncy of the Index
|
| hour
| The hours of the datetime
|
| inferred_type
|
| is_all_dates
| Checks that all the labels are datetime objects
|
| is_month_end
| Logical indicating if last day of month (defined by frequency)
|
| is_month_start
| Logical indicating if first day of month (defined by frequency)
|
| is_normalized
|
| is_quarter_end
| Logical indicating if last day of quarter (defined by frequency)
|
| is_quarter_start
| Logical indicating if first day of quarter (defined by frequency)
|
| is_year_end
| Logical indicating if last day of year (defined by frequency)
|
| is_year_start
| Logical indicating if first day of year (defined by frequency)
|
| microsecond
| The microseconds of the datetime
|
| millisecond
| The milliseconds of the datetime
|
| minute
| The minutes of the datetime
|
| month
| The month as January=1, December=12
|
| nanosecond
156
| The nanoseconds of the datetime
|
| quarter
| The quarter of the date
|
| second
| The seconds of the datetime
|
| time
| Returns numpy array of datetime.time. The time part of the Timestamps.
|
| tzinfo
| Alias for tz attribute
|
| week
| The week ordinal of the year
|
| weekday
| The day of the week with Monday=0, Sunday=6
|
| weekofyear
| The week ordinal of the year
|
| year
| The year of the datetime
|
| ----------------------------------------------------------------------| 其他数据、属性定义：
|
| __hash__ = None
|
| offset = None
|
| tz = None
|
| ----------------------------------------------------------------------| Methods inherited from pandas.tseries.base.DatelikeOps:
|
| strftime(self, date_format)
| Return an array of formatted strings specified by date_format, which
| supports the same string format as the python standard library. Details
| of the string format can be found in the</code>python string format doc<br>| <a href="https://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior" target="_blank" rel="external">https://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior</a><code>__
|
| .. versionadded:: 0.17.0
|
| 【参数】
| ----------| date_format : str
| date format string (e.g. &quot;%Y-%m-%d&quot;)
|
| 【返回值】
| -------| ndarray of formatted strings
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.tseries.base.DatelikeOps:
157
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
|
| ----------------------------------------------------------------------| Methods inherited from pandas.tseries.base.DatetimeIndexOpsMixin:
|
| __contains__(self, key)
|
| __getitem__(self, key)
|
| argmax(self, axis=None)
| return a ndarray of the maximum argument indexer
|
| 【参见】
| --------| numpy.ndarray.argmax
|
| argmin(self, axis=None)
| return a ndarray of the minimum argument indexer
|
| 【参见】
| --------| numpy.ndarray.argmin
|
| get_duplicates(self)
|
| groupby(self, f)
|
| isin(self, values)
| Compute boolean array of whether each index value is found in the
| passed set of values
|
| 【参数】
| ----------| values : set or sequence of values
|
| 【返回值】
| -------| is_contained : ndarray (boolean dtype)
|
| map(self, f)
| # Try to run function on index first, and then on elements of index
| # Especially important for group-by functionality
|
| max(self, axis=None)
| return the maximum value of the Index
|
| 【参见】
| --------| numpy.ndarray.max
|
| min(self, axis=None)
| return the minimum value of the Index
158
|
| 【参见】
| --------| numpy.ndarray.min
|
| repeat(self, repeats, axis=None)
| Analogous to ndarray.repeat
|
| shift(self, n, freq=None)
| Specialized shift which produces a DatetimeIndex
|
| 【参数】
| ----------| n : int
| Periods to shift by
| freq : DateOffset or timedelta-like, optional
|
| 【返回值】
| -------| shifted : DatetimeIndex
|
| sort_values(self, return_indexer=False, ascending=True)
| Return sorted copy of Index
|
| summary(self, name=None)
| return a summarized representation
|
| take(self, indices, axis=0, allow_fill=True, fill_value=None)
| Analogous to ndarray.take
|
| tolist(self)
| return a list of the underlying data
|
| unique(self)
| Index.unique with handling for DatetimeIndex/PeriodIndex metadata
|
| 【返回值】
| -------| result : DatetimeIndex or PeriodIndex
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.tseries.base.DatetimeIndexOpsMixin:
|
| asobject
|
| freqstr
| return the frequency object as a string if its set, otherwise None
|
| hasnans
|
| inferred_freq
|
| resolution
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.index.Int64Index:
|
159
| asi8
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.index.Index:
|
| __and__(self, other)
|
| __array__(self, dtype=None)
| the array interface, return my values
|
| __array_wrap__(self, result, context=None)
| Gets called after a ufunc
|
| __bool__ = __nonzero__(self)
|
| __copy__ = copy(self, names=None, name=None, dtype=None, deep=False)
| Make a copy of this object. Name and dtype sets those attributes on
| the new object.
|
| 【参数】
| ----------| name : string, optional
| dtype : numpy dtype or pandas type
|
| 【返回值】
| -------| copy : Index
|
| 【注意】
| -----| In most cases, there should be no functional difference from using
| ``deep``, but if ``deep`` is passed it will attempt to deepcopy.
|
| __deepcopy__(self, memo={})
|
| __len__(self)
| return the length of the Index
|
| __nonzero__(self)
|
| __or__(self, other)
|
| __setitem__(self, key, value)
|
| __unicode__(self)
| Return a string representation for this object.
|
| Invoked by unicode(df) in py2 only. Yields a Unicode String in both
| py2/py3.
|
| __xor__(self, other)
|
| argsort(self, *args, **kwargs)
| return an ndarray indexer of the underlying data
|
| 【参见】
| --------
160
| numpy.ndarray.argsort
|
| asof(self, label)
| For a sorted index, return the most recent label up to and including
| the passed label. Return NaN if not found.
|
| 【参见】
| --------| get_loc : asof is a thin wrapper around get_loc with method=&#39;pad&#39;
|
| asof_locs(self, where, mask)
| where : array of timestamps
| mask : array of booleans where data is not NA
|
| copy(self, names=None, name=None, dtype=None, deep=False)
| Make a copy of this object. Name and dtype sets those attributes on
| the new object.
|
| 【参数】
| ----------| name : string, optional
| dtype : numpy dtype or pandas type
|
| 【返回值】
| -------| copy : Index
|
| 【注意】
| -----| In most cases, there should be no functional difference from using
| ``deep``, but if ``deep`` is passed it will attempt to deepcopy.
|
| diff = wrapper(*args, **kwargs)
|
| difference(self, other)
| Return a new Index with elements from the index that are not in</code>other<code>.
|
| This is the sorted set difference of two Index objects.
|
| 【参数】
| ----------| other : Index or array-like
|
| 【返回值】
| -------| difference : Index
|
| 【示例】
| --------|
| &gt;&gt;&gt; idx1 = pd.Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = pd.Index([3, 4, 5, 6])
| &gt;&gt;&gt; idx1.difference(idx2)
| Int64Index([1, 2], dtype=&#39;int64&#39;)
|
| drop(self, labels, errors=&#39;raise&#39;)
| Make new Index with passed list of labels deleted
161
|
| 【参数】
| ----------| labels : array-like
| errors : {&#39;ignore&#39;, &#39;raise&#39;}, default &#39;raise&#39;
| If &#39;ignore&#39;, suppress error and existing labels are dropped.
|
| 【返回值】
| -------| dropped : Index
|
| drop_duplicates(self, keep=&#39;first&#39;)
| Return Index with duplicate values removed
|
| 【参数】
| ----------|
| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| - ``first`` : Drop duplicates except for the first occurrence.
| - ``last`` : Drop duplicates except for the last occurrence.
| - False : Drop all duplicates.
| take_last : deprecated
|
|
| 【返回值】
| -------| deduplicated : Index
|
| duplicated(self, keep=&#39;first&#39;)
| Return boolean np.array denoting duplicate values
|
| 【参数】
| ----------| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| - ``first`` : Mark duplicates as ``True`` except for the first occurrence.
| - ``last`` : Mark duplicates as ``True`` except for the last occurrence.
| - False : Mark all duplicates as ``True``.
| take_last : deprecated
|
| 【返回值】
| -------| duplicated : np.array
|
| fillna(self, value=None, downcast=None)
| Fill NA/NaN values with the specified value
|
| 【参数】
| ----------| value : scalar
| Scalar value to use to fill holes (e.g. 0).
| This value cannot be a list-likes.
| downcast : dict, default is None
| a dict of item-&gt;dtype of what to downcast if possible,
| or the string &#39;infer&#39; which will try to downcast to an appropriate
| equal type (e.g. float64 to int64 if possible)
|
162
| 【返回值】
| -------| filled : Index
|
| format(self, name=False, formatter=None, **kwargs)
| Render a string representation of the Index
|
| get_indexer(self, target, method=None, limit=None, tolerance=None)
| Compute indexer and mask for new index given the current index. The
| indexer should be then used as an input to ndarray.take to align the
| current data to the new index.
|
| 【参数】
| ----------| target : Index
| method : {None, &#39;pad&#39;/&#39;ffill&#39;, &#39;backfill&#39;/&#39;bfill&#39;, &#39;nearest&#39;}, optional
| * default: exact matches only.
| * pad / ffill: find the PREVIOUS index value if no exact match.
| * backfill / bfill: use NEXT index value if no exact match
| * nearest: use the NEAREST index value if no exact match. Tied
| distances are broken by preferring the larger index value.
| limit : int, optional
| Maximum number of consecutive labels in ``target`` to match for
| inexact matches.
| tolerance : optional
| Maximum distance between original and new labels for inexact
| matches. The values of the index at the matching locations most
| satisfy the equation ``abs(index[indexer] - target) &lt;= tolerance``.
|
| .. versionadded:: 0.17.0
|
| 【示例】
| --------| &gt;&gt;&gt; indexer = index.get_indexer(new_index)
| &gt;&gt;&gt; new_values = cur_values.take(indexer)
|
| 【返回值】
| -------| indexer : ndarray of int
| Integers from 0 to n - 1 indicating that the index at these
| positions matches the corresponding target values. Missing values
| in the target are marked by -1.
|
| get_indexer_for(self, target, **kwargs)
| guaranteed return of an indexer even when non-unique
|
| get_indexer_non_unique(self, target)
| return an indexer suitable for taking from a non unique index
| return the labels in the same order as the target, and
| return a missing indexer into the target (missing are marked as -1
| in the indexer); target must be an iterable
|
| get_level_values(self, level)
| Return vector of label values for requested level, equal to the length
| of the index
|
| 【参数】
163
| ----------| level : int
|
| 【返回值】
| -------| values : ndarray
|
| get_slice_bound(self, label, side, kind)
| Calculate slice bound that corresponds to given label.
|
| Returns leftmost (one-past-the-rightmost if ``side==&#39;right&#39;``) position
| of given label.
|
| 【参数】
| ----------| label : object
| side : {&#39;left&#39;, &#39;right&#39;}
| kind : string / None, the type of indexer
|
| get_values(self)
| return the underlying data as an ndarray
|
| holds_integer(self)
|
| identical(self, other)
| Similar to equals, but check that other comparable attributes are
| also equal
|
| is_(self, other)
| More flexible, faster check like ``is`` but that works through views
|
| Note: this is *not* the same as ``Index.identical()``, which checks
| that metadata is also the same.
|
| 【参数】
| ----------| other : object
| other object to compare against.
|
| 【返回值】
| -------| True if both have same underlying data, False otherwise : bool
|
| is_boolean(self)
|
| is_categorical(self)
|
| is_floating(self)
|
| is_integer(self)
|
| is_lexsorted_for_tuple(self, tup)
|
| is_mixed(self)
|
| is_numeric(self)
|
164
| is_object(self)
|
| order(self, return_indexer=False, ascending=True)
| Return sorted copy of Index
|
| DEPRECATED: use :meth:</code>Index.sort_values<code>|
| putmask(self, mask, value)
| return a new Index of the values set with the mask
|
| 【参见】
| --------| numpy.ndarray.putmask
|
| ravel(self, order=&#39;C&#39;)
| return an ndarray of the flattened values of the underlying data
|
| 【参见】
| --------| numpy.ndarray.ravel
|
| reindex(self, target, method=None, level=None, limit=None, tolerance=None)
| Create index with target&#39;s values (move/add/delete values as necessary)
|
| 【参数】
| ----------| target : an iterable
|
| 【返回值】
| -------| new_index : pd.Index
| Resulting index
| indexer : np.ndarray or None
| Indices of output values in original index
|
| rename(self, name, inplace=False)
| Set new names on index. Defaults to returning new index.
|
| 【参数】
| ----------| name : str or list
| name to set
| inplace : bool
| if True, mutates in place
|
| 【返回值】
| -------| new index (of same type and class...etc) [if inplace, returns None]
|
| set_names(self, names, level=None, inplace=False)
| Set new names on index. Defaults to returning new index.
|
| 【参数】
| ----------| names : str or sequence
| name(s) to set
| level : int or level name, or sequence of int / level names (default None)
165
| If the index is a MultiIndex (hierarchical), level(s) to set (None for all levels)
| Otherwise level must be None
| inplace : bool
| if True, mutates in place
|
| 【返回值】
| -------| new index (of same type and class...etc) [if inplace, returns None]
|
| 【示例】
| --------| &gt;&gt;&gt; Index([1, 2, 3, 4]).set_names(&#39;foo&#39;)
| Int64Index([1, 2, 3, 4], dtype=&#39;int64&#39;)
| &gt;&gt;&gt; Index([1, 2, 3, 4]).set_names([&#39;foo&#39;])
| Int64Index([1, 2, 3, 4], dtype=&#39;int64&#39;)
| &gt;&gt;&gt; idx = MultiIndex.from_tuples([(1, u&#39;one&#39;), (1, u&#39;two&#39;),
| (2, u&#39;one&#39;), (2, u&#39;two&#39;)],
| names=[&#39;foo&#39;, &#39;bar&#39;])
| &gt;&gt;&gt; idx.set_names([&#39;baz&#39;, &#39;quz&#39;])
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
| names=[u&#39;baz&#39;, u&#39;quz&#39;])
| &gt;&gt;&gt; idx.set_names(&#39;baz&#39;, level=0)
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
| names=[u&#39;baz&#39;, u&#39;bar&#39;])
|
| set_value(self, arr, key, value)
| Fast lookup of value from 1-dimensional ndarray. Only use this if you
| know what you&#39;re doing
|
| slice_locs(self, start=None, end=None, step=None, kind=None)
| Compute slice locations for input labels.
|
| 【参数】
| ----------| start : label, default None
| If None, defaults to the beginning
| end : label, default None
| If None, defaults to the end
| step : int, defaults None
| If None, defaults to 1
| kind : string, defaults None
|
| 【返回值】
| -------| start, end : int
|
| sort(self, *args, **kwargs)
|
| sortlevel(self, level=None, ascending=True, sort_remaining=None)
| For internal compatibility with with the Index API
|
| Sort the Index. This is for compat with MultiIndex
|
| 【参数】
| ----------
166
| ascending : boolean, default True
| False to sort in descending order
|
| level, sort_remaining are compat paramaters
|
| 【返回值】
| -------| sorted_index : Index
|
| sym_diff(self, other, result_name=None)
| Compute the sorted symmetric difference of two Index objects.
|
| 【参数】
| ----------| other : Index or array-like
| result_name : str
|
| 【返回值】
| -------| sym_diff : Index
|
| 【注意】
| -----| ``sym_diff`` contains elements that appear in either ``idx1`` or
| ``idx2`` but not both. Equivalent to the Index created by
| ``(idx1 - idx2) + (idx2 - idx1)`` with duplicates dropped.
|
| The sorting of a result containing ``NaN`` values is not guaranteed
| across Python versions. See GitHub issue #6444.
|
| 【示例】
| --------| &gt;&gt;&gt; idx1 = Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = Index([2, 3, 4, 5])
| &gt;&gt;&gt; idx1.sym_diff(idx2)
| Int64Index([1, 5], dtype=&#39;int64&#39;)
|
| You can also use the ``^`` operator:
|
| &gt;&gt;&gt; idx1 ^ idx2
| Int64Index([1, 5], dtype=&#39;int64&#39;)
|
| to_native_types(self, slicer=None, **kwargs)
| slice and dice then format
|
| view(self, cls=None)
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.index.Index:
|
| dtype_str
|
| has_duplicates
|
| is_monotonic
| alias for is_monotonic_increasing (deprecated)
|
167
| is_monotonic_decreasing
| return if the index is monotonic decreasing (only equal or
| decreasing) values.
|
| is_monotonic_increasing
| return if the index is monotonic increasing (only equal or
| increasing) values.
|
| is_unique
|
| names
|
| nlevels
|
| values
| return the underlying data as an ndarray
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.index.Index:
|
| name = None
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.IndexOpsMixin:
|
| factorize(self, sort=False, na_sentinel=-1)
| Encode the object as an enumerated type or categorical variable
|
| 【参数】
| ----------| sort : boolean, default False
| Sort by values
| na_sentinel: int, default -1
| Value to mark &quot;not found&quot;
|
| 【返回值】
| -------| labels : the indexer to the original array
| uniques : the unique Index
|
| item(self)
| return the first element of the underlying data as a python scalar
|
| memory_usage(self, deep=False)
| Memory usage of my values
|
| 【参数】
| ----------| deep : bool
| Introspect the data deeply, interrogate
|</code>object<code>dtypes for system-level memory consumption
|
| 【返回值】
| -------| bytes used
|
| 【注意】
168
| -----| Memory usage does not include memory consumed by elements that
| are not components of the array if deep=False
|
| 【参见】
| --------| numpy.ndarray.nbytes
|
| nunique(self, dropna=True)
| Return number of unique elements in the object.
|
| Excludes NA values by default.
|
| 【参数】
| ----------| dropna : boolean, default True
| Don&#39;t include NaN in the count.
|
| 【返回值】
| -------| nunique : int
|
| transpose(self)
| return the transpose, which is by definition self
|
| value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)
| Returns object containing counts of unique values.
|
| The resulting object will be in descending order so that the
| first element is the most frequently-occurring element.
| Excludes NA values by default.
|
| 【参数】
| ----------| normalize : boolean, default False
| If True then the object returned will contain the relative
| frequencies of the unique values.
| sort : boolean, default True
| Sort by values
| ascending : boolean, default False
| Sort in ascending order
| bins : integer, optional
| Rather than count values, group them into half-open bins,
| a convenience for pd.cut, only works with numeric data
| dropna : boolean, default True
| Don&#39;t include counts of NaN.
|
| 【返回值】
| -------| counts : Series
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.base.IndexOpsMixin:
|
| T
| return the transpose, which is by definition self
|
169
| base
| return the base object if the memory of the underlying data is shared
|
| data
| return the data pointer of the underlying data
|
| flags
| return the ndarray.flags for the underlying data
|
| itemsize
| return the size of the dtype of the item of the underlying data
|
| nbytes
| return the number of bytes in the underlying data
|
| ndim
| return the number of dimensions of the underlying data, by definition 1
|
| shape
| return a tuple of the shape of the underlying data
|
| size
| return the number of elements in the underlying data
|
| strides
| return the strides of the underlying data
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.base.IndexOpsMixin:
|
| __array_priority__ = 1000
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.strings.StringAccessorMixin:
|
| str = &lt;class &#39;pandas.core.strings.StringMethods&#39;&gt;
| Vectorized string functions for Series and Index. NAs stay NA unless
| handled otherwise by a particular method. Patterned after Python&#39;s string
| methods, with some inspiration from R&#39;s stringr package.
|
| 【示例】
| --------| &gt;&gt;&gt; s.str.split(&#39;_&#39;)
| &gt;&gt;&gt; s.str.replace(&#39;_&#39;, &#39;&#39;)
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.PandasObject:
|
| __dir__(self)
| Provide method name lookup and completion
| Only provide &#39;public&#39; methods
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
| Return a string representation for a particular object.
170
|
| Invoked by bytes(obj) in py3 only.
| Yields a bytestring in both py2/py3.
|
| __repr__(self)
| Return a string representation for a particular object.
|
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
ExcelFile
ExcelFile 模块所属：pandas.io.excel:
类定义：ExcelFile(builtins.object)
| Class for parsing tabular excel sheets into DataFrame objects.
| Uses xlrd. See read_excel for more documentation
|
| 【参数】
| ----------| io : string, file-like object or xlrd workbook
| If a string, expected to be a path to xls or xlsx file
| engine: string, default None
| If io is not a buffer or path, this must be set to identify io.
| Acceptable values are None or xlrd
|
| 【方法定义】
|
| __enter__(self)
|
| __exit__(self, exc_type, exc_value, traceback)
|
| __init__(self, io, **kwds)
| Initialize self. See help(type(self)) for accurate signature.
|
| close(self)
| close io if necessary
|
| parse(self, sheetname=0, header=0, skiprows=None, skip_footer=0, index_col=None, parse_cols=None, parse_dates=False,
date_parser=None, na_values=None, thousands=None, convert_float=True, has_index_names=None, converters=None,
**kwds)
| Parse specified sheet(s) into a DataFrame
|
| Equivalent to read_excel(ExcelFile, ...) See the read_excel
| docstring for more info on accepted parameters
171
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
|
| sheet_names
ExcelWriter
ExcelWriter 模块所属：pandas.io.excel:
类定义：ExcelWriter(builtins.object)
| Class for writing DataFrame objects into excel sheets, default is to use
| xlwt for xls, openpyxl for xlsx. See DataFrame.to_excel for typical usage.
|
| 【参数】
| ----------| path : string
| Path to xls or xlsx file.
| engine : string (optional)
| Engine to use for writing. If None, defaults to
| ``io.excel.&lt;extension&gt;.writer``. NOTE: can only be passed as a keyword
| argument.
| date_format : string, default None
| Format string for dates written into Excel files (e.g. &#39;YYYY-MM-DD&#39;)
| datetime_format : string, default None
| Format string for datetime objects written into Excel files
| (e.g. &#39;YYYY-MM-DD HH:MM:SS&#39;)
|
|【注意】
| -----| For compatibility with CSV writers, ExcelWriter serializes lists
| and dicts to strings before writing.
|
| 【方法定义】
|
| __enter__(self)
| # Allow use as a contextmanager
|
| __exit__(self, exc_type, exc_value, traceback)
|
| __init__(self, path, engine=None, date_format=None, datetime_format=None, **engine_kwargs)
| Initialize self. See help(type(self)) for accurate signature.
|
| close(self)
172
| synonym for save, to make it more file-like
|
| save(self)
| Save workbook to disk.
|
| write_cells(self, cells, sheet_name=None, startrow=0, startcol=0)
| Write given formated cells into Excel an excel sheet
|
| 【参数】
| ----------| cells : generator
| cell of formated data to save to Excel sheet
| sheet_name : string, default None
| Name of Excel sheet, if None, then use self.cur_sheet
| startrow: upper left cell row to dump data frame
| startcol: upper left cell column to dump data frame
|
| ----------------------------------------------------------------------| Class methods defined here:
|
| check_extension(ext) from abc.ABCMeta
| checks that path&#39;s extension against the Writer&#39;s supported
| extensions. If it isn&#39;t supported, raises UnsupportedFiletypeError.
|
| ----------------------------------------------------------------------| Static methods defined here:
|
| __new__(cls, path, engine=None, **kwargs)
| Create and return a new object. See help(type) for accurate signature.
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
|
| engine
| name of engine
|
| supported_extensions
| extensions that writer engine supports
|
| ----------------------------------------------------------------------| 其他数据、属性定义：
|
| __abstractmethods__ = frozenset({&#39;engine&#39;, &#39;save&#39;, &#39;supported_extensio...
|
| book = None
|
| curr_sheet = None
|
| path = None
173
Expr
Expr 模块所属：pandas.computation.expr:
类定义：Expr(pandas.core.base.StringMixin)
| Object encapsulating an expression.
|
| 【参数】
| ----------| expr : str
| engine : str, optional, default &#39;numexpr&#39;
| parser : str, optional, default &#39;pandas&#39;
| env : Scope, optional, default None
| truediv : bool, optional, default True
| level : int, optional, default 2
|
| 【方法排序】
| Expr
| pandas.core.base.StringMixin
| 【内置对象】
|
| 【方法定义】
|
| __call__(self)
| Call self as a function.
|
| __init__(self, expr, engine=&#39;numexpr&#39;, parser=&#39;pandas&#39;, env=None, truediv=True, level=0)
| Initialize self. See help(type(self)) for accurate signature.
|
| __len__(self)
|
| __unicode__(self)
|
| parse(self)
| Parse an expression
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| assigner
|
| names
| Get the names in an expression
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
| Return a string representation for a particular object.
|
| Invoked by bytes(obj) in py3 only.
174
| Yields a bytestring in both py2/py3.
|
| __repr__(self)
| Return a string representation for a particular object.
|
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.base.StringMixin:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
Float64Index
Float64Index 模块所属：pandas.core.index:
类定义：Float64Index(NumericIndex)
| Immutable ndarray implementing an ordered, sliceable set. The basic object
| storing axis labels for all pandas objects. Float64Index is a special case
| of</code>Index<code>with purely floating point labels.
|
| 【参数】
| ----------| data : array-like (1-dimensional)
| dtype : NumPy dtype (default: object)
| copy : bool
| Make a copy of input ndarray
| name : object
| Name to be stored in the index
|
|【注意】
| -----| An Float64Index instance can **only** contain hashable objects
|
| 【方法排序】
| Float64Index
| NumericIndex
| Index
| pandas.core.base.IndexOpsMixin
| pandas.core.strings.StringAccessorMixin
175
| pandas.core.base.PandasObject
| pandas.core.base.StringMixin
| 【内置对象】
|
| 【方法定义】
|
| __abs__ = _evaluate_numeric_unary(self)
|
| __add__ = _evaluate_numeric_binop(self, other)
|
| __contains__(self, other)
|
| __floordiv__ = _evaluate_numeric_binop(self, other)
|
| __inv__ = _evaluate_numeric_unary(self)
|
| __mul__ = _evaluate_numeric_binop(self, other)
|
| __neg__ = _evaluate_numeric_unary(self)
|
| __pos__ = _evaluate_numeric_unary(self)
|
| __radd__ = _evaluate_numeric_binop(self, other)
|
| __rfloordiv__ = _evaluate_numeric_binop(self, other)
|
| __rmul__ = _evaluate_numeric_binop(self, other)
|
| __rsub__ = _evaluate_numeric_binop(self, other)
|
| __rtruediv__ = _evaluate_numeric_binop(self, other)
|
| __sub__ = _evaluate_numeric_binop(self, other)
|
| __truediv__ = _evaluate_numeric_binop(self, other)
|
| all(self, other=None)
|
| any(self, other=None)
|
| astype(self, dtype)
|
| equals(self, other)
| Determines if two Index objects contain the same elements.
|
| get_loc(self, key, method=None, tolerance=None)
| Get integer location for requested label
|
| 【参数】
| ----------| key : label
| method : {None, &#39;pad&#39;/&#39;ffill&#39;, &#39;backfill&#39;/&#39;bfill&#39;, &#39;nearest&#39;}, optional
| * default: exact matches only.
| * pad / ffill: find the PREVIOUS index value if no exact match.
| * backfill / bfill: use NEXT index value if no exact match
| * nearest: use the NEAREST index value if no exact match. Tied
| distances are broken by preferring the larger index value.
176
| tolerance : optional
| Maximum distance from index value for inexact matches. The value of
| the index at the matching location most satisfy the equation
| ``abs(index[loc] - key) &lt;= tolerance``.
|
| .. versionadded:: 0.17.0
|
| 【返回值】
| -------| loc : int if unique index, possibly slice or mask if not
|
| get_value(self, series, key)
| we always want to get an index value, never a value
|
| isin(self, values, level=None)
| Compute boolean array of whether each index value is found in the
| passed set of values.
|
| 【参数】
| ----------| values : set or sequence of values
| Sought values.
| level : str or int, optional
| Name or position of the index level to use (if the index is a
| MultiIndex).
|
| 【注意】
| -----| If</code>level<code>is specified:
|
| - if it is the name of one *and only one* index level, use that level;
| - otherwise it should be a number indicating level position.
|
| 【返回值】
| -------| is_contained : ndarray (boolean dtype)
|
| ----------------------------------------------------------------------| Static methods defined here:
|
| __new__(cls, data=None, dtype=None, copy=False, name=None, fastpath=False, **kwargs)
| Create and return a new object. See help(type) for accurate signature.
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| inferred_type
|
| is_all_dates
| Checks that all the labels are datetime objects
|
| is_unique
|
| ----------------------------------------------------------------------| Methods inherited from Index:
|
| __and__(self, other)
177
|
| __array__(self, dtype=None)
| the array interface, return my values
|
| __array_wrap__(self, result, context=None)
| Gets called after a ufunc
|
| __bool__ = __nonzero__(self)
|
| __copy__ = copy(self, names=None, name=None, dtype=None, deep=False)
| Make a copy of this object. Name and dtype sets those attributes on
| the new object.
|
| 【参数】
| ----------| name : string, optional
| dtype : numpy dtype or pandas type
|
| 【返回值】
| -------| copy : Index
|
| 【注意】
| -----| In most cases, there should be no functional difference from using
| ``deep``, but if ``deep`` is passed it will attempt to deepcopy.
|
| __deepcopy__(self, memo={})
|
| __eq__ = _evaluate_compare(self, other)
|
| __ge__ = _evaluate_compare(self, other)
|
| __getitem__(self, key)
| Override numpy.ndarray&#39;s __getitem__ method to work as desired.
|
| This function adds lists and Series as valid boolean indexers
| (ndarrays only supports ndarray with dtype=bool).
|
| If resulting ndim != 1, plain ndarray is returned instead of
| corresponding</code>Index<code>subclass.
|
| __gt__ = _evaluate_compare(self, other)
|
| __hash__(self)
| Return hash(self).
|
| __iadd__ = __add__(self, other)
|
| __iter__(self)
|
| __le__ = _evaluate_compare(self, other)
|
| __len__(self)
| return the length of the Index
|
| __lt__ = _evaluate_compare(self, other)
178
|
| __ne__ = _evaluate_compare(self, other)
|
| __nonzero__(self)
|
| __or__(self, other)
|
| __reduce__(self)
| helper for pickle
|
| __setitem__(self, key, value)
|
| __setstate__(self, state)
| Necessary for making this object picklable
|
| __unicode__(self)
| Return a string representation for this object.
|
| Invoked by unicode(df) in py2 only. Yields a Unicode String in both
| py2/py3.
|
| __xor__(self, other)
|
| append(self, other)
| Append a collection of Index options together
|
| 【参数】
| ----------| other : Index or list/tuple of indices
|
| 【返回值】
| -------| appended : Index
|
| argsort(self, *args, **kwargs)
| return an ndarray indexer of the underlying data
|
| 【参见】
| --------| numpy.ndarray.argsort
|
| asof(self, label)
| For a sorted index, return the most recent label up to and including
| the passed label. Return NaN if not found.
|
| 【参见】
| --------| get_loc : asof is a thin wrapper around get_loc with method=&#39;pad&#39;
|
| asof_locs(self, where, mask)
| where : array of timestamps
| mask : array of booleans where data is not NA
|
| copy(self, names=None, name=None, dtype=None, deep=False)
| Make a copy of this object. Name and dtype sets those attributes on
| the new object.
|
179
| 【参数】
| ----------| name : string, optional
| dtype : numpy dtype or pandas type
|
| 【返回值】
| -------| copy : Index
|
| 【注意】
| -----| In most cases, there should be no functional difference from using
| ``deep``, but if ``deep`` is passed it will attempt to deepcopy.
|
| delete(self, loc)
| Make new Index with passed location(-s) deleted
|
| 【返回值】
| -------| new_index : Index
|
| diff = wrapper(*args, **kwargs)
|
| difference(self, other)
| Return a new Index with elements from the index that are not in</code>other<code>.
|
| This is the sorted set difference of two Index objects.
|
| 【参数】
| ----------| other : Index or array-like
|
| 【返回值】
| -------| difference : Index
|
| 【示例】
| --------|
| &gt;&gt;&gt; idx1 = pd.Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = pd.Index([3, 4, 5, 6])
| &gt;&gt;&gt; idx1.difference(idx2)
| Int64Index([1, 2], dtype=&#39;int64&#39;)
|
| drop(self, labels, errors=&#39;raise&#39;)
| Make new Index with passed list of labels deleted
|
| 【参数】
| ----------| labels : array-like
| errors : {&#39;ignore&#39;, &#39;raise&#39;}, default &#39;raise&#39;
| If &#39;ignore&#39;, suppress error and existing labels are dropped.
|
| 【返回值】
| -------| dropped : Index
180
|
| drop_duplicates(self, keep=&#39;first&#39;)
| Return Index with duplicate values removed
|
| 【参数】
| ----------|
| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| - ``first`` : Drop duplicates except for the first occurrence.
| - ``last`` : Drop duplicates except for the last occurrence.
| - False : Drop all duplicates.
| take_last : deprecated
|
|
| 【返回值】
| -------| deduplicated : Index
|
| duplicated(self, keep=&#39;first&#39;)
| Return boolean np.array denoting duplicate values
|
| 【参数】
| ----------| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| - ``first`` : Mark duplicates as ``True`` except for the first occurrence.
| - ``last`` : Mark duplicates as ``True`` except for the last occurrence.
| - False : Mark all duplicates as ``True``.
| take_last : deprecated
|
| 【返回值】
| -------| duplicated : np.array
|
| fillna(self, value=None, downcast=None)
| Fill NA/NaN values with the specified value
|
| 【参数】
| ----------| value : scalar
| Scalar value to use to fill holes (e.g. 0).
| This value cannot be a list-likes.
| downcast : dict, default is None
| a dict of item-&gt;dtype of what to downcast if possible,
| or the string &#39;infer&#39; which will try to downcast to an appropriate
| equal type (e.g. float64 to int64 if possible)
|
| 【返回值】
| -------| filled : Index
|
| format(self, name=False, formatter=None, **kwargs)
| Render a string representation of the Index
|
| get_duplicates(self)
|
| get_indexer(self, target, method=None, limit=None, tolerance=None)
| Compute indexer and mask for new index given the current index. The
181
| indexer should be then used as an input to ndarray.take to align the
| current data to the new index.
|
| 【参数】
| ----------| target : Index
| method : {None, &#39;pad&#39;/&#39;ffill&#39;, &#39;backfill&#39;/&#39;bfill&#39;, &#39;nearest&#39;}, optional
| * default: exact matches only.
| * pad / ffill: find the PREVIOUS index value if no exact match.
| * backfill / bfill: use NEXT index value if no exact match
| * nearest: use the NEAREST index value if no exact match. Tied
| distances are broken by preferring the larger index value.
| limit : int, optional
| Maximum number of consecutive labels in ``target`` to match for
| inexact matches.
| tolerance : optional
| Maximum distance between original and new labels for inexact
| matches. The values of the index at the matching locations most
| satisfy the equation ``abs(index[indexer] - target) &lt;= tolerance``.
|
| .. versionadded:: 0.17.0
|
| 【示例】
| --------| &gt;&gt;&gt; indexer = index.get_indexer(new_index)
| &gt;&gt;&gt; new_values = cur_values.take(indexer)
|
| 【返回值】
| -------| indexer : ndarray of int
| Integers from 0 to n - 1 indicating that the index at these
| positions matches the corresponding target values. Missing values
| in the target are marked by -1.
|
| get_indexer_for(self, target, **kwargs)
| guaranteed return of an indexer even when non-unique
|
| get_indexer_non_unique(self, target)
| return an indexer suitable for taking from a non unique index
| return the labels in the same order as the target, and
| return a missing indexer into the target (missing are marked as -1
| in the indexer); target must be an iterable
|
| get_level_values(self, level)
| Return vector of label values for requested level, equal to the length
| of the index
|
| 【参数】
| ----------| level : int
|
| 【返回值】
| -------| values : ndarray
|
| get_slice_bound(self, label, side, kind)
| Calculate slice bound that corresponds to given label.
182
|
| Returns leftmost (one-past-the-rightmost if ``side==&#39;right&#39;``) position
| of given label.
|
| 【参数】
| ----------| label : object
| side : {&#39;left&#39;, &#39;right&#39;}
| kind : string / None, the type of indexer
|
| get_values(self)
| return the underlying data as an ndarray
|
| groupby(self, to_groupby)
| Group the index labels by a given array of values.
|
| 【参数】
| ----------| to_groupby : array
| Values used to determine the groups.
|
| 【返回值】
| -------| groups : dict
| {group name -&gt; group labels}
|
| holds_integer(self)
|
| identical(self, other)
| Similar to equals, but check that other comparable attributes are
| also equal
|
| insert(self, loc, item)
| Make new Index inserting new item at location. Follows
| Python list.append semantics for negative values
|
| 【参数】
| ----------| loc : int
| item : object
|
| 【返回值】
| -------| new_index : Index
|
| intersection(self, other)
| Form the intersection of two Index objects.
|
| This returns a new Index with elements common to the index and</code>other<code>.
| Sortedness of the result is not guaranteed.
|
| 【参数】
| ----------| other : Index or array-like
|
| 【返回值】
| -------
183
| intersection : Index
|
| 【示例】
| --------|
| &gt;&gt;&gt; idx1 = pd.Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = pd.Index([3, 4, 5, 6])
| &gt;&gt;&gt; idx1.intersection(idx2)
| Int64Index([3, 4], dtype=&#39;int64&#39;)
|
| is_(self, other)
| More flexible, faster check like ``is`` but that works through views
|
| Note: this is *not* the same as ``Index.identical()``, which checks
| that metadata is also the same.
|
| 【参数】
| ----------| other : object
| other object to compare against.
|
| 【返回值】
| -------| True if both have same underlying data, False otherwise : bool
|
| is_boolean(self)
|
| is_categorical(self)
|
| is_floating(self)
|
| is_integer(self)
|
| is_lexsorted_for_tuple(self, tup)
|
| is_mixed(self)
|
| is_numeric(self)
|
| is_object(self)
|
| is_type_compatible(self, kind)
|
| join(self, other, how=&#39;left&#39;, level=None, return_indexers=False)
| *this is an internal non-public method*
|
| Compute join_index and indexers to conform data
| structures to the new index.
|
| 【参数】
| ----------| other : Index
| how : {&#39;left&#39;, &#39;right&#39;, &#39;inner&#39;, &#39;outer&#39;}
| level : int or level name, default None
| return_indexers : boolean, default False
|
| 【返回值】
184
| -------| join_index, (left_indexer, right_indexer)
|
| map(self, mapper)
|
| order(self, return_indexer=False, ascending=True)
| Return sorted copy of Index
|
| DEPRECATED: use :meth:</code>Index.sort_values<code>|
| putmask(self, mask, value)
| return a new Index of the values set with the mask
|
| 【参见】
| --------| numpy.ndarray.putmask
|
| ravel(self, order=&#39;C&#39;)
| return an ndarray of the flattened values of the underlying data
|
| 【参见】
| --------| numpy.ndarray.ravel
|
| reindex(self, target, method=None, level=None, limit=None, tolerance=None)
| Create index with target&#39;s values (move/add/delete values as necessary)
|
| 【参数】
| ----------| target : an iterable
|
| 【返回值】
| -------| new_index : pd.Index
| Resulting index
| indexer : np.ndarray or None
| Indices of output values in original index
|
| rename(self, name, inplace=False)
| Set new names on index. Defaults to returning new index.
|
| 【参数】
| ----------| name : str or list
| name to set
| inplace : bool
| if True, mutates in place
|
| 【返回值】
| -------| new index (of same type and class...etc) [if inplace, returns None]
|
| repeat(self, n)
| return a new Index of the values repeated n times
|
| 【参见】
| --------
185
| numpy.ndarray.repeat
|
| set_names(self, names, level=None, inplace=False)
| Set new names on index. Defaults to returning new index.
|
| 【参数】
| ----------| names : str or sequence
| name(s) to set
| level : int or level name, or sequence of int / level names (default None)
| If the index is a MultiIndex (hierarchical), level(s) to set (None for all levels)
| Otherwise level must be None
| inplace : bool
| if True, mutates in place
|
| 【返回值】
| -------| new index (of same type and class...etc) [if inplace, returns None]
|
| 【示例】
| --------| &gt;&gt;&gt; Index([1, 2, 3, 4]).set_names(&#39;foo&#39;)
| Int64Index([1, 2, 3, 4], dtype=&#39;int64&#39;)
| &gt;&gt;&gt; Index([1, 2, 3, 4]).set_names([&#39;foo&#39;])
| Int64Index([1, 2, 3, 4], dtype=&#39;int64&#39;)
| &gt;&gt;&gt; idx = MultiIndex.from_tuples([(1, u&#39;one&#39;), (1, u&#39;two&#39;),
| (2, u&#39;one&#39;), (2, u&#39;two&#39;)],
| names=[&#39;foo&#39;, &#39;bar&#39;])
| &gt;&gt;&gt; idx.set_names([&#39;baz&#39;, &#39;quz&#39;])
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
| names=[u&#39;baz&#39;, u&#39;quz&#39;])
| &gt;&gt;&gt; idx.set_names(&#39;baz&#39;, level=0)
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
| names=[u&#39;baz&#39;, u&#39;bar&#39;])
|
| set_value(self, arr, key, value)
| Fast lookup of value from 1-dimensional ndarray. Only use this if you
| know what you&#39;re doing
|
| shift(self, periods=1, freq=None)
| Shift Index containing datetime objects by input number of periods and
| DateOffset
|
| 【返回值】
| -------| shifted : Index
|
| slice_indexer(self, start=None, end=None, step=None, kind=None)
| For an ordered Index, compute the slice indexer for input labels and
| step
|
| 【参数】
| ----------| start : label, default None
| If None, defaults to the beginning
186
| end : label, default None
| If None, defaults to the end
| step : int, default None
| kind : string, default None
|
| 【返回值】
| -------| indexer : ndarray or slice
|
| 【注意】
| -----| This function assumes that the data is sorted, so use at your own peril
|
| slice_locs(self, start=None, end=None, step=None, kind=None)
| Compute slice locations for input labels.
|
| 【参数】
| ----------| start : label, default None
| If None, defaults to the beginning
| end : label, default None
| If None, defaults to the end
| step : int, defaults None
| If None, defaults to 1
| kind : string, defaults None
|
| 【返回值】
| -------| start, end : int
|
| sort(self, *args, **kwargs)
|
| sort_values(self, return_indexer=False, ascending=True)
| Return sorted copy of Index
|
| sortlevel(self, level=None, ascending=True, sort_remaining=None)
| For internal compatibility with with the Index API
|
| Sort the Index. This is for compat with MultiIndex
|
| 【参数】
| ----------| ascending : boolean, default True
| False to sort in descending order
|
| level, sort_remaining are compat paramaters
|
| 【返回值】
| -------| sorted_index : Index
|
| summary(self, name=None)
|
| sym_diff(self, other, result_name=None)
| Compute the sorted symmetric difference of two Index objects.
|
| 【参数】
187
| ----------| other : Index or array-like
| result_name : str
|
| 【返回值】
| -------| sym_diff : Index
|
| 【注意】
| -----| ``sym_diff`` contains elements that appear in either ``idx1`` or
| ``idx2`` but not both. Equivalent to the Index created by
| ``(idx1 - idx2) + (idx2 - idx1)`` with duplicates dropped.
|
| The sorting of a result containing ``NaN`` values is not guaranteed
| across Python versions. See GitHub issue #6444.
|
| 【示例】
| --------| &gt;&gt;&gt; idx1 = Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = Index([2, 3, 4, 5])
| &gt;&gt;&gt; idx1.sym_diff(idx2)
| Int64Index([1, 5], dtype=&#39;int64&#39;)
|
| You can also use the ``^`` operator:
|
| &gt;&gt;&gt; idx1 ^ idx2
| Int64Index([1, 5], dtype=&#39;int64&#39;)
|
| take(self, indices, axis=0, allow_fill=True, fill_value=None)
| return a new Index of the values selected by the indexer
|
| For internal compatibility with numpy arrays.
|
| # filling must always be None/nan here
| # but is passed thru internally
|
| 【参见】
| --------| numpy.ndarray.take
|
| to_datetime(self, dayfirst=False)
| For an Index containing strings or datetime.datetime objects, attempt
| conversion to DatetimeIndex
|
| to_native_types(self, slicer=None, **kwargs)
| slice and dice then format
|
| to_series(self, **kwargs)
| Create a Series with both index and values equal to the index keys
| useful with map for returning an indexer based on an index
|
| 【返回值】
| -------| Series : dtype will be based on the type of the Index values.
|
| tolist(self)
188
| return a list of the Index values
|
| union(self, other)
| Form the union of two Index objects and sorts if possible.
|
| 【参数】
| ----------| other : Index or array-like
|
| 【返回值】
| -------| union : Index
|
| 【示例】
| --------|
| &gt;&gt;&gt; idx1 = pd.Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = pd.Index([3, 4, 5, 6])
| &gt;&gt;&gt; idx1.union(idx2)
| Int64Index([1, 2, 3, 4, 5, 6], dtype=&#39;int64&#39;)
|
| view(self, cls=None)
|
| ----------------------------------------------------------------------| Data descriptors inherited from Index:
|
| dtype
|
| dtype_str
|
| has_duplicates
|
| hasnans
|
| is_monotonic
| alias for is_monotonic_increasing (deprecated)
|
| is_monotonic_decreasing
| return if the index is monotonic decreasing (only equal or
| decreasing) values.
|
| is_monotonic_increasing
| return if the index is monotonic increasing (only equal or
| increasing) values.
|
| names
|
| nlevels
|
| values
| return the underlying data as an ndarray
|
| ----------------------------------------------------------------------| Data and other attributes inherited from Index:
|
| asi8 = None
|
189
| name = None
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.IndexOpsMixin:
|
| argmax(self, axis=None)
| return a ndarray of the maximum argument indexer
|
| 【参见】
| --------| numpy.ndarray.argmax
|
| argmin(self, axis=None)
| return a ndarray of the minimum argument indexer
|
| 【参见】
| --------| numpy.ndarray.argmin
|
| factorize(self, sort=False, na_sentinel=-1)
| Encode the object as an enumerated type or categorical variable
|
| 【参数】
| ----------| sort : boolean, default False
| Sort by values
| na_sentinel: int, default -1
| Value to mark &quot;not found&quot;
|
| 【返回值】
| -------| labels : the indexer to the original array
| uniques : the unique Index
|
| item(self)
| return the first element of the underlying data as a python scalar
|
| max(self)
| The maximum value of the object
|
| memory_usage(self, deep=False)
| Memory usage of my values
|
| 【参数】
| ----------| deep : bool
| Introspect the data deeply, interrogate
|</code>object<code>dtypes for system-level memory consumption
|
| 【返回值】
| -------| bytes used
|
| 【注意】
| -----| Memory usage does not include memory consumed by elements that
| are not components of the array if deep=False
190
|
| 【参见】
| --------| numpy.ndarray.nbytes
|
| min(self)
| The minimum value of the object
|
| nunique(self, dropna=True)
| Return number of unique elements in the object.
|
| Excludes NA values by default.
|
| 【参数】
| ----------| dropna : boolean, default True
| Don&#39;t include NaN in the count.
|
| 【返回值】
| -------| nunique : int
|
| searchsorted(self, key, side=&#39;left&#39;)
| np.ndarray searchsorted compat
|
| transpose(self)
| return the transpose, which is by definition self
|
| unique(self)
| Return array of unique values in the object. Significantly faster than
| numpy.unique. Includes NA values.
|
| 【返回值】
| -------| uniques : ndarray
|
| value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)
| Returns object containing counts of unique values.
|
| The resulting object will be in descending order so that the
| first element is the most frequently-occurring element.
| Excludes NA values by default.
|
| 【参数】
| ----------| normalize : boolean, default False
| If True then the object returned will contain the relative
| frequencies of the unique values.
| sort : boolean, default True
| Sort by values
| ascending : boolean, default False
| Sort in ascending order
| bins : integer, optional
| Rather than count values, group them into half-open bins,
| a convenience for pd.cut, only works with numeric data
| dropna : boolean, default True
| Don&#39;t include counts of NaN.
191
|
| 【返回值】
| -------| counts : Series
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.base.IndexOpsMixin:
|
| T
| return the transpose, which is by definition self
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
|
| base
| return the base object if the memory of the underlying data is shared
|
| data
| return the data pointer of the underlying data
|
| flags
| return the ndarray.flags for the underlying data
|
| itemsize
| return the size of the dtype of the item of the underlying data
|
| nbytes
| return the number of bytes in the underlying data
|
| ndim
| return the number of dimensions of the underlying data, by definition 1
|
| shape
| return a tuple of the shape of the underlying data
|
| size
| return the number of elements in the underlying data
|
| strides
| return the strides of the underlying data
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.base.IndexOpsMixin:
|
| __array_priority__ = 1000
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.strings.StringAccessorMixin:
|
| str = &lt;class &#39;pandas.core.strings.StringMethods&#39;&gt;
| Vectorized string functions for Series and Index. NAs stay NA unless
| handled otherwise by a particular method. Patterned after Python&#39;s string
| methods, with some inspiration from R&#39;s stringr package.
|
192
| 【示例】
| --------| &gt;&gt;&gt; s.str.split(&#39;_&#39;)
| &gt;&gt;&gt; s.str.replace(&#39;_&#39;, &#39;&#39;)
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.PandasObject:
|
| __dir__(self)
| Provide method name lookup and completion
| Only provide &#39;public&#39; methods
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
| Return a string representation for a particular object.
|
| Invoked by bytes(obj) in py3 only.
| Yields a bytestring in both py2/py3.
|
| __repr__(self)
| Return a string representation for a particular object.
|
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
Grouper
Grouper 模块所属：pandas.core.groupby:
类定义：Grouper(builtins.object)
| A Grouper allows the user to specify a groupby instruction for a target object
|
| This specification will select a column via the key parameter, or if the level and/or
| axis parameters are given, a level of the index of the target object.
|
| These are local specifications and will override &#39;global&#39; settings, that is the parameters
| axis and level which are passed to the groupby itself.
|
| 【参数】
| ----------| key : string, defaults to None
| groupby key, which selects the grouping column of the target
| level : name/number, defaults to None
193
| the level for the target index
| freq : string / frequency object, defaults to None
| This will groupby the specified frequency if the target selection (via key or level) is
| a datetime-like object. For full specification of available frequencies, please see
|</code>here <a href="http://pandas.pydata.org/pandas-docs/stable/timeseries.html" target="_blank" rel="external">http://pandas.pydata.org/pandas-docs/stable/timeseries.html</a><code>_.
| axis : number/name of the axis, defaults to 0
| sort : boolean, default to False
| whether to sort the resulting labels
|
| additional kwargs to control time-like groupers (when freq is passed)
|
| closed : closed end of interval; left or right
| label : interval boundary to use for labeling; left or right
| convention : {&#39;start&#39;, &#39;end&#39;, &#39;e&#39;, &#39;s&#39;}
| If grouper is PeriodIndex
|
| Returns
| -------| A specification for a groupby instruction
|
| 【示例】
| --------|
| Syntactic sugar for ``df.groupby(&#39;A&#39;)``
|
| &gt;&gt;&gt; df.groupby(Grouper(key=&#39;A&#39;))
|
| Specify a resample operation on the column &#39;date&#39;
|
| &gt;&gt;&gt; df.groupby(Grouper(key=&#39;date&#39;, freq=&#39;60s&#39;))
|
| Specify a resample operation on the level &#39;date&#39; on the columns axis
| with a frequency of 60s
|
| &gt;&gt;&gt; df.groupby(Grouper(level=&#39;date&#39;, freq=&#39;60s&#39;, axis=1))
|
| 【方法定义】
|
| __init__(self, key=None, level=None, freq=None, axis=0, sort=False)
| Initialize self. See help(type(self)) for accurate signature.
|
| ----------------------------------------------------------------------| Static methods defined here:
|
| __new__(cls, *args, **kwargs)
| Create and return a new object. See help(type) for accurate signature.
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
|
| ax
194
|
| groups
HDFStore
HDFStore 模块所属：pandas.io.pytables:
类定义：HDFStore(pandas.core.base.StringMixin)
| dict-like IO interface for storing pandas objects in PyTables
| either Fixed or Table format.
|
| 【参数】
| ----------| path : string
| File path to HDF5 file
| mode : {&#39;a&#39;, &#39;w&#39;, &#39;r&#39;, &#39;r+&#39;}, default &#39;a&#39;
|
| ``&#39;r&#39;``
| Read-only; no data can be modified.
| ``&#39;w&#39;``
| Write; a new file is created (an existing file with the same
| name would be deleted).
| ``&#39;a&#39;``
| Append; an existing file is opened for reading and writing,
| and if the file does not exist it is created.
| ``&#39;r+&#39;``
| It is similar to ``&#39;a&#39;``, but the file must already exist.
| complevel : int, 1-9, default 0
| If a complib is specified compression will be applied
| where possible
| complib : {&#39;zlib&#39;, &#39;bzip2&#39;, &#39;lzo&#39;, &#39;blosc&#39;, None}, default None
| If complevel is &gt; 0 apply compression to objects written
| in the store wherever possible
| fletcher32 : bool, default False
| If applying compression use the fletcher32 checksum
|
| 【示例】
| --------| &gt;&gt;&gt; from pandas import DataFrame
| &gt;&gt;&gt; from numpy.random import randn
| &gt;&gt;&gt; bar = DataFrame(randn(10, 4))
| &gt;&gt;&gt; store = HDFStore(&#39;test.h5&#39;)
| &gt;&gt;&gt; store[&#39;foo&#39;] = bar # write to HDF5
| &gt;&gt;&gt; bar = store[&#39;foo&#39;] # retrieve
| &gt;&gt;&gt; store.close()
|
| 【方法排序】
| HDFStore
| pandas.core.base.StringMixin
| 【内置对象】
195
|
| 【方法定义】
|
| __contains__(self, key)
| check for existance of this key
| can match the exact pathname or the pathnm w/o the leading &#39;/&#39;
|
| __delitem__(self, key)
|
| __enter__(self)
|
| __exit__(self, exc_type, exc_value, traceback)
|
| __getattr__(self, name)
| allow attribute access to get stores
|
| __getitem__(self, key)
|
| __init__(self, path, mode=None, complevel=None, complib=None, fletcher32=False, **kwargs)
| Initialize self. See help(type(self)) for accurate signature.
|
| __len__(self)
|
| __setitem__(self, key, value)
|
| __unicode__(self)
|
| append(self, key, value, format=None, append=True, columns=None, dropna=None, **kwargs)
| Append to Table in file. Node must already exist and be Table
| format.
|
| 【参数】
| ----------| key : object
| value : {Series, DataFrame, Panel, Panel4D}
| format: &#39;table&#39; is the default
| table(t) : table format
| Write as a PyTables Table structure which may perform
| worse but allow more flexible operations like searching
| / selecting subsets of the data
| append : boolean, default True, append the input data to the
| existing
| data_columns : list of columns to create as data columns, or True to
| use all columns
| min_itemsize : dict of columns that specify minimum string sizes
| nan_rep : string to use as string nan represenation
| chunksize : size to chunk the writing
| expectedrows : expected TOTAL row size of this table
| encoding : default None, provide an encoding for strings
| dropna : boolean, default False, do not write an ALL nan row to
| the store settable by the option &#39;io.hdf.dropna_table&#39;
| 【注意】
| -----| Does *not* check if data being appended overlaps with existing
| data in the table, so be careful
|
| append_to_multiple(self, d, value, selector, data_columns=None, axes=None, dropna=False, **kwargs)
196
| Append to multiple tables
|
| 【参数】
| ----------| d : a dict of table_name to table_columns, None is acceptable as the
| values of one node (this will get all the remaining columns)
| value : a pandas object
| selector : a string that designates the indexable table; all of its
| columns will be designed as data_columns, unless data_columns is
| passed, in which case these are used
| data_columns : list of columns to create as data columns, or True to
| use all columns
| dropna : if evaluates to True, drop rows from all tables if any single
| row in each table has all NaN. Default False.
|
| 【注意】
| -----| axes parameter is currently not accepted
|
| close(self)
| Close the PyTables file handle
|
| copy(self, file, mode=&#39;w&#39;, propindexes=True, keys=None, complib=None, complevel=None, fletcher32=False,
overwrite=True)
| copy the existing store to a new file, upgrading in place
|
| 【参数】
| ----------| propindexes: restore indexes in copied file (defaults to True)
| keys : list of keys to include in the copy (defaults to all)
| overwrite : overwrite (remove and replace) existing nodes in the
| new store (default is True)
| mode, complib, complevel, fletcher32 same as in HDFStore.__init__
|
| 【返回值】
| -------| open file handle of the new store
|
| create_table_index(self, key, **kwargs)
| Create a pytables index on the table
| Paramaters
| ----------| key : object (the node to index)
|
| Exceptions
| ----------| raises if the node is not a table
|
| flush(self, fsync=False)
| Force all buffered modifications to be written to disk.
|
| 【参数】
| ----------| fsync : bool (default False)
| call ``os.fsync()`` on the file handle to force writing to disk.
|
| 【注意】
197
| -----| Without ``fsync=True``, flushing may not guarantee that the OS writes
| to disk. With fsync, the operation will block until the OS claims the
| file has been written; however, other caching layers may still
| interfere.
|
| get(self, key)
| Retrieve pandas object stored in file
|
| 【参数】
| ----------| key : object
|
| 【返回值】
| -------| obj : type of object stored in file
|
| get_node(self, key)
| return the node with the key or None if it does not exist
|
| get_storer(self, key)
| return the storer object for a key, raise if not in the file
|
| groups(self)
| return a list of all the top-level nodes (that are not themselves a
| pandas storage object)
|
| items(self)
| iterate on key-&gt;group
|
| iteritems = items(self)
|
| keys(self)
| Return a (potentially unordered) list of the keys corresponding to the
| objects stored in the HDFStore. These are ABSOLUTE path-names (e.g.
| have the leading &#39;/&#39;
|
| open(self, mode=&#39;a&#39;, **kwargs)
| Open the file in the specified mode
|
| 【参数】
| ----------| mode : {&#39;a&#39;, &#39;w&#39;, &#39;r&#39;, &#39;r+&#39;}, default &#39;a&#39;
| See HDFStore docstring or tables.open_file for info about modes
|
| put(self, key, value, format=None, append=False, **kwargs)
| Store object in HDFStore
|
| 【参数】
| ----------| key : object
| value : {Series, DataFrame, Panel}
| format : &#39;fixed(f)|table(t)&#39;, default is &#39;fixed&#39;
| fixed(f) : Fixed format
| Fast writing/reading. Not-appendable, nor searchable
| table(t) : Table format
| Write as a PyTables Table structure which may perform
198
| worse but allow more flexible operations like searching
| / selecting subsets of the data
| append : boolean, default False
| This will force Table format, append the input data to the
| existing.
| encoding : default None, provide an encoding for strings
| dropna : boolean, default False, do not write an ALL nan row to
| the store settable by the option &#39;io.hdf.dropna_table&#39;
|
| remove(self, key, where=None, start=None, stop=None)
| Remove pandas object partially by specifying the where condition
|
| 【参数】
| ----------| key : string
| Node to remove or delete rows from
| where : list of Term (or convertable) objects, optional
| start : integer (defaults to None), row number to start selection
| stop : integer (defaults to None), row number to stop selection
|
| 【返回值】
| -------| number of rows removed (or None if not a Table)
|
| Exceptions
| ----------| raises KeyError if key is not a valid store
|
| select(self, key, where=None, start=None, stop=None, columns=None, iterator=False, chunksize=None, auto_close=False,
**kwargs)
| Retrieve pandas object stored in file, optionally based on where
| criteria
|
| 【参数】
| ----------| key : object
| where : list of Term (or convertable) objects, optional
| start : integer (defaults to None), row number to start selection
| stop : integer (defaults to None), row number to stop selection
| columns : a list of columns that if not None, will limit the return
| columns
| iterator : boolean, return an iterator, default False
| chunksize : nrows to include in iteration, return an iterator
| auto_close : boolean, should automatically close the store when
| finished, default is False
|
| 【返回值】
| -------| The selected object
|
| select_as_coordinates(self, key, where=None, start=None, stop=None, **kwargs)
| return the selection as an Index
|
| 【参数】
| ----------| key : object
| where : list of Term (or convertable) objects, optional
199
| start : integer (defaults to None), row number to start selection
| stop : integer (defaults to None), row number to stop selection
|
| select_as_multiple(self, keys, where=None, selector=None, columns=None, start=None, stop=None, iterator=False,
chunksize=None, auto_close=False, **kwargs)
| Retrieve pandas objects from multiple tables
|
| 【参数】
| ----------| keys : a list of the tables
| selector : the table to apply the where criteria (defaults to keys[0]
| if not supplied)
| columns : the columns I want back
| start : integer (defaults to None), row number to start selection
| stop : integer (defaults to None), row number to stop selection
| iterator : boolean, return an iterator, default False
| chunksize : nrows to include in iteration, return an iterator
|
| Exceptions
| ----------| raises KeyError if keys or selector is not found or keys is empty
| raises TypeError if keys is not a list or tuple
| raises ValueError if the tables are not ALL THE SAME DIMENSIONS
|
| select_column(self, key, column, **kwargs)
| return a single column from the table. This is generally only useful to
| select an indexable
|
| 【参数】
| ----------| key : object
| column: the column of interest
|
| Exceptions
| ----------| raises KeyError if the column is not found (or key is not a valid
| store)
| raises ValueError if the column can not be extracted individually (it
| is part of a data block)
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| filename
|
| is_open
| return a boolean indicating whether the file is open
|
| root
| return the root node
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
| Return a string representation for a particular object.
|
200
| Invoked by bytes(obj) in py3 only.
| Yields a bytestring in both py2/py3.
|
| __repr__(self)
| Return a string representation for a particular object.
|
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.base.StringMixin:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
Index
Index 模块所属：pandas.core.index:
类定义：Index(pandas.core.base.IndexOpsMixin, pandas.core.strings.StringAccessorMixin, pandas.core.base.PandasObject)
| Immutable ndarray implementing an ordered, sliceable set. The basic object
| storing axis labels for all pandas objects
|
| 【参数】
| ----------| data : array-like (1-dimensional)
| dtype : NumPy dtype (default: object)
| copy : bool
| Make a copy of input ndarray
| name : object
| Name to be stored in the index
| tupleize_cols : bool (default: True)
| When True, attempt to create a MultiIndex if possible
|
|【注意】
| -----| An Index instance can **only** contain hashable objects
|
| 【方法排序】
| Index
| pandas.core.base.IndexOpsMixin
| pandas.core.strings.StringAccessorMixin
201
| pandas.core.base.PandasObject
| pandas.core.base.StringMixin
| 【内置对象】
|
| 【方法定义】
|
| __abs__(self, other=None)
|
| __add__(self, other)
|
| __and__(self, other)
|
| __array__(self, dtype=None)
| the array interface, return my values
|
| __array_wrap__(self, result, context=None)
| Gets called after a ufunc
|
| __bool__ = __nonzero__(self)
|
| __contains__(self, key)
|
| __copy__ = copy(self, names=None, name=None, dtype=None, deep=False)
|
| __deepcopy__(self, memo={})
|
| __eq__ = _evaluate_compare(self, other)
|
| __floordiv__(self, other=None)
|
| __ge__ = _evaluate_compare(self, other)
|
| __getitem__(self, key)
| Override numpy.ndarray&#39;s __getitem__ method to work as desired.
|
| This function adds lists and Series as valid boolean indexers
| (ndarrays only supports ndarray with dtype=bool).
|
| If resulting ndim != 1, plain ndarray is returned instead of
| corresponding</code>Index<code>subclass.
|
| __gt__ = _evaluate_compare(self, other)
|
| __hash__(self)
| Return hash(self).
|
| __iadd__ = __add__(self, other)
|
| __inv__(self, other=None)
|
| __iter__(self)
|
| __le__ = _evaluate_compare(self, other)
|
| __len__(self)
| return the length of the Index
|
202
| __lt__ = _evaluate_compare(self, other)
|
| __mul__(self, other=None)
|
| __ne__ = _evaluate_compare(self, other)
|
| __neg__(self, other=None)
|
| __nonzero__(self)
|
| __or__(self, other)
|
| __pos__(self, other=None)
|
| __radd__(self, other)
|
| __reduce__(self)
| helper for pickle
|
| __rfloordiv__ = __floordiv__(self, other=None)
|
| __rmul__ = __mul__(self, other=None)
|
| __rtruediv__ = __truediv__(self, other=None)
|
| __setitem__(self, key, value)
|
| __setstate__(self, state)
| Necessary for making this object picklable
|
| __sub__(self, other)
|
| __truediv__(self, other=None)
|
| __unicode__(self)
| Return a string representation for this object.
|
| Invoked by unicode(df) in py2 only. Yields a Unicode String in both
| py2/py3.
|
| __xor__(self, other)
|
| all(self, *args, **kwargs)
| Return whether all elements are True
|
| 【参数】
| ----------| All arguments to numpy.all are accepted.
|
| 【返回值】
| -------| all : bool or array_like (if axis is specified)
| A single element array_like may be converted to bool.
|
| any(self, *args, **kwargs)
| Return whether any element is True
|
203
| 【参数】
| ----------| All arguments to numpy.any are accepted.
|
| 【返回值】
| -------| any : bool or array_like (if axis is specified)
| A single element array_like may be converted to bool.
|
| append(self, other)
| Append a collection of Index options together
|
| 【参数】
| ----------| other : Index or list/tuple of indices
|
| 【返回值】
| -------| appended : Index
|
| argsort(self, *args, **kwargs)
| return an ndarray indexer of the underlying data
|
| 【参见】
| --------| numpy.ndarray.argsort
|
| asof(self, label)
| For a sorted index, return the most recent label up to and including
| the passed label. Return NaN if not found.
|
| 【参见】
| --------| get_loc : asof is a thin wrapper around get_loc with method=&#39;pad&#39;
|
| asof_locs(self, where, mask)
| where : array of timestamps
| mask : array of booleans where data is not NA
|
| astype(self, dtype)
|
| copy(self, names=None, name=None, dtype=None, deep=False)
| Make a copy of this object. Name and dtype sets those attributes on
| the new object.
|
| 【参数】
| ----------| name : string, optional
| dtype : numpy dtype or pandas type
|
| 【返回值】
| -------| copy : Index
|
| 【注意】
| -----
204
| In most cases, there should be no functional difference from using
| ``deep``, but if ``deep`` is passed it will attempt to deepcopy.
|
| delete(self, loc)
| Make new Index with passed location(-s) deleted
|
| 【返回值】
| -------| new_index : Index
|
| diff = wrapper(*args, **kwargs)
|
| difference(self, other)
| Return a new Index with elements from the index that are not in</code>other<code>.
|
| This is the sorted set difference of two Index objects.
|
| 【参数】
| ----------| other : Index or array-like
|
| 【返回值】
| -------| difference : Index
|
| 【示例】
| --------|
| &gt;&gt;&gt; idx1 = pd.Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = pd.Index([3, 4, 5, 6])
| &gt;&gt;&gt; idx1.difference(idx2)
| Int64Index([1, 2], dtype=&#39;int64&#39;)
|
| drop(self, labels, errors=&#39;raise&#39;)
| Make new Index with passed list of labels deleted
|
| 【参数】
| ----------| labels : array-like
| errors : {&#39;ignore&#39;, &#39;raise&#39;}, default &#39;raise&#39;
| If &#39;ignore&#39;, suppress error and existing labels are dropped.
|
| 【返回值】
| -------| dropped : Index
|
| drop_duplicates(self, keep=&#39;first&#39;)
| Return Index with duplicate values removed
|
| 【参数】
| ----------|
| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| - ``first`` : Drop duplicates except for the first occurrence.
| - ``last`` : Drop duplicates except for the last occurrence.
| - False : Drop all duplicates.
| take_last : deprecated
205
|
|
| 【返回值】
| -------| deduplicated : Index
|
| duplicated(self, keep=&#39;first&#39;)
| Return boolean np.array denoting duplicate values
|
| 【参数】
| ----------| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| - ``first`` : Mark duplicates as ``True`` except for the first occurrence.
| - ``last`` : Mark duplicates as ``True`` except for the last occurrence.
| - False : Mark all duplicates as ``True``.
| take_last : deprecated
|
| 【返回值】
| -------| duplicated : np.array
|
| equals(self, other)
| Determines if two Index objects contain the same elements.
|
| fillna(self, value=None, downcast=None)
| Fill NA/NaN values with the specified value
|
| 【参数】
| ----------| value : scalar
| Scalar value to use to fill holes (e.g. 0).
| This value cannot be a list-likes.
| downcast : dict, default is None
| a dict of item-&gt;dtype of what to downcast if possible,
| or the string &#39;infer&#39; which will try to downcast to an appropriate
| equal type (e.g. float64 to int64 if possible)
|
| 【返回值】
| -------| filled : Index
|
| format(self, name=False, formatter=None, **kwargs)
| Render a string representation of the Index
|
| get_duplicates(self)
|
| get_indexer(self, target, method=None, limit=None, tolerance=None)
| Compute indexer and mask for new index given the current index. The
| indexer should be then used as an input to ndarray.take to align the
| current data to the new index.
|
| 【参数】
| ----------| target : Index
| method : {None, &#39;pad&#39;/&#39;ffill&#39;, &#39;backfill&#39;/&#39;bfill&#39;, &#39;nearest&#39;}, optional
| * default: exact matches only.
| * pad / ffill: find the PREVIOUS index value if no exact match.
206
| * backfill / bfill: use NEXT index value if no exact match
| * nearest: use the NEAREST index value if no exact match. Tied
| distances are broken by preferring the larger index value.
| limit : int, optional
| Maximum number of consecutive labels in ``target`` to match for
| inexact matches.
| tolerance : optional
| Maximum distance between original and new labels for inexact
| matches. The values of the index at the matching locations most
| satisfy the equation ``abs(index[indexer] - target) &lt;= tolerance``.
|
| .. versionadded:: 0.17.0
|
| 【示例】
| --------| &gt;&gt;&gt; indexer = index.get_indexer(new_index)
| &gt;&gt;&gt; new_values = cur_values.take(indexer)
|
| 【返回值】
| -------| indexer : ndarray of int
| Integers from 0 to n - 1 indicating that the index at these
| positions matches the corresponding target values. Missing values
| in the target are marked by -1.
|
| get_indexer_for(self, target, **kwargs)
| guaranteed return of an indexer even when non-unique
|
| get_indexer_non_unique(self, target)
| return an indexer suitable for taking from a non unique index
| return the labels in the same order as the target, and
| return a missing indexer into the target (missing are marked as -1
| in the indexer); target must be an iterable
|
| get_level_values(self, level)
| Return vector of label values for requested level, equal to the length
| of the index
|
| 【参数】
| ----------| level : int
|
| 【返回值】
| -------| values : ndarray
|
| get_loc(self, key, method=None, tolerance=None)
| Get integer location for requested label
|
| 【参数】
| ----------| key : label
| method : {None, &#39;pad&#39;/&#39;ffill&#39;, &#39;backfill&#39;/&#39;bfill&#39;, &#39;nearest&#39;}, optional
| * default: exact matches only.
| * pad / ffill: find the PREVIOUS index value if no exact match.
| * backfill / bfill: use NEXT index value if no exact match
| * nearest: use the NEAREST index value if no exact match. Tied
207
| distances are broken by preferring the larger index value.
| tolerance : optional
| Maximum distance from index value for inexact matches. The value of
| the index at the matching location most satisfy the equation
| ``abs(index[loc] - key) &lt;= tolerance``.
|
| .. versionadded:: 0.17.0
|
| 【返回值】
| -------| loc : int if unique index, possibly slice or mask if not
|
| get_slice_bound(self, label, side, kind)
| Calculate slice bound that corresponds to given label.
|
| Returns leftmost (one-past-the-rightmost if ``side==&#39;right&#39;``) position
| of given label.
|
| 【参数】
| ----------| label : object
| side : {&#39;left&#39;, &#39;right&#39;}
| kind : string / None, the type of indexer
|
| get_value(self, series, key)
| Fast lookup of value from 1-dimensional ndarray. Only use this if you
| know what you&#39;re doing
|
| get_values(self)
| return the underlying data as an ndarray
|
| groupby(self, to_groupby)
| Group the index labels by a given array of values.
|
| 【参数】
| ----------| to_groupby : array
| Values used to determine the groups.
|
| 【返回值】
| -------| groups : dict
| {group name -&gt; group labels}
|
| holds_integer(self)
|
| identical(self, other)
| Similar to equals, but check that other comparable attributes are
| also equal
|
| insert(self, loc, item)
| Make new Index inserting new item at location. Follows
| Python list.append semantics for negative values
|
| 【参数】
| ----------| loc : int
208
| item : object
|
| 【返回值】
| -------| new_index : Index
|
| intersection(self, other)
| Form the intersection of two Index objects.
|
| This returns a new Index with elements common to the index and</code>other<code>.
| Sortedness of the result is not guaranteed.
|
| 【参数】
| ----------| other : Index or array-like
|
| 【返回值】
| -------| intersection : Index
|
| 【示例】
| --------|
| &gt;&gt;&gt; idx1 = pd.Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = pd.Index([3, 4, 5, 6])
| &gt;&gt;&gt; idx1.intersection(idx2)
| Int64Index([3, 4], dtype=&#39;int64&#39;)
|
| is_(self, other)
| More flexible, faster check like ``is`` but that works through views
|
| Note: this is *not* the same as ``Index.identical()``, which checks
| that metadata is also the same.
|
| 【参数】
| ----------| other : object
| other object to compare against.
|
| 【返回值】
| -------| True if both have same underlying data, False otherwise : bool
|
| is_boolean(self)
|
| is_categorical(self)
|
| is_floating(self)
|
| is_integer(self)
|
| is_lexsorted_for_tuple(self, tup)
|
| is_mixed(self)
|
| is_numeric(self)
|
209
| is_object(self)
|
| is_type_compatible(self, kind)
|
| isin(self, values, level=None)
| Compute boolean array of whether each index value is found in the
| passed set of values.
|
| 【参数】
| ----------| values : set or sequence of values
| Sought values.
| level : str or int, optional
| Name or position of the index level to use (if the index is a
| MultiIndex).
|
| 【注意】
| -----| If</code>level<code>is specified:
|
| - if it is the name of one *and only one* index level, use that level;
| - otherwise it should be a number indicating level position.
|
| 【返回值】
| -------| is_contained : ndarray (boolean dtype)
|
| join(self, other, how=&#39;left&#39;, level=None, return_indexers=False)
| *this is an internal non-public method*
|
| Compute join_index and indexers to conform data
| structures to the new index.
|
| 【参数】
| ----------| other : Index
| how : {&#39;left&#39;, &#39;right&#39;, &#39;inner&#39;, &#39;outer&#39;}
| level : int or level name, default None
| return_indexers : boolean, default False
|
| 【返回值】
| -------| join_index, (left_indexer, right_indexer)
|
| map(self, mapper)
|
| order(self, return_indexer=False, ascending=True)
| Return sorted copy of Index
|
| DEPRECATED: use :meth:</code>Index.sort_values<code>|
| putmask(self, mask, value)
| return a new Index of the values set with the mask
|
| 【参见】
| --------| numpy.ndarray.putmask
210
|
| ravel(self, order=&#39;C&#39;)
| return an ndarray of the flattened values of the underlying data
|
| 【参见】
| --------| numpy.ndarray.ravel
|
| reindex(self, target, method=None, level=None, limit=None, tolerance=None)
| Create index with target&#39;s values (move/add/delete values as necessary)
|
| 【参数】
| ----------| target : an iterable
|
| 【返回值】
| -------| new_index : pd.Index
| Resulting index
| indexer : np.ndarray or None
| Indices of output values in original index
|
| rename(self, name, inplace=False)
| Set new names on index. Defaults to returning new index.
|
| 【参数】
| ----------| name : str or list
| name to set
| inplace : bool
| if True, mutates in place
|
| 【返回值】
| -------| new index (of same type and class...etc) [if inplace, returns None]
|
| repeat(self, n)
| return a new Index of the values repeated n times
|
| 【参见】
| --------| numpy.ndarray.repeat
|
| set_names(self, names, level=None, inplace=False)
| Set new names on index. Defaults to returning new index.
|
| 【参数】
| ----------| names : str or sequence
| name(s) to set
| level : int or level name, or sequence of int / level names (default None)
| If the index is a MultiIndex (hierarchical), level(s) to set (None for all levels)
| Otherwise level must be None
| inplace : bool
| if True, mutates in place
|
211
| 【返回值】
| -------| new index (of same type and class...etc) [if inplace, returns None]
|
| 【示例】
| --------| &gt;&gt;&gt; Index([1, 2, 3, 4]).set_names(&#39;foo&#39;)
| Int64Index([1, 2, 3, 4], dtype=&#39;int64&#39;)
| &gt;&gt;&gt; Index([1, 2, 3, 4]).set_names([&#39;foo&#39;])
| Int64Index([1, 2, 3, 4], dtype=&#39;int64&#39;)
| &gt;&gt;&gt; idx = MultiIndex.from_tuples([(1, u&#39;one&#39;), (1, u&#39;two&#39;),
| (2, u&#39;one&#39;), (2, u&#39;two&#39;)],
| names=[&#39;foo&#39;, &#39;bar&#39;])
| &gt;&gt;&gt; idx.set_names([&#39;baz&#39;, &#39;quz&#39;])
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
| names=[u&#39;baz&#39;, u&#39;quz&#39;])
| &gt;&gt;&gt; idx.set_names(&#39;baz&#39;, level=0)
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
| names=[u&#39;baz&#39;, u&#39;bar&#39;])
|
| set_value(self, arr, key, value)
| Fast lookup of value from 1-dimensional ndarray. Only use this if you
| know what you&#39;re doing
|
| shift(self, periods=1, freq=None)
| Shift Index containing datetime objects by input number of periods and
| DateOffset
|
| 【返回值】
| -------| shifted : Index
|
| slice_indexer(self, start=None, end=None, step=None, kind=None)
| For an ordered Index, compute the slice indexer for input labels and
| step
|
| 【参数】
| ----------| start : label, default None
| If None, defaults to the beginning
| end : label, default None
| If None, defaults to the end
| step : int, default None
| kind : string, default None
|
| 【返回值】
| -------| indexer : ndarray or slice
|
| 【注意】
| -----| This function assumes that the data is sorted, so use at your own peril
|
| slice_locs(self, start=None, end=None, step=None, kind=None)
| Compute slice locations for input labels.
212
|
| 【参数】
| ----------| start : label, default None
| If None, defaults to the beginning
| end : label, default None
| If None, defaults to the end
| step : int, defaults None
| If None, defaults to 1
| kind : string, defaults None
|
| 【返回值】
| -------| start, end : int
|
| sort(self, *args, **kwargs)
|
| sort_values(self, return_indexer=False, ascending=True)
| Return sorted copy of Index
|
| sortlevel(self, level=None, ascending=True, sort_remaining=None)
| For internal compatibility with with the Index API
|
| Sort the Index. This is for compat with MultiIndex
|
| 【参数】
| ----------| ascending : boolean, default True
| False to sort in descending order
|
| level, sort_remaining are compat paramaters
|
| 【返回值】
| -------| sorted_index : Index
|
| summary(self, name=None)
|
| sym_diff(self, other, result_name=None)
| Compute the sorted symmetric difference of two Index objects.
|
| 【参数】
| ----------| other : Index or array-like
| result_name : str
|
| 【返回值】
| -------| sym_diff : Index
|
| 【注意】
| -----| ``sym_diff`` contains elements that appear in either ``idx1`` or
| ``idx2`` but not both. Equivalent to the Index created by
| ``(idx1 - idx2) + (idx2 - idx1)`` with duplicates dropped.
|
| The sorting of a result containing ``NaN`` values is not guaranteed
213
| across Python versions. See GitHub issue #6444.
|
| 【示例】
| --------| &gt;&gt;&gt; idx1 = Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = Index([2, 3, 4, 5])
| &gt;&gt;&gt; idx1.sym_diff(idx2)
| Int64Index([1, 5], dtype=&#39;int64&#39;)
|
| You can also use the ``^`` operator:
|
| &gt;&gt;&gt; idx1 ^ idx2
| Int64Index([1, 5], dtype=&#39;int64&#39;)
|
| take(self, indices, axis=0, allow_fill=True, fill_value=None)
| return a new Index of the values selected by the indexer
|
| For internal compatibility with numpy arrays.
|
| # filling must always be None/nan here
| # but is passed thru internally
|
| 【参见】
| --------| numpy.ndarray.take
|
| to_datetime(self, dayfirst=False)
| For an Index containing strings or datetime.datetime objects, attempt
| conversion to DatetimeIndex
|
| to_native_types(self, slicer=None, **kwargs)
| slice and dice then format
|
| to_series(self, **kwargs)
| Create a Series with both index and values equal to the index keys
| useful with map for returning an indexer based on an index
|
| 【返回值】
| -------| Series : dtype will be based on the type of the Index values.
|
| tolist(self)
| return a list of the Index values
|
| union(self, other)
| Form the union of two Index objects and sorts if possible.
|
| 【参数】
| ----------| other : Index or array-like
|
| 【返回值】
| -------| union : Index
|
| 【示例】
| --------
214
|
| &gt;&gt;&gt; idx1 = pd.Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = pd.Index([3, 4, 5, 6])
| &gt;&gt;&gt; idx1.union(idx2)
| Int64Index([1, 2, 3, 4, 5, 6], dtype=&#39;int64&#39;)
|
| view(self, cls=None)
|
| ----------------------------------------------------------------------| Static methods defined here:
|
| __new__(cls, data=None, dtype=None, copy=False, name=None, fastpath=False, tupleize_cols=True, **kwargs)
| Create and return a new object. See help(type) for accurate signature.
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| dtype
|
| dtype_str
|
| has_duplicates
|
| hasnans
|
| inferred_type
|
| is_all_dates
|
| is_monotonic
| alias for is_monotonic_increasing (deprecated)
|
| is_monotonic_decreasing
| return if the index is monotonic decreasing (only equal or
| decreasing) values.
|
| is_monotonic_increasing
| return if the index is monotonic increasing (only equal or
| increasing) values.
|
| is_unique
|
| names
|
| nlevels
|
| values
| return the underlying data as an ndarray
|
| ----------------------------------------------------------------------| 其他数据、属性定义：
|
| asi8 = None
|
| name = None
|
| ----------------------------------------------------------------------
215
| Methods inherited from pandas.core.base.IndexOpsMixin:
|
| argmax(self, axis=None)
| return a ndarray of the maximum argument indexer
|
| 【参见】
| --------| numpy.ndarray.argmax
|
| argmin(self, axis=None)
| return a ndarray of the minimum argument indexer
|
| 【参见】
| --------| numpy.ndarray.argmin
|
| factorize(self, sort=False, na_sentinel=-1)
| Encode the object as an enumerated type or categorical variable
|
| 【参数】
| ----------| sort : boolean, default False
| Sort by values
| na_sentinel: int, default -1
| Value to mark &quot;not found&quot;
|
| 【返回值】
| -------| labels : the indexer to the original array
| uniques : the unique Index
|
| item(self)
| return the first element of the underlying data as a python scalar
|
| max(self)
| The maximum value of the object
|
| memory_usage(self, deep=False)
| Memory usage of my values
|
| 【参数】
| ----------| deep : bool
| Introspect the data deeply, interrogate
|</code>object<code>dtypes for system-level memory consumption
|
| 【返回值】
| -------| bytes used
|
| 【注意】
| -----| Memory usage does not include memory consumed by elements that
| are not components of the array if deep=False
|
| 【参见】
216
| --------| numpy.ndarray.nbytes
|
| min(self)
| The minimum value of the object
|
| nunique(self, dropna=True)
| Return number of unique elements in the object.
|
| Excludes NA values by default.
|
| 【参数】
| ----------| dropna : boolean, default True
| Don&#39;t include NaN in the count.
|
| 【返回值】
| -------| nunique : int
|
| searchsorted(self, key, side=&#39;left&#39;)
| np.ndarray searchsorted compat
|
| transpose(self)
| return the transpose, which is by definition self
|
| unique(self)
| Return array of unique values in the object. Significantly faster than
| numpy.unique. Includes NA values.
|
| 【返回值】
| -------| uniques : ndarray
|
| value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)
| Returns object containing counts of unique values.
|
| The resulting object will be in descending order so that the
| first element is the most frequently-occurring element.
| Excludes NA values by default.
|
| 【参数】
| ----------| normalize : boolean, default False
| If True then the object returned will contain the relative
| frequencies of the unique values.
| sort : boolean, default True
| Sort by values
| ascending : boolean, default False
| Sort in ascending order
| bins : integer, optional
| Rather than count values, group them into half-open bins,
| a convenience for pd.cut, only works with numeric data
| dropna : boolean, default True
| Don&#39;t include counts of NaN.
|
| 【返回值】
217
| -------| counts : Series
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.base.IndexOpsMixin:
|
| T
| return the transpose, which is by definition self
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
|
| base
| return the base object if the memory of the underlying data is shared
|
| data
| return the data pointer of the underlying data
|
| flags
| return the ndarray.flags for the underlying data
|
| itemsize
| return the size of the dtype of the item of the underlying data
|
| nbytes
| return the number of bytes in the underlying data
|
| ndim
| return the number of dimensions of the underlying data, by definition 1
|
| shape
| return a tuple of the shape of the underlying data
|
| size
| return the number of elements in the underlying data
|
| strides
| return the strides of the underlying data
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.base.IndexOpsMixin:
|
| __array_priority__ = 1000
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.strings.StringAccessorMixin:
|
| str = &lt;class &#39;pandas.core.strings.StringMethods&#39;&gt;
| Vectorized string functions for Series and Index. NAs stay NA unless
| handled otherwise by a particular method. Patterned after Python&#39;s string
| methods, with some inspiration from R&#39;s stringr package.
|
| 【示例】
| --------
218
| &gt;&gt;&gt; s.str.split(&#39;_&#39;)
| &gt;&gt;&gt; s.str.replace(&#39;_&#39;, &#39;&#39;)
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.PandasObject:
|
| __dir__(self)
| Provide method name lookup and completion
| Only provide &#39;public&#39; methods
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
| Return a string representation for a particular object.
|
| Invoked by bytes(obj) in py3 only.
| Yields a bytestring in both py2/py3.
|
| __repr__(self)
| Return a string representation for a particular object.
|
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
IndexSlice
_IndexSlice 模块所属：pandas.core.indexing object:
类定义：_IndexSlice(builtins.object)
| # the public IndexSlicerMaker
|
| 【方法定义】
|
| __getitem__(self, arg)
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
219
Int64Index
Int64Index 模块所属：pandas.core.index:
类定义：Int64Index(NumericIndex)
| Immutable ndarray implementing an ordered, sliceable set. The basic object
| storing axis labels for all pandas objects. Int64Index is a special case
| of</code>Index<code>with purely integer labels. This is the default index type used
| by the DataFrame and Series ctors when no explicit index is provided by the
| user.
|
| 【参数】
| ----------| data : array-like (1-dimensional)
| dtype : NumPy dtype (default: int64)
| copy : bool
| Make a copy of input ndarray
| name : object
| Name to be stored in the index
|
|【注意】
| -----| An Index instance can **only** contain hashable objects
|
| 【方法排序】
| Int64Index
| NumericIndex
| Index
| pandas.core.base.IndexOpsMixin
| pandas.core.strings.StringAccessorMixin
| pandas.core.base.PandasObject
| pandas.core.base.StringMixin
| 【内置对象】
|
| 【方法定义】
|
| __abs__ = _evaluate_numeric_unary(self)
|
| __add__ = _evaluate_numeric_binop(self, other)
|
| __floordiv__ = _evaluate_numeric_binop(self, other)
|
| __inv__ = _evaluate_numeric_unary(self)
|
| __mul__ = _evaluate_numeric_binop(self, other)
|
| __neg__ = _evaluate_numeric_unary(self)
|
| __pos__ = _evaluate_numeric_unary(self)
|
220
| __radd__ = _evaluate_numeric_binop(self, other)
|
| __rfloordiv__ = _evaluate_numeric_binop(self, other)
|
| __rmul__ = _evaluate_numeric_binop(self, other)
|
| __rsub__ = _evaluate_numeric_binop(self, other)
|
| __rtruediv__ = _evaluate_numeric_binop(self, other)
|
| __sub__ = _evaluate_numeric_binop(self, other)
|
| __truediv__ = _evaluate_numeric_binop(self, other)
|
| all(self, *args, **kwargs)
| Return whether all elements are True
|
| 【参数】
| ----------| All arguments to numpy.all are accepted.
|
| 【返回值】
| -------| all : bool or array_like (if axis is specified)
| A single element array_like may be converted to bool.
|
| any(self, *args, **kwargs)
| Return whether any element is True
|
| 【参数】
| ----------| All arguments to numpy.any are accepted.
|
| 【返回值】
| -------| any : bool or array_like (if axis is specified)
| A single element array_like may be converted to bool.
|
| equals(self, other)
| Determines if two Index objects contain the same elements.
|
| ----------------------------------------------------------------------| Static methods defined here:
|
| __new__(cls, data=None, dtype=None, copy=False, name=None, fastpath=False, **kwargs)
| Create and return a new object. See help(type) for accurate signature.
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| asi8
|
| inferred_type
|
| is_all_dates
| Checks that all the labels are datetime objects
|
221
| ----------------------------------------------------------------------| Methods inherited from Index:
|
| __and__(self, other)
|
| __array__(self, dtype=None)
| the array interface, return my values
|
| __array_wrap__(self, result, context=None)
| Gets called after a ufunc
|
| __bool__ = __nonzero__(self)
|
| __contains__(self, key)
|
| __copy__ = copy(self, names=None, name=None, dtype=None, deep=False)
| Make a copy of this object. Name and dtype sets those attributes on
| the new object.
|
| 【参数】
| ----------| name : string, optional
| dtype : numpy dtype or pandas type
|
| 【返回值】
| -------| copy : Index
|
| 【注意】
| -----| In most cases, there should be no functional difference from using
| ``deep``, but if ``deep`` is passed it will attempt to deepcopy.
|
| __deepcopy__(self, memo={})
|
| __eq__ = _evaluate_compare(self, other)
|
| __ge__ = _evaluate_compare(self, other)
|
| __getitem__(self, key)
| Override numpy.ndarray&#39;s __getitem__ method to work as desired.
|
| This function adds lists and Series as valid boolean indexers
| (ndarrays only supports ndarray with dtype=bool).
|
| If resulting ndim != 1, plain ndarray is returned instead of
| corresponding</code>Index<code>subclass.
|
| __gt__ = _evaluate_compare(self, other)
|
| __hash__(self)
| Return hash(self).
|
| __iadd__ = __add__(self, other)
|
| __iter__(self)
|
222
| __le__ = _evaluate_compare(self, other)
|
| __len__(self)
| return the length of the Index
|
| __lt__ = _evaluate_compare(self, other)
|
| __ne__ = _evaluate_compare(self, other)
|
| __nonzero__(self)
|
| __or__(self, other)
|
| __reduce__(self)
| helper for pickle
|
| __setitem__(self, key, value)
|
| __setstate__(self, state)
| Necessary for making this object picklable
|
| __unicode__(self)
| Return a string representation for this object.
|
| Invoked by unicode(df) in py2 only. Yields a Unicode String in both
| py2/py3.
|
| __xor__(self, other)
|
| append(self, other)
| Append a collection of Index options together
|
| 【参数】
| ----------| other : Index or list/tuple of indices
|
| 【返回值】
| -------| appended : Index
|
| argsort(self, *args, **kwargs)
| return an ndarray indexer of the underlying data
|
| 【参见】
| --------| numpy.ndarray.argsort
|
| asof(self, label)
| For a sorted index, return the most recent label up to and including
| the passed label. Return NaN if not found.
|
| 【参见】
| --------| get_loc : asof is a thin wrapper around get_loc with method=&#39;pad&#39;
|
| asof_locs(self, where, mask)
| where : array of timestamps
223
| mask : array of booleans where data is not NA
|
| astype(self, dtype)
|
| copy(self, names=None, name=None, dtype=None, deep=False)
| Make a copy of this object. Name and dtype sets those attributes on
| the new object.
|
| 【参数】
| ----------| name : string, optional
| dtype : numpy dtype or pandas type
|
| 【返回值】
| -------| copy : Index
|
| 【注意】
| -----| In most cases, there should be no functional difference from using
| ``deep``, but if ``deep`` is passed it will attempt to deepcopy.
|
| delete(self, loc)
| Make new Index with passed location(-s) deleted
|
| 【返回值】
| -------| new_index : Index
|
| diff = wrapper(*args, **kwargs)
|
| difference(self, other)
| Return a new Index with elements from the index that are not in</code>other<code>.
|
| This is the sorted set difference of two Index objects.
|
| 【参数】
| ----------| other : Index or array-like
|
| 【返回值】
| -------| difference : Index
|
| 【示例】
| --------|
| &gt;&gt;&gt; idx1 = pd.Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = pd.Index([3, 4, 5, 6])
| &gt;&gt;&gt; idx1.difference(idx2)
| Int64Index([1, 2], dtype=&#39;int64&#39;)
|
| drop(self, labels, errors=&#39;raise&#39;)
| Make new Index with passed list of labels deleted
|
| 【参数】
224
| ----------| labels : array-like
| errors : {&#39;ignore&#39;, &#39;raise&#39;}, default &#39;raise&#39;
| If &#39;ignore&#39;, suppress error and existing labels are dropped.
|
| 【返回值】
| -------| dropped : Index
|
| drop_duplicates(self, keep=&#39;first&#39;)
| Return Index with duplicate values removed
|
| 【参数】
| ----------|
| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| - ``first`` : Drop duplicates except for the first occurrence.
| - ``last`` : Drop duplicates except for the last occurrence.
| - False : Drop all duplicates.
| take_last : deprecated
|
|
| 【返回值】
| -------| deduplicated : Index
|
| duplicated(self, keep=&#39;first&#39;)
| Return boolean np.array denoting duplicate values
|
| 【参数】
| ----------| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| - ``first`` : Mark duplicates as ``True`` except for the first occurrence.
| - ``last`` : Mark duplicates as ``True`` except for the last occurrence.
| - False : Mark all duplicates as ``True``.
| take_last : deprecated
|
| 【返回值】
| -------| duplicated : np.array
|
| fillna(self, value=None, downcast=None)
| Fill NA/NaN values with the specified value
|
| 【参数】
| ----------| value : scalar
| Scalar value to use to fill holes (e.g. 0).
| This value cannot be a list-likes.
| downcast : dict, default is None
| a dict of item-&gt;dtype of what to downcast if possible,
| or the string &#39;infer&#39; which will try to downcast to an appropriate
| equal type (e.g. float64 to int64 if possible)
|
| 【返回值】
| -------| filled : Index
225
|
| format(self, name=False, formatter=None, **kwargs)
| Render a string representation of the Index
|
| get_duplicates(self)
|
| get_indexer(self, target, method=None, limit=None, tolerance=None)
| Compute indexer and mask for new index given the current index. The
| indexer should be then used as an input to ndarray.take to align the
| current data to the new index.
|
| 【参数】
| ----------| target : Index
| method : {None, &#39;pad&#39;/&#39;ffill&#39;, &#39;backfill&#39;/&#39;bfill&#39;, &#39;nearest&#39;}, optional
| * default: exact matches only.
| * pad / ffill: find the PREVIOUS index value if no exact match.
| * backfill / bfill: use NEXT index value if no exact match
| * nearest: use the NEAREST index value if no exact match. Tied
| distances are broken by preferring the larger index value.
| limit : int, optional
| Maximum number of consecutive labels in ``target`` to match for
| inexact matches.
| tolerance : optional
| Maximum distance between original and new labels for inexact
| matches. The values of the index at the matching locations most
| satisfy the equation ``abs(index[indexer] - target) &lt;= tolerance``.
|
| .. versionadded:: 0.17.0
|
| 【示例】
| --------| &gt;&gt;&gt; indexer = index.get_indexer(new_index)
| &gt;&gt;&gt; new_values = cur_values.take(indexer)
|
| 【返回值】
| -------| indexer : ndarray of int
| Integers from 0 to n - 1 indicating that the index at these
| positions matches the corresponding target values. Missing values
| in the target are marked by -1.
|
| get_indexer_for(self, target, **kwargs)
| guaranteed return of an indexer even when non-unique
|
| get_indexer_non_unique(self, target)
| return an indexer suitable for taking from a non unique index
| return the labels in the same order as the target, and
| return a missing indexer into the target (missing are marked as -1
| in the indexer); target must be an iterable
|
| get_level_values(self, level)
| Return vector of label values for requested level, equal to the length
| of the index
|
| 【参数】
| ----------
226
| level : int
|
| 【返回值】
| -------| values : ndarray
|
| get_loc(self, key, method=None, tolerance=None)
| Get integer location for requested label
|
| 【参数】
| ----------| key : label
| method : {None, &#39;pad&#39;/&#39;ffill&#39;, &#39;backfill&#39;/&#39;bfill&#39;, &#39;nearest&#39;}, optional
| * default: exact matches only.
| * pad / ffill: find the PREVIOUS index value if no exact match.
| * backfill / bfill: use NEXT index value if no exact match
| * nearest: use the NEAREST index value if no exact match. Tied
| distances are broken by preferring the larger index value.
| tolerance : optional
| Maximum distance from index value for inexact matches. The value of
| the index at the matching location most satisfy the equation
| ``abs(index[loc] - key) &lt;= tolerance``.
|
| .. versionadded:: 0.17.0
|
| 【返回值】
| -------| loc : int if unique index, possibly slice or mask if not
|
| get_slice_bound(self, label, side, kind)
| Calculate slice bound that corresponds to given label.
|
| Returns leftmost (one-past-the-rightmost if ``side==&#39;right&#39;``) position
| of given label.
|
| 【参数】
| ----------| label : object
| side : {&#39;left&#39;, &#39;right&#39;}
| kind : string / None, the type of indexer
|
| get_value(self, series, key)
| Fast lookup of value from 1-dimensional ndarray. Only use this if you
| know what you&#39;re doing
|
| get_values(self)
| return the underlying data as an ndarray
|
| groupby(self, to_groupby)
| Group the index labels by a given array of values.
|
| 【参数】
| ----------| to_groupby : array
| Values used to determine the groups.
|
| 【返回值】
227
| -------| groups : dict
| {group name -&gt; group labels}
|
| holds_integer(self)
|
| identical(self, other)
| Similar to equals, but check that other comparable attributes are
| also equal
|
| insert(self, loc, item)
| Make new Index inserting new item at location. Follows
| Python list.append semantics for negative values
|
| 【参数】
| ----------| loc : int
| item : object
|
| 【返回值】
| -------| new_index : Index
|
| intersection(self, other)
| Form the intersection of two Index objects.
|
| This returns a new Index with elements common to the index and</code>other<code>.
| Sortedness of the result is not guaranteed.
|
| 【参数】
| ----------| other : Index or array-like
|
| 【返回值】
| -------| intersection : Index
|
| 【示例】
| --------|
| &gt;&gt;&gt; idx1 = pd.Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = pd.Index([3, 4, 5, 6])
| &gt;&gt;&gt; idx1.intersection(idx2)
| Int64Index([3, 4], dtype=&#39;int64&#39;)
|
| is_(self, other)
| More flexible, faster check like ``is`` but that works through views
|
| Note: this is *not* the same as ``Index.identical()``, which checks
| that metadata is also the same.
|
| 【参数】
| ----------| other : object
| other object to compare against.
|
| 【返回值】
228
| -------| True if both have same underlying data, False otherwise : bool
|
| is_boolean(self)
|
| is_categorical(self)
|
| is_floating(self)
|
| is_integer(self)
|
| is_lexsorted_for_tuple(self, tup)
|
| is_mixed(self)
|
| is_numeric(self)
|
| is_object(self)
|
| is_type_compatible(self, kind)
|
| isin(self, values, level=None)
| Compute boolean array of whether each index value is found in the
| passed set of values.
|
| 【参数】
| ----------| values : set or sequence of values
| Sought values.
| level : str or int, optional
| Name or position of the index level to use (if the index is a
| MultiIndex).
|
| 【注意】
| -----| If</code>level<code>is specified:
|
| - if it is the name of one *and only one* index level, use that level;
| - otherwise it should be a number indicating level position.
|
| 【返回值】
| -------| is_contained : ndarray (boolean dtype)
|
| join(self, other, how=&#39;left&#39;, level=None, return_indexers=False)
| *this is an internal non-public method*
|
| Compute join_index and indexers to conform data
| structures to the new index.
|
| 【参数】
| ----------| other : Index
| how : {&#39;left&#39;, &#39;right&#39;, &#39;inner&#39;, &#39;outer&#39;}
| level : int or level name, default None
| return_indexers : boolean, default False
|
229
| 【返回值】
| -------| join_index, (left_indexer, right_indexer)
|
| map(self, mapper)
|
| order(self, return_indexer=False, ascending=True)
| Return sorted copy of Index
|
| DEPRECATED: use :meth:</code>Index.sort_values<code>|
| putmask(self, mask, value)
| return a new Index of the values set with the mask
|
| 【参见】
| --------| numpy.ndarray.putmask
|
| ravel(self, order=&#39;C&#39;)
| return an ndarray of the flattened values of the underlying data
|
| 【参见】
| --------| numpy.ndarray.ravel
|
| reindex(self, target, method=None, level=None, limit=None, tolerance=None)
| Create index with target&#39;s values (move/add/delete values as necessary)
|
| 【参数】
| ----------| target : an iterable
|
| 【返回值】
| -------| new_index : pd.Index
| Resulting index
| indexer : np.ndarray or None
| Indices of output values in original index
|
| rename(self, name, inplace=False)
| Set new names on index. Defaults to returning new index.
|
| 【参数】
| ----------| name : str or list
| name to set
| inplace : bool
| if True, mutates in place
|
| 【返回值】
| -------| new index (of same type and class...etc) [if inplace, returns None]
|
| repeat(self, n)
| return a new Index of the values repeated n times
|
230
| 【参见】
| --------| numpy.ndarray.repeat
|
| set_names(self, names, level=None, inplace=False)
| Set new names on index. Defaults to returning new index.
|
| 【参数】
| ----------| names : str or sequence
| name(s) to set
| level : int or level name, or sequence of int / level names (default None)
| If the index is a MultiIndex (hierarchical), level(s) to set (None for all levels)
| Otherwise level must be None
| inplace : bool
| if True, mutates in place
|
| 【返回值】
| -------| new index (of same type and class...etc) [if inplace, returns None]
|
| 【示例】
| --------| &gt;&gt;&gt; Index([1, 2, 3, 4]).set_names(&#39;foo&#39;)
| Int64Index([1, 2, 3, 4], dtype=&#39;int64&#39;)
| &gt;&gt;&gt; Index([1, 2, 3, 4]).set_names([&#39;foo&#39;])
| Int64Index([1, 2, 3, 4], dtype=&#39;int64&#39;)
| &gt;&gt;&gt; idx = MultiIndex.from_tuples([(1, u&#39;one&#39;), (1, u&#39;two&#39;),
| (2, u&#39;one&#39;), (2, u&#39;two&#39;)],
| names=[&#39;foo&#39;, &#39;bar&#39;])
| &gt;&gt;&gt; idx.set_names([&#39;baz&#39;, &#39;quz&#39;])
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
| names=[u&#39;baz&#39;, u&#39;quz&#39;])
| &gt;&gt;&gt; idx.set_names(&#39;baz&#39;, level=0)
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
| names=[u&#39;baz&#39;, u&#39;bar&#39;])
|
| set_value(self, arr, key, value)
| Fast lookup of value from 1-dimensional ndarray. Only use this if you
| know what you&#39;re doing
|
| shift(self, periods=1, freq=None)
| Shift Index containing datetime objects by input number of periods and
| DateOffset
|
| 【返回值】
| -------| shifted : Index
|
| slice_indexer(self, start=None, end=None, step=None, kind=None)
| For an ordered Index, compute the slice indexer for input labels and
| step
|
| 【参数】
| ----------
231
| start : label, default None
| If None, defaults to the beginning
| end : label, default None
| If None, defaults to the end
| step : int, default None
| kind : string, default None
|
| 【返回值】
| -------| indexer : ndarray or slice
|
| 【注意】
| -----| This function assumes that the data is sorted, so use at your own peril
|
| slice_locs(self, start=None, end=None, step=None, kind=None)
| Compute slice locations for input labels.
|
| 【参数】
| ----------| start : label, default None
| If None, defaults to the beginning
| end : label, default None
| If None, defaults to the end
| step : int, defaults None
| If None, defaults to 1
| kind : string, defaults None
|
| 【返回值】
| -------| start, end : int
|
| sort(self, *args, **kwargs)
|
| sort_values(self, return_indexer=False, ascending=True)
| Return sorted copy of Index
|
| sortlevel(self, level=None, ascending=True, sort_remaining=None)
| For internal compatibility with with the Index API
|
| Sort the Index. This is for compat with MultiIndex
|
| 【参数】
| ----------| ascending : boolean, default True
| False to sort in descending order
|
| level, sort_remaining are compat paramaters
|
| 【返回值】
| -------| sorted_index : Index
|
| summary(self, name=None)
|
| sym_diff(self, other, result_name=None)
| Compute the sorted symmetric difference of two Index objects.
232
|
| 【参数】
| ----------| other : Index or array-like
| result_name : str
|
| 【返回值】
| -------| sym_diff : Index
|
| 【注意】
| -----| ``sym_diff`` contains elements that appear in either ``idx1`` or
| ``idx2`` but not both. Equivalent to the Index created by
| ``(idx1 - idx2) + (idx2 - idx1)`` with duplicates dropped.
|
| The sorting of a result containing ``NaN`` values is not guaranteed
| across Python versions. See GitHub issue #6444.
|
| 【示例】
| --------| &gt;&gt;&gt; idx1 = Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = Index([2, 3, 4, 5])
| &gt;&gt;&gt; idx1.sym_diff(idx2)
| Int64Index([1, 5], dtype=&#39;int64&#39;)
|
| You can also use the ``^`` operator:
|
| &gt;&gt;&gt; idx1 ^ idx2
| Int64Index([1, 5], dtype=&#39;int64&#39;)
|
| take(self, indices, axis=0, allow_fill=True, fill_value=None)
| return a new Index of the values selected by the indexer
|
| For internal compatibility with numpy arrays.
|
| # filling must always be None/nan here
| # but is passed thru internally
|
| 【参见】
| --------| numpy.ndarray.take
|
| to_datetime(self, dayfirst=False)
| For an Index containing strings or datetime.datetime objects, attempt
| conversion to DatetimeIndex
|
| to_native_types(self, slicer=None, **kwargs)
| slice and dice then format
|
| to_series(self, **kwargs)
| Create a Series with both index and values equal to the index keys
| useful with map for returning an indexer based on an index
|
| 【返回值】
| -------| Series : dtype will be based on the type of the Index values.
233
|
| tolist(self)
| return a list of the Index values
|
| union(self, other)
| Form the union of two Index objects and sorts if possible.
|
| 【参数】
| ----------| other : Index or array-like
|
| 【返回值】
| -------| union : Index
|
| 【示例】
| --------|
| &gt;&gt;&gt; idx1 = pd.Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = pd.Index([3, 4, 5, 6])
| &gt;&gt;&gt; idx1.union(idx2)
| Int64Index([1, 2, 3, 4, 5, 6], dtype=&#39;int64&#39;)
|
| view(self, cls=None)
|
| ----------------------------------------------------------------------| Data descriptors inherited from Index:
|
| dtype
|
| dtype_str
|
| has_duplicates
|
| hasnans
|
| is_monotonic
| alias for is_monotonic_increasing (deprecated)
|
| is_monotonic_decreasing
| return if the index is monotonic decreasing (only equal or
| decreasing) values.
|
| is_monotonic_increasing
| return if the index is monotonic increasing (only equal or
| increasing) values.
|
| is_unique
|
| names
|
| nlevels
|
| values
| return the underlying data as an ndarray
|
| ----------------------------------------------------------------------
234
| Data and other attributes inherited from Index:
|
| name = None
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.IndexOpsMixin:
|
| argmax(self, axis=None)
| return a ndarray of the maximum argument indexer
|
| 【参见】
| --------| numpy.ndarray.argmax
|
| argmin(self, axis=None)
| return a ndarray of the minimum argument indexer
|
| 【参见】
| --------| numpy.ndarray.argmin
|
| factorize(self, sort=False, na_sentinel=-1)
| Encode the object as an enumerated type or categorical variable
|
| 【参数】
| ----------| sort : boolean, default False
| Sort by values
| na_sentinel: int, default -1
| Value to mark &quot;not found&quot;
|
| 【返回值】
| -------| labels : the indexer to the original array
| uniques : the unique Index
|
| item(self)
| return the first element of the underlying data as a python scalar
|
| max(self)
| The maximum value of the object
|
| memory_usage(self, deep=False)
| Memory usage of my values
|
| 【参数】
| ----------| deep : bool
| Introspect the data deeply, interrogate
|</code>object<code>dtypes for system-level memory consumption
|
| 【返回值】
| -------| bytes used
|
| 【注意】
| -----
235
| Memory usage does not include memory consumed by elements that
| are not components of the array if deep=False
|
| 【参见】
| --------| numpy.ndarray.nbytes
|
| min(self)
| The minimum value of the object
|
| nunique(self, dropna=True)
| Return number of unique elements in the object.
|
| Excludes NA values by default.
|
| 【参数】
| ----------| dropna : boolean, default True
| Don&#39;t include NaN in the count.
|
| 【返回值】
| -------| nunique : int
|
| searchsorted(self, key, side=&#39;left&#39;)
| np.ndarray searchsorted compat
|
| transpose(self)
| return the transpose, which is by definition self
|
| unique(self)
| Return array of unique values in the object. Significantly faster than
| numpy.unique. Includes NA values.
|
| 【返回值】
| -------| uniques : ndarray
|
| value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)
| Returns object containing counts of unique values.
|
| The resulting object will be in descending order so that the
| first element is the most frequently-occurring element.
| Excludes NA values by default.
|
| 【参数】
| ----------| normalize : boolean, default False
| If True then the object returned will contain the relative
| frequencies of the unique values.
| sort : boolean, default True
| Sort by values
| ascending : boolean, default False
| Sort in ascending order
| bins : integer, optional
| Rather than count values, group them into half-open bins,
| a convenience for pd.cut, only works with numeric data
236
| dropna : boolean, default True
| Don&#39;t include counts of NaN.
|
| 【返回值】
| -------| counts : Series
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.base.IndexOpsMixin:
|
| T
| return the transpose, which is by definition self
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
|
| base
| return the base object if the memory of the underlying data is shared
|
| data
| return the data pointer of the underlying data
|
| flags
| return the ndarray.flags for the underlying data
|
| itemsize
| return the size of the dtype of the item of the underlying data
|
| nbytes
| return the number of bytes in the underlying data
|
| ndim
| return the number of dimensions of the underlying data, by definition 1
|
| shape
| return a tuple of the shape of the underlying data
|
| size
| return the number of elements in the underlying data
|
| strides
| return the strides of the underlying data
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.base.IndexOpsMixin:
|
| __array_priority__ = 1000
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.strings.StringAccessorMixin:
|
| str = &lt;class &#39;pandas.core.strings.StringMethods&#39;&gt;
| Vectorized string functions for Series and Index. NAs stay NA unless
| handled otherwise by a particular method. Patterned after Python&#39;s string
237
| methods, with some inspiration from R&#39;s stringr package.
|
| 【示例】
| --------| &gt;&gt;&gt; s.str.split(&#39;_&#39;)
| &gt;&gt;&gt; s.str.replace(&#39;_&#39;, &#39;&#39;)
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.PandasObject:
|
| __dir__(self)
| Provide method name lookup and completion
| Only provide &#39;public&#39; methods
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
| Return a string representation for a particular object.
|
| Invoked by bytes(obj) in py3 only.
| Yields a bytestring in both py2/py3.
|
| __repr__(self)
| Return a string representation for a particular object.
|
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
LooseVersion
LooseVersion in module distutils.version:
类定义：LooseVersion(Version)
| Version numbering for anarchists and software realists.
| Implements the standard interface for version number classes as
| described above. A version number consists of a series of numbers,
| separated by either periods or strings of letters. When comparing
| version numbers, the numeric components will be compared
| numerically, and the alphabetic components lexically. The following
| are all valid version numbers, in no particular order:
|
| 1.5.1
| 1.5.2b2
| 161
238
| 3.10a
| 8.02
| 3.4j
| 1996.07.12
| 3.2.pl0
| 3.1.1.6
| 2g6
| 11g
| 0.960923
| 2.2beta29
| 1.13++
| 5.5.kw
| 2.0b1pl0
|
| In fact, there is no such thing as an invalid version number under
| this scheme; the rules for comparison are simple and predictable,
| but may not always give the results you want (for some definition
| of &quot;want&quot;).
|
| 【方法排序】
| LooseVersion
| Version
| 【内置对象】
|
| 【方法定义】
|
| __init__(self, vstring=None)
| Initialize self. See help(type(self)) for accurate signature.
|
| __repr__(self)
| Return repr(self).
|
| __str__(self)
| Return str(self).
|
| parse(self, vstring)
|
| ----------------------------------------------------------------------| 其他数据、属性定义：
|
| component_re = re.compile(&#39;(\d+ | [a-z]+ | \.)&#39;, re.VERBOSE)
|
| ----------------------------------------------------------------------| Methods inherited from Version:
|
| __eq__(self, other)
| Return self==value.
|
| __ge__(self, other)
| Return self&gt;=value.
|
| __gt__(self, other)
| Return self&gt;value.
|
| __le__(self, other)
| Return self&lt;=value.
|
239
| __lt__(self, other)
| Return self&lt;value.
|
| ----------------------------------------------------------------------| Data descriptors inherited from Version:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
|
| ----------------------------------------------------------------------| Data and other attributes inherited from Version:
|
| __hash__ = None
MultiIndex
MultiIndex 模块所属：pandas.core.index:
类定义：MultiIndex(Index)
| Implements multi-level, a.k.a. hierarchical, index object for pandas
| objects
|
| 【参数】
| ----------| levels : sequence of arrays
| The unique labels for each level
| labels : sequence of arrays
| Integers for each level designating which label at each location
| sortorder : optional int
| Level of sortedness (must be lexicographically sorted by that
| level)
| names : optional sequence of objects
| Names for each of the index levels. (name is accepted for compat)
| copy : boolean, default False
| Copy the meta-data
| verify_integrity : boolean, default True
| Check that the levels/labels are consistent and valid
|
| 【方法排序】
| MultiIndex
| Index
| pandas.core.base.IndexOpsMixin
| pandas.core.strings.StringAccessorMixin
| pandas.core.base.PandasObject
| pandas.core.base.StringMixin
| 【内置对象】
|
240
| 【方法定义】
|
| __abs__(self, other=None)
|
| __array__(self, dtype=None)
| the array interface, return my values
|
| __contains__(self, key)
|
| __floordiv__(self, other=None)
|
| __getitem__(self, key)
| Override numpy.ndarray&#39;s __getitem__ method to work as desired.
|
| This function adds lists and Series as valid boolean indexers
| (ndarrays only supports ndarray with dtype=bool).
|
| If resulting ndim != 1, plain ndarray is returned instead of
| corresponding</code>Index<code>subclass.
|
| __getslice__(self, i, j)
|
| __inv__(self, other=None)
|
| __len__(self)
| return the length of the Index
|
| __mul__(self, other=None)
|
| __neg__(self, other=None)
|
| __pos__(self, other=None)
|
| __reduce__(self)
| Necessary for making this object picklable
|
| __rfloordiv__ = __floordiv__(self, other=None)
|
| __rmul__ = __mul__(self, other=None)
|
| __rtruediv__ = __truediv__(self, other=None)
|
| __setstate__(self, state)
| Necessary for making this object picklable
|
| __truediv__(self, other=None)
|
| all(self, other=None)
|
| any(self, other=None)
|
| append(self, other)
| Append a collection of Index options together
|
| 【参数】
| ----------| other : Index or list/tuple of indices
241
|
| 【返回值】
| -------| appended : Index
|
| argsort(self, *args, **kwargs)
| return an ndarray indexer of the underlying data
|
| 【参见】
| --------| numpy.ndarray.argsort
|
| astype(self, dtype)
|
| copy(self, names=None, dtype=None, levels=None, labels=None, deep=False, _set_identity=False)
| Make a copy of this object. Names, dtype, levels and labels can be
| passed and will be set on new copy.
|
| 【参数】
| ----------| names : sequence, optional
| dtype : numpy dtype or pandas type, optional
| levels : sequence, optional
| labels : sequence, optional
|
| 【返回值】
| -------| copy : MultiIndex
|
| 【注意】
| -----| In most cases, there should be no functional difference from using
| ``deep``, but if ``deep`` is passed it will attempt to deepcopy.
| This could be potentially expensive on large MultiIndex objects.
|
| delete(self, loc)
| Make new index with passed location deleted
|
| 【返回值】
| -------| new_index : MultiIndex
|
| difference(self, other)
| Compute sorted set difference of two MultiIndex objects
|
| 【返回值】
| -------| diff : MultiIndex
|
| drop(self, labels, level=None, errors=&#39;raise&#39;)
| Make new MultiIndex with passed list of labels deleted
|
| 【参数】
| ----------| labels : array-like
| Must be a list of tuples
242
| level : int or level name, default None
|
| 【返回值】
| -------| dropped : MultiIndex
|
| droplevel(self, level=0)
| Return Index with requested level removed. If MultiIndex has only 2
| levels, the result will be of Index type not MultiIndex.
|
| 【参数】
| ----------| level : int/level name or list thereof
|
| 【注意】
| -----| Does not check if result index is unique or not
|
| 【返回值】
| -------| index : Index or MultiIndex
|
| duplicated(self, keep=&#39;first&#39;)
| Return boolean np.array denoting duplicate values
|
| 【参数】
| ----------| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| - ``first`` : Mark duplicates as ``True`` except for the first occurrence.
| - ``last`` : Mark duplicates as ``True`` except for the last occurrence.
| - False : Mark all duplicates as ``True``.
| take_last : deprecated
|
| 【返回值】
| -------| duplicated : np.array
|
| equal_levels(self, other)
| Return True if the levels of both MultiIndex objects are the same
|
| equals(self, other)
| Determines if two MultiIndex objects have the same labeling information
| (the levels themselves do not necessarily have to be the same)
|
| 【参见】
| --------| equal_levels
|
| fillna(self, value=None, downcast=None)
| Fill NA/NaN values with the specified value
|
| 【参数】
| ----------| value : scalar
| Scalar value to use to fill holes (e.g. 0).
| This value cannot be a list-likes.
243
| downcast : dict, default is None
| a dict of item-&gt;dtype of what to downcast if possible,
| or the string &#39;infer&#39; which will try to downcast to an appropriate
| equal type (e.g. float64 to int64 if possible)
|
| 【返回值】
| -------| filled : Index
|
| format(self, space=2, sparsify=None, adjoin=True, names=False, na_rep=None, formatter=None)
| Render a string representation of the Index
|
| get_indexer(self, target, method=None, limit=None, tolerance=None)
| Compute indexer and mask for new index given the current index. The
| indexer should be then used as an input to ndarray.take to align the
| current data to the new index. The mask determines whether labels are
| found or not in the current index
|
| 【参数】
| ----------| target : MultiIndex or Index (of tuples)
| method : {&#39;pad&#39;, &#39;ffill&#39;, &#39;backfill&#39;, &#39;bfill&#39;}
| pad / ffill: propagate LAST valid observation forward to next valid
| backfill / bfill: use NEXT valid observation to fill gap
|
| 【注意】
| -----| This is a low-level method and probably should be used at your own risk
|
| 【示例】
| --------| &gt;&gt;&gt; indexer, mask = index.get_indexer(new_index)
| &gt;&gt;&gt; new_values = cur_values.take(indexer)
| &gt;&gt;&gt; new_values[-mask] = np.nan
|
| 【返回值】
| -------| (indexer, mask) : (ndarray, ndarray)
|
| get_level_values(self, level)
| Return vector of label values for requested level, equal to the length
| of the index
|
| 【参数】
| ----------| level : int or level name
|
| 【返回值】
| -------| values : ndarray
|
| get_loc(self, key, method=None)
| Get integer location, slice or boolean mask for requested label or tuple
| If the key is past the lexsort depth, the return may be a boolean mask
| array, otherwise it is always a slice or int.
|
244
| 【参数】
| ----------| key : label or tuple
| method : None
|
| 【返回值】
| -------| loc : int, slice object or boolean mask
|
| get_loc_level(self, key, level=0, drop_level=True)
| Get integer location slice for requested label or tuple
|
| 【参数】
| ----------| key : label or tuple
| level : int/level name or list thereof
|
| 【返回值】
| -------| loc : int or slice object
|
| get_locs(self, tup)
| Given a tuple of slices/lists/labels/boolean indexer to a level-wise spec
| produce an indexer to extract those locations
|
| 【参数】
| ----------| key : tuple of (slices/list/labels)
|
| 【返回值】
| -------| locs : integer list of locations or boolean indexer suitable
| for passing to iloc
|
| get_major_bounds = slice_locs(self, start=None, end=None, step=None, kind=None)
|
| get_slice_bound(self, label, side, kind)
| Calculate slice bound that corresponds to given label.
|
| Returns leftmost (one-past-the-rightmost if ``side==&#39;right&#39;``) position
| of given label.
|
| 【参数】
| ----------| label : object
| side : {&#39;left&#39;, &#39;right&#39;}
| kind : string / None, the type of indexer
|
| get_value(self, series, key)
| Fast lookup of value from 1-dimensional ndarray. Only use this if you
| know what you&#39;re doing
|
| insert(self, loc, item)
| Make new MultiIndex inserting new item at location
|
| 【参数】
245
| ----------| loc : int
| item : tuple
| Must be same length as number of levels in the MultiIndex
|
| 【返回值】
| -------| new_index : Index
|
| intersection(self, other)
| Form the intersection of two MultiIndex objects, sorting if possible
|
| 【参数】
| ----------| other : MultiIndex or array / Index of tuples
|
| 【返回值】
| -------| Index
|
| is_lexsorted(self)
| Return True if the labels are lexicographically sorted
|
| is_lexsorted_for_tuple(self, tup)
| Return True if we are correctly lexsorted given the passed tuple
|
| isin(self, values, level=None)
| Compute boolean array of whether each index value is found in the
| passed set of values.
|
| 【参数】
| ----------| values : set or sequence of values
| Sought values.
| level : str or int, optional
| Name or position of the index level to use (if the index is a
| MultiIndex).
|
| 【注意】
| -----| If</code>level<code>is specified:
|
| - if it is the name of one *and only one* index level, use that level;
| - otherwise it should be a number indicating level position.
|
| 【返回值】
| -------| is_contained : ndarray (boolean dtype)
|
| reindex(self, target, method=None, level=None, limit=None, tolerance=None)
| Create index with target&#39;s values (move/add/delete values as necessary)
|
| 【返回值】
| -------| new_index : pd.MultiIndex
| Resulting index
| indexer : np.ndarray or None
246
| Indices of output values in original index
|
| rename = set_names(self, names, level=None, inplace=False)
| Set new names on index. Defaults to returning new index.
|
| 【参数】
| ----------| names : str or sequence
| name(s) to set
| level : int or level name, or sequence of int / level names (default None)
| If the index is a MultiIndex (hierarchical), level(s) to set (None for all levels)
| Otherwise level must be None
| inplace : bool
| if True, mutates in place
|
| 【返回值】
| -------| new index (of same type and class...etc) [if inplace, returns None]
|
| 【示例】
| --------| &gt;&gt;&gt; Index([1, 2, 3, 4]).set_names(&#39;foo&#39;)
| Int64Index([1, 2, 3, 4], dtype=&#39;int64&#39;)
| &gt;&gt;&gt; Index([1, 2, 3, 4]).set_names([&#39;foo&#39;])
| Int64Index([1, 2, 3, 4], dtype=&#39;int64&#39;)
| &gt;&gt;&gt; idx = MultiIndex.from_tuples([(1, u&#39;one&#39;), (1, u&#39;two&#39;),
| (2, u&#39;one&#39;), (2, u&#39;two&#39;)],
| names=[&#39;foo&#39;, &#39;bar&#39;])
| &gt;&gt;&gt; idx.set_names([&#39;baz&#39;, &#39;quz&#39;])
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
| names=[u&#39;baz&#39;, u&#39;quz&#39;])
| &gt;&gt;&gt; idx.set_names(&#39;baz&#39;, level=0)
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
| names=[u&#39;baz&#39;, u&#39;bar&#39;])
|
| reorder_levels(self, order)
| Rearrange levels using input order. May not drop or duplicate levels
|
| 【参数】
| ----------|
| repeat(self, n)
| return a new Index of the values repeated n times
|
| 【参见】
| --------| numpy.ndarray.repeat
|
| set_labels(self, labels, level=None, inplace=False, verify_integrity=True)
| Set new labels on MultiIndex. Defaults to returning
| new index.
|
| 【参数】
| ----------| labels : sequence or list of sequence
247
| new labels to apply
| level : int or level name, or sequence of int / level names (default None)
| level(s) to set (None for all levels)
| inplace : bool
| if True, mutates in place
| verify_integrity : bool (default True)
| if True, checks that levels and labels are compatible
|
| 【返回值】
| -------| new index (of same type and class...etc)
|
| 【示例】
| --------| &gt;&gt;&gt; idx = MultiIndex.from_tuples([(1, u&#39;one&#39;), (1, u&#39;two&#39;),
| (2, u&#39;one&#39;), (2, u&#39;two&#39;)],
| names=[&#39;foo&#39;, &#39;bar&#39;])
| &gt;&gt;&gt; idx.set_labels([[1,0,1,0], [0,0,1,1]])
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[1, 0, 1, 0], [0, 0, 1, 1]],
| names=[u&#39;foo&#39;, u&#39;bar&#39;])
| &gt;&gt;&gt; idx.set_labels([1,0,1,0], level=0)
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[1, 0, 1, 0], [0, 1, 0, 1]],
| names=[u&#39;foo&#39;, u&#39;bar&#39;])
| &gt;&gt;&gt; idx.set_labels([0,0,1,1], level=&#39;bar&#39;)
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[0, 0, 1, 1], [0, 0, 1, 1]],
| names=[u&#39;foo&#39;, u&#39;bar&#39;])
| &gt;&gt;&gt; idx.set_labels([[1,0,1,0], [0,0,1,1]], level=[0,1])
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[1, 0, 1, 0], [0, 0, 1, 1]],
| names=[u&#39;foo&#39;, u&#39;bar&#39;])
|
| set_levels(self, levels, level=None, inplace=False, verify_integrity=True)
| Set new levels on MultiIndex. Defaults to returning
| new index.
|
| 【参数】
| ----------| levels : sequence or list of sequence
| new level(s) to apply
| level : int or level name, or sequence of int / level names (default None)
| level(s) to set (None for all levels)
| inplace : bool
| if True, mutates in place
| verify_integrity : bool (default True)
| if True, checks that levels and labels are compatible
|
| 【返回值】
| -------| new index (of same type and class...etc)
|
|
| 【示例】
| --------| &gt;&gt;&gt; idx = MultiIndex.from_tuples([(1, u&#39;one&#39;), (1, u&#39;two&#39;),
248
| (2, u&#39;one&#39;), (2, u&#39;two&#39;)],
| names=[&#39;foo&#39;, &#39;bar&#39;])
| &gt;&gt;&gt; idx.set_levels([[&#39;a&#39;,&#39;b&#39;], [1,2]])
| MultiIndex(levels=[[u&#39;a&#39;, u&#39;b&#39;], [1, 2]],
| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
| names=[u&#39;foo&#39;, u&#39;bar&#39;])
| &gt;&gt;&gt; idx.set_levels([&#39;a&#39;,&#39;b&#39;], level=0)
| MultiIndex(levels=[[u&#39;a&#39;, u&#39;b&#39;], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
| names=[u&#39;foo&#39;, u&#39;bar&#39;])
| &gt;&gt;&gt; idx.set_levels([&#39;a&#39;,&#39;b&#39;], level=&#39;bar&#39;)
| MultiIndex(levels=[[1, 2], [u&#39;a&#39;, u&#39;b&#39;]],
| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
| names=[u&#39;foo&#39;, u&#39;bar&#39;])
| &gt;&gt;&gt; idx.set_levels([[&#39;a&#39;,&#39;b&#39;], [1,2]], level=[0,1])
| MultiIndex(levels=[[u&#39;a&#39;, u&#39;b&#39;], [1, 2]],
| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
| names=[u&#39;foo&#39;, u&#39;bar&#39;])
|
| slice_locs(self, start=None, end=None, step=None, kind=None)
| For an ordered MultiIndex, compute the slice locations for input
| labels. They can be tuples representing partial levels, e.g. for a
| MultiIndex with 3 levels, you can pass a single value (corresponding to
| the first level), or a 1-, 2-, or 3-tuple.
|
| 【参数】
| ----------| start : label or tuple, default None
| If None, defaults to the beginning
| end : label or tuple
| If None, defaults to the end
| step : int or None
| Slice step
| kind : string, optional, defaults None
|
| 【返回值】
| -------| (start, end) : (int, int)
|
| 【注意】
| -----| This function assumes that the data is sorted by the first level
|
| sortlevel(self, level=0, ascending=True, sort_remaining=True)
| Sort MultiIndex at the requested level. The result will respect the
| original ordering of the associated factor at that level.
|
| 【参数】
| ----------| level : list-like, int or str, default 0
| If a string is given, must be a name of the level
| If list-like must be names or ints of levels.
| ascending : boolean, default True
| False to sort in descending order
| Can also be a list to specify a directed ordering
| sort_remaining : sort by the remaining levels after level.
|
249
| 【返回值】
| -------| sorted_index : MultiIndex
|
| swaplevel(self, i, j)
| Swap level i with level j. Do not change the ordering of anything
|
| 【参数】
| ----------| i, j : int, string (can be mixed)
| Level of index to be swapped. Can pass level name as string.
|
| 【返回值】
| -------| swapped : MultiIndex
|
| take(self, indexer, axis=None)
| return a new Index of the values selected by the indexer
|
| For internal compatibility with numpy arrays.
|
| # filling must always be None/nan here
| # but is passed thru internally
|
| 【参见】
| --------| numpy.ndarray.take
|
| to_hierarchical(self, n_repeat, n_shuffle=1)
| Return a MultiIndex reshaped to conform to the
| shapes given by n_repeat and n_shuffle.
|
| Useful to replicate and rearrange a MultiIndex for combination
| with another Index with n_repeat items.
|
| 【参数】
| ----------| n_repeat : int
| Number of times to repeat the labels on self
| n_shuffle : int
| Controls the reordering of the labels. If the result is going
| to be an inner level in a MultiIndex, n_shuffle will need to be
| greater than one. The size of each label must divisible by
| n_shuffle.
|
| 【返回值】
| -------| MultiIndex
|
| 【示例】
| --------| &gt;&gt;&gt; idx = MultiIndex.from_tuples([(1, u&#39;one&#39;), (1, u&#39;two&#39;),
| (2, u&#39;one&#39;), (2, u&#39;two&#39;)])
| &gt;&gt;&gt; idx.to_hierarchical(3)
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],
| [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1]])
250
|
| truncate(self, before=None, after=None)
| Slice index between two labels / tuples, return new MultiIndex
|
| 【参数】
| ----------| before : label or tuple, can be partial. Default None
| None defaults to start
| after : label or tuple, can be partial. Default None
| None defaults to end
|
| 【返回值】
| -------| truncated : MultiIndex
|
| union(self, other)
| Form the union of two MultiIndex objects, sorting if possible
|
| 【参数】
| ----------| other : MultiIndex or array / Index of tuples
|
| 【返回值】
| -------| Index
|
| &gt;&gt;&gt; index.union(index2)
|
| view(self, cls=None)
| this is defined as a copy with the same identity
|
| ----------------------------------------------------------------------| Class methods defined here:
|
| from_arrays(arrays, sortorder=None, names=None) from builtins.type
| Convert arrays to MultiIndex
|
| 【参数】
| ----------| arrays : list / sequence of array-likes
| Each array-like gives one level&#39;s value for each data point.
| len(arrays) is the number of levels.
| sortorder : int or None
| Level of sortedness (must be lexicographically sorted by that
| level)
|
| 【返回值】
| -------| index : MultiIndex
|
| 【示例】
| --------| &gt;&gt;&gt; arrays = [[1, 1, 2, 2], [&#39;red&#39;, &#39;blue&#39;, &#39;red&#39;, &#39;blue&#39;]]
| &gt;&gt;&gt; MultiIndex.from_arrays(arrays, names=(&#39;number&#39;, &#39;color&#39;))
|
| 【参见】
251
| --------| MultiIndex.from_tuples : Convert list of tuples to MultiIndex
| MultiIndex.from_product : Make a MultiIndex from cartesian product
| of iterables
|
| from_product(iterables, sortorder=None, names=None) from builtins.type
| Make a MultiIndex from the cartesian product of multiple iterables
|
| 【参数】
| ----------| iterables : list / sequence of iterables
| Each iterable has unique labels for each level of the index.
| sortorder : int or None
| Level of sortedness (must be lexicographically sorted by that
| level).
| names : list / sequence of strings or None
| Names for the levels in the index.
|
| 【返回值】
| -------| index : MultiIndex
|
| 【示例】
| --------| &gt;&gt;&gt; numbers = [0, 1, 2]
| &gt;&gt;&gt; colors = [u&#39;green&#39;, u&#39;purple&#39;]
| &gt;&gt;&gt; MultiIndex.from_product([numbers, colors],
| names=[&#39;number&#39;, &#39;color&#39;])
| MultiIndex(levels=[[0, 1, 2], [u&#39;green&#39;, u&#39;purple&#39;]],
| labels=[[0, 0, 1, 1, 2, 2], [0, 1, 0, 1, 0, 1]],
| names=[u&#39;number&#39;, u&#39;color&#39;])
|
| 【参见】
| --------| MultiIndex.from_arrays : Convert list of arrays to MultiIndex
| MultiIndex.from_tuples : Convert list of tuples to MultiIndex
|
| from_tuples(tuples, sortorder=None, names=None) from builtins.type
| Convert list of tuples to MultiIndex
|
| 【参数】
| ----------| tuples : list / sequence of tuple-likes
| Each tuple is the index of one row/column.
| sortorder : int or None
| Level of sortedness (must be lexicographically sorted by that
| level)
|
| 【返回值】
| -------| index : MultiIndex
|
| 【示例】
| --------| &gt;&gt;&gt; tuples = [(1, u&#39;red&#39;), (1, u&#39;blue&#39;),
| (2, u&#39;red&#39;), (2, u&#39;blue&#39;)]
| &gt;&gt;&gt; MultiIndex.from_tuples(tuples, names=(&#39;number&#39;, &#39;color&#39;))
252
|
| 【参见】
| --------| MultiIndex.from_arrays : Convert list of arrays to MultiIndex
| MultiIndex.from_product : Make a MultiIndex from cartesian product
| of iterables
|
| ----------------------------------------------------------------------| Static methods defined here:
|
| __new__(cls, levels=None, labels=None, sortorder=None, names=None, copy=False, verify_integrity=True,
_set_identity=True, name=None, **kwargs)
| Create and return a new object. See help(type) for accurate signature.
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| dtype
|
| inferred_type
|
| is_all_dates
|
| is_unique
|
| labels
|
| levels
|
| levshape
|
| lexsort_depth
|
| names
| Names of levels in MultiIndex
|
| nbytes
|
| nlevels
|
| values
| return the underlying data as an ndarray
|
| ----------------------------------------------------------------------| Methods inherited from Index:
|
| __add__(self, other)
|
| __and__(self, other)
|
| __array_wrap__(self, result, context=None)
| Gets called after a ufunc
|
| __bool__ = __nonzero__(self)
|
| __copy__ = copy(self, names=None, name=None, dtype=None, deep=False)
| Make a copy of this object. Name and dtype sets those attributes on
253
| the new object.
|
| 【参数】
| ----------| name : string, optional
| dtype : numpy dtype or pandas type
|
| 【返回值】
| -------| copy : Index
|
| 【注意】
| -----| In most cases, there should be no functional difference from using
| ``deep``, but if ``deep`` is passed it will attempt to deepcopy.
|
| __deepcopy__(self, memo={})
|
| __eq__ = _evaluate_compare(self, other)
|
| __ge__ = _evaluate_compare(self, other)
|
| __gt__ = _evaluate_compare(self, other)
|
| __hash__(self)
| Return hash(self).
|
| __iadd__ = __add__(self, other)
|
| __iter__(self)
|
| __le__ = _evaluate_compare(self, other)
|
| __lt__ = _evaluate_compare(self, other)
|
| __ne__ = _evaluate_compare(self, other)
|
| __nonzero__(self)
|
| __or__(self, other)
|
| __radd__(self, other)
|
| __setitem__(self, key, value)
|
| __sub__(self, other)
|
| __unicode__(self)
| Return a string representation for this object.
|
| Invoked by unicode(df) in py2 only. Yields a Unicode String in both
| py2/py3.
|
| __xor__(self, other)
|
| asof(self, label)
| For a sorted index, return the most recent label up to and including
254
| the passed label. Return NaN if not found.
|
| 【参见】
| --------| get_loc : asof is a thin wrapper around get_loc with method=&#39;pad&#39;
|
| asof_locs(self, where, mask)
| where : array of timestamps
| mask : array of booleans where data is not NA
|
| diff = wrapper(*args, **kwargs)
|
| drop_duplicates(self, keep=&#39;first&#39;)
| Return Index with duplicate values removed
|
| 【参数】
| ----------|
| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| - ``first`` : Drop duplicates except for the first occurrence.
| - ``last`` : Drop duplicates except for the last occurrence.
| - False : Drop all duplicates.
| take_last : deprecated
|
|
| 【返回值】
| -------| deduplicated : Index
|
| get_duplicates(self)
|
| get_indexer_for(self, target, **kwargs)
| guaranteed return of an indexer even when non-unique
|
| get_indexer_non_unique(self, target)
| return an indexer suitable for taking from a non unique index
| return the labels in the same order as the target, and
| return a missing indexer into the target (missing are marked as -1
| in the indexer); target must be an iterable
|
| get_values(self)
| return the underlying data as an ndarray
|
| groupby(self, to_groupby)
| Group the index labels by a given array of values.
|
| 【参数】
| ----------| to_groupby : array
| Values used to determine the groups.
|
| 【返回值】
| -------| groups : dict
| {group name -&gt; group labels}
|
| holds_integer(self)
255
|
| identical(self, other)
| Similar to equals, but check that other comparable attributes are
| also equal
|
| is_(self, other)
| More flexible, faster check like ``is`` but that works through views
|
| Note: this is *not* the same as ``Index.identical()``, which checks
| that metadata is also the same.
|
| 【参数】
| ----------| other : object
| other object to compare against.
|
| 【返回值】
| -------| True if both have same underlying data, False otherwise : bool
|
| is_boolean(self)
|
| is_categorical(self)
|
| is_floating(self)
|
| is_integer(self)
|
| is_mixed(self)
|
| is_numeric(self)
|
| is_object(self)
|
| is_type_compatible(self, kind)
|
| join(self, other, how=&#39;left&#39;, level=None, return_indexers=False)
| *this is an internal non-public method*
|
| Compute join_index and indexers to conform data
| structures to the new index.
|
| 【参数】
| ----------| other : Index
| how : {&#39;left&#39;, &#39;right&#39;, &#39;inner&#39;, &#39;outer&#39;}
| level : int or level name, default None
| return_indexers : boolean, default False
|
| 【返回值】
| -------| join_index, (left_indexer, right_indexer)
|
| map(self, mapper)
|
| order(self, return_indexer=False, ascending=True)
| Return sorted copy of Index
256
|
| DEPRECATED: use :meth:</code>Index.sort_values<code>|
| putmask(self, mask, value)
| return a new Index of the values set with the mask
|
| 【参见】
| --------| numpy.ndarray.putmask
|
| ravel(self, order=&#39;C&#39;)
| return an ndarray of the flattened values of the underlying data
|
| 【参见】
| --------| numpy.ndarray.ravel
|
| set_names(self, names, level=None, inplace=False)
| Set new names on index. Defaults to returning new index.
|
| 【参数】
| ----------| names : str or sequence
| name(s) to set
| level : int or level name, or sequence of int / level names (default None)
| If the index is a MultiIndex (hierarchical), level(s) to set (None for all levels)
| Otherwise level must be None
| inplace : bool
| if True, mutates in place
|
| 【返回值】
| -------| new index (of same type and class...etc) [if inplace, returns None]
|
| 【示例】
| --------| &gt;&gt;&gt; Index([1, 2, 3, 4]).set_names(&#39;foo&#39;)
| Int64Index([1, 2, 3, 4], dtype=&#39;int64&#39;)
| &gt;&gt;&gt; Index([1, 2, 3, 4]).set_names([&#39;foo&#39;])
| Int64Index([1, 2, 3, 4], dtype=&#39;int64&#39;)
| &gt;&gt;&gt; idx = MultiIndex.from_tuples([(1, u&#39;one&#39;), (1, u&#39;two&#39;),
| (2, u&#39;one&#39;), (2, u&#39;two&#39;)],
| names=[&#39;foo&#39;, &#39;bar&#39;])
| &gt;&gt;&gt; idx.set_names([&#39;baz&#39;, &#39;quz&#39;])
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
| names=[u&#39;baz&#39;, u&#39;quz&#39;])
| &gt;&gt;&gt; idx.set_names(&#39;baz&#39;, level=0)
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
| names=[u&#39;baz&#39;, u&#39;bar&#39;])
|
| set_value(self, arr, key, value)
| Fast lookup of value from 1-dimensional ndarray. Only use this if you
| know what you&#39;re doing
|
| shift(self, periods=1, freq=None)
257
| Shift Index containing datetime objects by input number of periods and
| DateOffset
|
| 【返回值】
| -------| shifted : Index
|
| slice_indexer(self, start=None, end=None, step=None, kind=None)
| For an ordered Index, compute the slice indexer for input labels and
| step
|
| 【参数】
| ----------| start : label, default None
| If None, defaults to the beginning
| end : label, default None
| If None, defaults to the end
| step : int, default None
| kind : string, default None
|
| 【返回值】
| -------| indexer : ndarray or slice
|
| 【注意】
| -----| This function assumes that the data is sorted, so use at your own peril
|
| sort(self, *args, **kwargs)
|
| sort_values(self, return_indexer=False, ascending=True)
| Return sorted copy of Index
|
| summary(self, name=None)
|
| sym_diff(self, other, result_name=None)
| Compute the sorted symmetric difference of two Index objects.
|
| 【参数】
| ----------| other : Index or array-like
| result_name : str
|
| 【返回值】
| -------| sym_diff : Index
|
| 【注意】
| -----| ``sym_diff`` contains elements that appear in either ``idx1`` or
| ``idx2`` but not both. Equivalent to the Index created by
| ``(idx1 - idx2) + (idx2 - idx1)`` with duplicates dropped.
|
| The sorting of a result containing ``NaN`` values is not guaranteed
| across Python versions. See GitHub issue #6444.
|
258
| 【示例】
| --------| &gt;&gt;&gt; idx1 = Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = Index([2, 3, 4, 5])
| &gt;&gt;&gt; idx1.sym_diff(idx2)
| Int64Index([1, 5], dtype=&#39;int64&#39;)
|
| You can also use the ``^`` operator:
|
| &gt;&gt;&gt; idx1 ^ idx2
| Int64Index([1, 5], dtype=&#39;int64&#39;)
|
| to_datetime(self, dayfirst=False)
| For an Index containing strings or datetime.datetime objects, attempt
| conversion to DatetimeIndex
|
| to_native_types(self, slicer=None, **kwargs)
| slice and dice then format
|
| to_series(self, **kwargs)
| Create a Series with both index and values equal to the index keys
| useful with map for returning an indexer based on an index
|
| 【返回值】
| -------| Series : dtype will be based on the type of the Index values.
|
| tolist(self)
| return a list of the Index values
|
| ----------------------------------------------------------------------| Data descriptors inherited from Index:
|
| dtype_str
|
| has_duplicates
|
| hasnans
|
| is_monotonic
| alias for is_monotonic_increasing (deprecated)
|
| is_monotonic_decreasing
| return if the index is monotonic decreasing (only equal or
| decreasing) values.
|
| is_monotonic_increasing
| return if the index is monotonic increasing (only equal or
| increasing) values.
|
| ----------------------------------------------------------------------| Data and other attributes inherited from Index:
|
| asi8 = None
|
| name = None
|
259
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.IndexOpsMixin:
|
| argmax(self, axis=None)
| return a ndarray of the maximum argument indexer
|
| 【参见】
| --------| numpy.ndarray.argmax
|
| argmin(self, axis=None)
| return a ndarray of the minimum argument indexer
|
| 【参见】
| --------| numpy.ndarray.argmin
|
| factorize(self, sort=False, na_sentinel=-1)
| Encode the object as an enumerated type or categorical variable
|
| 【参数】
| ----------| sort : boolean, default False
| Sort by values
| na_sentinel: int, default -1
| Value to mark &quot;not found&quot;
|
| 【返回值】
| -------| labels : the indexer to the original array
| uniques : the unique Index
|
| item(self)
| return the first element of the underlying data as a python scalar
|
| max(self)
| The maximum value of the object
|
| memory_usage(self, deep=False)
| Memory usage of my values
|
| 【参数】
| ----------| deep : bool
| Introspect the data deeply, interrogate
|</code>object<code>dtypes for system-level memory consumption
|
| 【返回值】
| -------| bytes used
|
| 【注意】
| -----| Memory usage does not include memory consumed by elements that
| are not components of the array if deep=False
|
260
| 【参见】
| --------| numpy.ndarray.nbytes
|
| min(self)
| The minimum value of the object
|
| nunique(self, dropna=True)
| Return number of unique elements in the object.
|
| Excludes NA values by default.
|
| 【参数】
| ----------| dropna : boolean, default True
| Don&#39;t include NaN in the count.
|
| 【返回值】
| -------| nunique : int
|
| searchsorted(self, key, side=&#39;left&#39;)
| np.ndarray searchsorted compat
|
| transpose(self)
| return the transpose, which is by definition self
|
| unique(self)
| Return array of unique values in the object. Significantly faster than
| numpy.unique. Includes NA values.
|
| 【返回值】
| -------| uniques : ndarray
|
| value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)
| Returns object containing counts of unique values.
|
| The resulting object will be in descending order so that the
| first element is the most frequently-occurring element.
| Excludes NA values by default.
|
| 【参数】
| ----------| normalize : boolean, default False
| If True then the object returned will contain the relative
| frequencies of the unique values.
| sort : boolean, default True
| Sort by values
| ascending : boolean, default False
| Sort in ascending order
| bins : integer, optional
| Rather than count values, group them into half-open bins,
| a convenience for pd.cut, only works with numeric data
| dropna : boolean, default True
| Don&#39;t include counts of NaN.
|
261
| 【返回值】
| -------| counts : Series
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.base.IndexOpsMixin:
|
| T
| return the transpose, which is by definition self
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
|
| base
| return the base object if the memory of the underlying data is shared
|
| data
| return the data pointer of the underlying data
|
| flags
| return the ndarray.flags for the underlying data
|
| itemsize
| return the size of the dtype of the item of the underlying data
|
| ndim
| return the number of dimensions of the underlying data, by definition 1
|
| shape
| return a tuple of the shape of the underlying data
|
| size
| return the number of elements in the underlying data
|
| strides
| return the strides of the underlying data
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.base.IndexOpsMixin:
|
| __array_priority__ = 1000
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.strings.StringAccessorMixin:
|
| str = &lt;class &#39;pandas.core.strings.StringMethods&#39;&gt;
| Vectorized string functions for Series and Index. NAs stay NA unless
| handled otherwise by a particular method. Patterned after Python&#39;s string
| methods, with some inspiration from R&#39;s stringr package.
|
| 【示例】
| --------| &gt;&gt;&gt; s.str.split(&#39;_&#39;)
| &gt;&gt;&gt; s.str.replace(&#39;_&#39;, &#39;&#39;)
262
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.PandasObject:
|
| __dir__(self)
| Provide method name lookup and completion
| Only provide &#39;public&#39; methods
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
| Return a string representation for a particular object.
|
| Invoked by bytes(obj) in py3 only.
| Yields a bytestring in both py2/py3.
|
| __repr__(self)
| Return a string representation for a particular object.
|
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
NaT
NaTType 模块所属：pandas.tslib object:
类定义：NaTType(_NaT)
| (N)ot-(A)-(T)ime, the time equivalent of NaN
|
| 【方法排序】
| NaTType
| _NaT
| _Timestamp
| datetime.datetime
| datetime.date
| 【内置对象】
|
| 【方法定义】
|
| __hash__(self)
|
| __int__(self)
|
| __long__(self)
263
|
| __new__(cls)
|
| __reduce__(self)
|
| __repr__(self)
|
| __str__(self)
|
| astimezone(*args, **kwargs)
|
| combine(*args, **kwargs)
|
| ctime(*args, **kwargs)
|
| date(*args, **kwargs)
|
| dst(*args, **kwargs)
|
| fromordinal(*args, **kwargs)
|
| fromtimestamp(*args, **kwargs)
|
| isocalendar(*args, **kwargs)
|
| isoformat(*args, **kwargs)
|
| isoweekday(*args, **kwargs)
|
| now(*args, **kwargs)
|
| replace(*args, **kwargs)
|
| strftime(*args, **kwargs)
|
| strptime(*args, **kwargs)
|
| time(*args, **kwargs)
|
| timestamp(*args, **kwargs)
|
| timetuple(*args, **kwargs)
|
| timetz(*args, **kwargs)
|
| to_datetime(*args, **kwargs)
|
| today(*args, **kwargs)
|
| toordinal(*args, **kwargs)
|
| total_seconds(*args, **kwargs)
|
| tzname(*args, **kwargs)
|
| utcfromtimestamp(*args, **kwargs)
|
264
| utcnow(*args, **kwargs)
|
| utcoffset(*args, **kwargs)
|
| utctimetuple(*args, **kwargs)
|
| weekday(*args, **kwargs)
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
|
| day
|
| dayofweek
|
| dayofyear
|
| days_in_month
|
| daysinmonth
|
| hour
|
| microsecond
|
| millisecond
|
| minute
|
| month
|
| nanosecond
|
| quarter
|
| second
|
| week
|
| year
|
| ----------------------------------------------------------------------| Methods inherited from _NaT:
|
| __add__(self, value, /)
| Return self+value.
|
| __eq__(self, value, /)
| Return self==value.
|
| __ge__(self, value, /)
265
| Return self&gt;=value.
|
| __gt__(self, value, /)
| Return self&gt;value.
|
| __le__(self, value, /)
| Return self&lt;=value.
|
| __lt__(self, value, /)
| Return self&lt;value.
|
| __ne__(self, value, /)
| Return self!=value.
|
| __radd__(self, value, /)
| Return value+self.
|
| __rsub__(self, value, /)
| Return value-self.
|
| __sub__(self, value, /)
| Return self-value.
|
| ----------------------------------------------------------------------| Data and other attributes inherited from _NaT:
|
| __pyx_vtable__ = &lt;capsule object NULL&gt;
|
| ----------------------------------------------------------------------| Methods inherited from _Timestamp:
|
| to_datetime64(...)
| Returns a numpy.datetime64 object with &#39;ns&#39; precision
|
| ----------------------------------------------------------------------| Data descriptors inherited from _Timestamp:
|
| offset
|
| value
|
| ----------------------------------------------------------------------| Methods inherited from datetime.datetime:
|
| __getattribute__(self, name, /)
| Return getattr(self, name).
|
| ----------------------------------------------------------------------| Data descriptors inherited from datetime.datetime:
|
| tzinfo
|
| ----------------------------------------------------------------------| Data and other attributes inherited from datetime.datetime:
|
| max = datetime.datetime(9999, 12, 31, 23, 59, 59, 999999)
|
266
| min = datetime.datetime(1, 1, 1, 0, 0)
|
| resolution = datetime.timedelta(0, 0, 1)
|
| ----------------------------------------------------------------------| Methods inherited from datetime.date:
|
| __format__(...)
| Formats self with strftime.
Panel
Panel 模块所属：pandas.core.panel:
类定义：Panel(pandas.core.generic.NDFrame)
| Represents wide format panel data, stored as 3-dimensional array
|
| 【参数】
| ----------| data : ndarray (items x major x minor), or dict of DataFrames
| items : Index or array-like
| axis=0
| major_axis : Index or array-like
| axis=1
| minor_axis : Index or array-like
| axis=2
| dtype : dtype, default None
| Data type to force, otherwise infer
| copy : boolean, default False
| Copy data from inputs. Only affects DataFrame / 2d ndarray input
|
| 【方法排序】
| Panel
| pandas.core.generic.NDFrame
| pandas.core.base.PandasObject
| pandas.core.base.StringMixin
| 【内置对象】
|
| 【方法定义】
|
| __add__(self, other)
| # work only for scalars
|
| __and__(self, other)
| # work only for scalars
|
| __div__ = __truediv__(self, other)
|
| __eq__(self, other)
| Wrapper for comparison method __eq__
267
|
| __floordiv__(self, other)
| # work only for scalars
|
| __ge__(self, other)
| Wrapper for comparison method __ge__
|
| __getitem__(self, key)
|
| __gt__(self, other)
| Wrapper for comparison method __gt__
|
| __iadd__ = f(self, other)
|
| __imul__ = f(self, other)
|
| __init__(self, data=None, items=None, major_axis=None, minor_axis=None, copy=False, dtype=None)
| Initialize self. See help(type(self)) for accurate signature.
|
| __ipow__ = f(self, other)
|
| __isub__ = f(self, other)
|
| __itruediv__ = f(self, other)
|
| __le__(self, other)
| Wrapper for comparison method __le__
|
| __lt__(self, other)
| Wrapper for comparison method __lt__
|
| __mod__(self, other)
| # work only for scalars
|
| __mul__(self, other)
| # work only for scalars
|
| __ne__(self, other)
| Wrapper for comparison method __ne__
|
| __or__(self, other)
| # work only for scalars
|
| __pow__(self, other)
| # work only for scalars
|
| __radd__(self, other)
| # work only for scalars
|
| __rand__(self, other)
| # work only for scalars
|
| __rdiv__ = __rtruediv__(self, other)
|
| __rfloordiv__(self, other)
| # work only for scalars
|
268
| __rmod__(self, other)
| # work only for scalars
|
| __rmul__(self, other)
| # work only for scalars
|
| __ror__(self, other)
| # work only for scalars
|
| __rpow__(self, other)
| # work only for scalars
|
| __rsub__(self, other)
| # work only for scalars
|
| __rtruediv__(self, other)
| # work only for scalars
|
| __rxor__(self, other)
| # work only for scalars
|
| __setitem__(self, key, value)
|
| __sub__(self, other)
| # work only for scalars
|
| __truediv__(self, other)
| # work only for scalars
|
| __unicode__(self)
| Return a string representation for a particular Panel
|
| Invoked by unicode(df) in py2 only.
| Yields a Unicode String in both py2/py3.
|
| __xor__(self, other)
| # work only for scalars
|
| add(self, other, axis=0)
| Addition of series and other, element-wise (binary operator</code>add<code>).
| Equivalent to ``panel + other``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.radd
|
| align(self, other, **kwargs)
269
| Align two object on their axes with the
| specified join method for each axis Index
|
| 【参数】
| ----------| other : DataFrame or Series
| join : {&#39;outer&#39;, &#39;inner&#39;, &#39;left&#39;, &#39;right&#39;}, default &#39;outer&#39;
| axis : allowed axis of the other object, default None
| Align on index (0), columns (1), or both (None)
| level : int or level name, default None
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
| copy : boolean, default True
| Always returns new objects. If copy=False and no reindexing is
| required then original objects are returned.
| fill_value : scalar, default np.NaN
| Value to use for missing values. Defaults to NaN, but can be any
| &quot;compatible&quot; value
| method : str, default None
| limit : int, default None
| fill_axis : int or labels for object, default 0
| Filling axis, method and limit
| broadcast_axis : int or labels for object, default None
| Broadcast values along this axis, if aligning two objects of
| different dimensions
|
| .. versionadded:: 0.17.0
|
| 【返回值】
| -------| (left, right) : (NDFrame, type of other)
| Aligned objects
|
| all(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)
| Return whether all elements are True over requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| bool_only : boolean, default None
| Include only boolean data. If None, will attempt to use everything,
| then use only boolean data
|
| 【返回值】
| -------| all : DataFrame or Panel (if level specified)
|
| any(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)
| Return whether any element is True over requested axis
|
| 【参数】
270
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| bool_only : boolean, default None
| Include only boolean data. If None, will attempt to use everything,
| then use only boolean data
|
| 【返回值】
| -------| any : DataFrame or Panel (if level specified)
|
| apply(self, func, axis=&#39;major&#39;, **kwargs)
| Applies function along axis (or axes) of the Panel
|
| 【参数】
| ----------| func : function
| Function to apply to each combination of &#39;other&#39; axes
| e.g. if axis = &#39;items&#39;, the combination of major_axis/minor_axis
| will each be passed as a Series; if axis = (&#39;items&#39;, &#39;major&#39;), DataFrames
| of items &amp; major axis will be passed
| axis : {&#39;items&#39;, &#39;minor&#39;, &#39;major&#39;}, or {0, 1, 2}, or a tuple with two axes
| Additional keyword arguments will be passed as keywords to the function
|
| 【示例】
| --------|
| Returns a Panel with the square root of each element
|
| &gt;&gt;&gt; p = pd.Panel(np.random.rand(4,3,2))
| &gt;&gt;&gt; p.apply(np.sqrt)
|
| Equivalent to p.sum(1), returning a DataFrame
|
| &gt;&gt;&gt; p.apply(lambda x: x.sum(), axis=1)
|
| Equivalent to previous:
|
| &gt;&gt;&gt; p.apply(lambda x: x.sum(), axis=&#39;minor&#39;)
|
| Return the shapes of each DataFrame over axis 2 (i.e the shapes of items x major), as a Series
|
| &gt;&gt;&gt; p.apply(lambda x: x.shape, axis=(0,1))
|
| 【返回值】
| -------| result : Panel, DataFrame, or Series
|
| as_matrix(self)
| Convert the frame to its Numpy-array representation.
|
| 【参数】
271
| ----------| columns: list, optional, default:None
| If None, return all columns, otherwise, returns specified columns.
|
| 【返回值】
| -------| values : ndarray
| If the caller is heterogeneous and contains booleans or objects,
| the result will be of dtype=object. See Notes.
|
|
| 【注意】
| -----| Return is NOT a Numpy-matrix, rather, a Numpy-array.
|
| The dtype will be a lower-common-denominator dtype (implicit
| upcasting); that is to say if the dtypes (even of numeric types)
| are mixed, the one that accommodates all will be chosen. Use this
| with care if you are not dealing with the blocks.
|
| e.g. If the dtypes are float16 and float32, dtype will be upcast to
| float32. If dtypes are int32 and uint8, dtype will be upcase to
| int32.
|
| This method is provided for backwards compatibility. Generally,
| it is recommended to use &#39;.values&#39;.
|
| 【参见】
| --------| pandas.DataFrame.values
|
| compound(self, axis=None, skipna=None, level=None)
| Return the compound percentage of the values for the requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| compounded : DataFrame or Panel (if level specified)
|
| conform(self, frame, axis=&#39;items&#39;)
| Conform input DataFrame to align with chosen axis pair.
|
| 【参数】
| ----------| frame : DataFrame
272
| axis : {&#39;items&#39;, &#39;major&#39;, &#39;minor&#39;}
|
| Axis the input corresponds to. E.g., if axis=&#39;major&#39;, then
| the frame&#39;s columns would be items, and the index would be
| values of the minor axis
|
| 【返回值】
| -------| DataFrame
|
| count(self, axis=&#39;major&#39;)
| Return number of observations over requested axis.
|
| 【参数】
| ----------| axis : {&#39;items&#39;, &#39;major&#39;, &#39;minor&#39;} or {0, 1, 2}
|
| 【返回值】
| -------| count : DataFrame
|
| cummax = max(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative max over requested axis.
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| max : DataFrame
|
| cummin = min(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative min over requested axis.
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| min : DataFrame
|
| cumprod = prod(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative prod over requested axis.
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
273
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| prod : DataFrame
|
| cumsum = sum(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative sum over requested axis.
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| sum : DataFrame
|
| div = truediv(self, other, axis=0)
|
| divide = truediv(self, other, axis=0)
|
| dropna(self, axis=0, how=&#39;any&#39;, inplace=False)
| Drop 2D from panel, holding passed axis constant
|
| 【参数】
| ----------| axis : int, default 0
| Axis to hold constant. E.g. axis=1 will drop major_axis entries
| having a certain amount of NA data
| how : {&#39;all&#39;, &#39;any&#39;}, default &#39;any&#39;
| &#39;any&#39;: one or more values are NA in the DataFrame along the
| axis. For &#39;all&#39; they all must be.
| inplace : bool, default False
| If True, do operation inplace and return None.
|
| 【返回值】
| -------| dropped : Panel
|
| eq(self, other)
| Wrapper for comparison method eq
|
| fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)
| Fill NA/NaN values using the specified method
|
| 【参数】
| ----------| value : scalar, dict, Series, or DataFrame
| Value to use to fill holes (e.g. 0), alternately a dict/Series/DataFrame of
| values specifying which value to use for each index (for a Series) or
| column (for a DataFrame). (values not in the dict/Series/DataFrame will not be
| filled). This value cannot be a list.
| method : {&#39;backfill&#39;, &#39;bfill&#39;, &#39;pad&#39;, &#39;ffill&#39;, None}, default None
274
| Method to use for filling holes in reindexed Series
| pad / ffill: propagate last valid observation forward to next valid
| backfill / bfill: use NEXT valid observation to fill gap
| axis : {0, 1, 2, &#39;items&#39;, &#39;major_axis&#39;, &#39;minor_axis&#39;}
| inplace : boolean, default False
| If True, fill in place. Note: this will modify any
| other views on this object, (e.g. a no-copy slice for a column in a
| DataFrame).
| limit : int, default None
| If method is specified, this is the maximum number of consecutive
| NaN values to forward/backward fill. In other words, if there is
| a gap with more than this number of consecutive NaNs, it will only
| be partially filled. If method is not specified, this is the
| maximum number of entries along the entire axis where NaNs will be
| filled.
| downcast : dict, default is None
| a dict of item-&gt;dtype of what to downcast if possible,
| or the string &#39;infer&#39; which will try to downcast to an appropriate
| equal type (e.g. float64 to int64 if possible)
|
| 【参见】
| --------| reindex, asfreq
|
| 【返回值】
| -------| filled : Panel
|
| floordiv(self, other, axis=0)
| Integer division of series and other, element-wise (binary operator</code>floordiv<code>).
| Equivalent to ``panel // other``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.rfloordiv
|
| ge(self, other)
| Wrapper for comparison method ge
|
| get_value(self, *args, **kwargs)
| Quickly retrieve single value at (item, major, minor) location
|
| 【参数】
| ----------| item : item label (panel item)
| major : major axis label (panel item row)
| minor : minor axis label (panel item column)
275
| takeable : interpret the passed labels as indexers, default False
|
| 【返回值】
| -------| value : scalar value
|
| groupby(self, function, axis=&#39;major&#39;)
| Group data on given axis, returning GroupBy object
|
| 【参数】
| ----------| function : callable
| Mapping function for chosen access
| axis : {&#39;major&#39;, &#39;minor&#39;, &#39;items&#39;}, default &#39;major&#39;
|
| 【返回值】
| -------| grouped : PanelGroupBy
|
| gt(self, other)
| Wrapper for comparison method gt
|
| head(self, n=5)
| Returns first n rows
|
| join(self, other, how=&#39;left&#39;, lsuffix=&#39;&#39;, rsuffix=&#39;&#39;)
| Join items with other Panel either on major and minor axes column
|
| 【参数】
| ----------| other : Panel or list of Panels
| Index should be similar to one of the columns in this one
| how : {&#39;left&#39;, &#39;right&#39;, &#39;outer&#39;, &#39;inner&#39;}
| How to handle indexes of the two objects. Default: &#39;left&#39;
| for joining on index, None otherwise
| * left: use calling frame&#39;s index
| * right: use input frame&#39;s index
| * outer: form union of indexes
| * inner: use intersection of indexes
| lsuffix : string
| Suffix to use from left frame&#39;s overlapping columns
| rsuffix : string
| Suffix to use from right frame&#39;s overlapping columns
|
| 【返回值】
| -------| joined : Panel
|
| kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return unbiased kurtosis over requested axis using Fishers definition of
| kurtosis (kurtosis of normal == 0.0). Normalized by N-1
|
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
276
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| kurt : DataFrame or Panel (if level specified)
|
| kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
|
| le(self, other)
| Wrapper for comparison method le
|
| lt(self, other)
| Wrapper for comparison method lt
|
| mad(self, axis=None, skipna=None, level=None)
| Return the mean absolute deviation of the values for the requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| mad : DataFrame or Panel (if level specified)
|
| major_xs(self, key, copy=None)
| Return slice of panel along major axis
|
| 【参数】
| ----------| key : object
| Major axis label
| copy : boolean [deprecated]
| Whether to make a copy of the data
|
| 【返回值】
| -------| y : DataFrame
| index -&gt; minor axis, columns -&gt; items
|
| 【注意】
277
| -----| major_xs is only for getting, not setting values.
|
| MultiIndex Slicers is a generic way to get/set values on any level or levels
| it is a superset of major_xs functionality, see :ref:</code>MultiIndex Slicers <advanced.mi_slicers><code>|
| max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| This method returns the maximum of the values in the object. If you
| want the *index* of the maximum, use ``idxmax``. This is the
| equivalent of the ``numpy.ndarray`` method ``argmax``.
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| max : DataFrame or Panel (if level specified)
|
| mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the mean of the values for the requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| mean : DataFrame or Panel (if level specified)
|
| median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the median of the values for the requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
278
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| median : DataFrame or Panel (if level specified)
|
| min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| This method returns the minimum of the values in the object. If you
| want the *index* of the minimum, use ``idxmin``. This is the
| equivalent of the ``numpy.ndarray`` method ``argmin``.
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| min : DataFrame or Panel (if level specified)
|
| minor_xs(self, key, copy=None)
| Return slice of panel along minor axis
|
| 【参数】
| ----------| key : object
| Minor axis label
| copy : boolean [deprecated]
| Whether to make a copy of the data
|
| 【返回值】
| -------| y : DataFrame
| index -&gt; major axis, columns -&gt; items
|
| 【注意】
| -----| minor_xs is only for getting, not setting values.
|
| MultiIndex Slicers is a generic way to get/set values on any level or levels
| it is a superset of minor_xs functionality, see :ref:</code>MultiIndex Slicers <advanced.mi_slicers><code>|
| mod(self, other, axis=0)
| Modulo of series and other, element-wise (binary operator</code>mod<code>).
279
| Equivalent to ``panel % other``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.rmod
|
| mul(self, other, axis=0)
| Multiplication of series and other, element-wise (binary operator</code>mul<code>).
| Equivalent to ``panel * other``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.rmul
|
| multiply = mul(self, other, axis=0)
|
| ne(self, other)
| Wrapper for comparison method ne
|
| pow(self, other, axis=0)
| Exponential power of series and other, element-wise (binary operator</code>pow<code>).
| Equivalent to ``panel ** other``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.rpow
280
|
| prod(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the product of the values for the requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| prod : DataFrame or Panel (if level specified)
|
| product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
|
| radd(self, other, axis=0)
| Addition of series and other, element-wise (binary operator</code>radd<code>).
| Equivalent to ``other + panel``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.add
|
| rdiv = rtruediv(self, other, axis=0)
|
| reindex(self, items=None, major_axis=None, minor_axis=None, **kwargs)
| Conform Panel to new index with optional filling logic, placing
| NA/NaN in locations having no value in the previous index. A new object
| is produced unless the new index is equivalent to the current one and
| copy=False
|
| 【参数】
| ----------| items, major_axis, minor_axis : array-like, optional (can be specified in order, or as
| keywords)
| New labels / index to conform to. Preferably an Index object to
| avoid duplicating data
| method : {None, &#39;backfill&#39;/&#39;bfill&#39;, &#39;pad&#39;/&#39;ffill&#39;, &#39;nearest&#39;}, optional
| method to use for filling holes in reindexed DataFrame.
281
| Please note: this is only applicable to DataFrames/Series with a
| monotonically increasing/decreasing index.
| * default: don&#39;t fill gaps
| * pad / ffill: propagate last valid observation forward to next valid
| * backfill / bfill: use next valid observation to fill gap
| * nearest: use nearest valid observations to fill gap
| copy : boolean, default True
| Return a new object, even if the passed indexes are the same
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
| fill_value : scalar, default np.NaN
| Value to use for missing values. Defaults to NaN, but can be any
| &quot;compatible&quot; value
| limit : int, default None
| Maximum number of consecutive elements to forward or backward fill
| tolerance : optional
| Maximum distance between original and new labels for inexact
| matches. The values of the index at the matching locations most
| satisfy the equation ``abs(index[indexer] - target) &lt;= tolerance``.
|
| .. versionadded:: 0.17.0
|
| 【示例】
| --------|
| Create a dataframe with some fictional data.
|
| &gt;&gt;&gt; index = [&#39;Firefox&#39;, &#39;Chrome&#39;, &#39;Safari&#39;, &#39;IE10&#39;, &#39;Konqueror&#39;]
| &gt;&gt;&gt; df = pd.DataFrame({
| ... &#39;http_status&#39;: [200,200,404,404,301],
| ... &#39;response_time&#39;: [0.04, 0.02, 0.07, 0.08, 1.0]},
| ... index=index)
| &gt;&gt;&gt; df
| http_status response_time
| Firefox 200 0.04
| Chrome 200 0.02
| Safari 404 0.07
| IE10 404 0.08
| Konqueror 301 1.00
|
| Create a new index and reindex the dataframe. By default
| values in the new index that do not have corresponding
| records in the dataframe are assigned ``NaN``.
|
| &gt;&gt;&gt; new_index= [&#39;Safari&#39;, &#39;Iceweasel&#39;, &#39;Comodo Dragon&#39;, &#39;IE10&#39;,
| ... &#39;Chrome&#39;]
| &gt;&gt;&gt; df.reindex(new_index)
| http_status response_time
| Safari 404 0.07
| Iceweasel NaN NaN
| Comodo Dragon NaN NaN
| IE10 404 0.08
| Chrome 200 0.02
|
| We can fill in the missing values by passing a value to
| the keyword ``fill_value``. Because the index is not monotonically
282
| increasing or decreasing, we cannot use arguments to the keyword
| ``method`` to fill the ``NaN`` values.
|
| &gt;&gt;&gt; df.reindex(new_index, fill_value=0)
| http_status response_time
| Safari 404 0.07
| Iceweasel 0 0.00
| Comodo Dragon 0 0.00
| IE10 404 0.08
| Chrome 200 0.02
|
| &gt;&gt;&gt; df.reindex(new_index, fill_value=&#39;missing&#39;)
| http_status response_time
| Safari 404 0.07
| Iceweasel missing missing
| Comodo Dragon missing missing
| IE10 404 0.08
| Chrome 200 0.02
|
| To further illustrate the filling functionality in
| ``reindex``, we will create a dataframe with a
| monotonically increasing index (for example, a sequence
| of dates).
|
| &gt;&gt;&gt; date_index = pd.date_range(&#39;1/1/2010&#39;, periods=6, freq=&#39;D&#39;)
| &gt;&gt;&gt; df2 = pd.DataFrame({&quot;prices&quot;: [100, 101, np.nan, 100, 89, 88]},
| index=date_index)
| &gt;&gt;&gt; df2
| prices
| 2010-01-01 100
| 2010-01-02 101
| 2010-01-03 NaN
| 2010-01-04 100
| 2010-01-05 89
| 2010-01-06 88
|
| Suppose we decide to expand the dataframe to cover a wider
| date range.
|
| &gt;&gt;&gt; date_index2 = pd.date_range(&#39;12/29/2009&#39;, periods=10, freq=&#39;D&#39;)
| &gt;&gt;&gt; df2.reindex(date_index2)
| prices
| 2009-12-29 NaN
| 2009-12-30 NaN
| 2009-12-31 NaN
| 2010-01-01 100
| 2010-01-02 101
| 2010-01-03 NaN
| 2010-01-04 100
| 2010-01-05 89
| 2010-01-06 88
| 2010-01-07 NaN
|
| The index entries that did not have a value in the original data frame
| (for example, &#39;2009-12-29&#39;) are by default filled with ``NaN``.
| If desired, we can fill in the missing values using one of several
| options.
283
|
| For example, to backpropagate the last valid value to fill the ``NaN``
| values, pass ``bfill`` as an argument to the ``method`` keyword.
|
| &gt;&gt;&gt; df2.reindex(date_index2, method=&#39;bfill&#39;)
| prices
| 2009-12-29 100
| 2009-12-30 100
| 2009-12-31 100
| 2010-01-01 100
| 2010-01-02 101
| 2010-01-03 NaN
| 2010-01-04 100
| 2010-01-05 89
| 2010-01-06 88
| 2010-01-07 NaN
|
| Please note that the ``NaN`` value present in the original dataframe
| (at index value 2010-01-03) will not be filled by any of the
| value propagation schemes. This is because filling while reindexing
| does not look at dataframe values, but only compares the original and
| desired indexes. If you do want to fill in the ``NaN`` values present
| in the original dataframe, use the ``fillna()`` method.
|
| 【返回值】
| -------| reindexed : Panel
|
| reindex_axis(self, labels, axis=0, method=None, level=None, copy=True, limit=None, fill_value=nan)
| Conform input object to new index with optional filling logic,
| placing NA/NaN in locations having no value in the previous index. A
| new object is produced unless the new index is equivalent to the
| current one and copy=False
|
| 【参数】
| ----------| labels : array-like
| New labels / index to conform to. Preferably an Index object to
| avoid duplicating data
| axis : {0, 1, 2, &#39;items&#39;, &#39;major_axis&#39;, &#39;minor_axis&#39;}
| method : {None, &#39;backfill&#39;/&#39;bfill&#39;, &#39;pad&#39;/&#39;ffill&#39;, &#39;nearest&#39;}, optional
| Method to use for filling holes in reindexed DataFrame:
| * default: don&#39;t fill gaps
| * pad / ffill: propagate last valid observation forward to next valid
| * backfill / bfill: use next valid observation to fill gap
| * nearest: use nearest valid observations to fill gap
| copy : boolean, default True
| Return a new object, even if the passed indexes are the same
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
| limit : int, default None
| Maximum number of consecutive elements to forward or backward fill
| tolerance : optional
| Maximum distance between original and new labels for inexact
| matches. The values of the index at the matching locations most
| satisfy the equation ``abs(index[indexer] - target) &lt;= tolerance``.
284
|
| .. versionadded:: 0.17.0
|
| 【示例】
| --------| &gt;&gt;&gt; df.reindex_axis([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;], axis=1)
|
| 【参见】
| --------| reindex, reindex_like
|
| 【返回值】
| -------| reindexed : Panel
|
| rename(self, items=None, major_axis=None, minor_axis=None, **kwargs)
| Alter axes input function or functions. Function / dict values must be
| unique (1-to-1). Labels not contained in a dict / Series will be left
| as-is.
|
| 【参数】
| ----------| items, major_axis, minor_axis : dict-like or function, optional
| Transformation to apply to that axis values
|
| copy : boolean, default True
| Also copy underlying data
| inplace : boolean, default False
| Whether to return a new Panel. If True then value of copy is
| ignored.
|
| 【返回值】
| -------| renamed : Panel (new object)
|
| rfloordiv(self, other, axis=0)
| Integer division of series and other, element-wise (binary operator</code>rfloordiv<code>).
| Equivalent to ``other // panel``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.floordiv
|
| rmod(self, other, axis=0)
| Modulo of series and other, element-wise (binary operator</code>rmod<code>).
| Equivalent to ``other % panel``.
285
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.mod
|
| rmul(self, other, axis=0)
| Multiplication of series and other, element-wise (binary operator</code>rmul<code>).
| Equivalent to ``other * panel``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.mul
|
| rpow(self, other, axis=0)
| Exponential power of series and other, element-wise (binary operator</code>rpow<code>).
| Equivalent to ``other ** panel``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.pow
|
| rsub(self, other, axis=0)
| Subtraction of series and other, element-wise (binary operator</code>rsub<code>).
| Equivalent to ``other - panel``.
|
| 【参数】
286
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.sub
|
| rtruediv(self, other, axis=0)
| Floating division of series and other, element-wise (binary operator</code>rtruediv<code>).
| Equivalent to ``other / panel``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.truediv
|
| sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)
| Return unbiased standard error of the mean over requested axis.
|
| Normalized by N-1 by default. This can be changed using the ddof argument
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| ddof : int, default 1
| degrees of freedom
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| sem : DataFrame or Panel (if level specified)
|
| set_value(self, *args, **kwargs)
| Quickly set single value at (item, major, minor) location
287
|
| 【参数】
| ----------| item : item label (panel item)
| major : major axis label (panel item row)
| minor : minor axis label (panel item column)
| value : scalar
| takeable : interpret the passed labels as indexers, default False
|
| 【返回值】
| -------| panel : Panel
| If label combo is contained, will be reference to calling Panel,
| otherwise a new object
|
| shift(self, periods=1, freq=None, axis=&#39;major&#39;)
| Shift index by desired number of periods with an optional time freq.
| The shifted data will not include the dropped periods and the
| shifted axis will be smaller than the original. This is different
| from the behavior of DataFrame.shift()
|
| 【参数】
| ----------| periods : int
| Number of periods to move, can be positive or negative
| freq : DateOffset, timedelta, or time rule string, optional
| axis : {&#39;items&#39;, &#39;major&#39;, &#39;minor&#39;} or {0, 1, 2}
|
| 【返回值】
| -------| shifted : Panel
|
| skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return unbiased skew over requested axis
| Normalized by N-1
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| skew : DataFrame or Panel (if level specified)
|
| std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)
| Return unbiased standard deviation over requested axis.
|
| Normalized by N-1 by default. This can be changed using the ddof argument
288
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| ddof : int, default 1
| degrees of freedom
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| std : DataFrame or Panel (if level specified)
|
| sub(self, other, axis=0)
| Subtraction of series and other, element-wise (binary operator</code>sub<code>).
| Equivalent to ``panel - other``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.rsub
|
| subtract = sub(self, other, axis=0)
|
| sum(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the sum of the values for the requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
289
| -------| sum : DataFrame or Panel (if level specified)
|
| tail(self, n=5)
| Returns last n rows
|
| toLong = wrapper(*args, **kwargs)
|
| to_excel(self, path, na_rep=&#39;&#39;, engine=None, **kwargs)
| Write each DataFrame in Panel to a separate excel sheet
|
| 【参数】
| ----------| path : string or ExcelWriter object
| File path or existing ExcelWriter
| na_rep : string, default &#39;&#39;
| Missing data representation
| engine : string, default None
| write engine to use - you can also set this via the options
| ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and
| ``io.excel.xlsm.writer``.
|
| Other【参数】
| ----------------| float_format : string, default None
| Format string for floating point numbers
| cols : sequence, optional
| Columns to write
| header : boolean or list of string, default True
| Write out column names. If a list of string is given it is
| assumed to be aliases for the column names
| index : boolean, default True
| Write row names (index)
| index_label : string or sequence, default None
| Column label for index column(s) if desired. If None is given, and
|</code>header<code>and</code>index<code>are True, then the index names are used. A
| sequence should be given if the DataFrame uses MultiIndex.
| startrow : upper left cell row to dump data frame
| startcol : upper left cell column to dump data frame
|
| 【注意】
| -----| Keyword arguments (and na_rep) are passed to the ``to_excel`` method
| for each DataFrame written.
|
| to_frame(self, filter_observations=True)
| Transform wide format into long (stacked) format as DataFrame whose
| columns are the Panel&#39;s items and whose index is a MultiIndex formed
| of the Panel&#39;s major and minor axes.
|
| 【参数】
| ----------| filter_observations : boolean, default True
| Drop (major, minor) pairs without a complete set of observations
| across all the items
|
| 【返回值】
290
| -------| y : DataFrame
|
| to_long = wrapper(*args, **kwargs)
|
| to_sparse(self, fill_value=None, kind=&#39;block&#39;)
| Convert to SparsePanel
|
| 【参数】
| ----------| fill_value : float, default NaN
| kind : {&#39;block&#39;, &#39;integer&#39;}
|
| 【返回值】
| -------| y : SparseDataFrame
|
| transpose(self, *args, **kwargs)
| Permute the dimensions of the Panel
|
| 【参数】
| ----------| args : three positional arguments: each oneof
| {0, 1, 2, &#39;items&#39;, &#39;major_axis&#39;, &#39;minor_axis&#39;}
| copy : boolean, default False
| Make a copy of the underlying data. Mixed-dtype data will
| always result in a copy
|
| 【示例】
| --------| &gt;&gt;&gt; p.transpose(2, 0, 1)
| &gt;&gt;&gt; p.transpose(2, 0, 1, copy=True)
|
| 【返回值】
| -------| y : same as input
|
| truediv(self, other, axis=0)
| Floating division of series and other, element-wise (binary operator</code>truediv<code>).
| Equivalent to ``panel / other``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.rtruediv
|
| tshift(self, periods=1, freq=None, axis=&#39;major&#39;)
291
| Shift the time index, using the index&#39;s frequency if available
|
| 【参数】
| ----------| periods : int
| Number of periods to move, can be positive or negative
| freq : DateOffset, timedelta, or time rule string, default None
| Increment to use from datetools module or time rule (e.g. &#39;EOM&#39;)
| axis : int or basestring
| Corresponds to the axis that contains the Index
|
| 【注意】
| -----| If freq is not specified then tries to use the freq or inferred_freq
| attributes of the index. If neither of those attributes exist, a
| ValueError is thrown
|
| 【返回值】
| -------| shifted : NDFrame
|
| update(self, other, join=&#39;left&#39;, overwrite=True, filter_func=None, raise_conflict=False)
| Modify Panel in place using non-NA values from passed
| Panel, or object coercible to Panel. Aligns on items
|
| 【参数】
| ----------| other : Panel, or object coercible to Panel
| join : How to join individual DataFrames
| {&#39;left&#39;, &#39;right&#39;, &#39;outer&#39;, &#39;inner&#39;}, default &#39;left&#39;
| overwrite : boolean, default True
| If True then overwrite values for common keys in the calling panel
| filter_func : callable(1d-array) -&gt; 1d-array&lt;boolean&gt;, default None
| Can choose to replace values other than NA. Return True for values
| that should be updated
| raise_conflict : bool
| If True, will raise an error if a DataFrame and other both
| contain data in the same place.
|
| var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)
| Return unbiased variance over requested axis.
|
| Normalized by N-1 by default. This can be changed using the ddof argument
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| ddof : int, default 1
| degrees of freedom
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
292
| everything, then use only numeric data
|
| 【返回值】
| -------| var : DataFrame or Panel (if level specified)
|
| xs(self, key, axis=1, copy=None)
| Return slice of panel along selected axis
|
| 【参数】
| ----------| key : object
| Label
| axis : {&#39;items&#39;, &#39;major&#39;, &#39;minor}, default 1/&#39;major&#39;
| copy : boolean [deprecated]
| Whether to make a copy of the data
|
| 【返回值】
| -------| y : ndim(self)-1
|
| 【注意】
| -----| xs is only for getting, not setting values.
|
| MultiIndex Slicers is a generic way to get/set values on any level or levels
| it is a superset of xs functionality, see :ref:</code>MultiIndex Slicers <advanced.mi_slicers><code>|
| ----------------------------------------------------------------------| Class methods defined here:
|
| fromDict = from_dict(data, intersect=False, orient=&#39;items&#39;, dtype=None) from builtins.type
| Construct Panel from dict of DataFrame objects
|
| 【参数】
| ----------| data : dict
| {field : DataFrame}
| intersect : boolean
| Intersect indexes of input DataFrames
| orient : {&#39;items&#39;, &#39;minor&#39;}, default &#39;items&#39;
| The &quot;orientation&quot; of the data. If the keys of the passed dict
| should be the items of the result panel, pass &#39;items&#39;
| (default). Otherwise if the columns of the values of the passed
| DataFrame objects should be the items (which in the case of
| mixed-dtype data you should do), instead pass &#39;minor&#39;
| dtype : dtype, default None
| Data type to force, otherwise infer
|
| 【返回值】
| -------| Panel
|
| from_dict(data, intersect=False, orient=&#39;items&#39;, dtype=None) from builtins.type
| Construct Panel from dict of DataFrame objects
|
| 【参数】
293
| ----------| data : dict
| {field : DataFrame}
| intersect : boolean
| Intersect indexes of input DataFrames
| orient : {&#39;items&#39;, &#39;minor&#39;}, default &#39;items&#39;
| The &quot;orientation&quot; of the data. If the keys of the passed dict
| should be the items of the result panel, pass &#39;items&#39;
| (default). Otherwise if the columns of the values of the passed
| DataFrame objects should be the items (which in the case of
| mixed-dtype data you should do), instead pass &#39;minor&#39;
| dtype : dtype, default None
| Data type to force, otherwise infer
|
| 【返回值】
| -------| Panel
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| items
|
| major_axis
|
| minor_axis
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.generic.NDFrame:
|
| __abs__(self)
|
| __array__(self, dtype=None)
|
| __array_wrap__(self, result, context=None)
|
| __bool__ = __nonzero__(self)
|
| __contains__(self, key)
| True if the key is in the info axis
|
| __delitem__(self, key)
| Delete item
|
| __finalize__(self, other, method=None, **kwargs)
| propagate metadata from other to self
|
| 【参数】
| ----------| other : the object from which to get the attributes that we are going
| to propagate
| method : optional, a passed method name ; possibly to take different
| types of propagation actions based on this
|
| __getattr__(self, name)
| After regular attribute access, try looking up the name
| This allows simpler access to columns for interactive use.
294
|
| __getstate__(self)
|
| __hash__(self)
| Return hash(self).
|
| __invert__(self)
|
| __iter__(self)
| Iterate over infor axis
|
| __len__(self)
| Returns length of info axis
|
| __neg__(self)
|
| __nonzero__(self)
|
| __setattr__(self, name, value)
| After regular attribute access, try setting the name
| This allows simpler access to columns for interactive use.
|
| __setstate__(self, state)
|
| abs(self)
| Return an object with absolute value taken. Only applicable to objects
| that are all numeric
|
| 【返回值】
| -------| abs: type of caller
|
| add_prefix(self, prefix)
| Concatenate prefix string with panel items names.
|
| 【参数】
| ----------| prefix : string
|
| 【返回值】
| -------| with_prefix : type of caller
|
| add_suffix(self, suffix)
| Concatenate suffix string with panel items names
|
| 【参数】
| ----------| suffix : string
|
| 【返回值】
| -------| with_suffix : type of caller
|
| as_blocks(self, copy=True)
| Convert the frame to a dict of dtype -&gt; Constructor Types that each has
| a homogeneous dtype.
295
|
| NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in
| as_matrix)
|
| 【参数】
| ----------| copy : boolean, default True
|
| .. versionadded: 0.16.1
|
| 【返回值】
| -------| values : a dict of dtype -&gt; Constructor Types
|
| asfreq(self, freq, method=None, how=None, normalize=False)
| Convert all TimeSeries inside to specified frequency using DateOffset
| objects. Optionally provide fill method to pad/backfill missing values.
|
| 【参数】
| ----------| freq : DateOffset object, or string
| method : {&#39;backfill&#39;, &#39;bfill&#39;, &#39;pad&#39;, &#39;ffill&#39;, None}
| Method to use for filling holes in reindexed Series
| pad / ffill: propagate last valid observation forward to next valid
| backfill / bfill: use NEXT valid observation to fill method
| how : {&#39;start&#39;, &#39;end&#39;}, default end
| For PeriodIndex only, see PeriodIndex.asfreq
| normalize : bool, default False
| Whether to reset output index to midnight
|
| 【返回值】
| -------| converted : type of caller
|
| astype(self, dtype, copy=True, raise_on_error=True, **kwargs)
| Cast object to input numpy.dtype
| Return a copy when copy = True (be really careful with this!)
|
| 【参数】
| ----------| dtype : numpy.dtype or Python type
| raise_on_error : raise on invalid input
| kwargs : keyword arguments to pass on to the constructor
|
| 【返回值】
| -------| casted : type of caller
|
| at_time(self, time, asof=False)
| Select values at particular time of day (e.g. 9:30AM)
|
| 【参数】
| ----------| time : datetime.time or string
|
| 【返回值】
296
| -------| values_at_time : type of caller
|
| between_time(self, start_time, end_time, include_start=True, include_end=True)
| Select values between particular times of the day (e.g., 9:00-9:30 AM)
|
| 【参数】
| ----------| start_time : datetime.time or string
| end_time : datetime.time or string
| include_start : boolean, default True
| include_end : boolean, default True
|
| 【返回值】
| -------| values_between_time : type of caller
|
| bfill(self, axis=None, inplace=False, limit=None, downcast=None)
| Synonym for NDFrame.fillna(method=&#39;bfill&#39;)
|
| bool(self)
| Return the bool of a single element PandasObject
| This must be a boolean scalar value, either True or False
|
| Raise a ValueError if the PandasObject does not have exactly
| 1 element, or that element is not boolean
|
| clip(self, lower=None, upper=None, out=None, axis=None)
| Trim values at input threshold(s)
|
| 【参数】
| ----------| lower : float or array_like, default None
| upper : float or array_like, default None
| axis : int or string axis name, optional
| Align object with lower and upper along the given axis.
|
| 【返回值】
| -------| clipped : Series
|
| 【示例】
| --------| &gt;&gt;&gt; df
| 0 1
| 0 0.335232 -1.256177
| 1 -1.367855 0.746646
| 2 0.027753 -1.176076
| 3 0.230930 -0.679613
| 4 1.261967 0.570967
| &gt;&gt;&gt; df.clip(-1.0, 0.5)
| 0 1
| 0 0.335232 -1.000000
| 1 -1.000000 0.500000
| 2 0.027753 -1.000000
| 3 0.230930 -0.679613
| 4 0.500000 0.500000
297
| &gt;&gt;&gt; t
| 0 -0.3
| 1 -0.2
| 2 -0.1
| 3 0.0
| 4 0.1
| dtype: float64
| &gt;&gt;&gt; df.clip(t, t + 1, axis=0)
| 0 1
| 0 0.335232 -0.300000
| 1 -0.200000 0.746646
| 2 0.027753 -0.100000
| 3 0.230930 0.000000
| 4 1.100000 0.570967
|
| clip_lower(self, threshold, axis=None)
| Return copy of the input with values below given value(s) truncated
|
| 【参数】
| ----------| threshold : float or array_like
| axis : int or string axis name, optional
| Align object with threshold along the given axis.
|
| 【参见】
| --------| clip
|
| 【返回值】
| -------| clipped : same type as input
|
| clip_upper(self, threshold, axis=None)
| Return copy of input with values above given value(s) truncated
|
| 【参数】
| ----------| threshold : float or array_like
| axis : int or string axis name, optional
| Align object with threshold along the given axis.
|
| 【参见】
| --------| clip
|
| 【返回值】
| -------| clipped : same type as input
|
| consolidate(self, inplace=False)
| Compute NDFrame with &quot;consolidated&quot; internals (data of each dtype
| grouped together in a single ndarray). Mainly an internal API function,
| but available here to the savvy user
|
| 【参数】
| ----------| inplace : boolean, default False
298
| If False return new object, otherwise modify existing object
|
| 【返回值】
| -------| consolidated : type of caller
|
| convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)
| Attempt to infer better dtype for object columns
|
| 【参数】
| ----------| convert_dates : boolean, default True
| If True, convert to date where possible. If &#39;coerce&#39;, force
| conversion, with unconvertible values becoming NaT.
| convert_numeric : boolean, default False
| If True, attempt to coerce to numbers (including strings), with
| unconvertible values becoming NaN.
| convert_timedeltas : boolean, default True
| If True, convert to timedelta where possible. If &#39;coerce&#39;, force
| conversion, with unconvertible values becoming NaT.
| copy : boolean, default True
| If True, return a copy even if no copy is necessary (e.g. no
| conversion was done). Note: This is meant for internal use, and
| should not be confused with inplace.
|
| 【返回值】
| -------| converted : same as input object
|
| copy(self, deep=True)
| Make a copy of this object
|
| 【参数】
| ----------| deep : boolean or string, default True
| Make a deep copy, i.e. also copy data
|
| 【返回值】
| -------| copy : type of caller
|
| describe(self, percentiles=None, include=None, exclude=None)
| Generate various summary statistics, excluding NaN values.
|
| 【参数】
| ----------| percentiles : array-like, optional
| The percentiles to include in the output. Should all
| be in the interval [0, 1]. By default</code>percentiles<code>is
| [.25, .5, .75], returning the 25th, 50th, and 75th percentiles.
| include, exclude : list-like, &#39;all&#39;, or None (default)
| Specify the form of the returned result. Either:
|
| - None to both (default). The result will include only numeric-typed
| columns or, if none are, only categorical columns.
| - A list of dtypes or strings to be included/excluded.
| To select all numeric types use numpy numpy.number. To select
299
| categorical objects use type object. 参见：the select_dtypes
| documentation. eg. df.describe(include=[&#39;O&#39;])
| - If include is the string &#39;all&#39;, the output column-set will
| match the input one.
|
| 【返回值】
| -------| summary: NDFrame of summary statistics
|
| 【注意】
| -----| The output DataFrame index depends on the requested dtypes:
|
| For numeric dtypes, it will include: count, mean, std, min,
| max, and lower, 50, and upper percentiles.
|
| For object dtypes (e.g. timestamps or strings), the index
| will include the count, unique, most common, and frequency of the
| most common. Timestamps also include the first and last items.
|
| For mixed dtypes, the index will be the union of the corresponding
| output types. Non-applicable entries will be filled with NaN.
| Note that mixed-dtype outputs can only be returned from mixed-dtype
| inputs and appropriate use of the include/exclude arguments.
|
| If multiple values have the highest count, then the
|</code>count<code>and</code>most common<code>pair will be arbitrarily chosen from
| among those with the highest count.
|
| The include, exclude arguments are ignored for Series.
|
| 【参见】
| --------| DataFrame.select_dtypes
|
| drop(self, labels, axis=0, level=None, inplace=False, errors=&#39;raise&#39;)
| Return new object with labels in requested axis removed
|
| 【参数】
| ----------| labels : single label or list-like
| axis : int or axis name
| level : int or level name, default None
| For MultiIndex
| inplace : bool, default False
| If True, do operation inplace and return None.
| errors : {&#39;ignore&#39;, &#39;raise&#39;}, default &#39;raise&#39;
| If &#39;ignore&#39;, suppress error and existing labels are dropped.
|
| .. versionadded:: 0.16.1
|
| 【返回值】
| -------| dropped : type of caller
|
| equals(self, other)
| Determines if two NDFrame objects contain the same elements. NaNs in the
300
| same location are considered equal.
|
| ffill(self, axis=None, inplace=False, limit=None, downcast=None)
| Synonym for NDFrame.fillna(method=&#39;ffill&#39;)
|
| filter(self, items=None, like=None, regex=None, axis=None)
| Restrict the info axis to set of items or wildcard
|
| 【参数】
| ----------| items : list-like
| List of info axis to restrict to (must not all be present)
| like : string
| Keep info axis where &quot;arg in col == True&quot;
| regex : string (regular expression)
| Keep info axis with re.search(regex, col) == True
| axis : int or None
| The axis to filter on. By default this is the info axis. The &quot;info
| axis&quot; is the axis that is used when indexing with ``[]``. For
| example, ``df = DataFrame({&#39;a&#39;: [1, 2, 3, 4]]}); df[&#39;a&#39;]``. So,
| the ``DataFrame`` columns are the info axis.
|
| 【注意】
| -----| Arguments are mutually exclusive, but this is not checked for
|
| first(self, offset)
| Convenience method for subsetting initial periods of time series data
| based on a date offset
|
| 【参数】
| ----------| offset : string, DateOffset, dateutil.relativedelta
|
| 【示例】
| --------| ts.last(&#39;10D&#39;) -&gt; First 10 days
|
| 【返回值】
| -------| subset : type of caller
|
| get(self, key, default=None)
| Get item from object for given key (DataFrame column, Panel slice,
| etc.). Returns default value if not found
|
| 【参数】
| ----------| key : object
|
| 【返回值】
| -------| value : type of items contained in object
|
| get_dtype_counts(self)
| Return the counts of dtypes in this object
|
301
| get_ftype_counts(self)
| Return the counts of ftypes in this object
|
| get_values(self)
| same as values (but handles sparseness conversions)
|
| interpolate(self, method=&#39;linear&#39;, axis=0, limit=None, inplace=False, limit_direction=&#39;forward&#39;, downcast=None, **kwargs)
| Interpolate values according to different methods.
|
| Please note that only ``method=&#39;linear&#39;`` is supported for DataFrames/Series
| with a MultiIndex.
|
| 【参数】
| ----------| method : {&#39;linear&#39;, &#39;time&#39;, &#39;index&#39;, &#39;values&#39;, &#39;nearest&#39;, &#39;zero&#39;,
| &#39;slinear&#39;, &#39;quadratic&#39;, &#39;cubic&#39;, &#39;barycentric&#39;, &#39;krogh&#39;,
| &#39;polynomial&#39;, &#39;spline&#39; &#39;piecewise_polynomial&#39;, &#39;pchip&#39;}
|
| * &#39;linear&#39;: ignore the index and treat the values as equally
| spaced. This is the only method supported on MultiIndexes.
| default
| * &#39;time&#39;: interpolation works on daily and higher resolution
| data to interpolate given length of interval
| * &#39;index&#39;, &#39;values&#39;: use the actual numerical values of the index
| * &#39;nearest&#39;, &#39;zero&#39;, &#39;slinear&#39;, &#39;quadratic&#39;, &#39;cubic&#39;,
| &#39;barycentric&#39;, &#39;polynomial&#39; is passed to
| ``scipy.interpolate.interp1d``. Both &#39;polynomial&#39; and &#39;spline&#39;
| require that you also specify an</code>order<code>(int),
| e.g. df.interpolate(method=&#39;polynomial&#39;, order=4).
| These use the actual numerical values of the index.
| * &#39;krogh&#39;, &#39;piecewise_polynomial&#39;, &#39;spline&#39;, and &#39;pchip&#39; are all
| wrappers around the scipy interpolation methods of similar
| names. These use the actual numerical values of the index. See
| the scipy documentation for more on their behavior
|</code>here <a href="http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation" target="_blank" rel="external">http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation</a><code>__
|</code>and here <a href="http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html" target="_blank" rel="external">http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html</a><code>__
|
| axis : {0, 1}, default 0
| * 0: fill column-by-column
| * 1: fill row-by-row
| limit : int, default None.
| Maximum number of consecutive NaNs to fill.
| limit_direction : {&#39;forward&#39;, &#39;backward&#39;, &#39;both&#39;}, defaults to &#39;forward&#39;
| If limit is specified, consecutive NaNs will be filled in this
| direction.
|
| .. versionadded:: 0.17.0
|
| inplace : bool, default False
| Update the NDFrame in place if possible.
| downcast : optional, &#39;infer&#39; or None, defaults to None
| Downcast dtypes if possible.
| kwargs : keyword arguments to pass on to the interpolating function.
|
| 【返回值】
| -------| Series or DataFrame of same shape interpolated at the NaNs
302
|
| 【参见】
| --------| reindex, replace, fillna
|
| 【示例】
| --------|
| Filling in NaNs
|
| &gt;&gt;&gt; s = pd.Series([0, 1, np.nan, 3])
| &gt;&gt;&gt; s.interpolate()
| 0 0
| 1 1
| 2 2
| 3 3
| dtype: float64
|
| isnull(self)
| Return a boolean same-sized object indicating if the values are null
|
| 【参见】
| --------| notnull : boolean inverse of isnull
|
| iteritems(self)
| Iterate over (label, values) on info axis
|
| This is index for Series, columns for DataFrame, major_axis for Panel,
| and so on.
|
| iterkv(self, *args, **kwargs)
| iteritems alias used to get around 2to3. Deprecated
|
| keys(self)
| Get the &#39;info axis&#39; (see Indexing for more)
|
| This is index for Series, columns for DataFrame and major_axis for
| Panel.
|
| last(self, offset)
| Convenience method for subsetting final periods of time series data
| based on a date offset
|
| 【参数】
| ----------| offset : string, DateOffset, dateutil.relativedelta
|
| 【示例】
| --------| ts.last(&#39;5M&#39;) -&gt; Last 5 months
|
| 【返回值】
| -------| subset : type of caller
|
| mask(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)
303
| Return an object of same shape as self and whose corresponding
| entries are from self where cond is False and otherwise are from other.
|
| 【参数】
| ----------| cond : boolean NDFrame or array
| other : scalar or NDFrame
| inplace : boolean, default False
| Whether to perform the operation in place on the data
| axis : alignment axis if needed, default None
| level : alignment level if needed, default None
| try_cast : boolean, default False
| try to cast the result back to the input type (if possible),
| raise_on_error : boolean, default True
| Whether to raise on invalid data types (e.g. trying to where on
| strings)
|
| 【返回值】
| -------| wh : same type as caller
|
| notnull(self)
| Return a boolean same-sized object indicating if the values are
| not null
|
| 【参见】
| --------| isnull : boolean inverse of notnull
|
| pct_change(self, periods=1, fill_method=&#39;pad&#39;, limit=None, freq=None, **kwargs)
| Percent change over given number of periods.
|
| 【参数】
| ----------| periods : int, default 1
| Periods to shift for forming percent change
| fill_method : str, default &#39;pad&#39;
| How to handle NAs before computing percent changes
| limit : int, default None
| The number of consecutive NAs to fill before stopping
| freq : DateOffset, timedelta, or offset alias string, optional
| Increment to use from time series API (e.g. &#39;M&#39; or BDay())
|
| 【返回值】
| -------| chg : NDFrame
|
| 【注意】
| -----|
| By default, the percentage change is calculated along the stat
| axis: 0, or ``Index``, for ``DataFrame`` and 1, or ``minor`` for
| ``Panel``. You can change this with the ``axis`` keyword argument.
|
| pipe(self, func, *args, **kwargs)
| Apply func(self, \*args, \*\*kwargs)
|
304
| .. versionadded:: 0.16.2
|
| 【参数】
| ----------| func : function
| function to apply to the NDFrame.
| ``args``, and ``kwargs`` are passed into ``func``.
| Alternatively a ``(callable, data_keyword)`` tuple where
| ``data_keyword`` is a string indicating the keyword of
| ``callable`` that expects the NDFrame.
| args : positional arguments passed into ``func``.
| kwargs : a dictionary of keyword arguments passed into ``func``.
|
| 【返回值】
| -------| object : the return type of ``func``.
|
| 【注意】
| -----|
| Use ``.pipe`` when chaining together functions that expect
| on Series or DataFrames. Instead of writing
|
| &gt;&gt;&gt; f(g(h(df), arg1=a), arg2=b, arg3=c)
|
| You can write
|
| &gt;&gt;&gt; (df.pipe(h)
| ... .pipe(g, arg1=a)
| ... .pipe(f, arg2=b, arg3=c)
| ... )
|
| If you have a function that takes the data as (say) the second
| argument, pass a tuple indicating which keyword expects the
| data. For example, suppose ``f`` takes its data as ``arg2``:
|
| &gt;&gt;&gt; (df.pipe(h)
| ... .pipe(g, arg1=a)
| ... .pipe((f, &#39;arg2&#39;), arg1=a, arg3=c)
| ... )
|
| 【参见】
| --------| pandas.DataFrame.apply
| pandas.DataFrame.applymap
| pandas.Series.map
|
| pop(self, item)
| Return item and drop from frame. Raise KeyError if not found.
|
| reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)
| return an object with matching indicies to myself
|
| 【参数】
| ----------| other : Object
| method : string or None
305
| copy : boolean, default True
| limit : int, default None
| Maximum number of consecutive labels to fill for inexact matches.
| tolerance : optional
| Maximum distance between labels of the other object and this
| object for inexact matches.
|
| .. versionadded:: 0.17.0
|
| 【注意】
| -----| Like calling s.reindex(index=other.index, columns=other.columns,
| method=...)
|
| 【返回值】
| -------| reindexed : same as input
|
| rename_axis(self, mapper, axis=0, copy=True, inplace=False)
| Alter index and / or columns using input function or functions.
| Function / dict values must be unique (1-to-1). Labels not contained in
| a dict / Series will be left as-is.
|
| 【参数】
| ----------| mapper : dict-like or function, optional
| axis : int or string, default 0
| copy : boolean, default True
| Also copy underlying data
| inplace : boolean, default False
|
| 【返回值】
| -------| renamed : type of caller
|
| replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method=&#39;pad&#39;, axis=None)
| Replace values given in &#39;to_replace&#39; with &#39;value&#39;.
|
| 【参数】
| ----------| to_replace : str, regex, list, dict, Series, numeric, or None
|
| * str or regex:
|
| - str: string exactly matching</code>to_replace<code>will be replaced
| with</code>value<code>| - regex: regexs matching</code>to_replace<code>will be replaced with
|</code>value<code>|
| * list of str, regex, or numeric:
|
| - First, if</code>to_replace<code>and</code>value<code>are both lists, they
| **must** be the same length.
| - Second, if ``regex=True`` then all of the strings in **both**
| lists will be interpreted as regexs otherwise they will match
| directly. This doesn&#39;t matter much for</code>value<code>since there
| are only a few possible substitution regexes you can use.
306
| - str and regex rules apply as above.
|
| * dict:
|
| - Nested dictionaries, e.g., {&#39;a&#39;: {&#39;b&#39;: nan}}, are read as
| follows: look in column &#39;a&#39; for the value &#39;b&#39; and replace it
| with nan. You can nest regular expressions as well. Note that
| column names (the top-level dictionary keys in a nested
| dictionary) **cannot** be regular expressions.
| - Keys map to column names and values map to substitution
| values. You can treat this as a special case of passing two
| lists except that you are specifying the column to search in.
|
| * None:
|
| - This means that the ``regex`` argument must be a string,
| compiled regular expression, or list, dict, ndarray or Series
| of such elements. If</code>value<code>is also ``None`` then this
| **must** be a nested dictionary or ``Series``.
|
| See the examples section for examples of each of these.
| value : scalar, dict, list, str, regex, default None
| Value to use to fill holes (e.g. 0), alternately a dict of values
| specifying which value to use for each column (columns not in the
| dict will not be filled). Regular expressions, strings and lists or
| dicts of such objects are also allowed.
| inplace : boolean, default False
| If True, in place. Note: this will modify any
| other views on this object (e.g. a column form a DataFrame).
| Returns the caller if this is True.
| limit : int, default None
| Maximum size gap to forward or backward fill
| regex : bool or same types as</code>to_replace<code>, default False
| Whether to interpret</code>to_replace<code>and/or</code>value<code>as regular
| expressions. If this is ``True`` then</code>to_replace<code>*must* be a
| string. Otherwise,</code>to_replace<code>must be ``None`` because this
| parameter will be interpreted as a regular expression or a list,
| dict, or array of regular expressions.
| method : string, optional, {&#39;pad&#39;, &#39;ffill&#39;, &#39;bfill&#39;}
| The method to use when for replacement, when ``to_replace`` is a
| ``list``.
|
| 【参见】
| --------| NDFrame.reindex
| NDFrame.asfreq
| NDFrame.fillna
|
| 【返回值】
| -------| filled : NDFrame
|
| 【Raises 引发错误】
| ------| AssertionError
| * If</code>regex<code>is not a ``bool`` and</code>to_replace<code>is not ``None``.
| TypeError
307
| * If</code>to_replace<code>is a ``dict`` and</code>value<code>is not a ``list``,
| ``dict``, ``ndarray``, or ``Series``
| * If</code>to_replace<code>is ``None`` and</code>regex<code>is not compilable into a
| regular expression or is a list, dict, ndarray, or Series.
| ValueError
| * If</code>to_replace<code>and</code>value<code>are ``list`` s or ``ndarray`` s, but
| they are not the same length.
|
| 【注意】
| -----| * Regex substitution is performed under the hood with ``re.sub``. The
| rules for substitution for ``re.sub`` are the same.
| * Regular expressions will only substitute on strings, meaning you
| cannot provide, for example, a regular expression matching floating
| point numbers and expect the columns in your frame that have a
| numeric dtype to be matched. However, if those floating point numbers
| *are* strings, then you can do this.
| * This method has *a lot* of options. You are encouraged to experiment
| and play with this method to gain intuition about how it works.
|
| resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention=&#39;start&#39;, kind=None,
loffset=None, limit=None, base=0)
| Convenience method for frequency conversion and resampling of regular
| time-series data.
|
| 【参数】
| ----------| rule : string
| the offset string or object representing target conversion
| how : string
| method for down- or re-sampling, default to &#39;mean&#39; for
| downsampling
| axis : int, optional, default 0
| fill_method : string, default None
| fill_method for upsampling
| closed : {&#39;right&#39;, &#39;left&#39;}
| Which side of bin interval is closed
| label : {&#39;right&#39;, &#39;left&#39;}
| Which bin edge label to label bucket with
| convention : {&#39;start&#39;, &#39;end&#39;, &#39;s&#39;, &#39;e&#39;}
| kind : &quot;period&quot;/&quot;timestamp&quot;
| loffset : timedelta
| Adjust the resampled time labels
| limit : int, default None
| Maximum size gap to when reindexing with fill_method
| base : int, default 0
| For frequencies that evenly subdivide 1 day, the &quot;origin&quot; of the
| aggregated intervals. For example, for &#39;5min&#39; frequency, base could
| range from 0 through 4. Defaults to 0
|
|
| 【示例】
| --------|
| Start by creating a series with 9 one minute timestamps.
|
| &gt;&gt;&gt; index = pd.date_range(&#39;1/1/2000&#39;, periods=9, freq=&#39;T&#39;)
308
| &gt;&gt;&gt; series = pd.Series(range(9), index=index)
| &gt;&gt;&gt; series
| 2000-01-01 00:00:00 0
| 2000-01-01 00:01:00 1
| 2000-01-01 00:02:00 2
| 2000-01-01 00:03:00 3
| 2000-01-01 00:04:00 4
| 2000-01-01 00:05:00 5
| 2000-01-01 00:06:00 6
| 2000-01-01 00:07:00 7
| 2000-01-01 00:08:00 8
| Freq: T, dtype: int64
|
| Downsample the series into 3 minute bins and sum the values
| of the timestamps falling into a bin.
|
| &gt;&gt;&gt; series.resample(&#39;3T&#39;, how=&#39;sum&#39;)
| 2000-01-01 00:00:00 3
| 2000-01-01 00:03:00 12
| 2000-01-01 00:06:00 21
| Freq: 3T, dtype: int64
|
| Downsample the series into 3 minute bins as above, but label each
| bin using the right edge instead of the left. Please note that the
| value in the bucket used as the label is not included in the bucket,
| which it labels. For example, in the original series the
| bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed
| value in the resampled bucket with the label``2000-01-01 00:03:00``
| does not include 3 (if it did, the summed value would be 6, not 3).
| To include this value close the right side of the bin interval as
| illustrated in the example below this one.
|
| &gt;&gt;&gt; series.resample(&#39;3T&#39;, how=&#39;sum&#39;, label=&#39;right&#39;)
| 2000-01-01 00:03:00 3
| 2000-01-01 00:06:00 12
| 2000-01-01 00:09:00 21
| Freq: 3T, dtype: int64
|
| Downsample the series into 3 minute bins as above, but close the right
| side of the bin interval.
|
| &gt;&gt;&gt; series.resample(&#39;3T&#39;, how=&#39;sum&#39;, label=&#39;right&#39;, closed=&#39;right&#39;)
| 2000-01-01 00:00:00 0
| 2000-01-01 00:03:00 6
| 2000-01-01 00:06:00 15
| 2000-01-01 00:09:00 15
| Freq: 3T, dtype: int64
|
| Upsample the series into 30 second bins.
|
| &gt;&gt;&gt; series.resample(&#39;30S&#39;)[0:5] #select first 5 rows
| 2000-01-01 00:00:00 0
| 2000-01-01 00:00:30 NaN
| 2000-01-01 00:01:00 1
| 2000-01-01 00:01:30 NaN
| 2000-01-01 00:02:00 2
| Freq: 30S, dtype: float64
309
|
| Upsample the series into 30 second bins and fill the ``NaN``
| values using the ``pad`` method.
|
| &gt;&gt;&gt; series.resample(&#39;30S&#39;, fill_method=&#39;pad&#39;)[0:5]
| 2000-01-01 00:00:00 0
| 2000-01-01 00:00:30 0
| 2000-01-01 00:01:00 1
| 2000-01-01 00:01:30 1
| 2000-01-01 00:02:00 2
| Freq: 30S, dtype: int64
|
| Upsample the series into 30 second bins and fill the
| ``NaN`` values using the ``bfill`` method.
|
| &gt;&gt;&gt; series.resample(&#39;30S&#39;, fill_method=&#39;bfill&#39;)[0:5]
| 2000-01-01 00:00:00 0
| 2000-01-01 00:00:30 1
| 2000-01-01 00:01:00 1
| 2000-01-01 00:01:30 2
| 2000-01-01 00:02:00 2
| Freq: 30S, dtype: int64
|
| Pass a custom function to ``how``.
|
| &gt;&gt;&gt; def custom_resampler(array_like):
| ... return np.sum(array_like)+5
|
| &gt;&gt;&gt; series.resample(&#39;3T&#39;, how=custom_resampler)
| 2000-01-01 00:00:00 8
| 2000-01-01 00:03:00 17
| 2000-01-01 00:06:00 26
| Freq: 3T, dtype: int64
|
| sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)
| Returns a random sample of items from an axis of object.
|
| .. versionadded:: 0.16.1
|
| 【参数】
| ----------| n : int, optional
| Number of items from axis to return. Cannot be used with</code>frac<code>.
| Default = 1 if</code>frac<code>= None.
| frac : float, optional
| Fraction of axis items to return. Cannot be used with</code>n<code>.
| replace : boolean, optional
| Sample with or without replacement. Default = False.
| weights : str or ndarray-like, optional
| Default &#39;None&#39; results in equal probability weighting.
| If passed a Series, will align with target object on index. Index
| values in weights not found in sampled object will be ignored and
| index values in sampled object not in weights will be assigned
| weights of zero.
| If called on a DataFrame, will accept the name of a column
| when axis = 0.
| Unless weights are a Series, weights must be same length as axis
310
| being sampled.
| If weights do not sum to 1, they will be normalized to sum to 1.
| Missing values in the weights column will be treated as zero.
| inf and -inf values not allowed.
| random_state : int or numpy.random.RandomState, optional
| Seed for the random number generator (if int), or numpy RandomState
| object.
| axis : int or string, optional
| Axis to sample. Accepts axis number or name. Default is stat axis
| for given data type (0 for Series and DataFrames, 1 for Panels).
|
| 【返回值】
| -------| A new object of same type as caller.
|
| select(self, crit, axis=0)
| Return data corresponding to axis labels matching criteria
|
| 【参数】
| ----------| crit : function
| To be called on each index (label). Should return True or False
| axis : int
|
| 【返回值】
| -------| selection : type of caller
|
| set_axis(self, axis, labels)
| public verson of axis assignment
|
| slice_shift(self, periods=1, axis=0)
| Equivalent to</code>shift<code>without copying data. The shifted data will
| not include the dropped periods and the shifted axis will be smaller
| than the original.
|
| 【参数】
| ----------| periods : int
| Number of periods to move, can be positive or negative
|
| 【注意】
| -----| While the</code>slice_shift<code>is faster than</code>shift<code>, you may pay for it
| later during alignment.
|
| 【返回值】
| -------| shifted : same type as caller
|
| sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind=&#39;quicksort&#39;, na_position=&#39;last&#39;,
sort_remaining=True)
| Sort object by labels (along an axis)
|
| 【参数】
| ----------| axis : axes to direct sorting
311
| level : int or level name or list of ints or list of level names
| if not None, sort on values in specified index level(s)
| ascending : boolean, default True
| Sort ascending vs. descending
| inplace : bool
| if True, perform operation in-place
| kind : {</code>quicksort<code>,</code>mergesort<code>,</code>heapsort<code>}
| Choice of sorting algorithm. 参见：ndarray.np.sort for more information.
|</code>mergesort<code>is the only stable algorithm. For DataFrames, this option is
| only applied when sorting on a single column or label.
| na_position : {&#39;first&#39;, &#39;last&#39;}
|</code>first<code>puts NaNs at the beginning,</code>last<code>puts NaNs at the end
| sort_remaining : bool
| if true and sorting by level and index is multilevel, sort by other levels
| too (in order) after sorting by specified level
|
| 【返回值】
| -------| sorted_obj : NDFrame
|
| sort_values(self, by, axis=0, ascending=True, inplace=False, kind=&#39;quicksort&#39;, na_position=&#39;last&#39;)
|
| squeeze(self)
| squeeze length 1 dimensions
|
| swapaxes(self, axis1, axis2, copy=True)
| Interchange axes and swap values axes appropriately
|
| 【返回值】
| -------| y : same as input
|
| swaplevel(self, i, j, axis=0)
| Swap levels i and j in a MultiIndex on a particular axis
|
| 【参数】
| ----------| i, j : int, string (can be mixed)
| Level of index to be swapped. Can pass level name as string.
|
| 【返回值】
| -------| swapped : type of caller (new object)
|
| take(self, indices, axis=0, convert=True, is_copy=True)
| Analogous to ndarray.take
|
| 【参数】
| ----------| indices : list / array of ints
| axis : int, default 0
| convert : translate neg to pos indices (default)
| is_copy : mark the returned frame as a copy
|
| 【返回值】
| -------| taken : type of caller
312
|
| to_clipboard(self, excel=None, sep=None, **kwargs)
| Attempt to write text representation of object to the system clipboard
| This can be pasted into Excel, for example.
|
| 【参数】
| ----------| excel : boolean, defaults to True
| if True, use the provided separator, writing in a csv
| format for allowing easy pasting into excel.
| if False, write a string representation of the object
| to the clipboard
| sep : optional, defaults to tab
| other keywords are passed to to_csv
|
| 【注意】
| -----| Requirements for your platform
| - Linux: xclip, or xsel (with gtk or PyQt4 modules)
| - Windows: none
| - OS X: none
|
| to_dense(self)
| Return dense representation of NDFrame (as opposed to sparse)
|
| to_hdf(self, path_or_buf, key, **kwargs)
| activate the HDFStore
|
| 【参数】
| ----------| path_or_buf : the path (string) or HDFStore object
| key : string
| indentifier for the group in the store
| mode : optional, {&#39;a&#39;, &#39;w&#39;, &#39;r&#39;, &#39;r+&#39;}, default &#39;a&#39;
|
| ``&#39;r&#39;``
| Read-only; no data can be modified.
| ``&#39;w&#39;``
| Write; a new file is created (an existing file with the same
| name would be deleted).
| ``&#39;a&#39;``
| Append; an existing file is opened for reading and writing,
| and if the file does not exist it is created.
| ``&#39;r+&#39;``
| It is similar to ``&#39;a&#39;``, but the file must already exist.
| format : &#39;fixed(f)|table(t)&#39;, default is &#39;fixed&#39;
| fixed(f) : Fixed format
| Fast writing/reading. Not-appendable, nor searchable
| table(t) : Table format
| Write as a PyTables Table structure which may perform
| worse but allow more flexible operations like searching
| / selecting subsets of the data
| append : boolean, default False
| For Table formats, append the input data to the existing
| complevel : int, 1-9, default 0
| If a complib is specified compression will be applied
| where possible
313
| complib : {&#39;zlib&#39;, &#39;bzip2&#39;, &#39;lzo&#39;, &#39;blosc&#39;, None}, default None
| If complevel is &gt; 0 apply compression to objects written
| in the store wherever possible
| fletcher32 : bool, default False
| If applying compression use the fletcher32 checksum
| dropna : boolean, default False.
| If true, ALL nan rows will not be written to store.
|
| to_json(self, path_or_buf=None, orient=None, date_format=&#39;epoch&#39;, double_precision=10, force_ascii=True, date_unit=&#39;ms&#39;,
default_handler=None)
| Convert the object to a JSON string.
|
| Note NaN&#39;s and None will be converted to null and datetime objects
| will be converted to UNIX timestamps.
|
| 【参数】
| ----------| path_or_buf : the path or buffer to write the result string
| if this is None, return a StringIO of the converted string
| orient : string
|
| * Series
|
| - default is &#39;index&#39;
| - allowed values are: {&#39;split&#39;,&#39;records&#39;,&#39;index&#39;}
|
| * DataFrame
|
| - default is &#39;columns&#39;
| - allowed values are:
| {&#39;split&#39;,&#39;records&#39;,&#39;index&#39;,&#39;columns&#39;,&#39;values&#39;}
|
| * The format of the JSON string
|
| - split : dict like
| {index -&gt; [index], columns -&gt; [columns], data -&gt; [values]}
| - records : list like
| [{column -&gt; value}, ... , {column -&gt; value}]
| - index : dict like {index -&gt; {column -&gt; value}}
| - columns : dict like {column -&gt; {index -&gt; value}}
| - values : just the values array
|
| date_format : {&#39;epoch&#39;, &#39;iso&#39;}
| Type of date conversion.</code>epoch<code>= epoch milliseconds,
|</code>iso<code>= ISO8601, default is epoch.
| double_precision : The number of decimal places to use when encoding
| floating point values, default 10.
| force_ascii : force encoded string to be ASCII, default True.
| date_unit : string, default &#39;ms&#39; (milliseconds)
| The time unit to encode to, governs timestamp and ISO8601
| precision. One of &#39;s&#39;, &#39;ms&#39;, &#39;us&#39;, &#39;ns&#39; for second, millisecond,
| microsecond, and nanosecond respectively.
| default_handler : callable, default None
| Handler to call if object cannot otherwise be converted to a
| suitable format for JSON. Should receive a single argument which is
| the object to convert and return a serialisable object.
|
314
| 【返回值】
| -------| same type as input object with filtered info axis
|
| to_msgpack(self, path_or_buf=None, **kwargs)
| msgpack (serialize) object to input file path
|
| THIS IS AN EXPERIMENTAL LIBRARY and the storage format
| may not be stable until a future release.
|
| 【参数】
| ----------| path : string File path, buffer-like, or None
| if None, return generated string
| append : boolean whether to append to an existing msgpack
| (default is False)
| compress : type of compressor (zlib or blosc), default to None (no
| compression)
|
| to_pickle(self, path)
| Pickle (serialize) object to input file path
|
| 【参数】
| ----------| path : string
| File path
|
| to_sql(self, name, con, flavor=&#39;sqlite&#39;, schema=None, if_exists=&#39;fail&#39;, index=True, index_label=None, chunksize=None,
dtype=None)
| Write records stored in a DataFrame to a SQL database.
|
| 【参数】
| ----------| name : string
| Name of SQL table
| con : SQLAlchemy engine or DBAPI2 connection (legacy mode)
| Using SQLAlchemy makes it possible to use any DB supported by that
| library.
| If a DBAPI2 object, only sqlite3 is supported.
| flavor : {&#39;sqlite&#39;, &#39;mysql&#39;}, default &#39;sqlite&#39;
| The flavor of SQL to use. Ignored when using SQLAlchemy engine.
| &#39;mysql&#39; is deprecated and will be removed in future versions, but it
| will be further supported through SQLAlchemy engines.
| schema : string, default None
| Specify the schema (if database flavor supports this). If None, use
| default schema.
| if_exists : {&#39;fail&#39;, &#39;replace&#39;, &#39;append&#39;}, default &#39;fail&#39;
| - fail: If table exists, do nothing.
| - replace: If table exists, drop it, recreate it, and insert data.
| - append: If table exists, insert data. Create if does not exist.
| index : boolean, default True
| Write DataFrame index as a column.
| index_label : string or sequence, default None
| Column label for index column(s). If None is given (default) and
| `index` is True, then the index names are used.
| A sequence should be given if the DataFrame uses MultiIndex.
| chunksize : int, default None
315
| If not None, then rows will be written in batches of this size at a
| time. If None, all rows will be written at once.
| dtype : dict of column name to SQL type, default None
| Optional specifying the datatype for columns. The SQL type should
| be a SQLAlchemy type, or a string for sqlite3 fallback connection.
|
| truncate(self, before=None, after=None, axis=None, copy=True)
| Truncates a sorted NDFrame before and/or after some particular
| dates.
|
| 【参数】
| ----------| before : date
| Truncate before date
| after : date
| Truncate after date
| axis : the truncation axis, defaults to the stat axis
| copy : boolean, default is True,
| return a copy of the truncated section
|
| 【返回值】
| -------| truncated : type of caller
|
| tz_convert(self, tz, axis=0, level=None, copy=True)
| Convert tz-aware axis to target time zone.
|
| 【参数】
| ----------| tz : string or pytz.timezone object
| axis : the axis to convert
| level : int, str, default None
| If axis ia a MultiIndex, convert a specific level. Otherwise
| must be None
| copy : boolean, default True
| Also make a copy of the underlying data
|
| 【返回值】
| -------|
| 【Raises 引发错误】
| ------| TypeError
| If the axis is tz-naive.
|
| tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous=&#39;raise&#39;)
| Localize tz-naive TimeSeries to target time zone
|
| 【参数】
| ----------| tz : string or pytz.timezone object
| axis : the axis to localize
| level : int, str, default None
| If axis ia a MultiIndex, localize a specific level. Otherwise
| must be None
| copy : boolean, default True
| Also make a copy of the underlying data
316
| ambiguous : &#39;infer&#39;, bool-ndarray, &#39;NaT&#39;, default &#39;raise&#39;
| - &#39;infer&#39; will attempt to infer fall dst-transition hours based on order
| - bool-ndarray where True signifies a DST time, False designates
| a non-DST time (note that this flag is only applicable for ambiguous times)
| - &#39;NaT&#39; will return NaT where there are ambiguous times
| - &#39;raise&#39; will raise an AmbiguousTimeError if there are ambiguous times
| infer_dst : boolean, default False (DEPRECATED)
| Attempt to infer fall dst-transition hours based on order
|
| 【返回值】
| -------|
| 【Raises 引发错误】
| ------| TypeError
| If the TimeSeries is tz-aware and tz is not None.
|
| where(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)
| Return an object of same shape as self and whose corresponding
| entries are from self where cond is True and otherwise are from other.
|
| 【参数】
| ----------| cond : boolean NDFrame or array
| other : scalar or NDFrame
| inplace : boolean, default False
| Whether to perform the operation in place on the data
| axis : alignment axis if needed, default None
| level : alignment level if needed, default None
| try_cast : boolean, default False
| try to cast the result back to the input type (if possible),
| raise_on_error : boolean, default True
| Whether to raise on invalid data types (e.g. trying to where on
| strings)
|
| 【返回值】
| -------| wh : same type as caller
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.generic.NDFrame:
|
| at
| Fast label-based scalar accessor
|
| Similarly to</code>loc<code>,</code>at<code>provides **label** based scalar lookups.
| You can also set using these indexers.
|
| axes
| Return index label(s) of the internal NDFrame
|
| blocks
| Internal property, property synonym for as_blocks()
|
| dtypes
| Return the dtypes in this object
|
317
| empty
| True if NDFrame is entirely empty [no items]
|
| ftypes
| Return the ftypes (indication of sparse/dense and dtype)
| in this object.
|
| iat
| Fast integer location scalar accessor.
|
| Similarly to</code>iloc<code>,</code>iat<code>provides **integer** based lookups.
| You can also set using these indexers.
|
| iloc
| Purely integer-location based indexing for selection by position.
|
|</code>.iloc[]<code>is primarily integer position based (from</code>0<code>to
|</code>length-1<code>of the axis), but may also be used with a boolean
| array.
|
| Allowed inputs are:
|
| - An integer, e.g.</code>5<code>.
| - A list or array of integers, e.g.</code>[4, 3, 0]<code>.
| - A slice object with ints, e.g.</code>1:7<code>.
| - A boolean array.
|
|</code>.iloc<code>will raise</code>IndexError<code>if a requested indexer is
| out-of-bounds, except *slice* indexers which allow out-of-bounds
| indexing (this conforms with python/numpy *slice* semantics).
|
| See more at :ref:`Selection by Position &lt;indexing.integer&gt;`
|
| ix
| A primarily label-location based indexer, with integer position
| fallback.
|
|</code>.ix[]<code>supports mixed integer and label based access. It is
| primarily label based, but will fall back to integer positional
| access unless the corresponding axis is of integer type.
|
|</code>.ix<code>is the most general indexer and will support any of the
| inputs in</code>.loc<code>and</code>.iloc<code>.</code>.ix<code>also supports floating
| point label schemes.</code>.ix<code>is exceptionally useful when dealing
| with mixed positional and label based hierachical indexes.
|
| However, when an axis is integer based, ONLY label based access
| and not positional access is supported. Thus, in such cases, it&#39;s
| usually better to be explicit and use</code>.iloc<code>or</code>.loc<code>.
|
| See more at :ref:`Advanced Indexing &lt;advanced&gt;`.
|
| loc
| Purely label-location based indexer for selection by label.
|
|</code>.loc[]<code>is primarily label based, but may also be used with a
| boolean array.
318
|
| Allowed inputs are:
|
| - A single label, e.g.</code>5<code>or</code>‘a’<code>, (note that</code>5<code>is
| interpreted as a *label* of the index, and **never** as an
| integer position along the index).
| - A list or array of labels, e.g.</code>[‘a’, ‘b’, ‘c’]<code>.
| - A slice object with labels, e.g.</code>‘a’:’f’<code>(note that contrary
| to usual python slices, **both** the start and the stop are included!).
| - A boolean array.
|
|</code>.loc<code>will raise a</code>KeyError<code>when the items are not found.
|
| See more at :ref:`Selection by Label &lt;indexing.label&gt;`
|
| ndim
| Number of axes / array dimensions
|
| shape
| Return a tuple of axis dimensions
|
| size
| number of elements in the NDFrame
|
| values
| Numpy representation of NDFrame
|
| 【注意】
| -----| The dtype will be a lower-common-denominator dtype (implicit
| upcasting); that is to say if the dtypes (even of numeric types)
| are mixed, the one that accommodates all will be chosen. Use this
| with care if you are not dealing with the blocks.
|
| e.g. If the dtypes are float16 and float32, dtype will be upcast to
| float32. If dtypes are int32 and uint8, dtype will be upcase to
| int32.
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.generic.NDFrame:
|
| is_copy = None
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.PandasObject:
|
| __dir__(self)
| Provide method name lookup and completion
| Only provide &#39;public&#39; methods
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
| Return a string representation for a particular object.
|
| Invoked by bytes(obj) in py3 only.
319
| Yields a bytestring in both py2/py3.
|
| __repr__(self)
| Return a string representation for a particular object.
|
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.base.StringMixin:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
Panel4D
Panel4D 模块所属：pandas.core.panelnd:
类定义：Panel4D(pandas.core.panel.Panel)
| Panel4D is a 4-Dimensional named container very much like a Panel, but
| having 4 named dimensions. It is intended as a test bed for more
| N-Dimensional named containers.
|
| 【参数】
| ----------| data : ndarray (labels x items x major x minor), or dict of Panels
|
| labels : Index or array-like : axis=0
| items : Index or array-like : axis=1
| major_axis : Index or array-like: axis=2
| minor_axis : Index or array-like: axis=3
|
| dtype : dtype, default None
| Data type to force, otherwise infer
| copy : boolean, default False
| Copy data from inputs. Only affects DataFrame / 2d ndarray input
|
| 【方法排序】
| Panel4D
| pandas.core.panel.Panel
| pandas.core.generic.NDFrame
| pandas.core.base.PandasObject
320
| pandas.core.base.StringMixin
| 【内置对象】
|
| 【方法定义】
|
| __init__ = panel4d_init(self, data=None, labels=None, items=None, major_axis=None, minor_axis=None, copy=False,
dtype=None)
|
| add(self, other, axis=0)
| Addition of series and other, element-wise (binary operator `add`).
| Equivalent to</code>panel + other<code>.
|
| 【参数】
| ----------| other : Panel or Panel4D
| axis : {labels, items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel4D
|
| 【参见】
| --------| Panel4D.radd
|
| all(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)
| Return whether all elements are True over requested axis
|
| 【参数】
| ----------| axis : {labels (0), items (1), major_axis (2), minor_axis (3)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a Panel
| bool_only : boolean, default None
| Include only boolean data. If None, will attempt to use everything,
| then use only boolean data
|
| 【返回值】
| -------| all : Panel or Panel4D (if level specified)
|
| any(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)
| Return whether any element is True over requested axis
|
| 【参数】
| ----------| axis : {labels (0), items (1), major_axis (2), minor_axis (3)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
321
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a Panel
| bool_only : boolean, default None
| Include only boolean data. If None, will attempt to use everything,
| then use only boolean data
|
| 【返回值】
| -------| any : Panel or Panel4D (if level specified)
|
| compound(self, axis=None, skipna=None, level=None)
| Return the compound percentage of the values for the requested axis
|
| 【参数】
| ----------| axis : {labels (0), items (1), major_axis (2), minor_axis (3)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a Panel
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| compounded : Panel or Panel4D (if level specified)
|
| cummax = max(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative max over requested axis.
|
| 【参数】
| ----------| axis : {labels (0), items (1), major_axis (2), minor_axis (3)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| max : Panel
|
| cummin = min(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative min over requested axis.
|
| 【参数】
| ----------| axis : {labels (0), items (1), major_axis (2), minor_axis (3)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| min : Panel
322
|
| cumprod = prod(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative prod over requested axis.
|
| 【参数】
| ----------| axis : {labels (0), items (1), major_axis (2), minor_axis (3)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| prod : Panel
|
| cumsum = sum(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative sum over requested axis.
|
| 【参数】
| ----------| axis : {labels (0), items (1), major_axis (2), minor_axis (3)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| sum : Panel
|
| div = truediv(self, other, axis=0)
|
| divide = truediv(self, other, axis=0)
|
| dropna = func(self, *args, **kwargs)
|
| eq(self, other)
| Wrapper for comparison method eq
|
| filter = func(self, *args, **kwargs)
|
| floordiv(self, other, axis=0)
| Integer division of series and other, element-wise (binary operator `floordiv`).
| Equivalent to</code>panel // other<code>.
|
| 【参数】
| ----------| other : Panel or Panel4D
| axis : {labels, items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel4D
|
| 【参见】
| --------| Panel4D.rfloordiv
323
|
| ge(self, other)
| Wrapper for comparison method ge
|
| groupby = func(self, *args, **kwargs)
|
| gt(self, other)
| Wrapper for comparison method gt
|
| join = func(self, *args, **kwargs)
|
| kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return unbiased kurtosis over requested axis using Fishers definition of
| kurtosis (kurtosis of normal == 0.0). Normalized by N-1
|
|
| 【参数】
| ----------| axis : {labels (0), items (1), major_axis (2), minor_axis (3)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a Panel
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| kurt : Panel or Panel4D (if level specified)
|
| kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
|
| le(self, other)
| Wrapper for comparison method le
|
| lt(self, other)
| Wrapper for comparison method lt
|
| mad(self, axis=None, skipna=None, level=None)
| Return the mean absolute deviation of the values for the requested axis
|
| 【参数】
| ----------| axis : {labels (0), items (1), major_axis (2), minor_axis (3)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a Panel
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
324
| 【返回值】
| -------| mad : Panel or Panel4D (if level specified)
|
| max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| This method returns the maximum of the values in the object. If you
| want the *index* of the maximum, use</code>idxmax<code>. This is the
| equivalent of the</code>numpy.ndarray<code>method</code>argmax<code>.
|
| 【参数】
| ----------| axis : {labels (0), items (1), major_axis (2), minor_axis (3)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a Panel
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| max : Panel or Panel4D (if level specified)
|
| mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the mean of the values for the requested axis
|
| 【参数】
| ----------| axis : {labels (0), items (1), major_axis (2), minor_axis (3)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a Panel
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| mean : Panel or Panel4D (if level specified)
|
| median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the median of the values for the requested axis
|
| 【参数】
| ----------| axis : {labels (0), items (1), major_axis (2), minor_axis (3)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
325
| particular level, collapsing into a Panel
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| median : Panel or Panel4D (if level specified)
|
| min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| This method returns the minimum of the values in the object. If you
| want the *index* of the minimum, use</code>idxmin<code>. This is the
| equivalent of the</code>numpy.ndarray<code>method</code>argmin<code>.
|
| 【参数】
| ----------| axis : {labels (0), items (1), major_axis (2), minor_axis (3)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a Panel
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| min : Panel or Panel4D (if level specified)
|
| mod(self, other, axis=0)
| Modulo of series and other, element-wise (binary operator `mod`).
| Equivalent to</code>panel % other<code>.
|
| 【参数】
| ----------| other : Panel or Panel4D
| axis : {labels, items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel4D
|
| 【参见】
| --------| Panel4D.rmod
|
| mul(self, other, axis=0)
| Multiplication of series and other, element-wise (binary operator `mul`).
| Equivalent to</code>panel <em> other<code>.
|
| 【参数】
| ----------| other : Panel or Panel4D
| axis : {labels, items, major_axis, minor_axis}
326
| Axis to broadcast over
|
| 【返回值】
| -------| Panel4D
|
| 【参见】
| --------| Panel4D.rmul
|
| multiply = mul(self, other, axis=0)
|
| ne(self, other)
| Wrapper for comparison method ne
|
| pow(self, other, axis=0)
| Exponential power of series and other, element-wise (binary operator `pow`).
| Equivalent to</code>panel <strong> other``.<br>|<br>| 【参数】<br>| ———-| other : Panel or Panel4D<br>| axis : {labels, items, major_axis, minor_axis}<br>| Axis to broadcast over<br>|<br>| 【返回值】<br>| ——-| Panel4D<br>|<br>| 【参见】<br>| ——–| Panel4D.rpow<br>|<br>| prod(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| Return the product of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {labels (0), items (1), major_axis (2), minor_axis (3)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Panel<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| prod : Panel or Panel4D (if level specified)<br>|<br>| product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)<br>|<br>| radd(self, other, axis=0)<br>| Addition of series and other, element-wise (binary operator <code>radd</code>).<br>327<br>| Equivalent to <code>other + panel</code>.<br>|<br>| 【参数】<br>| ———-| other : Panel or Panel4D<br>| axis : {labels, items, major_axis, minor_axis}<br>| Axis to broadcast over<br>|<br>| 【返回值】<br>| ——-| Panel4D<br>|<br>| 【参见】<br>| ——–| Panel4D.add<br>|<br>| rdiv = rtruediv(self, other, axis=0)<br>|<br>| rfloordiv(self, other, axis=0)<br>| Integer division of series and other, element-wise (binary operator <code>rfloordiv</code>).<br>| Equivalent to <code>other // panel</code>.<br>|<br>| 【参数】<br>| ———-| other : Panel or Panel4D<br>| axis : {labels, items, major_axis, minor_axis}<br>| Axis to broadcast over<br>|<br>| 【返回值】<br>| ——-| Panel4D<br>|<br>| 【参见】<br>| ——–| Panel4D.floordiv<br>|<br>| rmod(self, other, axis=0)<br>| Modulo of series and other, element-wise (binary operator <code>rmod</code>).<br>| Equivalent to <code>other % panel</code>.<br>|<br>| 【参数】<br>| ———-| other : Panel or Panel4D<br>| axis : {labels, items, major_axis, minor_axis}<br>| Axis to broadcast over<br>|<br>| 【返回值】<br>| ——-| Panel4D<br>|<br>| 【参见】<br>| ——–| Panel4D.mod<br>|<br>| rmul(self, other, axis=0)<br>| Multiplication of series and other, element-wise (binary operator <code>rmul</code>).<br>328<br>| Equivalent to ``other </em> panel<code>.
|
| 【参数】
| ----------| other : Panel or Panel4D
| axis : {labels, items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel4D
|
| 【参见】
| --------| Panel4D.mul
|
| rpow(self, other, axis=0)
| Exponential power of series and other, element-wise (binary operator `rpow`).
| Equivalent to</code>other <strong> panel<code>.
|
| 【参数】
| ----------| other : Panel or Panel4D
| axis : {labels, items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel4D
|
| 【参见】
| --------| Panel4D.pow
|
| rsub(self, other, axis=0)
| Subtraction of series and other, element-wise (binary operator `rsub`).
| Equivalent to</code>other - panel<code>.
|
| 【参数】
| ----------| other : Panel or Panel4D
| axis : {labels, items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel4D
|
| 【参见】
| --------| Panel4D.sub
|
| rtruediv(self, other, axis=0)
| Floating division of series and other, element-wise (binary operator `rtruediv`).
| Equivalent to</code>other / panel``.<br>|<br>329<br>| 【参数】<br>| ———-| other : Panel or Panel4D<br>| axis : {labels, items, major_axis, minor_axis}<br>| Axis to broadcast over<br>|<br>| 【返回值】<br>| ——-| Panel4D<br>|<br>| 【参见】<br>| ——–| Panel4D.truediv<br>|<br>| sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, </strong>kwargs)<br>| Return unbiased standard error of the mean over requested axis.<br>|<br>| Normalized by N-1 by default. This can be changed using the ddof argument<br>|<br>| 【参数】<br>| ———-| axis : {labels (0), items (1), major_axis (2), minor_axis (3)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Panel<br>| ddof : int, default 1<br>| degrees of freedom<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| sem : Panel or Panel4D (if level specified)<br>|<br>| shift = func(self, <em>args, <strong>kwargs)<br>|<br>| skew(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| Return unbiased skew over requested axis<br>| Normalized by N-1<br>|<br>| 【参数】<br>| ———-| axis : {labels (0), items (1), major_axis (2), minor_axis (3)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Panel<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>330<br>| 【返回值】<br>| ——-| skew : Panel or Panel4D (if level specified)<br>|<br>| std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, <strong>kwargs)<br>| Return unbiased standard deviation over requested axis.<br>|<br>| Normalized by N-1 by default. This can be changed using the ddof argument<br>|<br>| 【参数】<br>| ———-| axis : {labels (0), items (1), major_axis (2), minor_axis (3)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Panel<br>| ddof : int, default 1<br>| degrees of freedom<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| std : Panel or Panel4D (if level specified)<br>|<br>| sub(self, other, axis=0)<br>| Subtraction of series and other, element-wise (binary operator <code>sub</code>).<br>| Equivalent to <code>panel - other</code>.<br>|<br>| 【参数】<br>| ———-| other : Panel or Panel4D<br>| axis : {labels, items, major_axis, minor_axis}<br>| Axis to broadcast over<br>|<br>| 【返回值】<br>| ——-| Panel4D<br>|<br>| 【参见】<br>| ——–| Panel4D.rsub<br>|<br>| subtract = sub(self, other, axis=0)<br>|<br>| sum(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| Return the sum of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {labels (0), items (1), major_axis (2), minor_axis (3)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>331<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Panel<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| sum : Panel or Panel4D (if level specified)<br>|<br>| to_excel = func(self, </em>args, <strong>kwargs)<br>|<br>| to_frame = func(self, *args, </strong>kwargs)<br>|<br>| to_sparse = func(self, <em>args, <strong>kwargs)<br>|<br>| truediv(self, other, axis=0)<br>| Floating division of series and other, element-wise (binary operator <code>truediv</code>).<br>| Equivalent to <code>panel / other</code>.<br>|<br>| 【参数】<br>| ———-| other : Panel or Panel4D<br>| axis : {labels, items, major_axis, minor_axis}<br>| Axis to broadcast over<br>|<br>| 【返回值】<br>| ——-| Panel4D<br>|<br>| 【参见】<br>| ——–| Panel4D.rtruediv<br>|<br>| var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, </strong>kwargs)<br>| Return unbiased variance over requested axis.<br>|<br>| Normalized by N-1 by default. This can be changed using the ddof argument<br>|<br>| 【参数】<br>| ———-| axis : {labels (0), items (1), major_axis (2), minor_axis (3)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Panel<br>| ddof : int, default 1<br>| degrees of freedom<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-<br>332<br>| var : Panel or Panel4D (if level specified)<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| items<br>|<br>| labels<br>|<br>| major_axis<br>|<br>| minor_axis<br>|<br>| ———————————————————————-| Methods inherited from pandas.core.panel.Panel:<br>|<br>| <strong>add</strong>(self, other)<br>| # work only for scalars<br>|<br>| <strong>and</strong>(self, other)<br>| # work only for scalars<br>|<br>| <strong>div</strong> = <strong>truediv</strong>(self, other)<br>| # work only for scalars<br>|<br>| <strong>eq</strong>(self, other)<br>| Wrapper for comparison method <strong>eq</strong><br>|<br>| <strong>floordiv</strong>(self, other)<br>| # work only for scalars<br>|<br>| <strong>ge</strong>(self, other)<br>| Wrapper for comparison method <strong>ge</strong><br>|<br>| <strong>getitem</strong>(self, key)<br>|<br>| <strong>gt</strong>(self, other)<br>| Wrapper for comparison method <strong>gt</strong><br>|<br>| <strong>iadd</strong> = f(self, other)<br>|<br>| <strong>imul</strong> = f(self, other)<br>|<br>| <strong>ipow</strong> = f(self, other)<br>|<br>| <strong>isub</strong> = f(self, other)<br>|<br>| <strong>itruediv</strong> = f(self, other)<br>|<br>| <strong>le</strong>(self, other)<br>| Wrapper for comparison method <strong>le</strong><br>|<br>| <strong>lt</strong>(self, other)<br>| Wrapper for comparison method <strong>lt</strong><br>|<br>| <strong>mod</strong>(self, other)<br>| # work only for scalars<br>333<br>|<br>| <strong>mul</strong>(self, other)<br>| # work only for scalars<br>|<br>| <strong>ne</strong>(self, other)<br>| Wrapper for comparison method <strong>ne</strong><br>|<br>| <strong>or</strong>(self, other)<br>| # work only for scalars<br>|<br>| <strong>pow</strong>(self, other)<br>| # work only for scalars<br>|<br>| <strong>radd</strong>(self, other)<br>| # work only for scalars<br>|<br>| <strong>rand</strong>(self, other)<br>| # work only for scalars<br>|<br>| <strong>rdiv</strong> = <strong>rtruediv</strong>(self, other)<br>| # work only for scalars<br>|<br>| <strong>rfloordiv</strong>(self, other)<br>| # work only for scalars<br>|<br>| <strong>rmod</strong>(self, other)<br>| # work only for scalars<br>|<br>| <strong>rmul</strong>(self, other)<br>| # work only for scalars<br>|<br>| <strong>ror</strong>(self, other)<br>| # work only for scalars<br>|<br>| <strong>rpow</strong>(self, other)<br>| # work only for scalars<br>|<br>| <strong>rsub</strong>(self, other)<br>| # work only for scalars<br>|<br>| <strong>rtruediv</strong>(self, other)<br>| # work only for scalars<br>|<br>| <strong>rxor</strong>(self, other)<br>| # work only for scalars<br>|<br>| <strong>setitem</strong>(self, key, value)<br>|<br>| <strong>sub</strong>(self, other)<br>| # work only for scalars<br>|<br>| <strong>truediv</strong>(self, other)<br>| # work only for scalars<br>|<br>| <strong>unicode</strong>(self)<br>| Return a string representation for a particular Panel<br>|<br>334<br>| Invoked by unicode(df) in py2 only.<br>| Yields a Unicode String in both py2/py3.<br>|<br>| <strong>xor</strong>(self, other)<br>| # work only for scalars<br>|<br>| align(self, other, <strong>kwargs)<br>| Align two object on their axes with the<br>| specified join method for each axis Index<br>|<br>| 【参数】<br>| ———-| other : DataFrame or Series<br>| join : {‘outer’, ‘inner’, ‘left’, ‘right’}, default ‘outer’<br>| axis : allowed axis of the other object, default None<br>| Align on index (0), columns (1), or both (None)<br>| level : int or level name, default None<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>| copy : boolean, default True<br>| Always returns new objects. If copy=False and no reindexing is<br>| required then original objects are returned.<br>| fill_value : scalar, default np.NaN<br>| Value to use for missing values. Defaults to NaN, but can be any<br>| “compatible” value<br>| method : str, default None<br>| limit : int, default None<br>| fill_axis : int or labels for object, default 0<br>| Filling axis, method and limit<br>| broadcast_axis : int or labels for object, default None<br>| Broadcast values along this axis, if aligning two objects of<br>| different dimensions<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【返回值】<br>| ——-| (left, right) : (NDFrame, type of other)<br>| Aligned objects<br>|<br>| apply(self, func, axis=’major’, </strong>kwargs)<br>| Applies function along axis (or axes) of the Panel<br>|<br>| 【参数】<br>| ———-| func : function<br>| Function to apply to each combination of ‘other’ axes<br>| e.g. if axis = ‘items’, the combination of major_axis/minor_axis<br>| will each be passed as a Series; if axis = (‘items’, ‘major’), DataFrames<br>| of items &amp; major axis will be passed<br>| axis : {‘items’, ‘minor’, ‘major’}, or {0, 1, 2}, or a tuple with two axes<br>| Additional keyword arguments will be passed as keywords to the function<br>|<br>| 【示例】<br>| ——–|<br>| Returns a Panel with the square root of each element<br>335<br>|<br>| &gt;&gt;&gt; p = pd.Panel(np.random.rand(4,3,2))<br>| &gt;&gt;&gt; p.apply(np.sqrt)<br>|<br>| Equivalent to p.sum(1), returning a DataFrame<br>|<br>| &gt;&gt;&gt; p.apply(lambda x: x.sum(), axis=1)<br>|<br>| Equivalent to previous:<br>|<br>| &gt;&gt;&gt; p.apply(lambda x: x.sum(), axis=’minor’)<br>|<br>| Return the shapes of each DataFrame over axis 2 (i.e the shapes of items x major), as a Series<br>|<br>| &gt;&gt;&gt; p.apply(lambda x: x.shape, axis=(0,1))<br>|<br>| 【返回值】<br>| ——-| result : Panel, DataFrame, or Series<br>|<br>| as_matrix(self)<br>| Convert the frame to its Numpy-array representation.<br>|<br>| 【参数】<br>| ———-| columns: list, optional, default:None<br>| If None, return all columns, otherwise, returns specified columns.<br>|<br>| 【返回值】<br>| ——-| values : ndarray<br>| If the caller is heterogeneous and contains booleans or objects,<br>| the result will be of dtype=object. See Notes.<br>|<br>|<br>| 【注意】<br>| —–| Return is NOT a Numpy-matrix, rather, a Numpy-array.<br>|<br>| The dtype will be a lower-common-denominator dtype (implicit<br>| upcasting); that is to say if the dtypes (even of numeric types)<br>| are mixed, the one that accommodates all will be chosen. Use this<br>| with care if you are not dealing with the blocks.<br>|<br>| e.g. If the dtypes are float16 and float32, dtype will be upcast to<br>| float32. If dtypes are int32 and uint8, dtype will be upcase to<br>| int32.<br>|<br>| This method is provided for backwards compatibility. Generally,<br>| it is recommended to use ‘.values’.<br>|<br>| 【参见】<br>| ——–| pandas.DataFrame.values<br>|<br>| conform(self, frame, axis=’items’)<br>| Conform input DataFrame to align with chosen axis pair.<br>336<br>|<br>| 【参数】<br>| ———-| frame : DataFrame<br>| axis : {‘items’, ‘major’, ‘minor’}<br>|<br>| Axis the input corresponds to. E.g., if axis=’major’, then<br>| the frame’s columns would be items, and the index would be<br>| values of the minor axis<br>|<br>| 【返回值】<br>| ——-| DataFrame<br>|<br>| count(self, axis=’major’)<br>| Return number of observations over requested axis.<br>|<br>| 【参数】<br>| ———-| axis : {‘items’, ‘major’, ‘minor’} or {0, 1, 2}<br>|<br>| 【返回值】<br>| ——-| count : DataFrame<br>|<br>| fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)<br>| Fill NA/NaN values using the specified method<br>|<br>| 【参数】<br>| ———-| value : scalar, dict, Series, or DataFrame<br>| Value to use to fill holes (e.g. 0), alternately a dict/Series/DataFrame of<br>| values specifying which value to use for each index (for a Series) or<br>| column (for a DataFrame). (values not in the dict/Series/DataFrame will not be<br>| filled). This value cannot be a list.<br>| method : {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default None<br>| Method to use for filling holes in reindexed Series<br>| pad / ffill: propagate last valid observation forward to next valid<br>| backfill / bfill: use NEXT valid observation to fill gap<br>| axis : {0, 1, 2, ‘items’, ‘major_axis’, ‘minor_axis’}<br>| inplace : boolean, default False<br>| If True, fill in place. Note: this will modify any<br>| other views on this object, (e.g. a no-copy slice for a column in a<br>| DataFrame).<br>| limit : int, default None<br>| If method is specified, this is the maximum number of consecutive<br>| NaN values to forward/backward fill. In other words, if there is<br>| a gap with more than this number of consecutive NaNs, it will only<br>| be partially filled. If method is not specified, this is the<br>| maximum number of entries along the entire axis where NaNs will be<br>| filled.<br>| downcast : dict, default is None<br>| a dict of item-&gt;dtype of what to downcast if possible,<br>| or the string ‘infer’ which will try to downcast to an appropriate<br>| equal type (e.g. float64 to int64 if possible)<br>|<br>| 【参见】<br>337<br>| ——–| reindex, asfreq<br>|<br>| 【返回值】<br>| ——-| filled : Panel<br>|<br>| get_value(self, </em>args, <strong>kwargs)<br>| Quickly retrieve single value at (item, major, minor) location<br>|<br>| 【参数】<br>| ———-| item : item label (panel item)<br>| major : major axis label (panel item row)<br>| minor : minor axis label (panel item column)<br>| takeable : interpret the passed labels as indexers, default False<br>|<br>| 【返回值】<br>| ——-| value : scalar value<br>|<br>| head(self, n=5)<br>| Returns first n rows<br>|<br>| major_xs(self, key, copy=None)<br>| Return slice of panel along major axis<br>|<br>| 【参数】<br>| ———-| key : object<br>| Major axis label<br>| copy : boolean [deprecated]<br>| Whether to make a copy of the data<br>|<br>| 【返回值】<br>| ——-| y : DataFrame<br>| index -&gt; minor axis, columns -&gt; items<br>|<br>| 【注意】<br>| —–| major_xs is only for getting, not setting values.<br>|<br>| MultiIndex Slicers is a generic way to get/set values on any level or levels<br>| it is a superset of major_xs functionality, see :ref:<code>MultiIndex Slicers &lt;advanced.mi_slicers&gt;</code><br>|<br>| minor_xs(self, key, copy=None)<br>| Return slice of panel along minor axis<br>|<br>| 【参数】<br>| ———-| key : object<br>| Minor axis label<br>| copy : boolean [deprecated]<br>| Whether to make a copy of the data<br>|<br>338<br>| 【返回值】<br>| ——-| y : DataFrame<br>| index -&gt; major axis, columns -&gt; items<br>|<br>| 【注意】<br>| —–| minor_xs is only for getting, not setting values.<br>|<br>| MultiIndex Slicers is a generic way to get/set values on any level or levels<br>| it is a superset of minor_xs functionality, see :ref:<code>MultiIndex Slicers &lt;advanced.mi_slicers&gt;</code><br>|<br>| reindex(self, items=None, major_axis=None, minor_axis=None, </strong>kwargs)<br>| Conform Panel to new index with optional filling logic, placing<br>| NA/NaN in locations having no value in the previous index. A new object<br>| is produced unless the new index is equivalent to the current one and<br>| copy=False<br>|<br>| 【参数】<br>| ———-| items, major_axis, minor_axis : array-like, optional (can be specified in order, or as<br>| keywords)<br>| New labels / index to conform to. Preferably an Index object to<br>| avoid duplicating data<br>| method : {None, ‘backfill’/‘bfill’, ‘pad’/‘ffill’, ‘nearest’}, optional<br>| method to use for filling holes in reindexed DataFrame.<br>| Please note: this is only applicable to DataFrames/Series with a<br>| monotonically increasing/decreasing index.<br>| <em> default: don’t fill gaps<br>| </em> pad / ffill: propagate last valid observation forward to next valid<br>| <em> backfill / bfill: use next valid observation to fill gap<br>| </em> nearest: use nearest valid observations to fill gap<br>| copy : boolean, default True<br>| Return a new object, even if the passed indexes are the same<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>| fill_value : scalar, default np.NaN<br>| Value to use for missing values. Defaults to NaN, but can be any<br>| “compatible” value<br>| limit : int, default None<br>| Maximum number of consecutive elements to forward or backward fill<br>| tolerance : optional<br>| Maximum distance between original and new labels for inexact<br>| matches. The values of the index at the matching locations most<br>| satisfy the equation <code>abs(index[indexer] - target) &lt;= tolerance</code>.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【示例】<br>| ——–|<br>| Create a dataframe with some fictional data.<br>|<br>| &gt;&gt;&gt; index = [‘Firefox’, ‘Chrome’, ‘Safari’, ‘IE10’, ‘Konqueror’]<br>| &gt;&gt;&gt; df = pd.DataFrame({<br>| … ‘http_status’: [200,200,404,404,301],<br>339<br>| … ‘response_time’: [0.04, 0.02, 0.07, 0.08, 1.0]},<br>| … index=index)<br>| &gt;&gt;&gt; df<br>| http_status response_time<br>| Firefox 200 0.04<br>| Chrome 200 0.02<br>| Safari 404 0.07<br>| IE10 404 0.08<br>| Konqueror 301 1.00<br>|<br>| Create a new index and reindex the dataframe. By default<br>| values in the new index that do not have corresponding<br>| records in the dataframe are assigned <code>NaN</code>.<br>|<br>| &gt;&gt;&gt; new_index= [‘Safari’, ‘Iceweasel’, ‘Comodo Dragon’, ‘IE10’,<br>| … ‘Chrome’]<br>| &gt;&gt;&gt; df.reindex(new_index)<br>| http_status response_time<br>| Safari 404 0.07<br>| Iceweasel NaN NaN<br>| Comodo Dragon NaN NaN<br>| IE10 404 0.08<br>| Chrome 200 0.02<br>|<br>| We can fill in the missing values by passing a value to<br>| the keyword <code>fill_value</code>. Because the index is not monotonically<br>| increasing or decreasing, we cannot use arguments to the keyword<br>| <code>method</code> to fill the <code>NaN</code> values.<br>|<br>| &gt;&gt;&gt; df.reindex(new_index, fill_value=0)<br>| http_status response_time<br>| Safari 404 0.07<br>| Iceweasel 0 0.00<br>| Comodo Dragon 0 0.00<br>| IE10 404 0.08<br>| Chrome 200 0.02<br>|<br>| &gt;&gt;&gt; df.reindex(new_index, fill_value=’missing’)<br>| http_status response_time<br>| Safari 404 0.07<br>| Iceweasel missing missing<br>| Comodo Dragon missing missing<br>| IE10 404 0.08<br>| Chrome 200 0.02<br>|<br>| To further illustrate the filling functionality in<br>| <code>reindex</code>, we will create a dataframe with a<br>| monotonically increasing index (for example, a sequence<br>| of dates).<br>|<br>| &gt;&gt;&gt; date_index = pd.date_range(‘1/1/2010’, periods=6, freq=’D’)<br>| &gt;&gt;&gt; df2 = pd.DataFrame({“prices”: [100, 101, np.nan, 100, 89, 88]},<br>| index=date_index)<br>| &gt;&gt;&gt; df2<br>| prices<br>| 2010-01-01 100<br>| 2010-01-02 101<br>340<br>| 2010-01-03 NaN<br>| 2010-01-04 100<br>| 2010-01-05 89<br>| 2010-01-06 88<br>|<br>| Suppose we decide to expand the dataframe to cover a wider<br>| date range.<br>|<br>| &gt;&gt;&gt; date_index2 = pd.date_range(‘12/29/2009’, periods=10, freq=’D’)<br>| &gt;&gt;&gt; df2.reindex(date_index2)<br>| prices<br>| 2009-12-29 NaN<br>| 2009-12-30 NaN<br>| 2009-12-31 NaN<br>| 2010-01-01 100<br>| 2010-01-02 101<br>| 2010-01-03 NaN<br>| 2010-01-04 100<br>| 2010-01-05 89<br>| 2010-01-06 88<br>| 2010-01-07 NaN<br>|<br>| The index entries that did not have a value in the original data frame<br>| (for example, ‘2009-12-29’) are by default filled with <code>NaN</code>.<br>| If desired, we can fill in the missing values using one of several<br>| options.<br>|<br>| For example, to backpropagate the last valid value to fill the <code>NaN</code><br>| values, pass <code>bfill</code> as an argument to the <code>method</code> keyword.<br>|<br>| &gt;&gt;&gt; df2.reindex(date_index2, method=’bfill’)<br>| prices<br>| 2009-12-29 100<br>| 2009-12-30 100<br>| 2009-12-31 100<br>| 2010-01-01 100<br>| 2010-01-02 101<br>| 2010-01-03 NaN<br>| 2010-01-04 100<br>| 2010-01-05 89<br>| 2010-01-06 88<br>| 2010-01-07 NaN<br>|<br>| Please note that the <code>NaN</code> value present in the original dataframe<br>| (at index value 2010-01-03) will not be filled by any of the<br>| value propagation schemes. This is because filling while reindexing<br>| does not look at dataframe values, but only compares the original and<br>| desired indexes. If you do want to fill in the <code>NaN</code> values present<br>| in the original dataframe, use the <code>fillna()</code> method.<br>|<br>| 【返回值】<br>| ——-| reindexed : Panel<br>|<br>| reindex_axis(self, labels, axis=0, method=None, level=None, copy=True, limit=None, fill_value=nan)<br>| Conform input object to new index with optional filling logic,<br>| placing NA/NaN in locations having no value in the previous index. A<br>341<br>| new object is produced unless the new index is equivalent to the<br>| current one and copy=False<br>|<br>| 【参数】<br>| ———-| labels : array-like<br>| New labels / index to conform to. Preferably an Index object to<br>| avoid duplicating data<br>| axis : {0, 1, 2, ‘items’, ‘major_axis’, ‘minor_axis’}<br>| method : {None, ‘backfill’/‘bfill’, ‘pad’/‘ffill’, ‘nearest’}, optional<br>| Method to use for filling holes in reindexed DataFrame:<br>| <em> default: don’t fill gaps<br>| </em> pad / ffill: propagate last valid observation forward to next valid<br>| <em> backfill / bfill: use next valid observation to fill gap<br>| </em> nearest: use nearest valid observations to fill gap<br>| copy : boolean, default True<br>| Return a new object, even if the passed indexes are the same<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>| limit : int, default None<br>| Maximum number of consecutive elements to forward or backward fill<br>| tolerance : optional<br>| Maximum distance between original and new labels for inexact<br>| matches. The values of the index at the matching locations most<br>| satisfy the equation <code>abs(index[indexer] - target) &lt;= tolerance</code>.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df.reindex_axis([‘A’, ‘B’, ‘C’], axis=1)<br>|<br>| 【参见】<br>| ——–| reindex, reindex_like<br>|<br>| 【返回值】<br>| ——-| reindexed : Panel<br>|<br>| rename(self, items=None, major_axis=None, minor_axis=None, <strong>kwargs)<br>| Alter axes input function or functions. Function / dict values must be<br>| unique (1-to-1). Labels not contained in a dict / Series will be left<br>| as-is.<br>|<br>| 【参数】<br>| ———-| items, major_axis, minor_axis : dict-like or function, optional<br>| Transformation to apply to that axis values<br>|<br>| copy : boolean, default True<br>| Also copy underlying data<br>| inplace : boolean, default False<br>| Whether to return a new Panel. If True then value of copy is<br>| ignored.<br>|<br>342<br>| 【返回值】<br>| ——-| renamed : Panel (new object)<br>|<br>| set_value(self, *args, </strong>kwargs)<br>| Quickly set single value at (item, major, minor) location<br>|<br>| 【参数】<br>| ———-| item : item label (panel item)<br>| major : major axis label (panel item row)<br>| minor : minor axis label (panel item column)<br>| value : scalar<br>| takeable : interpret the passed labels as indexers, default False<br>|<br>| 【返回值】<br>| ——-| panel : Panel<br>| If label combo is contained, will be reference to calling Panel,<br>| otherwise a new object<br>|<br>| tail(self, n=5)<br>| Returns last n rows<br>|<br>| toLong = wrapper(<em>args, **kwargs)<br>|<br>| to_long = wrapper(</em>args, <strong>kwargs)<br>|<br>| transpose(self, *args, </strong>kwargs)<br>| Permute the dimensions of the Panel<br>|<br>| 【参数】<br>| ———-| args : three positional arguments: each oneof<br>| {0, 1, 2, ‘items’, ‘major_axis’, ‘minor_axis’}<br>| copy : boolean, default False<br>| Make a copy of the underlying data. Mixed-dtype data will<br>| always result in a copy<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; p.transpose(2, 0, 1)<br>| &gt;&gt;&gt; p.transpose(2, 0, 1, copy=True)<br>|<br>| 【返回值】<br>| ——-| y : same as input<br>|<br>| tshift(self, periods=1, freq=None, axis=’major’)<br>| Shift the time index, using the index’s frequency if available<br>|<br>| 【参数】<br>| ———-| periods : int<br>| Number of periods to move, can be positive or negative<br>| freq : DateOffset, timedelta, or time rule string, default None<br>| Increment to use from datetools module or time rule (e.g. ‘EOM’)<br>343<br>| axis : int or basestring<br>| Corresponds to the axis that contains the Index<br>|<br>| 【注意】<br>| —–| If freq is not specified then tries to use the freq or inferred_freq<br>| attributes of the index. If neither of those attributes exist, a<br>| ValueError is thrown<br>|<br>| 【返回值】<br>| ——-| shifted : NDFrame<br>|<br>| update(self, other, join=’left’, overwrite=True, filter_func=None, raise_conflict=False)<br>| Modify Panel in place using non-NA values from passed<br>| Panel, or object coercible to Panel. Aligns on items<br>|<br>| 【参数】<br>| ———-| other : Panel, or object coercible to Panel<br>| join : How to join individual DataFrames<br>| {‘left’, ‘right’, ‘outer’, ‘inner’}, default ‘left’<br>| overwrite : boolean, default True<br>| If True then overwrite values for common keys in the calling panel<br>| filter_func : callable(1d-array) -&gt; 1d-array<boolean>, default None<br>| Can choose to replace values other than NA. Return True for values<br>| that should be updated<br>| raise_conflict : bool<br>| If True, will raise an error if a DataFrame and other both<br>| contain data in the same place.<br>|<br>| xs(self, key, axis=1, copy=None)<br>| Return slice of panel along selected axis<br>|<br>| 【参数】<br>| ———-| key : object<br>| Label<br>| axis : {‘items’, ‘major’, ‘minor}, default 1/‘major’<br>| copy : boolean [deprecated]<br>| Whether to make a copy of the data<br>|<br>| 【返回值】<br>| ——-| y : ndim(self)-1<br>|<br>| 【注意】<br>| —–| xs is only for getting, not setting values.<br>|<br>| MultiIndex Slicers is a generic way to get/set values on any level or levels<br>| it is a superset of xs functionality, see :ref:<code>MultiIndex Slicers &lt;advanced.mi_slicers&gt;</code><br>|<br>| ———————————————————————-| Class methods inherited from pandas.core.panel.Panel:<br>|<br>| fromDict = from_dict(data, intersect=False, orient=’items’, dtype=None) from builtins.type<br>344<br>| Construct Panel from dict of DataFrame objects<br>|<br>| 【参数】<br>| ———-| data : dict<br>| {field : DataFrame}<br>| intersect : boolean<br>| Intersect indexes of input DataFrames<br>| orient : {‘items’, ‘minor’}, default ‘items’<br>| The “orientation” of the data. If the keys of the passed dict<br>| should be the items of the result panel, pass ‘items’<br>| (default). Otherwise if the columns of the values of the passed<br>| DataFrame objects should be the items (which in the case of<br>| mixed-dtype data you should do), instead pass ‘minor’<br>| dtype : dtype, default None<br>| Data type to force, otherwise infer<br>|<br>| 【返回值】<br>| ——-| Panel<br>|<br>| from_dict(data, intersect=False, orient=’items’, dtype=None) from builtins.type<br>| Construct Panel from dict of DataFrame objects<br>|<br>| 【参数】<br>| ———-| data : dict<br>| {field : DataFrame}<br>| intersect : boolean<br>| Intersect indexes of input DataFrames<br>| orient : {‘items’, ‘minor’}, default ‘items’<br>| The “orientation” of the data. If the keys of the passed dict<br>| should be the items of the result panel, pass ‘items’<br>| (default). Otherwise if the columns of the values of the passed<br>| DataFrame objects should be the items (which in the case of<br>| mixed-dtype data you should do), instead pass ‘minor’<br>| dtype : dtype, default None<br>| Data type to force, otherwise infer<br>|<br>| 【返回值】<br>| ——-| Panel<br>|<br>| ———————————————————————-| Methods inherited from pandas.core.generic.NDFrame:<br>|<br>| <strong>abs</strong>(self)<br>|<br>| <strong>array</strong>(self, dtype=None)<br>|<br>| <strong>array_wrap</strong>(self, result, context=None)<br>|<br>| <strong>bool</strong> = <strong>nonzero</strong>(self)<br>|<br>| <strong>contains</strong>(self, key)<br>| True if the key is in the info axis<br>|<br>345<br>| <strong>delitem</strong>(self, key)<br>| Delete item<br>|<br>| <strong>finalize</strong>(self, other, method=None, <strong>kwargs)<br>| propagate metadata from other to self<br>|<br>| 【参数】<br>| ———-| other : the object from which to get the attributes that we are going<br>| to propagate<br>| method : optional, a passed method name ; possibly to take different<br>| types of propagation actions based on this<br>|<br>| <strong>getattr</strong>(self, name)<br>| After regular attribute access, try looking up the name<br>| This allows simpler access to columns for interactive use.<br>|<br>| <strong>getstate</strong>(self)<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>invert</strong>(self)<br>|<br>| <strong>iter</strong>(self)<br>| Iterate over infor axis<br>|<br>| <strong>len</strong>(self)<br>| Returns length of info axis<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>nonzero</strong>(self)<br>|<br>| <strong>setattr</strong>(self, name, value)<br>| After regular attribute access, try setting the name<br>| This allows simpler access to columns for interactive use.<br>|<br>| <strong>setstate</strong>(self, state)<br>|<br>| abs(self)<br>| Return an object with absolute value taken. Only applicable to objects<br>| that are all numeric<br>|<br>| 【返回值】<br>| ——-| abs: type of caller<br>|<br>| add_prefix(self, prefix)<br>| Concatenate prefix string with panel items names.<br>|<br>| 【参数】<br>| ———-| prefix : string<br>|<br>| 【返回值】<br>| ——-<br>346<br>| with_prefix : type of caller<br>|<br>| add_suffix(self, suffix)<br>| Concatenate suffix string with panel items names<br>|<br>| 【参数】<br>| ———-| suffix : string<br>|<br>| 【返回值】<br>| ——-| with_suffix : type of caller<br>|<br>| as_blocks(self, copy=True)<br>| Convert the frame to a dict of dtype -&gt; Constructor Types that each has<br>| a homogeneous dtype.<br>|<br>| NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in<br>| as_matrix)<br>|<br>| 【参数】<br>| ———-| copy : boolean, default True<br>|<br>| .. versionadded: 0.16.1<br>|<br>| 【返回值】<br>| ——-| values : a dict of dtype -&gt; Constructor Types<br>|<br>| asfreq(self, freq, method=None, how=None, normalize=False)<br>| Convert all TimeSeries inside to specified frequency using DateOffset<br>| objects. Optionally provide fill method to pad/backfill missing values.<br>|<br>| 【参数】<br>| ———-| freq : DateOffset object, or string<br>| method : {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}<br>| Method to use for filling holes in reindexed Series<br>| pad / ffill: propagate last valid observation forward to next valid<br>| backfill / bfill: use NEXT valid observation to fill method<br>| how : {‘start’, ‘end’}, default end<br>| For PeriodIndex only, see PeriodIndex.asfreq<br>| normalize : bool, default False<br>| Whether to reset output index to midnight<br>|<br>| 【返回值】<br>| ——-| converted : type of caller<br>|<br>| astype(self, dtype, copy=True, raise_on_error=True, </strong>kwargs)<br>| Cast object to input numpy.dtype<br>| Return a copy when copy = True (be really careful with this!)<br>|<br>| 【参数】<br>| ———-| dtype : numpy.dtype or Python type<br>347<br>| raise_on_error : raise on invalid input<br>| kwargs : keyword arguments to pass on to the constructor<br>|<br>| 【返回值】<br>| ——-| casted : type of caller<br>|<br>| at_time(self, time, asof=False)<br>| Select values at particular time of day (e.g. 9:30AM)<br>|<br>| 【参数】<br>| ———-| time : datetime.time or string<br>|<br>| 【返回值】<br>| ——-| values_at_time : type of caller<br>|<br>| between_time(self, start_time, end_time, include_start=True, include_end=True)<br>| Select values between particular times of the day (e.g., 9:00-9:30 AM)<br>|<br>| 【参数】<br>| ———-| start_time : datetime.time or string<br>| end_time : datetime.time or string<br>| include_start : boolean, default True<br>| include_end : boolean, default True<br>|<br>| 【返回值】<br>| ——-| values_between_time : type of caller<br>|<br>| bfill(self, axis=None, inplace=False, limit=None, downcast=None)<br>| Synonym for NDFrame.fillna(method=’bfill’)<br>|<br>| bool(self)<br>| Return the bool of a single element PandasObject<br>| This must be a boolean scalar value, either True or False<br>|<br>| Raise a ValueError if the PandasObject does not have exactly<br>| 1 element, or that element is not boolean<br>|<br>| clip(self, lower=None, upper=None, out=None, axis=None)<br>| Trim values at input threshold(s)<br>|<br>| 【参数】<br>| ———-| lower : float or array_like, default None<br>| upper : float or array_like, default None<br>| axis : int or string axis name, optional<br>| Align object with lower and upper along the given axis.<br>|<br>| 【返回值】<br>| ——-| clipped : Series<br>|<br>348<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df<br>| 0 1<br>| 0 0.335232 -1.256177<br>| 1 -1.367855 0.746646<br>| 2 0.027753 -1.176076<br>| 3 0.230930 -0.679613<br>| 4 1.261967 0.570967<br>| &gt;&gt;&gt; df.clip(-1.0, 0.5)<br>| 0 1<br>| 0 0.335232 -1.000000<br>| 1 -1.000000 0.500000<br>| 2 0.027753 -1.000000<br>| 3 0.230930 -0.679613<br>| 4 0.500000 0.500000<br>| &gt;&gt;&gt; t<br>| 0 -0.3<br>| 1 -0.2<br>| 2 -0.1<br>| 3 0.0<br>| 4 0.1<br>| dtype: float64<br>| &gt;&gt;&gt; df.clip(t, t + 1, axis=0)<br>| 0 1<br>| 0 0.335232 -0.300000<br>| 1 -0.200000 0.746646<br>| 2 0.027753 -0.100000<br>| 3 0.230930 0.000000<br>| 4 1.100000 0.570967<br>|<br>| clip_lower(self, threshold, axis=None)<br>| Return copy of the input with values below given value(s) truncated<br>|<br>| 【参数】<br>| ———-| threshold : float or array_like<br>| axis : int or string axis name, optional<br>| Align object with threshold along the given axis.<br>|<br>| 【参见】<br>| ——–| clip<br>|<br>| 【返回值】<br>| ——-| clipped : same type as input<br>|<br>| clip_upper(self, threshold, axis=None)<br>| Return copy of input with values above given value(s) truncated<br>|<br>| 【参数】<br>| ———-| threshold : float or array_like<br>| axis : int or string axis name, optional<br>| Align object with threshold along the given axis.<br>|<br>349<br>| 【参见】<br>| ——–| clip<br>|<br>| 【返回值】<br>| ——-| clipped : same type as input<br>|<br>| consolidate(self, inplace=False)<br>| Compute NDFrame with “consolidated” internals (data of each dtype<br>| grouped together in a single ndarray). Mainly an internal API function,<br>| but available here to the savvy user<br>|<br>| 【参数】<br>| ———-| inplace : boolean, default False<br>| If False return new object, otherwise modify existing object<br>|<br>| 【返回值】<br>| ——-| consolidated : type of caller<br>|<br>| convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)<br>| Attempt to infer better dtype for object columns<br>|<br>| 【参数】<br>| ———-| convert_dates : boolean, default True<br>| If True, convert to date where possible. If ‘coerce’, force<br>| conversion, with unconvertible values becoming NaT.<br>| convert_numeric : boolean, default False<br>| If True, attempt to coerce to numbers (including strings), with<br>| unconvertible values becoming NaN.<br>| convert_timedeltas : boolean, default True<br>| If True, convert to timedelta where possible. If ‘coerce’, force<br>| conversion, with unconvertible values becoming NaT.<br>| copy : boolean, default True<br>| If True, return a copy even if no copy is necessary (e.g. no<br>| conversion was done). Note: This is meant for internal use, and<br>| should not be confused with inplace.<br>|<br>| 【返回值】<br>| ——-| converted : same as input object<br>|<br>| copy(self, deep=True)<br>| Make a copy of this object<br>|<br>| 【参数】<br>| ———-| deep : boolean or string, default True<br>| Make a deep copy, i.e. also copy data<br>|<br>| 【返回值】<br>| ——-| copy : type of caller<br>350<br>|<br>| describe(self, percentiles=None, include=None, exclude=None)<br>| Generate various summary statistics, excluding NaN values.<br>|<br>| 【参数】<br>| ———-| percentiles : array-like, optional<br>| The percentiles to include in the output. Should all<br>| be in the interval [0, 1]. By default <code>percentiles</code> is<br>| [.25, .5, .75], returning the 25th, 50th, and 75th percentiles.<br>| include, exclude : list-like, ‘all’, or None (default)<br>| Specify the form of the returned result. Either:<br>|<br>| - None to both (default). The result will include only numeric-typed<br>| columns or, if none are, only categorical columns.<br>| - A list of dtypes or strings to be included/excluded.<br>| To select all numeric types use numpy numpy.number. To select<br>| categorical objects use type object. 参见：the select_dtypes<br>| documentation. eg. df.describe(include=[‘O’])<br>| - If include is the string ‘all’, the output column-set will<br>| match the input one.<br>|<br>| 【返回值】<br>| ——-| summary: NDFrame of summary statistics<br>|<br>| 【注意】<br>| —–| The output DataFrame index depends on the requested dtypes:<br>|<br>| For numeric dtypes, it will include: count, mean, std, min,<br>| max, and lower, 50, and upper percentiles.<br>|<br>| For object dtypes (e.g. timestamps or strings), the index<br>| will include the count, unique, most common, and frequency of the<br>| most common. Timestamps also include the first and last items.<br>|<br>| For mixed dtypes, the index will be the union of the corresponding<br>| output types. Non-applicable entries will be filled with NaN.<br>| Note that mixed-dtype outputs can only be returned from mixed-dtype<br>| inputs and appropriate use of the include/exclude arguments.<br>|<br>| If multiple values have the highest count, then the<br>| <code>count</code> and <code>most common</code> pair will be arbitrarily chosen from<br>| among those with the highest count.<br>|<br>| The include, exclude arguments are ignored for Series.<br>|<br>| 【参见】<br>| ——–| DataFrame.select_dtypes<br>|<br>| drop(self, labels, axis=0, level=None, inplace=False, errors=’raise’)<br>| Return new object with labels in requested axis removed<br>|<br>| 【参数】<br>| ———-<br>351<br>| labels : single label or list-like<br>| axis : int or axis name<br>| level : int or level name, default None<br>| For MultiIndex<br>| inplace : bool, default False<br>| If True, do operation inplace and return None.<br>| errors : {‘ignore’, ‘raise’}, default ‘raise’<br>| If ‘ignore’, suppress error and existing labels are dropped.<br>|<br>| .. versionadded:: 0.16.1<br>|<br>| 【返回值】<br>| ——-| dropped : type of caller<br>|<br>| equals(self, other)<br>| Determines if two NDFrame objects contain the same elements. NaNs in the<br>| same location are considered equal.<br>|<br>| ffill(self, axis=None, inplace=False, limit=None, downcast=None)<br>| Synonym for NDFrame.fillna(method=’ffill’)<br>|<br>| first(self, offset)<br>| Convenience method for subsetting initial periods of time series data<br>| based on a date offset<br>|<br>| 【参数】<br>| ———-| offset : string, DateOffset, dateutil.relativedelta<br>|<br>| 【示例】<br>| ——–| ts.last(‘10D’) -&gt; First 10 days<br>|<br>| 【返回值】<br>| ——-| subset : type of caller<br>|<br>| get(self, key, default=None)<br>| Get item from object for given key (DataFrame column, Panel slice,<br>| etc.). Returns default value if not found<br>|<br>| 【参数】<br>| ———-| key : object<br>|<br>| 【返回值】<br>| ——-| value : type of items contained in object<br>|<br>| get_dtype_counts(self)<br>| Return the counts of dtypes in this object<br>|<br>| get_ftype_counts(self)<br>| Return the counts of ftypes in this object<br>|<br>| get_values(self)<br>352<br>| same as values (but handles sparseness conversions)<br>|<br>| interpolate(self, method=’linear’, axis=0, limit=None, inplace=False, limit_direction=’forward’, downcast=None, <strong>kwargs)<br>| Interpolate values according to different methods.<br>|<br>| Please note that only <code>method=&#39;linear&#39;</code> is supported for DataFrames/Series<br>| with a MultiIndex.<br>|<br>| 【参数】<br>| ———-| method : {‘linear’, ‘time’, ‘index’, ‘values’, ‘nearest’, ‘zero’,<br>| ‘slinear’, ‘quadratic’, ‘cubic’, ‘barycentric’, ‘krogh’,<br>| ‘polynomial’, ‘spline’ ‘piecewise_polynomial’, ‘pchip’}<br>|<br>| <em> ‘linear’: ignore the index and treat the values as equally<br>| spaced. This is the only method supported on MultiIndexes.<br>| default<br>| </em> ‘time’: interpolation works on daily and higher resolution<br>| data to interpolate given length of interval<br>| <em> ‘index’, ‘values’: use the actual numerical values of the index<br>| </em> ‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’,<br>| ‘barycentric’, ‘polynomial’ is passed to<br>| <code>scipy.interpolate.interp1d</code>. Both ‘polynomial’ and ‘spline’<br>| require that you also specify an <code>order</code> (int),<br>| e.g. df.interpolate(method=’polynomial’, order=4).<br>| These use the actual numerical values of the index.<br>| <em> ‘krogh’, ‘piecewise_polynomial’, ‘spline’, and ‘pchip’ are all<br>| wrappers around the scipy interpolation methods of similar<br>| names. These use the actual numerical values of the index. See<br>| the scipy documentation for more on their behavior<br>| <code>here &lt;http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation&gt;</code><strong><br>| <code>and here &lt;http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html&gt;</code></strong><br>|<br>| axis : {0, 1}, default 0<br>| </em> 0: fill column-by-column<br>| <em> 1: fill row-by-row<br>| limit : int, default None.<br>| Maximum number of consecutive NaNs to fill.<br>| limit_direction : {‘forward’, ‘backward’, ‘both’}, defaults to ‘forward’<br>| If limit is specified, consecutive NaNs will be filled in this<br>| direction.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| inplace : bool, default False<br>| Update the NDFrame in place if possible.<br>| downcast : optional, ‘infer’ or None, defaults to None<br>| Downcast dtypes if possible.<br>| kwargs : keyword arguments to pass on to the interpolating function.<br>|<br>| 【返回值】<br>| ——-| Series or DataFrame of same shape interpolated at the NaNs<br>|<br>| 【参见】<br>| ——–| reindex, replace, fillna<br>353<br>|<br>| 【示例】<br>| ——–|<br>| Filling in NaNs<br>|<br>| &gt;&gt;&gt; s = pd.Series([0, 1, np.nan, 3])<br>| &gt;&gt;&gt; s.interpolate()<br>| 0 0<br>| 1 1<br>| 2 2<br>| 3 3<br>| dtype: float64<br>|<br>| isnull(self)<br>| Return a boolean same-sized object indicating if the values are null<br>|<br>| 【参见】<br>| ——–| notnull : boolean inverse of isnull<br>|<br>| iteritems(self)<br>| Iterate over (label, values) on info axis<br>|<br>| This is index for Series, columns for DataFrame, major_axis for Panel,<br>| and so on.<br>|<br>| iterkv(self, </em>args, </strong>kwargs)<br>| iteritems alias used to get around 2to3. Deprecated<br>|<br>| keys(self)<br>| Get the ‘info axis’ (see Indexing for more)<br>|<br>| This is index for Series, columns for DataFrame and major_axis for<br>| Panel.<br>|<br>| last(self, offset)<br>| Convenience method for subsetting final periods of time series data<br>| based on a date offset<br>|<br>| 【参数】<br>| ———-| offset : string, DateOffset, dateutil.relativedelta<br>|<br>| 【示例】<br>| ——–| ts.last(‘5M’) -&gt; Last 5 months<br>|<br>| 【返回值】<br>| ——-| subset : type of caller<br>|<br>| mask(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)<br>| Return an object of same shape as self and whose corresponding<br>| entries are from self where cond is False and otherwise are from other.<br>|<br>| 【参数】<br>354<br>| ———-| cond : boolean NDFrame or array<br>| other : scalar or NDFrame<br>| inplace : boolean, default False<br>| Whether to perform the operation in place on the data<br>| axis : alignment axis if needed, default None<br>| level : alignment level if needed, default None<br>| try_cast : boolean, default False<br>| try to cast the result back to the input type (if possible),<br>| raise_on_error : boolean, default True<br>| Whether to raise on invalid data types (e.g. trying to where on<br>| strings)<br>|<br>| 【返回值】<br>| ——-| wh : same type as caller<br>|<br>| notnull(self)<br>| Return a boolean same-sized object indicating if the values are<br>| not null<br>|<br>| 【参见】<br>| ——–| isnull : boolean inverse of notnull<br>|<br>| pct_change(self, periods=1, fill_method=’pad’, limit=None, freq=None, <strong>kwargs)<br>| Percent change over given number of periods.<br>|<br>| 【参数】<br>| ———-| periods : int, default 1<br>| Periods to shift for forming percent change<br>| fill_method : str, default ‘pad’<br>| How to handle NAs before computing percent changes<br>| limit : int, default None<br>| The number of consecutive NAs to fill before stopping<br>| freq : DateOffset, timedelta, or offset alias string, optional<br>| Increment to use from time series API (e.g. ‘M’ or BDay())<br>|<br>| 【返回值】<br>| ——-| chg : NDFrame<br>|<br>| 【注意】<br>| —–|<br>| By default, the percentage change is calculated along the stat<br>| axis: 0, or <code>Index</code>, for <code>DataFrame</code> and 1, or <code>minor</code> for<br>| <code>Panel</code>. You can change this with the <code>axis</code> keyword argument.<br>|<br>| pipe(self, func, *args, </strong>kwargs)<br>| Apply func(self, *args, **kwargs)<br>|<br>| .. versionadded:: 0.16.2<br>|<br>| 【参数】<br>| ———-<br>355<br>| func : function<br>| function to apply to the NDFrame.<br>| <code>args</code>, and <code>kwargs</code> are passed into <code>func</code>.<br>| Alternatively a <code>(callable, data_keyword)</code> tuple where<br>| <code>data_keyword</code> is a string indicating the keyword of<br>| <code>callable</code> that expects the NDFrame.<br>| args : positional arguments passed into <code>func</code>.<br>| kwargs : a dictionary of keyword arguments passed into <code>func</code>.<br>|<br>| 【返回值】<br>| ——-| object : the return type of <code>func</code>.<br>|<br>| 【注意】<br>| —–|<br>| Use <code>.pipe</code> when chaining together functions that expect<br>| on Series or DataFrames. Instead of writing<br>|<br>| &gt;&gt;&gt; f(g(h(df), arg1=a), arg2=b, arg3=c)<br>|<br>| You can write<br>|<br>| &gt;&gt;&gt; (df.pipe(h)<br>| … .pipe(g, arg1=a)<br>| … .pipe(f, arg2=b, arg3=c)<br>| … )<br>|<br>| If you have a function that takes the data as (say) the second<br>| argument, pass a tuple indicating which keyword expects the<br>| data. For example, suppose <code>f</code> takes its data as <code>arg2</code>:<br>|<br>| &gt;&gt;&gt; (df.pipe(h)<br>| … .pipe(g, arg1=a)<br>| … .pipe((f, ‘arg2’), arg1=a, arg3=c)<br>| … )<br>|<br>| 【参见】<br>| ——–| pandas.DataFrame.apply<br>| pandas.DataFrame.applymap<br>| pandas.Series.map<br>|<br>| pop(self, item)<br>| Return item and drop from frame. Raise KeyError if not found.<br>|<br>| reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)<br>| return an object with matching indicies to myself<br>|<br>| 【参数】<br>| ———-| other : Object<br>| method : string or None<br>| copy : boolean, default True<br>| limit : int, default None<br>| Maximum number of consecutive labels to fill for inexact matches.<br>| tolerance : optional<br>356<br>| Maximum distance between labels of the other object and this<br>| object for inexact matches.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【注意】<br>| —–| Like calling s.reindex(index=other.index, columns=other.columns,<br>| method=…)<br>|<br>| 【返回值】<br>| ——-| reindexed : same as input<br>|<br>| rename_axis(self, mapper, axis=0, copy=True, inplace=False)<br>| Alter index and / or columns using input function or functions.<br>| Function / dict values must be unique (1-to-1). Labels not contained in<br>| a dict / Series will be left as-is.<br>|<br>| 【参数】<br>| ———-| mapper : dict-like or function, optional<br>| axis : int or string, default 0<br>| copy : boolean, default True<br>| Also copy underlying data<br>| inplace : boolean, default False<br>|<br>| 【返回值】<br>| ——-| renamed : type of caller<br>|<br>| replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method=’pad’, axis=None)<br>| Replace values given in ‘to_replace’ with ‘value’.<br>|<br>| 【参数】<br>| ———-| to_replace : str, regex, list, dict, Series, numeric, or None<br>|<br>| <em> str or regex:<br>|<br>| - str: string exactly matching <code>to_replace</code> will be replaced<br>| with <code>value</code><br>| - regex: regexs matching <code>to_replace</code> will be replaced with<br>| <code>value</code><br>|<br>| </em> list of str, regex, or numeric:<br>|<br>| - First, if <code>to_replace</code> and <code>value</code> are both lists, they<br>| <strong>must</strong> be the same length.<br>| - Second, if <code>regex=True</code> then all of the strings in <strong>both</strong><br>| lists will be interpreted as regexs otherwise they will match<br>| directly. This doesn’t matter much for <code>value</code> since there<br>| are only a few possible substitution regexes you can use.<br>| - str and regex rules apply as above.<br>|<br>| <em> dict:<br>|<br>357<br>| - Nested dictionaries, e.g., {‘a’: {‘b’: nan}}, are read as<br>| follows: look in column ‘a’ for the value ‘b’ and replace it<br>| with nan. You can nest regular expressions as well. Note that<br>| column names (the top-level dictionary keys in a nested<br>| dictionary) <strong>cannot</strong> be regular expressions.<br>| - Keys map to column names and values map to substitution<br>| values. You can treat this as a special case of passing two<br>| lists except that you are specifying the column to search in.<br>|<br>| </em> None:<br>|<br>| - This means that the <code>regex</code> argument must be a string,<br>| compiled regular expression, or list, dict, ndarray or Series<br>| of such elements. If <code>value</code> is also <code>None</code> then this<br>| <strong>must</strong> be a nested dictionary or <code>Series</code>.<br>|<br>| See the examples section for examples of each of these.<br>| value : scalar, dict, list, str, regex, default None<br>| Value to use to fill holes (e.g. 0), alternately a dict of values<br>| specifying which value to use for each column (columns not in the<br>| dict will not be filled). Regular expressions, strings and lists or<br>| dicts of such objects are also allowed.<br>| inplace : boolean, default False<br>| If True, in place. Note: this will modify any<br>| other views on this object (e.g. a column form a DataFrame).<br>| Returns the caller if this is True.<br>| limit : int, default None<br>| Maximum size gap to forward or backward fill<br>| regex : bool or same types as <code>to_replace</code>, default False<br>| Whether to interpret <code>to_replace</code> and/or <code>value</code> as regular<br>| expressions. If this is <code>True</code> then <code>to_replace</code> <em>must</em> be a<br>| string. Otherwise, <code>to_replace</code> must be <code>None</code> because this<br>| parameter will be interpreted as a regular expression or a list,<br>| dict, or array of regular expressions.<br>| method : string, optional, {‘pad’, ‘ffill’, ‘bfill’}<br>| The method to use when for replacement, when <code>to_replace</code> is a<br>| <code>list</code>.<br>|<br>| 【参见】<br>| ——–| NDFrame.reindex<br>| NDFrame.asfreq<br>| NDFrame.fillna<br>|<br>| 【返回值】<br>| ——-| filled : NDFrame<br>|<br>| 【Raises 引发错误】<br>| ——| AssertionError<br>| <em> If <code>regex</code> is not a <code>bool</code> and <code>to_replace</code> is not <code>None</code>.<br>| TypeError<br>| </em> If <code>to_replace</code> is a <code>dict</code> and <code>value</code> is not a <code>list</code>,<br>| <code>dict</code>, <code>ndarray</code>, or <code>Series</code><br>| <em> If <code>to_replace</code> is <code>None</code> and <code>regex</code> is not compilable into a<br>| regular expression or is a list, dict, ndarray, or Series.<br>358<br>| ValueError<br>| </em> If <code>to_replace</code> and <code>value</code> are <code>list</code> s or <code>ndarray</code> s, but<br>| they are not the same length.<br>|<br>| 【注意】<br>| —–| <em> Regex substitution is performed under the hood with <code>re.sub</code>. The<br>| rules for substitution for <code>re.sub</code> are the same.<br>| </em> Regular expressions will only substitute on strings, meaning you<br>| cannot provide, for example, a regular expression matching floating<br>| point numbers and expect the columns in your frame that have a<br>| numeric dtype to be matched. However, if those floating point numbers<br>| <em>are</em> strings, then you can do this.<br>| <em> This method has </em>a lot<em> of options. You are encouraged to experiment<br>| and play with this method to gain intuition about how it works.<br>|<br>| resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention=’start’, kind=None,<br>loffset=None, limit=None, base=0)<br>| Convenience method for frequency conversion and resampling of regular<br>| time-series data.<br>|<br>| 【参数】<br>| ———-| rule : string<br>| the offset string or object representing target conversion<br>| how : string<br>| method for down- or re-sampling, default to ‘mean’ for<br>| downsampling<br>| axis : int, optional, default 0<br>| fill_method : string, default None<br>| fill_method for upsampling<br>| closed : {‘right’, ‘left’}<br>| Which side of bin interval is closed<br>| label : {‘right’, ‘left’}<br>| Which bin edge label to label bucket with<br>| convention : {‘start’, ‘end’, ‘s’, ‘e’}<br>| kind : “period”/“timestamp”<br>| loffset : timedelta<br>| Adjust the resampled time labels<br>| limit : int, default None<br>| Maximum size gap to when reindexing with fill_method<br>| base : int, default 0<br>| For frequencies that evenly subdivide 1 day, the “origin” of the<br>| aggregated intervals. For example, for ‘5min’ frequency, base could<br>| range from 0 through 4. Defaults to 0<br>|<br>|<br>| 【示例】<br>| ——–|<br>| Start by creating a series with 9 one minute timestamps.<br>|<br>| &gt;&gt;&gt; index = pd.date_range(‘1/1/2000’, periods=9, freq=’T’)<br>| &gt;&gt;&gt; series = pd.Series(range(9), index=index)<br>| &gt;&gt;&gt; series<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:01:00 1<br>359<br>| 2000-01-01 00:02:00 2<br>| 2000-01-01 00:03:00 3<br>| 2000-01-01 00:04:00 4<br>| 2000-01-01 00:05:00 5<br>| 2000-01-01 00:06:00 6<br>| 2000-01-01 00:07:00 7<br>| 2000-01-01 00:08:00 8<br>| Freq: T, dtype: int64<br>|<br>| Downsample the series into 3 minute bins and sum the values<br>| of the timestamps falling into a bin.<br>|<br>| &gt;&gt;&gt; series.resample(‘3T’, how=’sum’)<br>| 2000-01-01 00:00:00 3<br>| 2000-01-01 00:03:00 12<br>| 2000-01-01 00:06:00 21<br>| Freq: 3T, dtype: int64<br>|<br>| Downsample the series into 3 minute bins as above, but label each<br>| bin using the right edge instead of the left. Please note that the<br>| value in the bucket used as the label is not included in the bucket,<br>| which it labels. For example, in the original series the<br>| bucket <code>2000-01-01 00:03:00</code> contains the value 3, but the summed<br>| value in the resampled bucket with the label<code>2000-01-01 00:03:00</code><br>| does not include 3 (if it did, the summed value would be 6, not 3).<br>| To include this value close the right side of the bin interval as<br>| illustrated in the example below this one.<br>|<br>| &gt;&gt;&gt; series.resample(‘3T’, how=’sum’, label=’right’)<br>| 2000-01-01 00:03:00 3<br>| 2000-01-01 00:06:00 12<br>| 2000-01-01 00:09:00 21<br>| Freq: 3T, dtype: int64<br>|<br>| Downsample the series into 3 minute bins as above, but close the right<br>| side of the bin interval.<br>|<br>| &gt;&gt;&gt; series.resample(‘3T’, how=’sum’, label=’right’, closed=’right’)<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:03:00 6<br>| 2000-01-01 00:06:00 15<br>| 2000-01-01 00:09:00 15<br>| Freq: 3T, dtype: int64<br>|<br>| Upsample the series into 30 second bins.<br>|<br>| &gt;&gt;&gt; series.resample(‘30S’)[0:5] #select first 5 rows<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:00:30 NaN<br>| 2000-01-01 00:01:00 1<br>| 2000-01-01 00:01:30 NaN<br>| 2000-01-01 00:02:00 2<br>| Freq: 30S, dtype: float64<br>|<br>| Upsample the series into 30 second bins and fill the <code>NaN</code><br>| values using the <code>pad</code> method.<br>|<br>360<br>| &gt;&gt;&gt; series.resample(‘30S’, fill_method=’pad’)[0:5]<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:00:30 0<br>| 2000-01-01 00:01:00 1<br>| 2000-01-01 00:01:30 1<br>| 2000-01-01 00:02:00 2<br>| Freq: 30S, dtype: int64<br>|<br>| Upsample the series into 30 second bins and fill the<br>| <code>NaN</code> values using the <code>bfill</code> method.<br>|<br>| &gt;&gt;&gt; series.resample(‘30S’, fill_method=’bfill’)[0:5]<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:00:30 1<br>| 2000-01-01 00:01:00 1<br>| 2000-01-01 00:01:30 2<br>| 2000-01-01 00:02:00 2<br>| Freq: 30S, dtype: int64<br>|<br>| Pass a custom function to <code>how</code>.<br>|<br>| &gt;&gt;&gt; def custom_resampler(array_like):<br>| … return np.sum(array_like)+5<br>|<br>| &gt;&gt;&gt; series.resample(‘3T’, how=custom_resampler)<br>| 2000-01-01 00:00:00 8<br>| 2000-01-01 00:03:00 17<br>| 2000-01-01 00:06:00 26<br>| Freq: 3T, dtype: int64<br>|<br>| sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)<br>| Returns a random sample of items from an axis of object.<br>|<br>| .. versionadded:: 0.16.1<br>|<br>| 【参数】<br>| ———-| n : int, optional<br>| Number of items from axis to return. Cannot be used with <code>frac</code>.<br>| Default = 1 if <code>frac</code> = None.<br>| frac : float, optional<br>| Fraction of axis items to return. Cannot be used with <code>n</code>.<br>| replace : boolean, optional<br>| Sample with or without replacement. Default = False.<br>| weights : str or ndarray-like, optional<br>| Default ‘None’ results in equal probability weighting.<br>| If passed a Series, will align with target object on index. Index<br>| values in weights not found in sampled object will be ignored and<br>| index values in sampled object not in weights will be assigned<br>| weights of zero.<br>| If called on a DataFrame, will accept the name of a column<br>| when axis = 0.<br>| Unless weights are a Series, weights must be same length as axis<br>| being sampled.<br>| If weights do not sum to 1, they will be normalized to sum to 1.<br>| Missing values in the weights column will be treated as zero.<br>| inf and -inf values not allowed.<br>361<br>| random_state : int or numpy.random.RandomState, optional<br>| Seed for the random number generator (if int), or numpy RandomState<br>| object.<br>| axis : int or string, optional<br>| Axis to sample. Accepts axis number or name. Default is stat axis<br>| for given data type (0 for Series and DataFrames, 1 for Panels).<br>|<br>| 【返回值】<br>| ——-| A new object of same type as caller.<br>|<br>| select(self, crit, axis=0)<br>| Return data corresponding to axis labels matching criteria<br>|<br>| 【参数】<br>| ———-| crit : function<br>| To be called on each index (label). Should return True or False<br>| axis : int<br>|<br>| 【返回值】<br>| ——-| selection : type of caller<br>|<br>| set_axis(self, axis, labels)<br>| public verson of axis assignment<br>|<br>| slice_shift(self, periods=1, axis=0)<br>| Equivalent to <code>shift</code> without copying data. The shifted data will<br>| not include the dropped periods and the shifted axis will be smaller<br>| than the original.<br>|<br>| 【参数】<br>| ———-| periods : int<br>| Number of periods to move, can be positive or negative<br>|<br>| 【注意】<br>| —–| While the <code>slice_shift</code> is faster than <code>shift</code>, you may pay for it<br>| later during alignment.<br>|<br>| 【返回值】<br>| ——-| shifted : same type as caller<br>|<br>| sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind=’quicksort’, na_position=’last’,<br>sort_remaining=True)<br>| Sort object by labels (along an axis)<br>|<br>| 【参数】<br>| ———-| axis : axes to direct sorting<br>| level : int or level name or list of ints or list of level names<br>| if not None, sort on values in specified index level(s)<br>| ascending : boolean, default True<br>| Sort ascending vs. descending<br>362<br>| inplace : bool<br>| if True, perform operation in-place<br>| kind : {<code>quicksort</code>, <code>mergesort</code>, <code>heapsort</code>}<br>| Choice of sorting algorithm. 参见：ndarray.np.sort for more information.<br>| <code>mergesort</code> is the only stable algorithm. For DataFrames, this option is<br>| only applied when sorting on a single column or label.<br>| na_position : {‘first’, ‘last’}<br>| <code>first</code> puts NaNs at the beginning, <code>last</code> puts NaNs at the end<br>| sort_remaining : bool<br>| if true and sorting by level and index is multilevel, sort by other levels<br>| too (in order) after sorting by specified level<br>|<br>| 【返回值】<br>| ——-| sorted_obj : NDFrame<br>|<br>| sort_values(self, by, axis=0, ascending=True, inplace=False, kind=’quicksort’, na_position=’last’)<br>|<br>| squeeze(self)<br>| squeeze length 1 dimensions<br>|<br>| swapaxes(self, axis1, axis2, copy=True)<br>| Interchange axes and swap values axes appropriately<br>|<br>| 【返回值】<br>| ——-| y : same as input<br>|<br>| swaplevel(self, i, j, axis=0)<br>| Swap levels i and j in a MultiIndex on a particular axis<br>|<br>| 【参数】<br>| ———-| i, j : int, string (can be mixed)<br>| Level of index to be swapped. Can pass level name as string.<br>|<br>| 【返回值】<br>| ——-| swapped : type of caller (new object)<br>|<br>| take(self, indices, axis=0, convert=True, is_copy=True)<br>| Analogous to ndarray.take<br>|<br>| 【参数】<br>| ———-| indices : list / array of ints<br>| axis : int, default 0<br>| convert : translate neg to pos indices (default)<br>| is_copy : mark the returned frame as a copy<br>|<br>| 【返回值】<br>| ——-| taken : type of caller<br>|<br>| to_clipboard(self, excel=None, sep=None, <strong>kwargs)<br>| Attempt to write text representation of object to the system clipboard<br>| This can be pasted into Excel, for example.<br>363<br>|<br>| 【参数】<br>| ———-| excel : boolean, defaults to True<br>| if True, use the provided separator, writing in a csv<br>| format for allowing easy pasting into excel.<br>| if False, write a string representation of the object<br>| to the clipboard<br>| sep : optional, defaults to tab<br>| other keywords are passed to to_csv<br>|<br>| 【注意】<br>| —–| Requirements for your platform<br>| - Linux: xclip, or xsel (with gtk or PyQt4 modules)<br>| - Windows: none<br>| - OS X: none<br>|<br>| to_dense(self)<br>| Return dense representation of NDFrame (as opposed to sparse)<br>|<br>| to_hdf(self, path_or_buf, key, </strong>kwargs)<br>| activate the HDFStore<br>|<br>| 【参数】<br>| ———-| path_or_buf : the path (string) or HDFStore object<br>| key : string<br>| indentifier for the group in the store<br>| mode : optional, {‘a’, ‘w’, ‘r’, ‘r+’}, default ‘a’<br>|<br>| <code>&#39;r&#39;</code><br>| Read-only; no data can be modified.<br>| <code>&#39;w&#39;</code><br>| Write; a new file is created (an existing file with the same<br>| name would be deleted).<br>| <code>&#39;a&#39;</code><br>| Append; an existing file is opened for reading and writing,<br>| and if the file does not exist it is created.<br>| <code>&#39;r+&#39;</code><br>| It is similar to <code>&#39;a&#39;</code>, but the file must already exist.<br>| format : ‘fixed(f)|table(t)’, default is ‘fixed’<br>| fixed(f) : Fixed format<br>| Fast writing/reading. Not-appendable, nor searchable<br>| table(t) : Table format<br>| Write as a PyTables Table structure which may perform<br>| worse but allow more flexible operations like searching<br>| / selecting subsets of the data<br>| append : boolean, default False<br>| For Table formats, append the input data to the existing<br>| complevel : int, 1-9, default 0<br>| If a complib is specified compression will be applied<br>| where possible<br>| complib : {‘zlib’, ‘bzip2’, ‘lzo’, ‘blosc’, None}, default None<br>| If complevel is &gt; 0 apply compression to objects written<br>| in the store wherever possible<br>| fletcher32 : bool, default False<br>364<br>| If applying compression use the fletcher32 checksum<br>| dropna : boolean, default False.<br>| If true, ALL nan rows will not be written to store.<br>|<br>| to_json(self, path_or_buf=None, orient=None, date_format=’epoch’, double_precision=10, force_ascii=True, date_unit=’ms’,<br>default_handler=None)<br>| Convert the object to a JSON string.<br>|<br>| Note NaN’s and None will be converted to null and datetime objects<br>| will be converted to UNIX timestamps.<br>|<br>| 【参数】<br>| ———-| path_or_buf : the path or buffer to write the result string<br>| if this is None, return a StringIO of the converted string<br>| orient : string<br>|<br>| </em> Series<br>|<br>| - default is ‘index’<br>| - allowed values are: {‘split’,’records’,’index’}<br>|<br>| <em> DataFrame<br>|<br>| - default is ‘columns’<br>| - allowed values are:<br>| {‘split’,’records’,’index’,’columns’,’values’}<br>|<br>| </em> The format of the JSON string<br>|<br>| - split : dict like<br>| {index -&gt; [index], columns -&gt; [columns], data -&gt; [values]}<br>| - records : list like<br>| [{column -&gt; value}, … , {column -&gt; value}]<br>| - index : dict like {index -&gt; {column -&gt; value}}<br>| - columns : dict like {column -&gt; {index -&gt; value}}<br>| - values : just the values array<br>|<br>| date_format : {‘epoch’, ‘iso’}<br>| Type of date conversion. <code>epoch</code> = epoch milliseconds,<br>| <code>iso`` = ISO8601, default is epoch.
| double_precision : The number of decimal places to use when encoding
| floating point values, default 10.
| force_ascii : force encoded string to be ASCII, default True.
| date_unit : string, default &#39;ms&#39; (milliseconds)
| The time unit to encode to, governs timestamp and ISO8601
| precision. One of &#39;s&#39;, &#39;ms&#39;, &#39;us&#39;, &#39;ns&#39; for second, millisecond,
| microsecond, and nanosecond respectively.
| default_handler : callable, default None
| Handler to call if object cannot otherwise be converted to a
| suitable format for JSON. Should receive a single argument which is
| the object to convert and return a serialisable object.
|
| 【返回值】
| -------| same type as input object with filtered info axis
|
365
| to_msgpack(self, path_or_buf=None, **kwargs)
| msgpack (serialize) object to input file path
|
| THIS IS AN EXPERIMENTAL LIBRARY and the storage format
| may not be stable until a future release.
|
| 【参数】
| ----------| path : string File path, buffer-like, or None
| if None, return generated string
| append : boolean whether to append to an existing msgpack
| (default is False)
| compress : type of compressor (zlib or blosc), default to None (no
| compression)
|
| to_pickle(self, path)
| Pickle (serialize) object to input file path
|
| 【参数】
| ----------| path : string
| File path
|
| to_sql(self, name, con, flavor=&#39;sqlite&#39;, schema=None, if_exists=&#39;fail&#39;, index=True, index_label=None, chunksize=None,
dtype=None)
| Write records stored in a DataFrame to a SQL database.
|
| 【参数】
| ----------| name : string
| Name of SQL table
| con : SQLAlchemy engine or DBAPI2 connection (legacy mode)
| Using SQLAlchemy makes it possible to use any DB supported by that
| library.
| If a DBAPI2 object, only sqlite3 is supported.
| flavor : {&#39;sqlite&#39;, &#39;mysql&#39;}, default &#39;sqlite&#39;
| The flavor of SQL to use. Ignored when using SQLAlchemy engine.
| &#39;mysql&#39; is deprecated and will be removed in future versions, but it
| will be further supported through SQLAlchemy engines.
| schema : string, default None
| Specify the schema (if database flavor supports this). If None, use
| default schema.
| if_exists : {&#39;fail&#39;, &#39;replace&#39;, &#39;append&#39;}, default &#39;fail&#39;
| - fail: If table exists, do nothing.
| - replace: If table exists, drop it, recreate it, and insert data.
| - append: If table exists, insert data. Create if does not exist.
| index : boolean, default True
| Write DataFrame index as a column.
| index_label : string or sequence, default None
| Column label for index column(s). If None is given (default) and
|</code>index<code>is True, then the index names are used.
| A sequence should be given if the DataFrame uses MultiIndex.
| chunksize : int, default None
| If not None, then rows will be written in batches of this size at a
| time. If None, all rows will be written at once.
| dtype : dict of column name to SQL type, default None
| Optional specifying the datatype for columns. The SQL type should
366
| be a SQLAlchemy type, or a string for sqlite3 fallback connection.
|
| truncate(self, before=None, after=None, axis=None, copy=True)
| Truncates a sorted NDFrame before and/or after some particular
| dates.
|
| 【参数】
| ----------| before : date
| Truncate before date
| after : date
| Truncate after date
| axis : the truncation axis, defaults to the stat axis
| copy : boolean, default is True,
| return a copy of the truncated section
|
| 【返回值】
| -------| truncated : type of caller
|
| tz_convert(self, tz, axis=0, level=None, copy=True)
| Convert tz-aware axis to target time zone.
|
| 【参数】
| ----------| tz : string or pytz.timezone object
| axis : the axis to convert
| level : int, str, default None
| If axis ia a MultiIndex, convert a specific level. Otherwise
| must be None
| copy : boolean, default True
| Also make a copy of the underlying data
|
| 【返回值】
| -------|
| 【Raises 引发错误】
| ------| TypeError
| If the axis is tz-naive.
|
| tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous=&#39;raise&#39;)
| Localize tz-naive TimeSeries to target time zone
|
| 【参数】
| ----------| tz : string or pytz.timezone object
| axis : the axis to localize
| level : int, str, default None
| If axis ia a MultiIndex, localize a specific level. Otherwise
| must be None
| copy : boolean, default True
| Also make a copy of the underlying data
| ambiguous : &#39;infer&#39;, bool-ndarray, &#39;NaT&#39;, default &#39;raise&#39;
| - &#39;infer&#39; will attempt to infer fall dst-transition hours based on order
| - bool-ndarray where True signifies a DST time, False designates
| a non-DST time (note that this flag is only applicable for ambiguous times)
367
| - &#39;NaT&#39; will return NaT where there are ambiguous times
| - &#39;raise&#39; will raise an AmbiguousTimeError if there are ambiguous times
| infer_dst : boolean, default False (DEPRECATED)
| Attempt to infer fall dst-transition hours based on order
|
| 【返回值】
| -------|
| 【Raises 引发错误】
| ------| TypeError
| If the TimeSeries is tz-aware and tz is not None.
|
| where(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)
| Return an object of same shape as self and whose corresponding
| entries are from self where cond is True and otherwise are from other.
|
| 【参数】
| ----------| cond : boolean NDFrame or array
| other : scalar or NDFrame
| inplace : boolean, default False
| Whether to perform the operation in place on the data
| axis : alignment axis if needed, default None
| level : alignment level if needed, default None
| try_cast : boolean, default False
| try to cast the result back to the input type (if possible),
| raise_on_error : boolean, default True
| Whether to raise on invalid data types (e.g. trying to where on
| strings)
|
| 【返回值】
| -------| wh : same type as caller
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.generic.NDFrame:
|
| at
| Fast label-based scalar accessor
|
| Similarly to ``loc``, ``at`` provides **label** based scalar lookups.
| You can also set using these indexers.
|
| axes
| Return index label(s) of the internal NDFrame
|
| blocks
| Internal property, property synonym for as_blocks()
|
| dtypes
| Return the dtypes in this object
|
| empty
| True if NDFrame is entirely empty [no items]
|
| ftypes
368
| Return the ftypes (indication of sparse/dense and dtype)
| in this object.
|
| iat
| Fast integer location scalar accessor.
|
| Similarly to ``iloc``, ``iat`` provides **integer** based lookups.
| You can also set using these indexers.
|
| iloc
| Purely integer-location based indexing for selection by position.
|
| ``.iloc[]`` is primarily integer position based (from ``0`` to
| ``length-1`` of the axis), but may also be used with a boolean
| array.
|
| Allowed inputs are:
|
| - An integer, e.g. ``5``.
| - A list or array of integers, e.g. ``[4, 3, 0]``.
| - A slice object with ints, e.g. ``1:7``.
| - A boolean array.
|
| ``.iloc`` will raise ``IndexError`` if a requested indexer is
| out-of-bounds, except *slice* indexers which allow out-of-bounds
| indexing (this conforms with python/numpy *slice* semantics).
|
| See more at :ref:</code>Selection by Position <indexing.integer><code>|
| ix
| A primarily label-location based indexer, with integer position
| fallback.
|
| ``.ix[]`` supports mixed integer and label based access. It is
| primarily label based, but will fall back to integer positional
| access unless the corresponding axis is of integer type.
|
| ``.ix`` is the most general indexer and will support any of the
| inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating
| point label schemes. ``.ix`` is exceptionally useful when dealing
| with mixed positional and label based hierachical indexes.
|
| However, when an axis is integer based, ONLY label based access
| and not positional access is supported. Thus, in such cases, it&#39;s
| usually better to be explicit and use ``.iloc`` or ``.loc``.
|
| See more at :ref:</code>Advanced Indexing <advanced><code>.
|
| loc
| Purely label-location based indexer for selection by label.
|
| ``.loc[]`` is primarily label based, but may also be used with a
| boolean array.
|
| Allowed inputs are:
|
| - A single label, e.g. ``5`` or ``&#39;a&#39;``, (note that ``5`` is
369
| interpreted as a *label* of the index, and **never** as an
| integer position along the index).
| - A list or array of labels, e.g. ``[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]``.
| - A slice object with labels, e.g. ``&#39;a&#39;:&#39;f&#39;`` (note that contrary
| to usual python slices, **both** the start and the stop are included!).
| - A boolean array.
|
| ``.loc`` will raise a ``KeyError`` when the items are not found.
|
| See more at :ref:</code>Selection by Label <indexing.label><code>|
| ndim
| Number of axes / array dimensions
|
| shape
| Return a tuple of axis dimensions
|
| size
| number of elements in the NDFrame
|
| values
| Numpy representation of NDFrame
|
| 【注意】
| -----| The dtype will be a lower-common-denominator dtype (implicit
| upcasting); that is to say if the dtypes (even of numeric types)
| are mixed, the one that accommodates all will be chosen. Use this
| with care if you are not dealing with the blocks.
|
| e.g. If the dtypes are float16 and float32, dtype will be upcast to
| float32. If dtypes are int32 and uint8, dtype will be upcase to
| int32.
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.generic.NDFrame:
|
| is_copy = None
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.PandasObject:
|
| __dir__(self)
| Provide method name lookup and completion
| Only provide &#39;public&#39; methods
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
| Return a string representation for a particular object.
|
| Invoked by bytes(obj) in py3 only.
| Yields a bytestring in both py2/py3.
|
| __repr__(self)
| Return a string representation for a particular object.
370
|
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.base.StringMixin:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
Period
Period 模块所属：pandas._period:
类定义：Period(builtins.object)
| Represents an period of time
|
| 【参数】
| ----------| value : Period or compat.string_types, default None
| The time period represented (e.g., &#39;4Q2005&#39;)
| freq : str, default None
| One of pandas period strings or corresponding objects
| year : int, default None
| month : int, default 1
| quarter : int, default None
| day : int, default 1
| hour : int, default 0
| minute : int, default 0
| second : int, default 0
|
| 【方法定义】
|
| __add__(self, value, /)
| Return self+value.
|
| __eq__(self, value, /)
| Return self==value.
|
| __ge__(self, value, /)
| Return self&gt;=value.
|
371
| __gt__(self, value, /)
| Return self&gt;value.
|
| __hash__(self, /)
| Return hash(self).
|
| __init__(self, /, *args, **kwargs)
| Initialize self. See help(type(self)) for accurate signature.
|
| __le__(self, value, /)
| Return self&lt;=value.
|
| __lt__(self, value, /)
| Return self&lt;value.
|
| __ne__(self, value, /)
| Return self!=value.
|
| __new__(*args, **kwargs) from builtins.type
| Create and return a new object. See help(type) for accurate signature.
|
| __radd__(self, value, /)
| Return value+self.
|
| __reduce__(...)
| helper for pickle
|
| __repr__(self, /)
| Return repr(self).
|
| __rsub__(self, value, /)
| Return value-self.
|
| __setstate__(...)
|
| __str__(self, /)
| Return str(self).
|
| __sub__(self, value, /)
| Return self-value.
|
| __unicode__(...)
| Return a string representation for a particular DataFrame
|
| Invoked by unicode(df) in py2 only. Yields a Unicode String in both
| py2/py3.
|
| asfreq(...)
| Convert Period to desired frequency, either at the start or end of the
| interval
|
| 【参数】
| ----------| freq : string
| how : {&#39;E&#39;, &#39;S&#39;, &#39;end&#39;, &#39;start&#39;}, default &#39;end&#39;
| Start or end of the timespan
|
372
| 【返回值】
| -------| resampled : Period
|
| now(...) from builtins.type
|
| strftime(...)
| Returns the string representation of the :class:</code>Period<code>, depending
| on the selected :keyword:</code>format<code>. :keyword:</code>format<code>must be a string
| containing one or several directives. The method recognizes the same
| directives as the :func:</code>time.strftime<code>function of the standard Python
| distribution, as well as the specific additional directives ``%f``,
| ``%F``, ``%q``. (formatting &amp; docs originally from scikits.timeries)
|
| +-----------+--------------------------------+-------+
| | Directive | Meaning | Notes |
| +===========+================================+=======+
| | ``%a`` | Locale&#39;s abbreviated weekday | |
| | | name. | |
| +-----------+--------------------------------+-------+
| | ``%A`` | Locale&#39;s full weekday name. | |
| +-----------+--------------------------------+-------+
| | ``%b`` | Locale&#39;s abbreviated month | |
| | | name. | |
| +-----------+--------------------------------+-------+
| | ``%B`` | Locale&#39;s full month name. | |
| +-----------+--------------------------------+-------+
| | ``%c`` | Locale&#39;s appropriate date and | |
| | | time representation. | |
| +-----------+--------------------------------+-------+
| | ``%d`` | Day of the month as a decimal | |
| | | number [01,31]. | |
| +-----------+--------------------------------+-------+
| | ``%f`` | &#39;Fiscal&#39; year without a | \(1) |
| | | century as a decimal number | |
| | | [00,99] | |
| +-----------+--------------------------------+-------+
| | ``%F`` | &#39;Fiscal&#39; year with a century | \(2) |
| | | as a decimal number | |
| +-----------+--------------------------------+-------+
| | ``%H`` | Hour (24-hour clock) as a | |
| | | decimal number [00,23]. | |
| +-----------+--------------------------------+-------+
| | ``%I`` | Hour (12-hour clock) as a | |
| | | decimal number [01,12]. | |
| +-----------+--------------------------------+-------+
| | ``%j`` | Day of the year as a decimal | |
| | | number [001,366]. | |
| +-----------+--------------------------------+-------+
| | ``%m`` | Month as a decimal number | |
| | | [01,12]. | |
| +-----------+--------------------------------+-------+
| | ``%M`` | Minute as a decimal number | |
| | | [00,59]. | |
| +-----------+--------------------------------+-------+
| | ``%p`` | Locale&#39;s equivalent of either | \(3) |
| | | AM or PM. | |
373
| +-----------+--------------------------------+-------+
| | ``%q`` | Quarter as a decimal number | |
| | | [01,04] | |
| +-----------+--------------------------------+-------+
| | ``%S`` | Second as a decimal number | \(4) |
| | | [00,61]. | |
| +-----------+--------------------------------+-------+
| | ``%U`` | Week number of the year | \(5) |
| | | (Sunday as the first day of | |
| | | the week) as a decimal number | |
| | | [00,53]. All days in a new | |
| | | year preceding the first | |
| | | Sunday are considered to be in | |
| | | week 0. | |
| +-----------+--------------------------------+-------+
| | ``%w`` | Weekday as a decimal number | |
| | | [0(Sunday),6]. | |
| +-----------+--------------------------------+-------+
| | ``%W`` | Week number of the year | \(5) |
| | | (Monday as the first day of | |
| | | the week) as a decimal number | |
| | | [00,53]. All days in a new | |
| | | year preceding the first | |
| | | Monday are considered to be in | |
| | | week 0. | |
| +-----------+--------------------------------+-------+
| | ``%x`` | Locale&#39;s appropriate date | |
| | | representation. | |
| +-----------+--------------------------------+-------+
| | ``%X`` | Locale&#39;s appropriate time | |
| | | representation. | |
| +-----------+--------------------------------+-------+
| | ``%y`` | Year without century as a | |
| | | decimal number [00,99]. | |
| +-----------+--------------------------------+-------+
| | ``%Y`` | Year with century as a decimal | |
| | | number. | |
| +-----------+--------------------------------+-------+
| | ``%Z`` | Time zone name (no characters | |
| | | if no time zone exists). | |
| +-----------+--------------------------------+-------+
| | ``%%`` | A literal ``&#39;%&#39;`` character. | |
| +-----------+--------------------------------+-------+
|
| .. note::
|
| (1)
| The ``%f`` directive is the same as ``%y`` if the frequency is
| not quarterly.
| Otherwise, it corresponds to the &#39;fiscal&#39; year, as defined by
| the :attr:</code>qyear<code>attribute.
|
| (2)
| The ``%F`` directive is the same as ``%Y`` if the frequency is
| not quarterly.
| Otherwise, it corresponds to the &#39;fiscal&#39; year, as defined by
| the :attr:</code>qyear<code>attribute.
374
|
| (3)
| The ``%p`` directive only affects the output hour field
| if the ``%I`` directive is used to parse the hour.
|
| (4)
| The range really is ``0`` to ``61``; this accounts for leap
| seconds and the (very rare) double leap seconds.
|
| (5)
| The ``%U`` and ``%W`` directives are only used in calculations
| when the day of the week and the year are specified.
|
| .. rubric:: 【示例】
|
| &gt;&gt;&gt; a = Period(freq=&#39;Q@JUL&#39;, year=2006, quarter=1)
| &gt;&gt;&gt; a.strftime(&#39;%F-Q%q&#39;)
| &#39;2006-Q1&#39;
| &gt;&gt;&gt; # Output the last month in the quarter of this date
| &gt;&gt;&gt; a.strftime(&#39;%b-%Y&#39;)
| &#39;Oct-2005&#39;
| &gt;&gt;&gt;
| &gt;&gt;&gt; a = Period(freq=&#39;D&#39;, year=2001, month=1, day=1)
| &gt;&gt;&gt; a.strftime(&#39;%d-%b-%Y&#39;)
| &#39;01-Jan-2006&#39;
| &gt;&gt;&gt; a.strftime(&#39;%b. %d, %Y was a %A&#39;)
| &#39;Jan. 01, 2001 was a Monday&#39;
|
| to_timestamp(...)
| Return the Timestamp representation of the Period at the target
| frequency at the specified end (how) of the Period
|
| 【参数】
| ----------| freq : string or DateOffset, default is &#39;D&#39; if self.freq is week or
| longer and &#39;S&#39; otherwise
| Target frequency
| how: str, default &#39;S&#39; (start)
| &#39;S&#39;, &#39;E&#39;. Can be aliased as case insensitive
| &#39;Start&#39;, &#39;Finish&#39;, &#39;Begin&#39;, &#39;End&#39;
|
| 【返回值】
| -------| Timestamp
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| day
|
| dayofweek
|
| dayofyear
|
| days_in_month
|
| daysinmonth
375
|
| end_time
|
| freq
|
| freqstr
|
| hour
|
| minute
|
| month
|
| ordinal
|
| quarter
|
| qyear
|
| second
|
| start_time
|
| week
|
| weekday
|
| weekofyear
|
| year
|
| ----------------------------------------------------------------------| 其他数据、属性定义：
|
| __pyx_vtable__ = &lt;capsule object NULL&gt;
PeriodIndex
PeriodIndex 模块所属：pandas.tseries.period:
类 定 义 ： PeriodIndex(pandas.tseries.base.DatelikeOps, pandas.tseries.base.DatetimeIndexOpsMixin,
pandas.core.index.Int64Index)
| Immutable ndarray holding ordinal values indicating regular periods in
| time such as particular years, quarters, months, etc. A value of 1 is the
| period containing the Gregorian proleptic datetime Jan 1, 0001 00:00:00.
| This ordinal representation is from the scikits.timeseries project.
|
| For instance,
| # construct period for day 1/1/1 and get the first second
| i = Period(year=1,month=1,day=1,freq=&#39;D&#39;).asfreq(&#39;S&#39;, &#39;S&#39;)
376
| i.ordinal
| ===&gt; 1
|
| Index keys are boxed to Period objects which carries the metadata (eg,
| frequency information).
|
| 【参数】
| ----------| data : array-like (1-dimensional), optional
| Optional period-like data to construct index with
| dtype : NumPy dtype (default: i8)
| copy : bool
| Make a copy of input ndarray
| freq : string or period object, optional
| One of pandas period strings or corresponding objects
| start : starting value, period-like, optional
| If data is None, used as the start point in generating regular
| period data.
| periods : int, optional, &gt; 0
| Number of periods to generate, if generating index. Takes precedence
| over end argument
| end : end value, period-like, optional
| If periods is none, generated index will extend to first conforming
| period on or just past end argument
| year : int, array, or Series, default None
| month : int, array, or Series, default None
| quarter : int, array, or Series, default None
| day : int, array, or Series, default None
| hour : int, array, or Series, default None
| minute : int, array, or Series, default None
| second : int, array, or Series, default None
| tz : object, default None
| Timezone for converting datetime64 data to Periods
|
| 【示例】
| --------| &gt;&gt;&gt; idx = PeriodIndex(year=year_arr, quarter=q_arr)
|
| &gt;&gt;&gt; idx2 = PeriodIndex(start=&#39;2000&#39;, end=&#39;2010&#39;, freq=&#39;A&#39;)
|
| 【方法排序】
| PeriodIndex
| pandas.tseries.base.DatelikeOps
| pandas.tseries.base.DatetimeIndexOpsMixin
| pandas.core.index.Int64Index
| pandas.core.index.NumericIndex
| pandas.core.index.Index
| pandas.core.base.IndexOpsMixin
| pandas.core.strings.StringAccessorMixin
| pandas.core.base.PandasObject
| pandas.core.base.StringMixin
| 【内置对象】
|
| 【方法定义】
|
| __abs__(self, other=None)
|
377
| __add__(self, other)
|
| __array_wrap__(self, result, context=None)
| Gets called after a ufunc. Needs additional handling as
| PeriodIndex stores internal data as int dtype
|
| Replace this to __numpy_ufunc__ in future version
|
| __contains__(self, key)
|
| __eq__ = wrapper(self, other)
|
| __floordiv__(self, other=None)
|
| __ge__ = wrapper(self, other)
|
| __getitem__(self, key)
| Override numpy.ndarray&#39;s __getitem__ method to work as desired.
|
| This function adds lists and Series as valid boolean indexers
| (ndarrays only supports ndarray with dtype=bool).
|
| If resulting ndim != 1, plain ndarray is returned instead of
| corresponding</code>Index<code>subclass.
|
| __gt__ = wrapper(self, other)
|
| __iadd__ = __add__(self, other)
|
| __inv__(self, other=None)
|
| __isub__ = __sub__(self, other)
|
| __le__ = wrapper(self, other)
|
| __lt__ = wrapper(self, other)
|
| __mul__(self, other=None)
|
| __ne__ = wrapper(self, other)
|
| __neg__(self, other=None)
|
| __pos__(self, other=None)
|
| __radd__ = __add__(self, other)
|
| __rfloordiv__ = __floordiv__(self, other=None)
|
| __rmul__ = __mul__(self, other=None)
|
| __rsub__(self, other)
|
| __rtruediv__ = __truediv__(self, other=None)
|
| __setstate__(self, state)
| Necessary for making this object picklable
378
|
| __sub__(self, other)
|
| __truediv__(self, other=None)
|
| all(self, other=None)
|
| any(self, other=None)
|
| append(self, other)
| Append a collection of Index options together
|
| 【参数】
| ----------| other : Index or list/tuple of indices
|
| 【返回值】
| -------| appended : Index
|
| asfreq(self, freq=None, how=&#39;E&#39;)
| Convert the PeriodIndex to the specified frequency</code>freq<code>.
|
| 【参数】
| ----------|
| freq : str
| a frequency
| how : str {&#39;E&#39;, &#39;S&#39;}
| &#39;E&#39;, &#39;END&#39;, or &#39;FINISH&#39; for end,
| &#39;S&#39;, &#39;START&#39;, or &#39;BEGIN&#39; for start.
| Whether the elements should be aligned to the end
| or start within pa period. January 31st (&#39;END&#39;) vs.
| Janury 1st (&#39;START&#39;) for example.
|
| 【返回值】
| -------|
| new : PeriodIndex with the new frequency
|
| 【示例】
| --------| &gt;&gt;&gt; pidx = pd.period_range(&#39;2010-01-01&#39;, &#39;2015-01-01&#39;, freq=&#39;A&#39;)
| &gt;&gt;&gt; pidx
| &lt;class &#39;pandas.tseries.period.PeriodIndex&#39;&gt;
| [2010, ..., 2015]
| Length: 6, Freq: A-DEC
|
| &gt;&gt;&gt; pidx.asfreq(&#39;M&#39;)
| &lt;class &#39;pandas.tseries.period.PeriodIndex&#39;&gt;
| [2010-12, ..., 2015-12]
| Length: 6, Freq: M
|
| &gt;&gt;&gt; pidx.asfreq(&#39;M&#39;, how=&#39;S&#39;)
| &lt;class &#39;pandas.tseries.period.PeriodIndex&#39;&gt;
| [2010-01, ..., 2015-01]
| Length: 6, Freq: M
379
|
| asof_locs(self, where, mask)
| where : array of timestamps
| mask : array of booleans where data is not NA
|
| astype(self, dtype)
|
| equals(self, other)
| Determines if two Index objects contain the same elements.
|
| get_indexer(self, target, method=None, limit=None, tolerance=None)
| Compute indexer and mask for new index given the current index. The
| indexer should be then used as an input to ndarray.take to align the
| current data to the new index.
|
| 【参数】
| ----------| target : Index
| method : {None, &#39;pad&#39;/&#39;ffill&#39;, &#39;backfill&#39;/&#39;bfill&#39;, &#39;nearest&#39;}, optional
| * default: exact matches only.
| * pad / ffill: find the PREVIOUS index value if no exact match.
| * backfill / bfill: use NEXT index value if no exact match
| * nearest: use the NEAREST index value if no exact match. Tied
| distances are broken by preferring the larger index value.
| limit : int, optional
| Maximum number of consecutive labels in ``target`` to match for
| inexact matches.
| tolerance : optional
| Maximum distance between original and new labels for inexact
| matches. The values of the index at the matching locations most
| satisfy the equation ``abs(index[indexer] - target) &lt;= tolerance``.
|
| .. versionadded:: 0.17.0
|
| 【示例】
| --------| &gt;&gt;&gt; indexer = index.get_indexer(new_index)
| &gt;&gt;&gt; new_values = cur_values.take(indexer)
|
| 【返回值】
| -------| indexer : ndarray of int
| Integers from 0 to n - 1 indicating that the index at these
| positions matches the corresponding target values. Missing values
| in the target are marked by -1.
|
| get_loc(self, key, method=None, tolerance=None)
| Get integer location for requested label
|
| 【返回值】
| -------| loc : int
|
| get_value(self, series, key)
| Fast lookup of value from 1-dimensional ndarray. Only use this if you
| know what you&#39;re doing
|
380
| join(self, other, how=&#39;left&#39;, level=None, return_indexers=False)
| See Index.join
|
| repeat(self, n)
| Return a new Index of the values repeated n times.
|
| 【参见】
| --------| numpy.ndarray.repeat
|
| searchsorted(self, key, side=&#39;left&#39;)
| np.ndarray searchsorted compat
|
| shift(self, n)
| Specialized shift which produces an PeriodIndex
|
| 【参数】
| ----------| n : int
| Periods to shift by
|
| 【返回值】
| -------| shifted : PeriodIndex
|
| take(self, indices, axis=0)
| Analogous to ndarray.take
|
| to_datetime(self, dayfirst=False)
| For an Index containing strings or datetime.datetime objects, attempt
| conversion to DatetimeIndex
|
| to_timestamp(self, freq=None, how=&#39;start&#39;)
| Cast to DatetimeIndex
|
| 【参数】
| ----------| freq : string or DateOffset, default &#39;D&#39; for week or longer, &#39;S&#39;
| otherwise
| Target frequency
| how : {&#39;s&#39;, &#39;e&#39;, &#39;start&#39;, &#39;end&#39;}
|
| 【返回值】
| -------| DatetimeIndex
|
| tz_convert(self, tz)
| Convert tz-aware DatetimeIndex from one time zone to another (using pytz/dateutil)
|
| 【参数】
| ----------| tz : string, pytz.timezone, dateutil.tz.tzfile or None
| Time zone for time. Corresponding timestamps would be converted to
| time zone of the TimeSeries.
| None will remove timezone holding UTC time.
|
| 【返回值】
381
| -------| normalized : DatetimeIndex
|
| Note
| ----| Not currently implemented for PeriodIndex
|
| tz_localize(self, tz, infer_dst=False)
| Localize tz-naive DatetimeIndex to given time zone (using pytz/dateutil),
| or remove timezone from tz-aware DatetimeIndex
|
| 【参数】
| ----------| tz : string, pytz.timezone, dateutil.tz.tzfile or None
| Time zone for time. Corresponding timestamps would be converted to
| time zone of the TimeSeries.
| None will remove timezone holding local time.
| infer_dst : boolean, default False
| Attempt to infer fall dst-transition hours based on order
|
| 【返回值】
| -------| localized : DatetimeIndex
|
| Note
| ----| Not currently implemented for PeriodIndex
|
| ----------------------------------------------------------------------| Static methods defined here:
|
| __new__(cls, data=None, ordinal=None, freq=None, start=None, end=None, periods=None, copy=False, name=None,
tz=None, **kwargs)
| Create and return a new object. See help(type) for accurate signature.
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| day
| The days of the period
|
| day_of_year
| The ordinal day of the year
|
| dayofweek
| The day of the week with Monday=0, Sunday=6
|
| dayofyear
| The ordinal day of the year
|
| days_in_month
| The number of days in the month
|
| daysinmonth
| The number of days in the month
|
| dtype_str
382
|
| hour
| The hour of the period
|
| inferred_type
|
| is_all_dates
| Checks that all the labels are datetime objects
|
| is_full
| Returns True if there are any missing periods from start to end
|
| minute
| The minute of the period
|
| month
| The month as January=1, December=12
|
| quarter
| The quarter of the date
|
| qyear
|
| second
| The second of the period
|
| week
| The week ordinal of the year
|
| weekday
| The day of the week with Monday=0, Sunday=6
|
| weekofyear
| The week ordinal of the year
|
| year
| The year of the period
|
| ----------------------------------------------------------------------| 其他数据、属性定义：
|
| __hash__ = None
|
| freq = None
|
| ----------------------------------------------------------------------| Methods inherited from pandas.tseries.base.DatelikeOps:
|
| strftime(self, date_format)
| Return an array of formatted strings specified by date_format, which
| supports the same string format as the python standard library. Details
| of the string format can be found in the</code>python string format doc<br>| <a href="https://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior" target="_blank" rel="external">https://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior</a><code>__
|
| .. versionadded:: 0.17.0
|
| 【参数】
383
| ----------| date_format : str
| date format string (e.g. &quot;%Y-%m-%d&quot;)
|
| 【返回值】
| -------| ndarray of formatted strings
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.tseries.base.DatelikeOps:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
|
| ----------------------------------------------------------------------| Methods inherited from pandas.tseries.base.DatetimeIndexOpsMixin:
|
| __iter__(self)
|
| argmax(self, axis=None)
| return a ndarray of the maximum argument indexer
|
| 【参见】
| --------| numpy.ndarray.argmax
|
| argmin(self, axis=None)
| return a ndarray of the minimum argument indexer
|
| 【参见】
| --------| numpy.ndarray.argmin
|
| get_duplicates(self)
|
| groupby(self, f)
|
| isin(self, values)
| Compute boolean array of whether each index value is found in the
| passed set of values
|
| 【参数】
| ----------| values : set or sequence of values
|
| 【返回值】
| -------| is_contained : ndarray (boolean dtype)
|
| map(self, f)
| # Try to run function on index first, and then on elements of index
| # Especially important for group-by functionality
|
| max(self, axis=None)
384
| return the maximum value of the Index
|
| 【参见】
| --------| numpy.ndarray.max
|
| min(self, axis=None)
| return the minimum value of the Index
|
| 【参见】
| --------| numpy.ndarray.min
|
| sort_values(self, return_indexer=False, ascending=True)
| Return sorted copy of Index
|
| summary(self, name=None)
| return a summarized representation
|
| tolist(self)
| return a list of the underlying data
|
| unique(self)
| Index.unique with handling for DatetimeIndex/PeriodIndex metadata
|
| 【返回值】
| -------| result : DatetimeIndex or PeriodIndex
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.tseries.base.DatetimeIndexOpsMixin:
|
| asobject
|
| freqstr
| return the frequency object as a string if its set, otherwise None
|
| hasnans
|
| inferred_freq
|
| resolution
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.index.Int64Index:
|
| asi8
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.index.Index:
|
| __and__(self, other)
|
| __array__(self, dtype=None)
| the array interface, return my values
|
| __bool__ = __nonzero__(self)
385
|
| __copy__ = copy(self, names=None, name=None, dtype=None, deep=False)
| Make a copy of this object. Name and dtype sets those attributes on
| the new object.
|
| 【参数】
| ----------| name : string, optional
| dtype : numpy dtype or pandas type
|
| 【返回值】
| -------| copy : Index
|
| 【注意】
| -----| In most cases, there should be no functional difference from using
| ``deep``, but if ``deep`` is passed it will attempt to deepcopy.
|
| __deepcopy__(self, memo={})
|
| __len__(self)
| return the length of the Index
|
| __nonzero__(self)
|
| __or__(self, other)
|
| __reduce__(self)
| helper for pickle
|
| __setitem__(self, key, value)
|
| __unicode__(self)
| Return a string representation for this object.
|
| Invoked by unicode(df) in py2 only. Yields a Unicode String in both
| py2/py3.
|
| __xor__(self, other)
|
| argsort(self, *args, **kwargs)
| return an ndarray indexer of the underlying data
|
| 【参见】
| --------| numpy.ndarray.argsort
|
| asof(self, label)
| For a sorted index, return the most recent label up to and including
| the passed label. Return NaN if not found.
|
| 【参见】
| --------| get_loc : asof is a thin wrapper around get_loc with method=&#39;pad&#39;
|
| copy(self, names=None, name=None, dtype=None, deep=False)
386
| Make a copy of this object. Name and dtype sets those attributes on
| the new object.
|
| 【参数】
| ----------| name : string, optional
| dtype : numpy dtype or pandas type
|
| 【返回值】
| -------| copy : Index
|
| 【注意】
| -----| In most cases, there should be no functional difference from using
| ``deep``, but if ``deep`` is passed it will attempt to deepcopy.
|
| delete(self, loc)
| Make new Index with passed location(-s) deleted
|
| 【返回值】
| -------| new_index : Index
|
| diff = wrapper(*args, **kwargs)
|
| difference(self, other)
| Return a new Index with elements from the index that are not in</code>other<code>.
|
| This is the sorted set difference of two Index objects.
|
| 【参数】
| ----------| other : Index or array-like
|
| 【返回值】
| -------| difference : Index
|
| 【示例】
| --------|
| &gt;&gt;&gt; idx1 = pd.Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = pd.Index([3, 4, 5, 6])
| &gt;&gt;&gt; idx1.difference(idx2)
| Int64Index([1, 2], dtype=&#39;int64&#39;)
|
| drop(self, labels, errors=&#39;raise&#39;)
| Make new Index with passed list of labels deleted
|
| 【参数】
| ----------| labels : array-like
| errors : {&#39;ignore&#39;, &#39;raise&#39;}, default &#39;raise&#39;
| If &#39;ignore&#39;, suppress error and existing labels are dropped.
|
387
| 【返回值】
| -------| dropped : Index
|
| drop_duplicates(self, keep=&#39;first&#39;)
| Return Index with duplicate values removed
|
| 【参数】
| ----------|
| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| - ``first`` : Drop duplicates except for the first occurrence.
| - ``last`` : Drop duplicates except for the last occurrence.
| - False : Drop all duplicates.
| take_last : deprecated
|
|
| 【返回值】
| -------| deduplicated : Index
|
| duplicated(self, keep=&#39;first&#39;)
| Return boolean np.array denoting duplicate values
|
| 【参数】
| ----------| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| - ``first`` : Mark duplicates as ``True`` except for the first occurrence.
| - ``last`` : Mark duplicates as ``True`` except for the last occurrence.
| - False : Mark all duplicates as ``True``.
| take_last : deprecated
|
| 【返回值】
| -------| duplicated : np.array
|
| fillna(self, value=None, downcast=None)
| Fill NA/NaN values with the specified value
|
| 【参数】
| ----------| value : scalar
| Scalar value to use to fill holes (e.g. 0).
| This value cannot be a list-likes.
| downcast : dict, default is None
| a dict of item-&gt;dtype of what to downcast if possible,
| or the string &#39;infer&#39; which will try to downcast to an appropriate
| equal type (e.g. float64 to int64 if possible)
|
| 【返回值】
| -------| filled : Index
|
| format(self, name=False, formatter=None, **kwargs)
| Render a string representation of the Index
|
| get_indexer_for(self, target, **kwargs)
388
| guaranteed return of an indexer even when non-unique
|
| get_indexer_non_unique(self, target)
| return an indexer suitable for taking from a non unique index
| return the labels in the same order as the target, and
| return a missing indexer into the target (missing are marked as -1
| in the indexer); target must be an iterable
|
| get_level_values(self, level)
| Return vector of label values for requested level, equal to the length
| of the index
|
| 【参数】
| ----------| level : int
|
| 【返回值】
| -------| values : ndarray
|
| get_slice_bound(self, label, side, kind)
| Calculate slice bound that corresponds to given label.
|
| Returns leftmost (one-past-the-rightmost if ``side==&#39;right&#39;``) position
| of given label.
|
| 【参数】
| ----------| label : object
| side : {&#39;left&#39;, &#39;right&#39;}
| kind : string / None, the type of indexer
|
| get_values(self)
| return the underlying data as an ndarray
|
| holds_integer(self)
|
| identical(self, other)
| Similar to equals, but check that other comparable attributes are
| also equal
|
| insert(self, loc, item)
| Make new Index inserting new item at location. Follows
| Python list.append semantics for negative values
|
| 【参数】
| ----------| loc : int
| item : object
|
| 【返回值】
| -------| new_index : Index
|
| intersection(self, other)
| Form the intersection of two Index objects.
|
389
| This returns a new Index with elements common to the index and</code>other<code>.
| Sortedness of the result is not guaranteed.
|
| 【参数】
| ----------| other : Index or array-like
|
| 【返回值】
| -------| intersection : Index
|
| 【示例】
| --------|
| &gt;&gt;&gt; idx1 = pd.Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = pd.Index([3, 4, 5, 6])
| &gt;&gt;&gt; idx1.intersection(idx2)
| Int64Index([3, 4], dtype=&#39;int64&#39;)
|
| is_(self, other)
| More flexible, faster check like ``is`` but that works through views
|
| Note: this is *not* the same as ``Index.identical()``, which checks
| that metadata is also the same.
|
| 【参数】
| ----------| other : object
| other object to compare against.
|
| 【返回值】
| -------| True if both have same underlying data, False otherwise : bool
|
| is_boolean(self)
|
| is_categorical(self)
|
| is_floating(self)
|
| is_integer(self)
|
| is_lexsorted_for_tuple(self, tup)
|
| is_mixed(self)
|
| is_numeric(self)
|
| is_object(self)
|
| is_type_compatible(self, kind)
|
| order(self, return_indexer=False, ascending=True)
| Return sorted copy of Index
|
| DEPRECATED: use :meth:</code>Index.sort_values<code>|
390
| putmask(self, mask, value)
| return a new Index of the values set with the mask
|
| 【参见】
| --------| numpy.ndarray.putmask
|
| ravel(self, order=&#39;C&#39;)
| return an ndarray of the flattened values of the underlying data
|
| 【参见】
| --------| numpy.ndarray.ravel
|
| reindex(self, target, method=None, level=None, limit=None, tolerance=None)
| Create index with target&#39;s values (move/add/delete values as necessary)
|
| 【参数】
| ----------| target : an iterable
|
| 【返回值】
| -------| new_index : pd.Index
| Resulting index
| indexer : np.ndarray or None
| Indices of output values in original index
|
| rename(self, name, inplace=False)
| Set new names on index. Defaults to returning new index.
|
| 【参数】
| ----------| name : str or list
| name to set
| inplace : bool
| if True, mutates in place
|
| 【返回值】
| -------| new index (of same type and class...etc) [if inplace, returns None]
|
| set_names(self, names, level=None, inplace=False)
| Set new names on index. Defaults to returning new index.
|
| 【参数】
| ----------| names : str or sequence
| name(s) to set
| level : int or level name, or sequence of int / level names (default None)
| If the index is a MultiIndex (hierarchical), level(s) to set (None for all levels)
| Otherwise level must be None
| inplace : bool
| if True, mutates in place
|
| 【返回值】
391
| -------| new index (of same type and class...etc) [if inplace, returns None]
|
| 【示例】
| --------| &gt;&gt;&gt; Index([1, 2, 3, 4]).set_names(&#39;foo&#39;)
| Int64Index([1, 2, 3, 4], dtype=&#39;int64&#39;)
| &gt;&gt;&gt; Index([1, 2, 3, 4]).set_names([&#39;foo&#39;])
| Int64Index([1, 2, 3, 4], dtype=&#39;int64&#39;)
| &gt;&gt;&gt; idx = MultiIndex.from_tuples([(1, u&#39;one&#39;), (1, u&#39;two&#39;),
| (2, u&#39;one&#39;), (2, u&#39;two&#39;)],
| names=[&#39;foo&#39;, &#39;bar&#39;])
| &gt;&gt;&gt; idx.set_names([&#39;baz&#39;, &#39;quz&#39;])
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
| names=[u&#39;baz&#39;, u&#39;quz&#39;])
| &gt;&gt;&gt; idx.set_names(&#39;baz&#39;, level=0)
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
| names=[u&#39;baz&#39;, u&#39;bar&#39;])
|
| set_value(self, arr, key, value)
| Fast lookup of value from 1-dimensional ndarray. Only use this if you
| know what you&#39;re doing
|
| slice_indexer(self, start=None, end=None, step=None, kind=None)
| For an ordered Index, compute the slice indexer for input labels and
| step
|
| 【参数】
| ----------| start : label, default None
| If None, defaults to the beginning
| end : label, default None
| If None, defaults to the end
| step : int, default None
| kind : string, default None
|
| 【返回值】
| -------| indexer : ndarray or slice
|
| 【注意】
| -----| This function assumes that the data is sorted, so use at your own peril
|
| slice_locs(self, start=None, end=None, step=None, kind=None)
| Compute slice locations for input labels.
|
| 【参数】
| ----------| start : label, default None
| If None, defaults to the beginning
| end : label, default None
| If None, defaults to the end
| step : int, defaults None
| If None, defaults to 1
392
| kind : string, defaults None
|
| 【返回值】
| -------| start, end : int
|
| sort(self, *args, **kwargs)
|
| sortlevel(self, level=None, ascending=True, sort_remaining=None)
| For internal compatibility with with the Index API
|
| Sort the Index. This is for compat with MultiIndex
|
| 【参数】
| ----------| ascending : boolean, default True
| False to sort in descending order
|
| level, sort_remaining are compat paramaters
|
| 【返回值】
| -------| sorted_index : Index
|
| sym_diff(self, other, result_name=None)
| Compute the sorted symmetric difference of two Index objects.
|
| 【参数】
| ----------| other : Index or array-like
| result_name : str
|
| 【返回值】
| -------| sym_diff : Index
|
| 【注意】
| -----| ``sym_diff`` contains elements that appear in either ``idx1`` or
| ``idx2`` but not both. Equivalent to the Index created by
| ``(idx1 - idx2) + (idx2 - idx1)`` with duplicates dropped.
|
| The sorting of a result containing ``NaN`` values is not guaranteed
| across Python versions. See GitHub issue #6444.
|
| 【示例】
| --------| &gt;&gt;&gt; idx1 = Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = Index([2, 3, 4, 5])
| &gt;&gt;&gt; idx1.sym_diff(idx2)
| Int64Index([1, 5], dtype=&#39;int64&#39;)
|
| You can also use the ``^`` operator:
|
| &gt;&gt;&gt; idx1 ^ idx2
| Int64Index([1, 5], dtype=&#39;int64&#39;)
|
393
| to_native_types(self, slicer=None, **kwargs)
| slice and dice then format
|
| to_series(self, **kwargs)
| Create a Series with both index and values equal to the index keys
| useful with map for returning an indexer based on an index
|
| 【返回值】
| -------| Series : dtype will be based on the type of the Index values.
|
| union(self, other)
| Form the union of two Index objects and sorts if possible.
|
| 【参数】
| ----------| other : Index or array-like
|
| 【返回值】
| -------| union : Index
|
| 【示例】
| --------|
| &gt;&gt;&gt; idx1 = pd.Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = pd.Index([3, 4, 5, 6])
| &gt;&gt;&gt; idx1.union(idx2)
| Int64Index([1, 2, 3, 4, 5, 6], dtype=&#39;int64&#39;)
|
| view(self, cls=None)
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.index.Index:
|
| dtype
|
| has_duplicates
|
| is_monotonic
| alias for is_monotonic_increasing (deprecated)
|
| is_monotonic_decreasing
| return if the index is monotonic decreasing (only equal or
| decreasing) values.
|
| is_monotonic_increasing
| return if the index is monotonic increasing (only equal or
| increasing) values.
|
| is_unique
|
| names
|
| nlevels
|
| values
394
| return the underlying data as an ndarray
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.index.Index:
|
| name = None
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.IndexOpsMixin:
|
| factorize(self, sort=False, na_sentinel=-1)
| Encode the object as an enumerated type or categorical variable
|
| 【参数】
| ----------| sort : boolean, default False
| Sort by values
| na_sentinel: int, default -1
| Value to mark &quot;not found&quot;
|
| 【返回值】
| -------| labels : the indexer to the original array
| uniques : the unique Index
|
| item(self)
| return the first element of the underlying data as a python scalar
|
| memory_usage(self, deep=False)
| Memory usage of my values
|
| 【参数】
| ----------| deep : bool
| Introspect the data deeply, interrogate
|</code>object<code>dtypes for system-level memory consumption
|
| 【返回值】
| -------| bytes used
|
| 【注意】
| -----| Memory usage does not include memory consumed by elements that
| are not components of the array if deep=False
|
| 【参见】
| --------| numpy.ndarray.nbytes
|
| nunique(self, dropna=True)
| Return number of unique elements in the object.
|
| Excludes NA values by default.
|
| 【参数】
| ----------
395
| dropna : boolean, default True
| Don&#39;t include NaN in the count.
|
| 【返回值】
| -------| nunique : int
|
| transpose(self)
| return the transpose, which is by definition self
|
| value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)
| Returns object containing counts of unique values.
|
| The resulting object will be in descending order so that the
| first element is the most frequently-occurring element.
| Excludes NA values by default.
|
| 【参数】
| ----------| normalize : boolean, default False
| If True then the object returned will contain the relative
| frequencies of the unique values.
| sort : boolean, default True
| Sort by values
| ascending : boolean, default False
| Sort in ascending order
| bins : integer, optional
| Rather than count values, group them into half-open bins,
| a convenience for pd.cut, only works with numeric data
| dropna : boolean, default True
| Don&#39;t include counts of NaN.
|
| 【返回值】
| -------| counts : Series
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.base.IndexOpsMixin:
|
| T
| return the transpose, which is by definition self
|
| base
| return the base object if the memory of the underlying data is shared
|
| data
| return the data pointer of the underlying data
|
| flags
| return the ndarray.flags for the underlying data
|
| itemsize
| return the size of the dtype of the item of the underlying data
|
| nbytes
| return the number of bytes in the underlying data
|
396
| ndim
| return the number of dimensions of the underlying data, by definition 1
|
| shape
| return a tuple of the shape of the underlying data
|
| size
| return the number of elements in the underlying data
|
| strides
| return the strides of the underlying data
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.base.IndexOpsMixin:
|
| __array_priority__ = 1000
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.strings.StringAccessorMixin:
|
| str = &lt;class &#39;pandas.core.strings.StringMethods&#39;&gt;
| Vectorized string functions for Series and Index. NAs stay NA unless
| handled otherwise by a particular method. Patterned after Python&#39;s string
| methods, with some inspiration from R&#39;s stringr package.
|
| 【示例】
| --------| &gt;&gt;&gt; s.str.split(&#39;_&#39;)
| &gt;&gt;&gt; s.str.replace(&#39;_&#39;, &#39;&#39;)
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.PandasObject:
|
| __dir__(self)
| Provide method name lookup and completion
| Only provide &#39;public&#39; methods
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
| Return a string representation for a particular object.
|
| Invoked by bytes(obj) in py3 only.
| Yields a bytestring in both py2/py3.
|
| __repr__(self)
| Return a string representation for a particular object.
|
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
397
Series
Series 模块所属：pandas.core.series:
类定义：Series(pandas.core.base.IndexOpsMixin, pandas.core.strings.StringAccessorMixin, pandas.core.generic.NDFrame)
| One-dimensional ndarray with axis labels (including time series).
|
| Labels need not be unique but must be any hashable type. The object
| supports both integer- and label-based indexing and provides a host of
| methods for performing operations involving the index. Statistical
| methods from ndarray have been overridden to automatically exclude
| missing data (currently represented as NaN)
|
| Operations between Series (+, -, /, *, **) align values based on their
| associated index values-- they need not be the same length. The result
| index will be the sorted union of the two indexes.
|
| 【参数】
| ----------| data : array-like, dict, or scalar value
| Contains data stored in Series
| index : array-like or Index (1d)
| Values must be unique and hashable, same length as data. Index
| object (or other iterable of same length as data) Will default to
| np.arange(len(data)) if not provided. If both a dict and index
| sequence are used, the index will override the keys found in the
| dict.
| dtype : numpy.dtype or None
| If None, dtype will be inferred
| copy : boolean, default False
| Copy input data
|
| 【方法排序】
| Series
| pandas.core.base.IndexOpsMixin
| pandas.core.strings.StringAccessorMixin
| pandas.core.generic.NDFrame
| pandas.core.base.PandasObject
| pandas.core.base.StringMixin
| 【内置对象】
|
| 【方法定义】
|
| __add__ = wrapper(left, right, name=&#39;__add__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004C630D0&gt;)
|
| __and__ = wrapper(self, other)
|
| __array__(self, result=None)
| the array interface, return my values
398
|
| __array_prepare__(self, result, context=None)
| Gets called prior to a ufunc
|
| __array_wrap__(self, result, context=None)
| Gets called after a ufunc
|
| __div__ = wrapper(left, right, name=&#39;__truediv__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004C63510&gt;)
|
| __eq__ = wrapper(self, other, axis=None)
|
| __float__ = wrapper(self)
|
| __floordiv__ = wrapper(left, right, name=&#39;__floordiv__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004C63620&gt;)
|
| __ge__ = wrapper(self, other, axis=None)
|
| __getitem__(self, key)
|
| __gt__ = wrapper(self, other, axis=None)
|
| __iadd__ = f(self, other)
|
| __imul__ = f(self, other)
|
| __init__(self, data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)
| Initialize self. See help(type(self)) for accurate signature.
|
| __int__ = wrapper(self)
|
| __ipow__ = f(self, other)
|
| __isub__ = f(self, other)
|
| __iter__(self)
| provide iteration over the values of the Series
| box values if necessary
|
| __itruediv__ = f(self, other)
|
| __le__ = wrapper(self, other, axis=None)
|
| __len__(self)
| return the length of the Series
|
| __long__ = wrapper(self)
|
| __lt__ = wrapper(self, other, axis=None)
|
| __mod__ = wrapper(left, right, name=&#39;__mod__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004C63730&gt;)
|
| __mul__ = wrapper(left, right, name=&#39;__mul__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004C63400&gt;)
|
399
| __ne__ = wrapper(self, other, axis=None)
|
| __or__ = wrapper(self, other)
|
| __pow__ = wrapper(left, right, name=&#39;__pow__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004C63840&gt;)
|
| __radd__ = wrapper(left, right, name=&#39;__radd__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004C631E0&gt;)
|
| __rand__ = wrapper(self, other)
|
| __rdiv__ = wrapper(left, right, name=&#39;__rtruediv__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004C63C80&gt;)
|
| __rfloordiv__ = wrapper(left, right, name=&#39;__rfloordiv__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004C63E18&gt;)
|
| __rmod__ = wrapper(left, right, name=&#39;__rmod__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004C651E0&gt;)
|
| __rmul__ = wrapper(left, right, name=&#39;__rmul__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004C63950&gt;)
|
| __ror__ = wrapper(self, other)
|
| __rpow__ = wrapper(left, right, name=&#39;__rpow__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004C65048&gt;)
|
| __rsub__ = wrapper(left, right, name=&#39;__rsub__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004C63AE8&gt;)
|
| __rtruediv__ = wrapper(left, right, name=&#39;__rtruediv__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004C63C80&gt;)
|
| __rxor__ = wrapper(self, other)
|
| __setitem__(self, key, value)
|
| __sub__ = wrapper(left, right, name=&#39;__sub__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004C632F0&gt;)
|
| __truediv__ = wrapper(left, right, name=&#39;__truediv__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004C63510&gt;)
|
| __unicode__(self)
| Return a string representation for a particular DataFrame
|
| Invoked by unicode(df) in py2 only. Yields a Unicode String in both
| py2/py3.
|
| __xor__ = wrapper(self, other)
|
| add(self, other, level=None, fill_value=None, axis=0)
| Addition of series and other, element-wise (binary operator</code>add<code>).
|
| Equivalent to ``series + other``, but with support to substitute a fill_value for
400
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.radd
|
| align(self, other, join=&#39;outer&#39;, axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0,
broadcast_axis=None)
| Align two object on their axes with the
| specified join method for each axis Index
|
| 【参数】
| ----------| other : DataFrame or Series
| join : {&#39;outer&#39;, &#39;inner&#39;, &#39;left&#39;, &#39;right&#39;}, default &#39;outer&#39;
| axis : allowed axis of the other object, default None
| Align on index (0), columns (1), or both (None)
| level : int or level name, default None
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
| copy : boolean, default True
| Always returns new objects. If copy=False and no reindexing is
| required then original objects are returned.
| fill_value : scalar, default np.NaN
| Value to use for missing values. Defaults to NaN, but can be any
| &quot;compatible&quot; value
| method : str, default None
| limit : int, default None
| fill_axis : {0, &#39;index&#39;}, default 0
| Filling axis, method and limit
| broadcast_axis : {0, &#39;index&#39;}, default None
| Broadcast values along this axis, if aligning two objects of
| different dimensions
|
| .. versionadded:: 0.17.0
|
| 【返回值】
| -------| (left, right) : (Series, type of other)
| Aligned objects
|
| all(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)
| Return whether all elements are True over requested axis
401
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| bool_only : boolean, default None
| Include only boolean data. If None, will attempt to use everything,
| then use only boolean data
|
| 【返回值】
| -------| all : scalar or Series (if level specified)
|
| any(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)
| Return whether any element is True over requested axis
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| bool_only : boolean, default None
| Include only boolean data. If None, will attempt to use everything,
| then use only boolean data
|
| 【返回值】
| -------| any : scalar or Series (if level specified)
|
| append(self, to_append, verify_integrity=False)
| Concatenate two or more Series.
|
| 【参数】
| ----------| to_append : Series or list/tuple of Series
| verify_integrity : boolean, default False
| If True, raise Exception on creating index with duplicates
|
| 【返回值】
| -------| appended : Series
|
| apply(self, func, convert_dtype=True, args=(), **kwds)
| Invoke function on values of Series. Can be ufunc (a NumPy function
| that applies to the entire Series) or a Python function that only works
| on single values
|
| 【参数】
402
| ----------| func : function
| convert_dtype : boolean, default True
| Try to find better dtype for elementwise function results. If
| False, leave as dtype=object
| args : tuple
| Positional arguments to pass to function in addition to the value
| Additional keyword arguments will be passed as keywords to the function
|
| 【返回值】
| -------| y : Series or DataFrame if func returns a Series
|
| 【参见】
| --------| Series.map: For element-wise operations
|
| 【示例】
| --------|
| Create a series with typical summer temperatures for each city.
|
| &gt;&gt;&gt; import pandas as pd
| &gt;&gt;&gt; import numpy as np
| &gt;&gt;&gt; series = pd.Series([20, 21, 12], index=[&#39;London&#39;,
| ... &#39;New York&#39;,&#39;Helsinki&#39;])
| London 20
| New York 21
| Helsinki 12
| dtype: int64
|
| Square the values by defining a function and passing it as an
| argument to ``apply()``.
|
| &gt;&gt;&gt; def square(x):
| ... return x**2
| &gt;&gt;&gt; series.apply(square)
| London 400
| New York 441
| Helsinki 144
| dtype: int64
|
| Square the values by passing an anonymous function as an
| argument to ``apply()``.
|
| &gt;&gt;&gt; series.apply(lambda x: x**2)
| London 400
| New York 441
| Helsinki 144
| dtype: int64
|
| Define a custom function that needs additional positional
| arguments and pass these additional arguments using the
| ``args`` keyword.
|
| &gt;&gt;&gt; def subtract_custom_value(x, custom_value):
| ... return x-custom_value
403
|
| &gt;&gt;&gt; series.apply(subtract_custom_value, args=(5,))
| London 15
| New York 16
| Helsinki 7
| dtype: int64
|
| Define a custom function that takes keyword arguments
| and pass these arguments to ``apply``.
|
| &gt;&gt;&gt; def add_custom_values(x, **kwargs):
| ... for month in kwargs:
| ... x+=kwargs[month]
| ... return x
|
| &gt;&gt;&gt; series.apply(add_custom_values, june=30, july=20, august=25)
| London 95
| New York 96
| Helsinki 87
| dtype: int64
|
| Use a function from the Numpy library.
|
| &gt;&gt;&gt; series.apply(np.log)
| London 2.995732
| New York 3.044522
| Helsinki 2.484907
| dtype: float64
|
| argmax = idxmax(self, axis=None, out=None, skipna=True)
|
| argmin = idxmin(self, axis=None, out=None, skipna=True)
|
| argsort(self, axis=0, kind=&#39;quicksort&#39;, order=None)
| Overrides ndarray.argsort. Argsorts the value, omitting NA/null values,
| and places the result in the same locations as the non-NA values
|
| 【参数】
| ----------| axis : int (can only be zero)
| kind : {&#39;mergesort&#39;, &#39;quicksort&#39;, &#39;heapsort&#39;}, default &#39;quicksort&#39;
| Choice of sorting algorithm. See np.sort for more
| information. &#39;mergesort&#39; is the only stable algorithm
| order : ignored
|
| 【返回值】
| -------| argsorted : Series, with -1 indicated where nan values are present
|
| 【参见】
| --------| numpy.ndarray.argsort
|
| asof(self, where)
| Return last good (non-NaN) value in Series if value is NaN for
| requested date.
|
404
| If there is no good value, NaN is returned.
|
| 【参数】
| ----------| where : date or array of dates
|
| 【注意】
| -----| Dates are assumed to be sorted
|
| 【返回值】
| -------| value or NaN
|
| autocorr(self, lag=1)
| Lag-N autocorrelation
|
| 【参数】
| ----------| lag : int, default 1
| Number of lags to apply before performing autocorrelation.
|
| 【返回值】
| -------| autocorr : float
|
| between(self, left, right, inclusive=True)
| Return boolean Series equivalent to left &lt;= series &lt;= right. NA values
| will be treated as False
|
| 【参数】
| ----------| left : scalar
| Left boundary
| right : scalar
| Right boundary
|
| 【返回值】
| -------| is_between : Series
|
| combine(self, other, func, fill_value=nan)
| Perform elementwise binary operation on two Series using given function
| with optional fill value when an index is missing from one Series or
| the other
|
| 【参数】
| ----------| other : Series or scalar value
| func : function
| fill_value : scalar value
|
| 【返回值】
| -------| result : Series
|
405
| combine_first(self, other)
| Combine Series values, choosing the calling Series&#39;s values
| first. Result index will be the union of the two indexes
|
| 【参数】
| ----------| other : Series
|
| 【返回值】
| -------| y : Series
|
| compound(self, axis=None, skipna=None, level=None)
| Return the compound percentage of the values for the requested axis
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| compounded : scalar or Series (if level specified)
|
| compress(self, condition, axis=0, out=None, **kwargs)
| Return selected slices of an array along given axis as a Series
|
| 【参见】
| --------| numpy.ndarray.compress
|
| corr(self, other, method=&#39;pearson&#39;, min_periods=None)
| Compute correlation with</code>other<code>Series, excluding missing values
|
| 【参数】
| ----------| other : Series
| method : {&#39;pearson&#39;, &#39;kendall&#39;, &#39;spearman&#39;}
| * pearson : standard correlation coefficient
| * kendall : Kendall Tau correlation coefficient
| * spearman : Spearman rank correlation
| min_periods : int, optional
| Minimum number of observations needed to have a valid result
|
|
| 【返回值】
| -------| correlation : float
|
406
| count(self, level=None)
| Return number of non-NA/null observations in the Series
|
| 【参数】
| ----------| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a smaller Series
|
| 【返回值】
| -------| nobs : int or Series (if level specified)
|
| cov(self, other, min_periods=None)
| Compute covariance with Series, excluding missing values
|
| 【参数】
| ----------| other : Series
| min_periods : int, optional
| Minimum number of observations needed to have a valid result
|
| 【返回值】
| -------| covariance : float
|
| Normalized by N-1 (unbiased estimator).
|
| cummax = max(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative max over requested axis.
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| max : scalar
|
| cummin = min(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative min over requested axis.
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| min : scalar
|
407
| cumprod = prod(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative prod over requested axis.
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| prod : scalar
|
| cumsum = sum(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative sum over requested axis.
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| sum : scalar
|
| diff(self, periods=1)
| 1st discrete difference of object
|
| 【参数】
| ----------| periods : int, default 1
| Periods to shift for forming difference
|
| 【返回值】
| -------| diffed : Series
|
| div = truediv(self, other, level=None, fill_value=None, axis=0)
|
| divide = truediv(self, other, level=None, fill_value=None, axis=0)
|
| dot(self, other)
| Matrix multiplication with DataFrame or inner-product with Series
| objects
|
| 【参数】
| ----------| other : Series or DataFrame
|
| 【返回值】
| -------| dot_product : scalar or Series
|
408
| drop_duplicates(self, keep=&#39;first&#39;, inplace=False)
| Return Series with duplicate values removed
|
| 【参数】
| ----------|
| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| - ``first`` : Drop duplicates except for the first occurrence.
| - ``last`` : Drop duplicates except for the last occurrence.
| - False : Drop all duplicates.
| take_last : deprecated
| inplace : boolean, default False
| If True, performs operation inplace and returns None.
|
| 【返回值】
| -------| deduplicated : Series
|
| dropna(self, axis=0, inplace=False, **kwargs)
| Return Series without null values
|
| 【返回值】
| -------| valid : Series
| inplace : boolean, default False
| Do operation in place.
|
| duplicated(self, keep=&#39;first&#39;)
| Return boolean Series denoting duplicate values
|
| 【参数】
| ----------| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| - ``first`` : Mark duplicates as ``True`` except for the first occurrence.
| - ``last`` : Mark duplicates as ``True`` except for the last occurrence.
| - False : Mark all duplicates as ``True``.
| take_last : deprecated
|
| 【返回值】
| -------| duplicated : Series
|
| eq = wrapper(self, other, axis=None)
|
| fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)
| Fill NA/NaN values using the specified method
|
| 【参数】
| ----------| value : scalar, dict, Series, or DataFrame
| Value to use to fill holes (e.g. 0), alternately a dict/Series/DataFrame of
| values specifying which value to use for each index (for a Series) or
| column (for a DataFrame). (values not in the dict/Series/DataFrame will not be
| filled). This value cannot be a list.
| method : {&#39;backfill&#39;, &#39;bfill&#39;, &#39;pad&#39;, &#39;ffill&#39;, None}, default None
| Method to use for filling holes in reindexed Series
| pad / ffill: propagate last valid observation forward to next valid
409
| backfill / bfill: use NEXT valid observation to fill gap
| axis : {0, &#39;index&#39;}
| inplace : boolean, default False
| If True, fill in place. Note: this will modify any
| other views on this object, (e.g. a no-copy slice for a column in a
| DataFrame).
| limit : int, default None
| If method is specified, this is the maximum number of consecutive
| NaN values to forward/backward fill. In other words, if there is
| a gap with more than this number of consecutive NaNs, it will only
| be partially filled. If method is not specified, this is the
| maximum number of entries along the entire axis where NaNs will be
| filled.
| downcast : dict, default is None
| a dict of item-&gt;dtype of what to downcast if possible,
| or the string &#39;infer&#39; which will try to downcast to an appropriate
| equal type (e.g. float64 to int64 if possible)
|
| 【参见】
| --------| reindex, asfreq
|
| 【返回值】
| -------| filled : Series
|
| first_valid_index(self)
| Return label for first non-NA/null value
|
| floordiv(self, other, level=None, fill_value=None, axis=0)
| Integer division of series and other, element-wise (binary operator</code>floordiv<code>).
|
| Equivalent to ``series // other``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rfloordiv
|
| ge = wrapper(self, other, axis=None)
|
| get_value(self, label, takeable=False)
| Quickly retrieve single value at passed index label
410
|
| 【参数】
| ----------| index : label
| takeable : interpret the index as indexers, default False
|
| 【返回值】
| -------| value : scalar value
|
| get_values(self)
| same as values (but handles sparseness conversions); is a view
|
| gt = wrapper(self, other, axis=None)
|
| hist = hist_series(self, by=None, ax=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None,
figsize=None, bins=10, **kwds)
| Draw histogram of the input series using matplotlib
|
| 【参数】
| ----------| by : object, optional
| If passed, then used to form histograms for separate groups
| ax : matplotlib axis object
| If not passed, uses gca()
| grid : boolean, default True
| Whether to show axis grid lines
| xlabelsize : int, default None
| If specified changes the x-axis label size
| xrot : float, default None
| rotation of x axis labels
| ylabelsize : int, default None
| If specified changes the y-axis label size
| yrot : float, default None
| rotation of y axis labels
| figsize : tuple, default None
| figure size in inches by default
| bins: integer, default 10
| Number of histogram bins to be used
| kwds : keywords
| To be passed to the actual plotting function
|
| 【注意】
| -----| See matplotlib documentation online for more on this
|
| idxmax(self, axis=None, out=None, skipna=True)
| Index of first occurrence of maximum of values.
|
| 【参数】
| ----------| skipna : boolean, default True
| Exclude NA/null values
|
| 【返回值】
| -------| idxmax : Index of maximum of values
411
|
| 【注意】
| -----| This method is the Series version of ``ndarray.argmax``.
|
| 【参见】
| --------| DataFrame.idxmax
| numpy.ndarray.argmax
|
| idxmin(self, axis=None, out=None, skipna=True)
| Index of first occurrence of minimum of values.
|
| 【参数】
| ----------| skipna : boolean, default True
| Exclude NA/null values
|
| 【返回值】
| -------| idxmin : Index of minimum of values
|
| 【注意】
| -----| This method is the Series version of ``ndarray.argmin``.
|
| 【参见】
| --------| DataFrame.idxmin
| numpy.ndarray.argmin
|
| iget(self, i, axis=0)
| DEPRECATED. Use ``.iloc[i]`` or ``.iat[i]`` instead
|
| iget_value(self, i, axis=0)
| DEPRECATED. Use ``.iloc[i]`` or ``.iat[i]`` instead
|
| irow(self, i, axis=0)
| DEPRECATED. Use ``.iloc[i]`` or ``.iat[i]`` instead
|
| isin(self, values)
| Return a boolean :class:</code>~pandas.Series<code>showing whether each element
| in the :class:</code>~pandas.Series<code>is exactly contained in the passed
| sequence of ``values``.
|
| 【参数】
| ----------| values : list-like
| The sequence of values to test. Passing in a single string will
| raise a ``TypeError``. Instead, turn a single string into a
| ``list`` of one element.
|
| 【返回值】
| -------| isin : Series (bool dtype)
|
412
| 【Raises 引发错误】
| ------| TypeError
| * If ``values`` is a string
|
| 【参见】
| --------| pandas.DataFrame.isin
|
| 【示例】
| --------|
| &gt;&gt;&gt; s = pd.Series(list(&#39;abc&#39;))
| &gt;&gt;&gt; s.isin([&#39;a&#39;, &#39;c&#39;, &#39;e&#39;])
| 0 True
| 1 False
| 2 True
| dtype: bool
|
| Passing a single string as ``s.isin(&#39;a&#39;)`` will raise an error. Use
| a list of one element instead:
|
| &gt;&gt;&gt; s.isin([&#39;a&#39;])
| 0 True
| 1 False
| 2 False
| dtype: bool
|
| items = iteritems(self)
|
| iteritems(self)
| Lazily iterate over (index, value) tuples
|
| keys(self)
| Alias for index
|
| kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return unbiased kurtosis over requested axis using Fishers definition of
| kurtosis (kurtosis of normal == 0.0). Normalized by N-1
|
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| kurt : scalar or Series (if level specified)
413
|
| kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
|
| last_valid_index(self)
| Return label for last non-NA/null value
|
| le = wrapper(self, other, axis=None)
|
| lt = wrapper(self, other, axis=None)
|
| mad(self, axis=None, skipna=None, level=None)
| Return the mean absolute deviation of the values for the requested axis
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| mad : scalar or Series (if level specified)
|
| map(self, arg, na_action=None)
| Map values of Series using input correspondence (which can be
| a dict, Series, or function)
|
| 【参数】
| ----------| arg : function, dict, or Series
| na_action : {None, &#39;ignore&#39;}
| If &#39;ignore&#39;, propagate NA values
|
| 【示例】
| --------| &gt;&gt;&gt; x
| one 1
| two 2
| three 3
|
| &gt;&gt;&gt; y
| 1 foo
| 2 bar
| 3 baz
|
| &gt;&gt;&gt; x.map(y)
| one foo
| two bar
| three baz
|
414
| 【返回值】
| -------| y : Series
| same index as caller
|
| max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| This method returns the maximum of the values in the object. If you
| want the *index* of the maximum, use ``idxmax``. This is the
| equivalent of the ``numpy.ndarray`` method ``argmax``.
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| max : scalar or Series (if level specified)
|
| mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the mean of the values for the requested axis
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| mean : scalar or Series (if level specified)
|
| median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the median of the values for the requested axis
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
415
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| median : scalar or Series (if level specified)
|
| memory_usage(self, index=False, deep=False)
| Memory usage of the Series
|
| 【参数】
| ----------| index : bool
| Specifies whether to include memory usage of Series index
| deep : bool
| Introspect the data deeply, interrogate
|</code>object<code>dtypes for system-level memory consumption
|
| 【返回值】
| -------| scalar bytes of memory consumed
|
| 【注意】
| -----| Memory usage does not include memory consumed by elements that
| are not components of the array if deep=False
|
| 【参见】
| --------| numpy.ndarray.nbytes
|
| min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| This method returns the minimum of the values in the object. If you
| want the *index* of the minimum, use ``idxmin``. This is the
| equivalent of the ``numpy.ndarray`` method ``argmin``.
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| min : scalar or Series (if level specified)
|
| mod(self, other, level=None, fill_value=None, axis=0)
416
| Modulo of series and other, element-wise (binary operator</code>mod<code>).
|
| Equivalent to ``series % other``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rmod
|
| mode(self)
| Returns the mode(s) of the dataset.
|
| Empty if nothing occurs at least 2 times. Always returns Series even
| if only one value.
|
| 【参数】
| ----------| sort : bool, default True
| If True, will lexicographically sort values, if False skips
| sorting. Result ordering when ``sort=False`` is not defined.
|
| 【返回值】
| -------| modes : Series (sorted)
|
| mul(self, other, level=None, fill_value=None, axis=0)
| Multiplication of series and other, element-wise (binary operator</code>mul<code>).
|
| Equivalent to ``series * other``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------
417
| result : Series
|
| 【参见】
| --------| Series.rmul
|
| multiply = mul(self, other, level=None, fill_value=None, axis=0)
|
| ne = wrapper(self, other, axis=None)
|
| nlargest(self, n=5, keep=&#39;first&#39;)
| Return the largest</code>n<code>elements.
|
| 【参数】
| ----------| n : int
| Return this many descending sorted values
| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| Where there are duplicate values:
| - ``first`` : take the first occurrence.
| - ``last`` : take the last occurrence.
| take_last : deprecated
|
| 【返回值】
| -------| top_n : Series
| The n largest values in the Series, in sorted order
|
| 【注意】
| -----| Faster than ``.sort_values(ascending=False).head(n)`` for small</code>n<code>relative
| to the size of the ``Series`` object.
|
| 【参见】
| --------| Series.nsmallest
|
| 【示例】
| --------| &gt;&gt;&gt; import pandas as pd
| &gt;&gt;&gt; import numpy as np
| &gt;&gt;&gt; s = pd.Series(np.random.randn(1e6))
| &gt;&gt;&gt; s.nlargest(10) # only sorts up to the N requested
|
| nonzero(self)
| Return the indices of the elements that are non-zero
|
| This method is equivalent to calling</code>numpy.nonzero<code>on the
| series data. For compatability with NumPy, the return value is
| the same (a tuple with an array of indices for each dimension),
| but it will always be a one-item tuple because series only have
| one dimension.
|
| 【示例】
| --------| &gt;&gt;&gt; s = pd.Series([0, 3, 0, 4])
| &gt;&gt;&gt; s.nonzero()
418
| (array([1, 3]),)
| &gt;&gt;&gt; s.iloc[s.nonzero()[0]]
| 1 3
| 3 4
| dtype: int64
|
| 【参见】
| --------| numpy.nonzero
|
| nsmallest(self, n=5, keep=&#39;first&#39;)
| Return the smallest</code>n<code>elements.
|
| 【参数】
| ----------| n : int
| Return this many ascending sorted values
| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| Where there are duplicate values:
| - ``first`` : take the first occurrence.
| - ``last`` : take the last occurrence.
| take_last : deprecated
|
| 【返回值】
| -------| bottom_n : Series
| The n smallest values in the Series, in sorted order
|
| 【注意】
| -----| Faster than ``.sort_values().head(n)`` for small</code>n<code>relative to
| the size of the ``Series`` object.
|
| 【参见】
| --------| Series.nlargest
|
| 【示例】
| --------| &gt;&gt;&gt; import pandas as pd
| &gt;&gt;&gt; import numpy as np
| &gt;&gt;&gt; s = pd.Series(np.random.randn(1e6))
| &gt;&gt;&gt; s.nsmallest(10) # only sorts up to the N requested
|
| order(self, na_last=None, ascending=True, kind=&#39;quicksort&#39;, na_position=&#39;last&#39;, inplace=False)
| DEPRECATED: use :meth:</code>Series.sort_values<code>|
| Sorts Series object, by value, maintaining index-value link.
| This will return a new Series by default. Series.sort is the equivalent but as an inplace method.
|
| 【参数】
| ----------| na_last : boolean (optional, default=True) (DEPRECATED; use na_position)
| Put NaN&#39;s at beginning or end
| ascending : boolean, default True
| Sort ascending. Passing False sorts descending
| kind : {&#39;mergesort&#39;, &#39;quicksort&#39;, &#39;heapsort&#39;}, default &#39;quicksort&#39;
419
| Choice of sorting algorithm. See np.sort for more
| information. &#39;mergesort&#39; is the only stable algorithm
| na_position : {&#39;first&#39;, &#39;last&#39;} (optional, default=&#39;last&#39;)
| &#39;first&#39; puts NaNs at the beginning
| &#39;last&#39; puts NaNs at the end
| inplace : boolean, default False
| Do operation in place.
|
| 【返回值】
| -------| y : Series
|
| 【参见】
| --------| Series.sort_values
|
| pow(self, other, level=None, fill_value=None, axis=0)
| Exponential power of series and other, element-wise (binary operator</code>pow<code>).
|
| Equivalent to ``series ** other``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rpow
|
| prod(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the product of the values for the requested axis
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
420
| -------| prod : scalar or Series (if level specified)
|
| product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
|
| ptp(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Returns the difference between the maximum value and the minimum
| value in the object. This is the equivalent of the ``numpy.ndarray``
| method ``ptp``.
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| ptp : scalar or Series (if level specified)
|
| put(self, *args, **kwargs)
| return a ndarray with the values put
|
| 【参见】
| --------| numpy.ndarray.put
|
| quantile(self, q=0.5)
| Return value at the given quantile, a la numpy.percentile.
|
| 【参数】
| ----------| q : float or array-like, default 0.5 (50% quantile)
| 0 &lt;= q &lt;= 1, the quantile(s) to compute
|
| 【返回值】
| -------| quantile : float or Series
| if ``q`` is an array, a Series will be returned where the
| index is ``q`` and the values are the quantiles.
|
| 【示例】
| --------|
| &gt;&gt;&gt; s = Series([1, 2, 3, 4])
| &gt;&gt;&gt; s.quantile(.5)
| 2.5
| &gt;&gt;&gt; s.quantile([.25, .5, .75])
| 0.25 1.75
| 0.50 2.50
421
| 0.75 3.25
| dtype: float64
|
| radd(self, other, level=None, fill_value=None, axis=0)
| Addition of series and other, element-wise (binary operator</code>radd<code>).
|
| Equivalent to ``other + series``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.add
|
| rank(self, method=&#39;average&#39;, na_option=&#39;keep&#39;, ascending=True, pct=False)
| Compute data ranks (1 through n). Equal values are assigned a rank that
| is the average of the ranks of those values
|
| 【参数】
| ----------| method : {&#39;average&#39;, &#39;min&#39;, &#39;max&#39;, &#39;first&#39;, &#39;dense&#39;}
| * average: average rank of group
| * min: lowest rank in group
| * max: highest rank in group
| * first: ranks assigned in order they appear in the array
| * dense: like &#39;min&#39;, but rank always increases by 1 between groups
| na_option : {&#39;keep&#39;}
| keep: leave NA values where they are
| ascending : boolean, default True
| False for ranks by high (1) to low (N)
| pct : boolean, default False
| Computes percentage rank of data
|
| 【返回值】
| -------| ranks : Series
|
| ravel(self, order=&#39;C&#39;)
| Return the flattened underlying data as an ndarray
|
| 【参见】
| --------| numpy.ndarray.ravel
|
422
| rdiv = rtruediv(self, other, level=None, fill_value=None, axis=0)
|
| reindex(self, index=None, **kwargs)
| Conform Series to new index with optional filling logic, placing
| NA/NaN in locations having no value in the previous index. A new object
| is produced unless the new index is equivalent to the current one and
| copy=False
|
| 【参数】
| ----------| index : array-like, optional (can be specified in order, or as
| keywords)
| New labels / index to conform to. Preferably an Index object to
| avoid duplicating data
| method : {None, &#39;backfill&#39;/&#39;bfill&#39;, &#39;pad&#39;/&#39;ffill&#39;, &#39;nearest&#39;}, optional
| method to use for filling holes in reindexed DataFrame.
| Please note: this is only applicable to DataFrames/Series with a
| monotonically increasing/decreasing index.
| * default: don&#39;t fill gaps
| * pad / ffill: propagate last valid observation forward to next valid
| * backfill / bfill: use next valid observation to fill gap
| * nearest: use nearest valid observations to fill gap
| copy : boolean, default True
| Return a new object, even if the passed indexes are the same
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
| fill_value : scalar, default np.NaN
| Value to use for missing values. Defaults to NaN, but can be any
| &quot;compatible&quot; value
| limit : int, default None
| Maximum number of consecutive elements to forward or backward fill
| tolerance : optional
| Maximum distance between original and new labels for inexact
| matches. The values of the index at the matching locations most
| satisfy the equation ``abs(index[indexer] - target) &lt;= tolerance``.
|
| .. versionadded:: 0.17.0
|
| 【示例】
| --------|
| Create a dataframe with some fictional data.
|
| &gt;&gt;&gt; index = [&#39;Firefox&#39;, &#39;Chrome&#39;, &#39;Safari&#39;, &#39;IE10&#39;, &#39;Konqueror&#39;]
| &gt;&gt;&gt; df = pd.DataFrame({
| ... &#39;http_status&#39;: [200,200,404,404,301],
| ... &#39;response_time&#39;: [0.04, 0.02, 0.07, 0.08, 1.0]},
| ... index=index)
| &gt;&gt;&gt; df
| http_status response_time
| Firefox 200 0.04
| Chrome 200 0.02
| Safari 404 0.07
| IE10 404 0.08
| Konqueror 301 1.00
|
423
| Create a new index and reindex the dataframe. By default
| values in the new index that do not have corresponding
| records in the dataframe are assigned ``NaN``.
|
| &gt;&gt;&gt; new_index= [&#39;Safari&#39;, &#39;Iceweasel&#39;, &#39;Comodo Dragon&#39;, &#39;IE10&#39;,
| ... &#39;Chrome&#39;]
| &gt;&gt;&gt; df.reindex(new_index)
| http_status response_time
| Safari 404 0.07
| Iceweasel NaN NaN
| Comodo Dragon NaN NaN
| IE10 404 0.08
| Chrome 200 0.02
|
| We can fill in the missing values by passing a value to
| the keyword ``fill_value``. Because the index is not monotonically
| increasing or decreasing, we cannot use arguments to the keyword
| ``method`` to fill the ``NaN`` values.
|
| &gt;&gt;&gt; df.reindex(new_index, fill_value=0)
| http_status response_time
| Safari 404 0.07
| Iceweasel 0 0.00
| Comodo Dragon 0 0.00
| IE10 404 0.08
| Chrome 200 0.02
|
| &gt;&gt;&gt; df.reindex(new_index, fill_value=&#39;missing&#39;)
| http_status response_time
| Safari 404 0.07
| Iceweasel missing missing
| Comodo Dragon missing missing
| IE10 404 0.08
| Chrome 200 0.02
|
| To further illustrate the filling functionality in
| ``reindex``, we will create a dataframe with a
| monotonically increasing index (for example, a sequence
| of dates).
|
| &gt;&gt;&gt; date_index = pd.date_range(&#39;1/1/2010&#39;, periods=6, freq=&#39;D&#39;)
| &gt;&gt;&gt; df2 = pd.DataFrame({&quot;prices&quot;: [100, 101, np.nan, 100, 89, 88]},
| index=date_index)
| &gt;&gt;&gt; df2
| prices
| 2010-01-01 100
| 2010-01-02 101
| 2010-01-03 NaN
| 2010-01-04 100
| 2010-01-05 89
| 2010-01-06 88
|
| Suppose we decide to expand the dataframe to cover a wider
| date range.
|
| &gt;&gt;&gt; date_index2 = pd.date_range(&#39;12/29/2009&#39;, periods=10, freq=&#39;D&#39;)
| &gt;&gt;&gt; df2.reindex(date_index2)
424
| prices
| 2009-12-29 NaN
| 2009-12-30 NaN
| 2009-12-31 NaN
| 2010-01-01 100
| 2010-01-02 101
| 2010-01-03 NaN
| 2010-01-04 100
| 2010-01-05 89
| 2010-01-06 88
| 2010-01-07 NaN
|
| The index entries that did not have a value in the original data frame
| (for example, &#39;2009-12-29&#39;) are by default filled with ``NaN``.
| If desired, we can fill in the missing values using one of several
| options.
|
| For example, to backpropagate the last valid value to fill the ``NaN``
| values, pass ``bfill`` as an argument to the ``method`` keyword.
|
| &gt;&gt;&gt; df2.reindex(date_index2, method=&#39;bfill&#39;)
| prices
| 2009-12-29 100
| 2009-12-30 100
| 2009-12-31 100
| 2010-01-01 100
| 2010-01-02 101
| 2010-01-03 NaN
| 2010-01-04 100
| 2010-01-05 89
| 2010-01-06 88
| 2010-01-07 NaN
|
| Please note that the ``NaN`` value present in the original dataframe
| (at index value 2010-01-03) will not be filled by any of the
| value propagation schemes. This is because filling while reindexing
| does not look at dataframe values, but only compares the original and
| desired indexes. If you do want to fill in the ``NaN`` values present
| in the original dataframe, use the ``fillna()`` method.
|
| 【返回值】
| -------| reindexed : Series
|
| reindex_axis(self, labels, axis=0, **kwargs)
| for compatibility with higher dims
|
| rename(self, index=None, **kwargs)
| Alter axes input function or functions. Function / dict values must be
| unique (1-to-1). Labels not contained in a dict / Series will be left
| as-is.
|
| 【参数】
| ----------| index : dict-like or function, optional
| Transformation to apply to that axis values
|
425
| copy : boolean, default True
| Also copy underlying data
| inplace : boolean, default False
| Whether to return a new Series. If True then value of copy is
| ignored.
|
| 【返回值】
| -------| renamed : Series (new object)
|
| reorder_levels(self, order)
| Rearrange index levels using input order. May not drop or duplicate
| levels
|
| 【参数】
| ----------| order: list of int representing new level order.
| (reference level by number or key)
| axis: where to reorder levels
|
| 【返回值】
| -------| type of caller (new object)
|
| repeat(self, reps)
| return a new Series with the values repeated reps times
|
| 【参见】
| --------| numpy.ndarray.repeat
|
| reset_index(self, level=None, drop=False, name=None, inplace=False)
| Analogous to the :meth:</code>pandas.DataFrame.reset_index<code>function, see
| docstring there.
|
| 【参数】
| ----------| level : int, str, tuple, or list, default None
| Only remove the given levels from the index. Removes all levels by
| default
| drop : boolean, default False
| Do not try to insert index into dataframe columns
| name : object, default None
| The name of the column corresponding to the Series values
| inplace : boolean, default False
| Modify the Series in place (do not create a new object)
|
| 【返回值】
| ----------| resetted : DataFrame, or Series if drop == True
|
| reshape(self, *args, **kwargs)
| return an ndarray with the values shape
| if the specified shape matches exactly the current shape, then
| return self (for compat)
|
| 【参见】
426
| --------| numpy.ndarray.take
|
| rfloordiv(self, other, level=None, fill_value=None, axis=0)
| Integer division of series and other, element-wise (binary operator</code>rfloordiv<code>).
|
| Equivalent to ``other // series``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.floordiv
|
| rmod(self, other, level=None, fill_value=None, axis=0)
| Modulo of series and other, element-wise (binary operator</code>rmod<code>).
|
| Equivalent to ``other % series``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.mod
|
| rmul(self, other, level=None, fill_value=None, axis=0)
| Multiplication of series and other, element-wise (binary operator</code>rmul<code>).
|
| Equivalent to ``other * series``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
427
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.mul
|
| round(self, decimals=0, out=None)
| a.round(decimals=0, out=None)
|
| Return</code>a<code>with each element rounded to the given number of decimals.
|
| Refer to</code>numpy.around<code>for full documentation.
|
| 【参见】
| --------| numpy.around : equivalent function
|
| rpow(self, other, level=None, fill_value=None, axis=0)
| Exponential power of series and other, element-wise (binary operator</code>rpow<code>).
|
| Equivalent to ``other ** series``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.pow
|
| rsub(self, other, level=None, fill_value=None, axis=0)
| Subtraction of series and other, element-wise (binary operator</code>rsub<code>).
|
| Equivalent to ``other - series``, but with support to substitute a fill_value for
428
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.sub
|
| rtruediv(self, other, level=None, fill_value=None, axis=0)
| Floating division of series and other, element-wise (binary operator</code>rtruediv<code>).
|
| Equivalent to ``other / series``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.truediv
|
| searchsorted(self, v, side=&#39;left&#39;, sorter=None)
| Find indices where elements should be inserted to maintain order.
|
| Find the indices into a sorted Series</code>self<code>such that, if the
| corresponding elements in</code>v<code>were inserted before the indices, the
| order of</code>self<code>would be preserved.
|
| 【参数】
| ----------| v : array_like
| Values to insert into</code>a<code>.
| side : {&#39;left&#39;, &#39;right&#39;}, optional
| If &#39;left&#39;, the index of the first suitable location found is given.
429
| If &#39;right&#39;, return the last such index. If there is no suitable
| index, return either 0 or N (where N is the length of</code>a<code>).
| sorter : 1-D array_like, optional
| Optional array of integer indices that sort</code>self<code>into ascending
| order. They are typically the result of ``np.argsort``.
|
| 【返回值】
| -------| indices : array of ints
| Array of insertion points with the same shape as</code>v<code>.
|
| 【参见】
| --------| Series.sort_values
| numpy.searchsorted
|
| 【注意】
| -----| Binary search is used to find the required insertion points.
|
| 【示例】
| --------| &gt;&gt;&gt; x = pd.Series([1, 2, 3])
| &gt;&gt;&gt; x
| 0 1
| 1 2
| 2 3
| dtype: int64
| &gt;&gt;&gt; x.searchsorted(4)
| array([3])
| &gt;&gt;&gt; x.searchsorted([0, 4])
| array([0, 3])
| &gt;&gt;&gt; x.searchsorted([1, 3], side=&#39;left&#39;)
| array([0, 2])
| &gt;&gt;&gt; x.searchsorted([1, 3], side=&#39;right&#39;)
| array([1, 3])
| &gt;&gt;&gt; x.searchsorted([1, 2], side=&#39;right&#39;, sorter=[0, 2, 1])
| array([1, 3])
|
| sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)
| Return unbiased standard error of the mean over requested axis.
|
| Normalized by N-1 by default. This can be changed using the ddof argument
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| ddof : int, default 1
| degrees of freedom
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
430
| everything, then use only numeric data
|
| 【返回值】
| -------| sem : scalar or Series (if level specified)
|
| set_value(self, label, value, takeable=False)
| Quickly set single value at passed label. If label is not contained, a
| new object is created with the label placed at the end of the result
| index
|
| 【参数】
| ----------| label : object
| Partial indexing with MultiIndex not allowed
| value : object
| Scalar value
| takeable : interpret the index as indexers, default False
|
| 【返回值】
| -------| series : Series
| If label is contained, will be reference to calling Series,
| otherwise a new object
|
| shift(self, periods=1, freq=None, axis=0)
| Shift index by desired number of periods with an optional time freq
|
| 【参数】
| ----------| periods : int
| Number of periods to move, can be positive or negative
| freq : DateOffset, timedelta, or time rule string, optional
| Increment to use from datetools module or time rule (e.g. &#39;EOM&#39;).
| See Notes.
| axis : {0, &#39;index&#39;}
|
| 【注意】
| -----| If freq is specified then the index values are shifted but the data
| is not realigned. That is, use freq if you would like to extend the
| index when shifting and preserve the original data.
|
| 【返回值】
| -------| shifted : Series
|
| skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return unbiased skew over requested axis
| Normalized by N-1
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
431
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| skew : scalar or Series (if level specified)
|
| sort(self, axis=0, ascending=True, kind=&#39;quicksort&#39;, na_position=&#39;last&#39;, inplace=True)
| DEPRECATED: use :meth:</code>Series.sort_values(inplace=True)<code>for INPLACE sorting
|
| Sort values and index labels by value. This is an inplace sort by default.
| Series.order is the equivalent but returns a new Series.
|
| 【参数】
| ----------| axis : int (can only be zero)
| ascending : boolean, default True
| Sort ascending. Passing False sorts descending
| kind : {&#39;mergesort&#39;, &#39;quicksort&#39;, &#39;heapsort&#39;}, default &#39;quicksort&#39;
| Choice of sorting algorithm. See np.sort for more
| information. &#39;mergesort&#39; is the only stable algorithm
| na_position : {&#39;first&#39;, &#39;last&#39;} (optional, default=&#39;last&#39;)
| &#39;first&#39; puts NaNs at the beginning
| &#39;last&#39; puts NaNs at the end
| inplace : boolean, default True
| Do operation in place.
|
| 【参见】
| --------| Series.sort_values
|
| sort_index(self, axis=0, level=None, ascending=True, inplace=False, sort_remaining=True)
| Sort object by labels (along an axis)
|
| 【参数】
| ----------| axis : index to direct sorting
| level : int or level name or list of ints or list of level names
| if not None, sort on values in specified index level(s)
| ascending : boolean, default True
| Sort ascending vs. descending
| inplace : bool
| if True, perform operation in-place
| kind : {</code>quicksort<code>,</code>mergesort<code>,</code>heapsort<code>}
| Choice of sorting algorithm. 参见：ndarray.np.sort for more information.
|</code>mergesort<code>is the only stable algorithm. For DataFrames, this option is
| only applied when sorting on a single column or label.
| na_position : {&#39;first&#39;, &#39;last&#39;}
|</code>first<code>puts NaNs at the beginning,</code>last<code>puts NaNs at the end
| sort_remaining : bool
| if true and sorting by level and index is multilevel, sort by other levels
| too (in order) after sorting by specified level
|
432
| 【返回值】
| -------| sorted_obj : Series
|
| sort_values(self, axis=0, ascending=True, inplace=False, kind=&#39;quicksort&#39;, na_position=&#39;last&#39;)
| Sort by the values along either axis
|
| .. versionadded:: 0.17.0
|
| 【参数】
| ----------| by : string name or list of names which refer to the axis items
| axis : index to direct sorting
| ascending : bool or list of bool
| Sort ascending vs. descending. Specify list for multiple sort orders.
| If this is a list of bools, must match the length of the by
| inplace : bool
| if True, perform operation in-place
| kind : {</code>quicksort<code>,</code>mergesort<code>,</code>heapsort<code>}
| Choice of sorting algorithm. 参见：ndarray.np.sort for more information.
|</code>mergesort<code>is the only stable algorithm. For DataFrames, this option is
| only applied when sorting on a single column or label.
| na_position : {&#39;first&#39;, &#39;last&#39;}
|</code>first<code>puts NaNs at the beginning,</code>last<code>puts NaNs at the end
|
| 【返回值】
| -------| sorted_obj : Series
|
| sortlevel(self, level=0, ascending=True, sort_remaining=True)
| Sort Series with MultiIndex by chosen level. Data will be
| lexicographically sorted by the chosen level followed by the other
| levels (in order)
|
| 【参数】
| ----------| level : int or level name, default None
| ascending : bool, default True
|
| 【返回值】
| -------| sorted : Series
|
| 【参见】
| --------| Series.sort_index(level=...)
|
| std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)
| Return unbiased standard deviation over requested axis.
|
| Normalized by N-1 by default. This can be changed using the ddof argument
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
433
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| ddof : int, default 1
| degrees of freedom
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| std : scalar or Series (if level specified)
|
| sub(self, other, level=None, fill_value=None, axis=0)
| Subtraction of series and other, element-wise (binary operator</code>sub<code>).
|
| Equivalent to ``series - other``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rsub
|
| subtract = sub(self, other, level=None, fill_value=None, axis=0)
|
| sum(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the sum of the values for the requested axis
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
434
| 【返回值】
| -------| sum : scalar or Series (if level specified)
|
| swaplevel(self, i, j, copy=True)
| Swap levels i and j in a MultiIndex
|
| 【参数】
| ----------| i, j : int, string (can be mixed)
| Level of index to be swapped. Can pass level name as string.
|
| 【返回值】
| -------| swapped : Series
|
| take(self, indices, axis=0, convert=True, is_copy=False)
| return Series corresponding to requested indices
|
| 【参数】
| ----------| indices : list / array of ints
| convert : translate negative to positive indices (default)
|
| 【返回值】
| -------| taken : Series
|
| 【参见】
| --------| numpy.ndarray.take
|
| to_csv(self, path, index=True, sep=&#39;,&#39;, na_rep=&#39;&#39;, float_format=None, header=False, index_label=None, mode=&#39;w&#39;,
nanRep=None, encoding=None, date_format=None, decimal=&#39;.&#39;)
| Write Series to a comma-separated values (csv) file
|
| 【参数】
| ----------| path : string file path or file handle / StringIO. If None is provided
| the result is returned as a string.
| na_rep : string, default &#39;&#39;
| Missing data representation
| float_format : string, default None
| Format string for floating point numbers
| header : boolean, default False
| Write out series name
| index : boolean, default True
| Write row names (index)
| index_label : string or sequence, default None
| Column label for index column(s) if desired. If None is given, and
|</code>header<code>and</code>index<code>are True, then the index names are used. A
| sequence should be given if the DataFrame uses MultiIndex.
| mode : Python write mode, default &#39;w&#39;
| sep : character, default &quot;,&quot;
| Field delimiter for the output file.
| encoding : string, optional
| a string representing the encoding to use if the contents are
435
| non-ascii, for python versions prior to 3
| date_format: string, default None
| Format string for datetime objects.
| decimal: string, default &#39;.&#39;
| Character recognized as decimal separator. E.g. use &#39;,&#39; for European data
|
| to_dict(self)
| Convert Series to {label -&gt; value} dict
|
| 【返回值】
| -------| value_dict : dict
|
| to_frame(self, name=None)
| Convert Series to DataFrame
|
| 【参数】
| ----------| name : object, default None
| The passed name should substitute for the series name (if it has
| one).
|
| 【返回值】
| -------| data_frame : DataFrame
|
| to_period(self, freq=None, copy=True)
| Convert Series from DatetimeIndex to PeriodIndex with desired
| frequency (inferred from index if not passed)
|
| 【参数】
| ----------| freq : string, default
|
| 【返回值】
| -------| ts : Series with PeriodIndex
|
| to_sparse(self, kind=&#39;block&#39;, fill_value=None)
| Convert Series to SparseSeries
|
| 【参数】
| ----------| kind : {&#39;block&#39;, &#39;integer&#39;}
| fill_value : float, defaults to NaN (missing)
|
| 【返回值】
| -------| sp : SparseSeries
|
| to_string(self, buf=None, na_rep=&#39;NaN&#39;, float_format=None, header=True, length=False, dtype=False, name=False,
max_rows=None)
| Render a string representation of the Series
|
| 【参数】
| ----------
436
| buf : StringIO-like, optional
| buffer to write to
| na_rep : string, optional
| string representation of NAN to use, default &#39;NaN&#39;
| float_format : one-parameter function, optional
| formatter function to apply to columns&#39; elements if they are floats
| default None
| header: boolean, default True
| Add the Series header (index name)
| length : boolean, default False
| Add the Series length
| dtype : boolean, default False
| Add the Series dtype
| name : boolean, default False
| Add the Series name if not None
| max_rows : int, optional
| Maximum number of rows to show before truncating. If None, show
| all.
|
| 【返回值】
| -------| formatted : string (if not buffer passed)
|
| to_timestamp(self, freq=None, how=&#39;start&#39;, copy=True)
| Cast to datetimeindex of timestamps, at *beginning* of period
|
| 【参数】
| ----------| freq : string, default frequency of PeriodIndex
| Desired frequency
| how : {&#39;s&#39;, &#39;e&#39;, &#39;start&#39;, &#39;end&#39;}
| Convention for converting period to timestamp; start of period
| vs. end
|
| 【返回值】
| -------| ts : Series with DatetimeIndex
|
| tolist(self)
| Convert Series to a nested list
|
| truediv(self, other, level=None, fill_value=None, axis=0)
| Floating division of series and other, element-wise (binary operator</code>truediv<code>).
|
| Equivalent to ``series / other``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
437
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rtruediv
|
| unstack(self, level=-1)
| Unstack, a.k.a. pivot, Series with MultiIndex to produce DataFrame.
| The level involved will automatically get sorted.
|
| 【参数】
| ----------| level : int, string, or list of these, default last level
| Level(s) to unstack, can pass level name
|
| 【示例】
| --------| &gt;&gt;&gt; s
| one a 1.
| one b 2.
| two a 3.
| two b 4.
|
| &gt;&gt;&gt; s.unstack(level=-1)
| a b
| one 1. 2.
| two 3. 4.
|
| &gt;&gt;&gt; s.unstack(level=0)
| one two
| a 1. 2.
| b 3. 4.
|
| 【返回值】
| -------| unstacked : DataFrame
|
| update(self, other)
| Modify Series in place using non-NA values from passed
| Series. Aligns on index
|
| 【参数】
| ----------| other : Series
|
| valid lambda self, inplace=False, **kwargs
|
| var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)
| Return unbiased variance over requested axis.
|
| Normalized by N-1 by default. This can be changed using the ddof argument
|
| 【参数】
| ----------| axis : {index (0)}
438
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| ddof : int, default 1
| degrees of freedom
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| var : scalar or Series (if level specified)
|
| view(self, dtype=None)
|
| ----------------------------------------------------------------------| Class methods defined here:
|
| from_array(arr, index=None, name=None, dtype=None, copy=False, fastpath=False) from builtins.type
|
| from_csv(path, sep=&#39;,&#39;, parse_dates=True, header=None, index_col=0, encoding=None, infer_datetime_format=False) from
builtins.type
| Read CSV file (DISCOURAGED, please use :func:</code>pandas.read_csv<code>instead).
|
| It is preferable to use the more powerful :func:</code>pandas.read_csv<code>| for most general purposes, but ``from_csv`` makes for an easy
| roundtrip to and from a file (the exact counterpart of
| ``to_csv``), especially with a time Series.
|
| This method only differs from :func:</code>pandas.read_csv<code>in some defaults:
|
| -</code>index_col<code>is ``0`` instead of ``None`` (take first column as index
| by default)
| -</code>header<code>is ``None`` instead of ``0`` (the first row is not used as
| the column names)
| -</code>parse_dates<code>is ``True`` instead of ``False`` (try parsing the index
| as datetime by default)
|
| With :func:</code>pandas.read_csv<code>, the option ``squeeze=True`` can be used
| to return a Series like ``from_csv``.
|
| 【参数】
| ----------| path : string file path or file handle / StringIO
| sep : string, default &#39;,&#39;
| Field delimiter
| parse_dates : boolean, default True
| Parse dates. Different default from read_table
| header : int, default None
| Row to use as header (skip prior rows)
| index_col : int or sequence, default 0
| Column to use for index. If a sequence is given, a MultiIndex
| is used. Different default from read_table
| encoding : string, optional
439
| a string representing the encoding to use if the contents are
| non-ascii, for python versions prior to 3
| infer_datetime_format: boolean, default False
| If True and</code>parse_dates<code>is True for a column, try to infer the
| datetime format based on the first datetime string. If the format
| can be inferred, there often will be a large parsing speed-up.
|
| 【参见】
| --------| pandas.read_csv
|
| 【返回值】
| -------| y : Series
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| axes
| Return a list of the row axis labels
|
| dtype
| return the dtype object of the underlying data
|
| dtypes
| return the dtype object of the underlying data
|
| ftype
| return if the data is sparse|dense
|
| ftypes
| return if the data is sparse|dense
|
| imag
|
| index
|
| is_time_series
|
| real
|
| values
| Return Series as ndarray or ndarray-like
| depending on the dtype
|
| 【返回值】
| -------| arr : numpy.ndarray or ndarray-like
|
| 【示例】
| --------| &gt;&gt;&gt; pd.Series([1, 2, 3]).values
| array([1, 2, 3])
|
| &gt;&gt;&gt; pd.Series(list(&#39;aabc&#39;)).values
| array([&#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;c&#39;], dtype=object)
|
440
| &gt;&gt;&gt; pd.Series(list(&#39;aabc&#39;)).astype(&#39;category&#39;).values
| [a, a, b, c]
| Categories (3, object): [a, b, c]
|
| Timezone aware datetime data is converted to UTC:
|
| &gt;&gt;&gt; pd.Series(pd.date_range(&#39;20130101&#39;,periods=3,tz=&#39;US/Eastern&#39;)).values
| array([&#39;2013-01-01T00:00:00.000000000-0500&#39;,
| &#39;2013-01-02T00:00:00.000000000-0500&#39;,
| &#39;2013-01-03T00:00:00.000000000-0500&#39;], dtype=&#39;datetime64[ns]&#39;)
|
| ----------------------------------------------------------------------| 其他数据、属性定义：
|
| cat = &lt;class &#39;pandas.core.categorical.CategoricalAccessor&#39;&gt;
| Accessor object for categorical properties of the Series values.
|
| Be aware that assigning to</code>categories<code>is a inplace operation, while all methods return
| new categorical data per default (but can be called with</code>inplace=True<code>).
|
| 【示例】
| --------| &gt;&gt;&gt; s.cat.categories
| &gt;&gt;&gt; s.cat.categories = list(&#39;abc&#39;)
| &gt;&gt;&gt; s.cat.rename_categories(list(&#39;cab&#39;))
| &gt;&gt;&gt; s.cat.reorder_categories(list(&#39;cab&#39;))
| &gt;&gt;&gt; s.cat.add_categories([&#39;d&#39;,&#39;e&#39;])
| &gt;&gt;&gt; s.cat.remove_categories([&#39;d&#39;])
| &gt;&gt;&gt; s.cat.remove_unused_categories()
| &gt;&gt;&gt; s.cat.set_categories(list(&#39;abcde&#39;))
| &gt;&gt;&gt; s.cat.as_ordered()
| &gt;&gt;&gt; s.cat.as_unordered()
|
| dt = &lt;class &#39;pandas.tseries.common.CombinedDatetimelikeProperties&#39;&gt;
| Accessor object for datetimelike properties of the Series values.
|
| 【示例】
| --------| &gt;&gt;&gt; s.dt.hour
| &gt;&gt;&gt; s.dt.second
| &gt;&gt;&gt; s.dt.quarter
|
| Returns a Series indexed like the original Series.
| Raises TypeError if the Series does not contain datetimelike values.
|
| plot = &lt;class &#39;pandas.tools.plotting.SeriesPlotMethods&#39;&gt;
| Series plotting accessor and method
|
| 【示例】
| --------| &gt;&gt;&gt; s.plot.line()
| &gt;&gt;&gt; s.plot.bar()
| &gt;&gt;&gt; s.plot.hist()
|
| Plotting methods can also be accessed by calling the accessor as a method
| with the ``kind`` argument:
| ``s.plot(kind=&#39;line&#39;)`` is equivalent to ``s.plot.line()``
441
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.IndexOpsMixin:
|
| factorize(self, sort=False, na_sentinel=-1)
| Encode the object as an enumerated type or categorical variable
|
| 【参数】
| ----------| sort : boolean, default False
| Sort by values
| na_sentinel: int, default -1
| Value to mark &quot;not found&quot;
|
| 【返回值】
| -------| labels : the indexer to the original array
| uniques : the unique Index
|
| item(self)
| return the first element of the underlying data as a python scalar
|
| nunique(self, dropna=True)
| Return number of unique elements in the object.
|
| Excludes NA values by default.
|
| 【参数】
| ----------| dropna : boolean, default True
| Don&#39;t include NaN in the count.
|
| 【返回值】
| -------| nunique : int
|
| transpose(self)
| return the transpose, which is by definition self
|
| unique(self)
| Return array of unique values in the object. Significantly faster than
| numpy.unique. Includes NA values.
|
| 【返回值】
| -------| uniques : ndarray
|
| value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)
| Returns object containing counts of unique values.
|
| The resulting object will be in descending order so that the
| first element is the most frequently-occurring element.
| Excludes NA values by default.
|
| 【参数】
| ----------| normalize : boolean, default False
442
| If True then the object returned will contain the relative
| frequencies of the unique values.
| sort : boolean, default True
| Sort by values
| ascending : boolean, default False
| Sort in ascending order
| bins : integer, optional
| Rather than count values, group them into half-open bins,
| a convenience for pd.cut, only works with numeric data
| dropna : boolean, default True
| Don&#39;t include counts of NaN.
|
| 【返回值】
| -------| counts : Series
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.base.IndexOpsMixin:
|
| T
| return the transpose, which is by definition self
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
|
| base
| return the base object if the memory of the underlying data is shared
|
| data
| return the data pointer of the underlying data
|
| flags
| return the ndarray.flags for the underlying data
|
| hasnans
|
| itemsize
| return the size of the dtype of the item of the underlying data
|
| nbytes
| return the number of bytes in the underlying data
|
| ndim
| return the number of dimensions of the underlying data, by definition 1
|
| shape
| return a tuple of the shape of the underlying data
|
| size
| return the number of elements in the underlying data
|
| strides
| return the strides of the underlying data
|
443
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.base.IndexOpsMixin:
|
| __array_priority__ = 1000
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.strings.StringAccessorMixin:
|
| str = &lt;class &#39;pandas.core.strings.StringMethods&#39;&gt;
| Vectorized string functions for Series and Index. NAs stay NA unless
| handled otherwise by a particular method. Patterned after Python&#39;s string
| methods, with some inspiration from R&#39;s stringr package.
|
| 【示例】
| --------| &gt;&gt;&gt; s.str.split(&#39;_&#39;)
| &gt;&gt;&gt; s.str.replace(&#39;_&#39;, &#39;&#39;)
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.generic.NDFrame:
|
| __abs__(self)
|
| __bool__ = __nonzero__(self)
|
| __contains__(self, key)
| True if the key is in the info axis
|
| __delitem__(self, key)
| Delete item
|
| __finalize__(self, other, method=None, **kwargs)
| propagate metadata from other to self
|
| 【参数】
| ----------| other : the object from which to get the attributes that we are going
| to propagate
| method : optional, a passed method name ; possibly to take different
| types of propagation actions based on this
|
| __getattr__(self, name)
| After regular attribute access, try looking up the name
| This allows simpler access to columns for interactive use.
|
| __getstate__(self)
|
| __hash__(self)
| Return hash(self).
|
| __invert__(self)
|
| __neg__(self)
|
| __nonzero__(self)
|
| __setattr__(self, name, value)
444
| After regular attribute access, try setting the name
| This allows simpler access to columns for interactive use.
|
| __setstate__(self, state)
|
| abs(self)
| Return an object with absolute value taken. Only applicable to objects
| that are all numeric
|
| 【返回值】
| -------| abs: type of caller
|
| add_prefix(self, prefix)
| Concatenate prefix string with panel items names.
|
| 【参数】
| ----------| prefix : string
|
| 【返回值】
| -------| with_prefix : type of caller
|
| add_suffix(self, suffix)
| Concatenate suffix string with panel items names
|
| 【参数】
| ----------| suffix : string
|
| 【返回值】
| -------| with_suffix : type of caller
|
| as_blocks(self, copy=True)
| Convert the frame to a dict of dtype -&gt; Constructor Types that each has
| a homogeneous dtype.
|
| NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in
| as_matrix)
|
| 【参数】
| ----------| copy : boolean, default True
|
| .. versionadded: 0.16.1
|
| 【返回值】
| -------| values : a dict of dtype -&gt; Constructor Types
|
| as_matrix(self, columns=None)
| Convert the frame to its Numpy-array representation.
|
| 【参数】
445
| ----------| columns: list, optional, default:None
| If None, return all columns, otherwise, returns specified columns.
|
| 【返回值】
| -------| values : ndarray
| If the caller is heterogeneous and contains booleans or objects,
| the result will be of dtype=object. See Notes.
|
|
| 【注意】
| -----| Return is NOT a Numpy-matrix, rather, a Numpy-array.
|
| The dtype will be a lower-common-denominator dtype (implicit
| upcasting); that is to say if the dtypes (even of numeric types)
| are mixed, the one that accommodates all will be chosen. Use this
| with care if you are not dealing with the blocks.
|
| e.g. If the dtypes are float16 and float32, dtype will be upcast to
| float32. If dtypes are int32 and uint8, dtype will be upcase to
| int32.
|
| This method is provided for backwards compatibility. Generally,
| it is recommended to use &#39;.values&#39;.
|
| 【参见】
| --------| pandas.DataFrame.values
|
| asfreq(self, freq, method=None, how=None, normalize=False)
| Convert all TimeSeries inside to specified frequency using DateOffset
| objects. Optionally provide fill method to pad/backfill missing values.
|
| 【参数】
| ----------| freq : DateOffset object, or string
| method : {&#39;backfill&#39;, &#39;bfill&#39;, &#39;pad&#39;, &#39;ffill&#39;, None}
| Method to use for filling holes in reindexed Series
| pad / ffill: propagate last valid observation forward to next valid
| backfill / bfill: use NEXT valid observation to fill method
| how : {&#39;start&#39;, &#39;end&#39;}, default end
| For PeriodIndex only, see PeriodIndex.asfreq
| normalize : bool, default False
| Whether to reset output index to midnight
|
| 【返回值】
| -------| converted : type of caller
|
| astype(self, dtype, copy=True, raise_on_error=True, **kwargs)
| Cast object to input numpy.dtype
| Return a copy when copy = True (be really careful with this!)
|
| 【参数】
| ----------
446
| dtype : numpy.dtype or Python type
| raise_on_error : raise on invalid input
| kwargs : keyword arguments to pass on to the constructor
|
| 【返回值】
| -------| casted : type of caller
|
| at_time(self, time, asof=False)
| Select values at particular time of day (e.g. 9:30AM)
|
| 【参数】
| ----------| time : datetime.time or string
|
| 【返回值】
| -------| values_at_time : type of caller
|
| between_time(self, start_time, end_time, include_start=True, include_end=True)
| Select values between particular times of the day (e.g., 9:00-9:30 AM)
|
| 【参数】
| ----------| start_time : datetime.time or string
| end_time : datetime.time or string
| include_start : boolean, default True
| include_end : boolean, default True
|
| 【返回值】
| -------| values_between_time : type of caller
|
| bfill(self, axis=None, inplace=False, limit=None, downcast=None)
| Synonym for NDFrame.fillna(method=&#39;bfill&#39;)
|
| bool(self)
| Return the bool of a single element PandasObject
| This must be a boolean scalar value, either True or False
|
| Raise a ValueError if the PandasObject does not have exactly
| 1 element, or that element is not boolean
|
| clip(self, lower=None, upper=None, out=None, axis=None)
| Trim values at input threshold(s)
|
| 【参数】
| ----------| lower : float or array_like, default None
| upper : float or array_like, default None
| axis : int or string axis name, optional
| Align object with lower and upper along the given axis.
|
| 【返回值】
| -------| clipped : Series
|
447
| 【示例】
| --------| &gt;&gt;&gt; df
| 0 1
| 0 0.335232 -1.256177
| 1 -1.367855 0.746646
| 2 0.027753 -1.176076
| 3 0.230930 -0.679613
| 4 1.261967 0.570967
| &gt;&gt;&gt; df.clip(-1.0, 0.5)
| 0 1
| 0 0.335232 -1.000000
| 1 -1.000000 0.500000
| 2 0.027753 -1.000000
| 3 0.230930 -0.679613
| 4 0.500000 0.500000
| &gt;&gt;&gt; t
| 0 -0.3
| 1 -0.2
| 2 -0.1
| 3 0.0
| 4 0.1
| dtype: float64
| &gt;&gt;&gt; df.clip(t, t + 1, axis=0)
| 0 1
| 0 0.335232 -0.300000
| 1 -0.200000 0.746646
| 2 0.027753 -0.100000
| 3 0.230930 0.000000
| 4 1.100000 0.570967
|
| clip_lower(self, threshold, axis=None)
| Return copy of the input with values below given value(s) truncated
|
| 【参数】
| ----------| threshold : float or array_like
| axis : int or string axis name, optional
| Align object with threshold along the given axis.
|
| 【参见】
| --------| clip
|
| 【返回值】
| -------| clipped : same type as input
|
| clip_upper(self, threshold, axis=None)
| Return copy of input with values above given value(s) truncated
|
| 【参数】
| ----------| threshold : float or array_like
| axis : int or string axis name, optional
| Align object with threshold along the given axis.
|
448
| 【参见】
| --------| clip
|
| 【返回值】
| -------| clipped : same type as input
|
| consolidate(self, inplace=False)
| Compute NDFrame with &quot;consolidated&quot; internals (data of each dtype
| grouped together in a single ndarray). Mainly an internal API function,
| but available here to the savvy user
|
| 【参数】
| ----------| inplace : boolean, default False
| If False return new object, otherwise modify existing object
|
| 【返回值】
| -------| consolidated : type of caller
|
| convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)
| Attempt to infer better dtype for object columns
|
| 【参数】
| ----------| convert_dates : boolean, default True
| If True, convert to date where possible. If &#39;coerce&#39;, force
| conversion, with unconvertible values becoming NaT.
| convert_numeric : boolean, default False
| If True, attempt to coerce to numbers (including strings), with
| unconvertible values becoming NaN.
| convert_timedeltas : boolean, default True
| If True, convert to timedelta where possible. If &#39;coerce&#39;, force
| conversion, with unconvertible values becoming NaT.
| copy : boolean, default True
| If True, return a copy even if no copy is necessary (e.g. no
| conversion was done). Note: This is meant for internal use, and
| should not be confused with inplace.
|
| 【返回值】
| -------| converted : same as input object
|
| copy(self, deep=True)
| Make a copy of this object
|
| 【参数】
| ----------| deep : boolean or string, default True
| Make a deep copy, i.e. also copy data
|
| 【返回值】
| -------| copy : type of caller
449
|
| describe(self, percentiles=None, include=None, exclude=None)
| Generate various summary statistics, excluding NaN values.
|
| 【参数】
| ----------| percentiles : array-like, optional
| The percentiles to include in the output. Should all
| be in the interval [0, 1]. By default</code>percentiles<code>is
| [.25, .5, .75], returning the 25th, 50th, and 75th percentiles.
| include, exclude : list-like, &#39;all&#39;, or None (default)
| Specify the form of the returned result. Either:
|
| - None to both (default). The result will include only numeric-typed
| columns or, if none are, only categorical columns.
| - A list of dtypes or strings to be included/excluded.
| To select all numeric types use numpy numpy.number. To select
| categorical objects use type object. 参见：the select_dtypes
| documentation. eg. df.describe(include=[&#39;O&#39;])
| - If include is the string &#39;all&#39;, the output column-set will
| match the input one.
|
| 【返回值】
| -------| summary: NDFrame of summary statistics
|
| 【注意】
| -----| The output DataFrame index depends on the requested dtypes:
|
| For numeric dtypes, it will include: count, mean, std, min,
| max, and lower, 50, and upper percentiles.
|
| For object dtypes (e.g. timestamps or strings), the index
| will include the count, unique, most common, and frequency of the
| most common. Timestamps also include the first and last items.
|
| For mixed dtypes, the index will be the union of the corresponding
| output types. Non-applicable entries will be filled with NaN.
| Note that mixed-dtype outputs can only be returned from mixed-dtype
| inputs and appropriate use of the include/exclude arguments.
|
| If multiple values have the highest count, then the
|</code>count<code>and</code>most common<code>pair will be arbitrarily chosen from
| among those with the highest count.
|
| The include, exclude arguments are ignored for Series.
|
| 【参见】
| --------| DataFrame.select_dtypes
|
| drop(self, labels, axis=0, level=None, inplace=False, errors=&#39;raise&#39;)
| Return new object with labels in requested axis removed
|
| 【参数】
| ----------
450
| labels : single label or list-like
| axis : int or axis name
| level : int or level name, default None
| For MultiIndex
| inplace : bool, default False
| If True, do operation inplace and return None.
| errors : {&#39;ignore&#39;, &#39;raise&#39;}, default &#39;raise&#39;
| If &#39;ignore&#39;, suppress error and existing labels are dropped.
|
| .. versionadded:: 0.16.1
|
| 【返回值】
| -------| dropped : type of caller
|
| equals(self, other)
| Determines if two NDFrame objects contain the same elements. NaNs in the
| same location are considered equal.
|
| ffill(self, axis=None, inplace=False, limit=None, downcast=None)
| Synonym for NDFrame.fillna(method=&#39;ffill&#39;)
|
| filter(self, items=None, like=None, regex=None, axis=None)
| Restrict the info axis to set of items or wildcard
|
| 【参数】
| ----------| items : list-like
| List of info axis to restrict to (must not all be present)
| like : string
| Keep info axis where &quot;arg in col == True&quot;
| regex : string (regular expression)
| Keep info axis with re.search(regex, col) == True
| axis : int or None
| The axis to filter on. By default this is the info axis. The &quot;info
| axis&quot; is the axis that is used when indexing with ``[]``. For
| example, ``df = DataFrame({&#39;a&#39;: [1, 2, 3, 4]]}); df[&#39;a&#39;]``. So,
| the ``DataFrame`` columns are the info axis.
|
| 【注意】
| -----| Arguments are mutually exclusive, but this is not checked for
|
| first(self, offset)
| Convenience method for subsetting initial periods of time series data
| based on a date offset
|
| 【参数】
| ----------| offset : string, DateOffset, dateutil.relativedelta
|
| 【示例】
| --------| ts.last(&#39;10D&#39;) -&gt; First 10 days
|
| 【返回值】
| -------
451
| subset : type of caller
|
| get(self, key, default=None)
| Get item from object for given key (DataFrame column, Panel slice,
| etc.). Returns default value if not found
|
| 【参数】
| ----------| key : object
|
| 【返回值】
| -------| value : type of items contained in object
|
| get_dtype_counts(self)
| Return the counts of dtypes in this object
|
| get_ftype_counts(self)
| Return the counts of ftypes in this object
|
| groupby(self, by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False)
| Group series using mapper (dict or key function, apply given function
| to group, return result as series) or by a series of columns
|
| 【参数】
| ----------| by : mapping function / list of functions, dict, Series, or tuple /
| list of column names.
| Called on each element of the object index to determine the groups.
| If a dict or Series is passed, the Series or dict VALUES will be
| used to determine the groups
| axis : int, default 0
| level : int, level name, or sequence of such, default None
| If the axis is a MultiIndex (hierarchical), group by a particular
| level or levels
| as_index : boolean, default True
| For aggregated output, return object with group labels as the
| index. Only relevant for DataFrame input. as_index=False is
| effectively &quot;SQL-style&quot; grouped output
| sort : boolean, default True
| Sort group keys. Get better performance by turning this off.
| Note this does not influence the order of observations within each group.
| groupby preserves the order of rows within each group.
| group_keys : boolean, default True
| When calling apply, add group keys to index to identify pieces
| squeeze : boolean, default False
| reduce the dimensionality of the return type if possible,
| otherwise return a consistent type
|
| 【示例】
| --------| DataFrame results
|
| &gt;&gt;&gt; data.groupby(func, axis=0).mean()
| &gt;&gt;&gt; data.groupby([&#39;col1&#39;, &#39;col2&#39;])[&#39;col3&#39;].mean()
|
| DataFrame with hierarchical index
452
|
| &gt;&gt;&gt; data.groupby([&#39;col1&#39;, &#39;col2&#39;]).mean()
|
| 【返回值】
| -------| GroupBy object
|
| head(self, n=5)
| Returns first n rows
|
| interpolate(self, method=&#39;linear&#39;, axis=0, limit=None, inplace=False, limit_direction=&#39;forward&#39;, downcast=None, **kwargs)
| Interpolate values according to different methods.
|
| Please note that only ``method=&#39;linear&#39;`` is supported for DataFrames/Series
| with a MultiIndex.
|
| 【参数】
| ----------| method : {&#39;linear&#39;, &#39;time&#39;, &#39;index&#39;, &#39;values&#39;, &#39;nearest&#39;, &#39;zero&#39;,
| &#39;slinear&#39;, &#39;quadratic&#39;, &#39;cubic&#39;, &#39;barycentric&#39;, &#39;krogh&#39;,
| &#39;polynomial&#39;, &#39;spline&#39; &#39;piecewise_polynomial&#39;, &#39;pchip&#39;}
|
| * &#39;linear&#39;: ignore the index and treat the values as equally
| spaced. This is the only method supported on MultiIndexes.
| default
| * &#39;time&#39;: interpolation works on daily and higher resolution
| data to interpolate given length of interval
| * &#39;index&#39;, &#39;values&#39;: use the actual numerical values of the index
| * &#39;nearest&#39;, &#39;zero&#39;, &#39;slinear&#39;, &#39;quadratic&#39;, &#39;cubic&#39;,
| &#39;barycentric&#39;, &#39;polynomial&#39; is passed to
| ``scipy.interpolate.interp1d``. Both &#39;polynomial&#39; and &#39;spline&#39;
| require that you also specify an</code>order<code>(int),
| e.g. df.interpolate(method=&#39;polynomial&#39;, order=4).
| These use the actual numerical values of the index.
| * &#39;krogh&#39;, &#39;piecewise_polynomial&#39;, &#39;spline&#39;, and &#39;pchip&#39; are all
| wrappers around the scipy interpolation methods of similar
| names. These use the actual numerical values of the index. See
| the scipy documentation for more on their behavior
|</code>here <a href="http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation" target="_blank" rel="external">http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation</a><code>__
|</code>and here <a href="http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html" target="_blank" rel="external">http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html</a><code>__
|
| axis : {0, 1}, default 0
| * 0: fill column-by-column
| * 1: fill row-by-row
| limit : int, default None.
| Maximum number of consecutive NaNs to fill.
| limit_direction : {&#39;forward&#39;, &#39;backward&#39;, &#39;both&#39;}, defaults to &#39;forward&#39;
| If limit is specified, consecutive NaNs will be filled in this
| direction.
|
| .. versionadded:: 0.17.0
|
| inplace : bool, default False
| Update the NDFrame in place if possible.
| downcast : optional, &#39;infer&#39; or None, defaults to None
| Downcast dtypes if possible.
| kwargs : keyword arguments to pass on to the interpolating function.
453
|
| 【返回值】
| -------| Series or DataFrame of same shape interpolated at the NaNs
|
| 【参见】
| --------| reindex, replace, fillna
|
| 【示例】
| --------|
| Filling in NaNs
|
| &gt;&gt;&gt; s = pd.Series([0, 1, np.nan, 3])
| &gt;&gt;&gt; s.interpolate()
| 0 0
| 1 1
| 2 2
| 3 3
| dtype: float64
|
| isnull(self)
| Return a boolean same-sized object indicating if the values are null
|
| 【参见】
| --------| notnull : boolean inverse of isnull
|
| iterkv(self, *args, **kwargs)
| iteritems alias used to get around 2to3. Deprecated
|
| last(self, offset)
| Convenience method for subsetting final periods of time series data
| based on a date offset
|
| 【参数】
| ----------| offset : string, DateOffset, dateutil.relativedelta
|
| 【示例】
| --------| ts.last(&#39;5M&#39;) -&gt; Last 5 months
|
| 【返回值】
| -------| subset : type of caller
|
| mask(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)
| Return an object of same shape as self and whose corresponding
| entries are from self where cond is False and otherwise are from other.
|
| 【参数】
| ----------| cond : boolean NDFrame or array
| other : scalar or NDFrame
454
| inplace : boolean, default False
| Whether to perform the operation in place on the data
| axis : alignment axis if needed, default None
| level : alignment level if needed, default None
| try_cast : boolean, default False
| try to cast the result back to the input type (if possible),
| raise_on_error : boolean, default True
| Whether to raise on invalid data types (e.g. trying to where on
| strings)
|
| 【返回值】
| -------| wh : same type as caller
|
| notnull(self)
| Return a boolean same-sized object indicating if the values are
| not null
|
| 【参见】
| --------| isnull : boolean inverse of notnull
|
| pct_change(self, periods=1, fill_method=&#39;pad&#39;, limit=None, freq=None, **kwargs)
| Percent change over given number of periods.
|
| 【参数】
| ----------| periods : int, default 1
| Periods to shift for forming percent change
| fill_method : str, default &#39;pad&#39;
| How to handle NAs before computing percent changes
| limit : int, default None
| The number of consecutive NAs to fill before stopping
| freq : DateOffset, timedelta, or offset alias string, optional
| Increment to use from time series API (e.g. &#39;M&#39; or BDay())
|
| 【返回值】
| -------| chg : NDFrame
|
| 【注意】
| -----|
| By default, the percentage change is calculated along the stat
| axis: 0, or ``Index``, for ``DataFrame`` and 1, or ``minor`` for
| ``Panel``. You can change this with the ``axis`` keyword argument.
|
| pipe(self, func, *args, **kwargs)
| Apply func(self, \*args, \*\*kwargs)
|
| .. versionadded:: 0.16.2
|
| 【参数】
| ----------| func : function
| function to apply to the NDFrame.
| ``args``, and ``kwargs`` are passed into ``func``.
455
| Alternatively a ``(callable, data_keyword)`` tuple where
| ``data_keyword`` is a string indicating the keyword of
| ``callable`` that expects the NDFrame.
| args : positional arguments passed into ``func``.
| kwargs : a dictionary of keyword arguments passed into ``func``.
|
| 【返回值】
| -------| object : the return type of ``func``.
|
| 【注意】
| -----|
| Use ``.pipe`` when chaining together functions that expect
| on Series or DataFrames. Instead of writing
|
| &gt;&gt;&gt; f(g(h(df), arg1=a), arg2=b, arg3=c)
|
| You can write
|
| &gt;&gt;&gt; (df.pipe(h)
| ... .pipe(g, arg1=a)
| ... .pipe(f, arg2=b, arg3=c)
| ... )
|
| If you have a function that takes the data as (say) the second
| argument, pass a tuple indicating which keyword expects the
| data. For example, suppose ``f`` takes its data as ``arg2``:
|
| &gt;&gt;&gt; (df.pipe(h)
| ... .pipe(g, arg1=a)
| ... .pipe((f, &#39;arg2&#39;), arg1=a, arg3=c)
| ... )
|
| 【参见】
| --------| pandas.DataFrame.apply
| pandas.DataFrame.applymap
| pandas.Series.map
|
| pop(self, item)
| Return item and drop from frame. Raise KeyError if not found.
|
| reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)
| return an object with matching indicies to myself
|
| 【参数】
| ----------| other : Object
| method : string or None
| copy : boolean, default True
| limit : int, default None
| Maximum number of consecutive labels to fill for inexact matches.
| tolerance : optional
| Maximum distance between labels of the other object and this
| object for inexact matches.
|
456
| .. versionadded:: 0.17.0
|
| 【注意】
| -----| Like calling s.reindex(index=other.index, columns=other.columns,
| method=...)
|
| 【返回值】
| -------| reindexed : same as input
|
| rename_axis(self, mapper, axis=0, copy=True, inplace=False)
| Alter index and / or columns using input function or functions.
| Function / dict values must be unique (1-to-1). Labels not contained in
| a dict / Series will be left as-is.
|
| 【参数】
| ----------| mapper : dict-like or function, optional
| axis : int or string, default 0
| copy : boolean, default True
| Also copy underlying data
| inplace : boolean, default False
|
| 【返回值】
| -------| renamed : type of caller
|
| replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method=&#39;pad&#39;, axis=None)
| Replace values given in &#39;to_replace&#39; with &#39;value&#39;.
|
| 【参数】
| ----------| to_replace : str, regex, list, dict, Series, numeric, or None
|
| * str or regex:
|
| - str: string exactly matching</code>to_replace<code>will be replaced
| with</code>value<code>| - regex: regexs matching</code>to_replace<code>will be replaced with
|</code>value<code>|
| * list of str, regex, or numeric:
|
| - First, if</code>to_replace<code>and</code>value<code>are both lists, they
| **must** be the same length.
| - Second, if ``regex=True`` then all of the strings in **both**
| lists will be interpreted as regexs otherwise they will match
| directly. This doesn&#39;t matter much for</code>value<code>since there
| are only a few possible substitution regexes you can use.
| - str and regex rules apply as above.
|
| * dict:
|
| - Nested dictionaries, e.g., {&#39;a&#39;: {&#39;b&#39;: nan}}, are read as
| follows: look in column &#39;a&#39; for the value &#39;b&#39; and replace it
| with nan. You can nest regular expressions as well. Note that
457
| column names (the top-level dictionary keys in a nested
| dictionary) **cannot** be regular expressions.
| - Keys map to column names and values map to substitution
| values. You can treat this as a special case of passing two
| lists except that you are specifying the column to search in.
|
| * None:
|
| - This means that the ``regex`` argument must be a string,
| compiled regular expression, or list, dict, ndarray or Series
| of such elements. If</code>value<code>is also ``None`` then this
| **must** be a nested dictionary or ``Series``.
|
| See the examples section for examples of each of these.
| value : scalar, dict, list, str, regex, default None
| Value to use to fill holes (e.g. 0), alternately a dict of values
| specifying which value to use for each column (columns not in the
| dict will not be filled). Regular expressions, strings and lists or
| dicts of such objects are also allowed.
| inplace : boolean, default False
| If True, in place. Note: this will modify any
| other views on this object (e.g. a column form a DataFrame).
| Returns the caller if this is True.
| limit : int, default None
| Maximum size gap to forward or backward fill
| regex : bool or same types as</code>to_replace<code>, default False
| Whether to interpret</code>to_replace<code>and/or</code>value<code>as regular
| expressions. If this is ``True`` then</code>to_replace<code>*must* be a
| string. Otherwise,</code>to_replace<code>must be ``None`` because this
| parameter will be interpreted as a regular expression or a list,
| dict, or array of regular expressions.
| method : string, optional, {&#39;pad&#39;, &#39;ffill&#39;, &#39;bfill&#39;}
| The method to use when for replacement, when ``to_replace`` is a
| ``list``.
|
| 【参见】
| --------| NDFrame.reindex
| NDFrame.asfreq
| NDFrame.fillna
|
| 【返回值】
| -------| filled : NDFrame
|
| 【Raises 引发错误】
| ------| AssertionError
| * If</code>regex<code>is not a ``bool`` and</code>to_replace<code>is not ``None``.
| TypeError
| * If</code>to_replace<code>is a ``dict`` and</code>value<code>is not a ``list``,
| ``dict``, ``ndarray``, or ``Series``
| * If</code>to_replace<code>is ``None`` and</code>regex<code>is not compilable into a
| regular expression or is a list, dict, ndarray, or Series.
| ValueError
| * If</code>to_replace<code>and</code>value<code>are ``list`` s or ``ndarray`` s, but
| they are not the same length.
458
|
| 【注意】
| -----| * Regex substitution is performed under the hood with ``re.sub``. The
| rules for substitution for ``re.sub`` are the same.
| * Regular expressions will only substitute on strings, meaning you
| cannot provide, for example, a regular expression matching floating
| point numbers and expect the columns in your frame that have a
| numeric dtype to be matched. However, if those floating point numbers
| *are* strings, then you can do this.
| * This method has *a lot* of options. You are encouraged to experiment
| and play with this method to gain intuition about how it works.
|
| resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention=&#39;start&#39;, kind=None,
loffset=None, limit=None, base=0)
| Convenience method for frequency conversion and resampling of regular
| time-series data.
|
| 【参数】
| ----------| rule : string
| the offset string or object representing target conversion
| how : string
| method for down- or re-sampling, default to &#39;mean&#39; for
| downsampling
| axis : int, optional, default 0
| fill_method : string, default None
| fill_method for upsampling
| closed : {&#39;right&#39;, &#39;left&#39;}
| Which side of bin interval is closed
| label : {&#39;right&#39;, &#39;left&#39;}
| Which bin edge label to label bucket with
| convention : {&#39;start&#39;, &#39;end&#39;, &#39;s&#39;, &#39;e&#39;}
| kind : &quot;period&quot;/&quot;timestamp&quot;
| loffset : timedelta
| Adjust the resampled time labels
| limit : int, default None
| Maximum size gap to when reindexing with fill_method
| base : int, default 0
| For frequencies that evenly subdivide 1 day, the &quot;origin&quot; of the
| aggregated intervals. For example, for &#39;5min&#39; frequency, base could
| range from 0 through 4. Defaults to 0
|
|
| 【示例】
| --------|
| Start by creating a series with 9 one minute timestamps.
|
| &gt;&gt;&gt; index = pd.date_range(&#39;1/1/2000&#39;, periods=9, freq=&#39;T&#39;)
| &gt;&gt;&gt; series = pd.Series(range(9), index=index)
| &gt;&gt;&gt; series
| 2000-01-01 00:00:00 0
| 2000-01-01 00:01:00 1
| 2000-01-01 00:02:00 2
| 2000-01-01 00:03:00 3
| 2000-01-01 00:04:00 4
459
| 2000-01-01 00:05:00 5
| 2000-01-01 00:06:00 6
| 2000-01-01 00:07:00 7
| 2000-01-01 00:08:00 8
| Freq: T, dtype: int64
|
| Downsample the series into 3 minute bins and sum the values
| of the timestamps falling into a bin.
|
| &gt;&gt;&gt; series.resample(&#39;3T&#39;, how=&#39;sum&#39;)
| 2000-01-01 00:00:00 3
| 2000-01-01 00:03:00 12
| 2000-01-01 00:06:00 21
| Freq: 3T, dtype: int64
|
| Downsample the series into 3 minute bins as above, but label each
| bin using the right edge instead of the left. Please note that the
| value in the bucket used as the label is not included in the bucket,
| which it labels. For example, in the original series the
| bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed
| value in the resampled bucket with the label``2000-01-01 00:03:00``
| does not include 3 (if it did, the summed value would be 6, not 3).
| To include this value close the right side of the bin interval as
| illustrated in the example below this one.
|
| &gt;&gt;&gt; series.resample(&#39;3T&#39;, how=&#39;sum&#39;, label=&#39;right&#39;)
| 2000-01-01 00:03:00 3
| 2000-01-01 00:06:00 12
| 2000-01-01 00:09:00 21
| Freq: 3T, dtype: int64
|
| Downsample the series into 3 minute bins as above, but close the right
| side of the bin interval.
|
| &gt;&gt;&gt; series.resample(&#39;3T&#39;, how=&#39;sum&#39;, label=&#39;right&#39;, closed=&#39;right&#39;)
| 2000-01-01 00:00:00 0
| 2000-01-01 00:03:00 6
| 2000-01-01 00:06:00 15
| 2000-01-01 00:09:00 15
| Freq: 3T, dtype: int64
|
| Upsample the series into 30 second bins.
|
| &gt;&gt;&gt; series.resample(&#39;30S&#39;)[0:5] #select first 5 rows
| 2000-01-01 00:00:00 0
| 2000-01-01 00:00:30 NaN
| 2000-01-01 00:01:00 1
| 2000-01-01 00:01:30 NaN
| 2000-01-01 00:02:00 2
| Freq: 30S, dtype: float64
|
| Upsample the series into 30 second bins and fill the ``NaN``
| values using the ``pad`` method.
|
| &gt;&gt;&gt; series.resample(&#39;30S&#39;, fill_method=&#39;pad&#39;)[0:5]
| 2000-01-01 00:00:00 0
| 2000-01-01 00:00:30 0
460
| 2000-01-01 00:01:00 1
| 2000-01-01 00:01:30 1
| 2000-01-01 00:02:00 2
| Freq: 30S, dtype: int64
|
| Upsample the series into 30 second bins and fill the
| ``NaN`` values using the ``bfill`` method.
|
| &gt;&gt;&gt; series.resample(&#39;30S&#39;, fill_method=&#39;bfill&#39;)[0:5]
| 2000-01-01 00:00:00 0
| 2000-01-01 00:00:30 1
| 2000-01-01 00:01:00 1
| 2000-01-01 00:01:30 2
| 2000-01-01 00:02:00 2
| Freq: 30S, dtype: int64
|
| Pass a custom function to ``how``.
|
| &gt;&gt;&gt; def custom_resampler(array_like):
| ... return np.sum(array_like)+5
|
| &gt;&gt;&gt; series.resample(&#39;3T&#39;, how=custom_resampler)
| 2000-01-01 00:00:00 8
| 2000-01-01 00:03:00 17
| 2000-01-01 00:06:00 26
| Freq: 3T, dtype: int64
|
| sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)
| Returns a random sample of items from an axis of object.
|
| .. versionadded:: 0.16.1
|
| 【参数】
| ----------| n : int, optional
| Number of items from axis to return. Cannot be used with</code>frac<code>.
| Default = 1 if</code>frac<code>= None.
| frac : float, optional
| Fraction of axis items to return. Cannot be used with</code>n<code>.
| replace : boolean, optional
| Sample with or without replacement. Default = False.
| weights : str or ndarray-like, optional
| Default &#39;None&#39; results in equal probability weighting.
| If passed a Series, will align with target object on index. Index
| values in weights not found in sampled object will be ignored and
| index values in sampled object not in weights will be assigned
| weights of zero.
| If called on a DataFrame, will accept the name of a column
| when axis = 0.
| Unless weights are a Series, weights must be same length as axis
| being sampled.
| If weights do not sum to 1, they will be normalized to sum to 1.
| Missing values in the weights column will be treated as zero.
| inf and -inf values not allowed.
| random_state : int or numpy.random.RandomState, optional
| Seed for the random number generator (if int), or numpy RandomState
| object.
461
| axis : int or string, optional
| Axis to sample. Accepts axis number or name. Default is stat axis
| for given data type (0 for Series and DataFrames, 1 for Panels).
|
| 【返回值】
| -------| A new object of same type as caller.
|
| select(self, crit, axis=0)
| Return data corresponding to axis labels matching criteria
|
| 【参数】
| ----------| crit : function
| To be called on each index (label). Should return True or False
| axis : int
|
| 【返回值】
| -------| selection : type of caller
|
| set_axis(self, axis, labels)
| public verson of axis assignment
|
| slice_shift(self, periods=1, axis=0)
| Equivalent to</code>shift<code>without copying data. The shifted data will
| not include the dropped periods and the shifted axis will be smaller
| than the original.
|
| 【参数】
| ----------| periods : int
| Number of periods to move, can be positive or negative
|
| 【注意】
| -----| While the</code>slice_shift<code>is faster than</code>shift<code>, you may pay for it
| later during alignment.
|
| 【返回值】
| -------| shifted : same type as caller
|
| squeeze(self)
| squeeze length 1 dimensions
|
| swapaxes(self, axis1, axis2, copy=True)
| Interchange axes and swap values axes appropriately
|
| 【返回值】
| -------| y : same as input
|
| tail(self, n=5)
| Returns last n rows
|
| to_clipboard(self, excel=None, sep=None, **kwargs)
462
| Attempt to write text representation of object to the system clipboard
| This can be pasted into Excel, for example.
|
| 【参数】
| ----------| excel : boolean, defaults to True
| if True, use the provided separator, writing in a csv
| format for allowing easy pasting into excel.
| if False, write a string representation of the object
| to the clipboard
| sep : optional, defaults to tab
| other keywords are passed to to_csv
|
| 【注意】
| -----| Requirements for your platform
| - Linux: xclip, or xsel (with gtk or PyQt4 modules)
| - Windows: none
| - OS X: none
|
| to_dense(self)
| Return dense representation of NDFrame (as opposed to sparse)
|
| to_hdf(self, path_or_buf, key, **kwargs)
| activate the HDFStore
|
| 【参数】
| ----------| path_or_buf : the path (string) or HDFStore object
| key : string
| indentifier for the group in the store
| mode : optional, {&#39;a&#39;, &#39;w&#39;, &#39;r&#39;, &#39;r+&#39;}, default &#39;a&#39;
|
| ``&#39;r&#39;``
| Read-only; no data can be modified.
| ``&#39;w&#39;``
| Write; a new file is created (an existing file with the same
| name would be deleted).
| ``&#39;a&#39;``
| Append; an existing file is opened for reading and writing,
| and if the file does not exist it is created.
| ``&#39;r+&#39;``
| It is similar to ``&#39;a&#39;``, but the file must already exist.
| format : &#39;fixed(f)|table(t)&#39;, default is &#39;fixed&#39;
| fixed(f) : Fixed format
| Fast writing/reading. Not-appendable, nor searchable
| table(t) : Table format
| Write as a PyTables Table structure which may perform
| worse but allow more flexible operations like searching
| / selecting subsets of the data
| append : boolean, default False
| For Table formats, append the input data to the existing
| complevel : int, 1-9, default 0
| If a complib is specified compression will be applied
| where possible
| complib : {&#39;zlib&#39;, &#39;bzip2&#39;, &#39;lzo&#39;, &#39;blosc&#39;, None}, default None
| If complevel is &gt; 0 apply compression to objects written
463
| in the store wherever possible
| fletcher32 : bool, default False
| If applying compression use the fletcher32 checksum
| dropna : boolean, default False.
| If true, ALL nan rows will not be written to store.
|
| to_json(self, path_or_buf=None, orient=None, date_format=&#39;epoch&#39;, double_precision=10, force_ascii=True, date_unit=&#39;ms&#39;,
default_handler=None)
| Convert the object to a JSON string.
|
| Note NaN&#39;s and None will be converted to null and datetime objects
| will be converted to UNIX timestamps.
|
| 【参数】
| ----------| path_or_buf : the path or buffer to write the result string
| if this is None, return a StringIO of the converted string
| orient : string
|
| * Series
|
| - default is &#39;index&#39;
| - allowed values are: {&#39;split&#39;,&#39;records&#39;,&#39;index&#39;}
|
| * DataFrame
|
| - default is &#39;columns&#39;
| - allowed values are:
| {&#39;split&#39;,&#39;records&#39;,&#39;index&#39;,&#39;columns&#39;,&#39;values&#39;}
|
| * The format of the JSON string
|
| - split : dict like
| {index -&gt; [index], columns -&gt; [columns], data -&gt; [values]}
| - records : list like
| [{column -&gt; value}, ... , {column -&gt; value}]
| - index : dict like {index -&gt; {column -&gt; value}}
| - columns : dict like {column -&gt; {index -&gt; value}}
| - values : just the values array
|
| date_format : {&#39;epoch&#39;, &#39;iso&#39;}
| Type of date conversion.</code>epoch<code>= epoch milliseconds,
|</code>iso<code>= ISO8601, default is epoch.
| double_precision : The number of decimal places to use when encoding
| floating point values, default 10.
| force_ascii : force encoded string to be ASCII, default True.
| date_unit : string, default &#39;ms&#39; (milliseconds)
| The time unit to encode to, governs timestamp and ISO8601
| precision. One of &#39;s&#39;, &#39;ms&#39;, &#39;us&#39;, &#39;ns&#39; for second, millisecond,
| microsecond, and nanosecond respectively.
| default_handler : callable, default None
| Handler to call if object cannot otherwise be converted to a
| suitable format for JSON. Should receive a single argument which is
| the object to convert and return a serialisable object.
|
| 【返回值】
| -------
464
| same type as input object with filtered info axis
|
| to_msgpack(self, path_or_buf=None, **kwargs)
| msgpack (serialize) object to input file path
|
| THIS IS AN EXPERIMENTAL LIBRARY and the storage format
| may not be stable until a future release.
|
| 【参数】
| ----------| path : string File path, buffer-like, or None
| if None, return generated string
| append : boolean whether to append to an existing msgpack
| (default is False)
| compress : type of compressor (zlib or blosc), default to None (no
| compression)
|
| to_pickle(self, path)
| Pickle (serialize) object to input file path
|
| 【参数】
| ----------| path : string
| File path
|
| to_sql(self, name, con, flavor=&#39;sqlite&#39;, schema=None, if_exists=&#39;fail&#39;, index=True, index_label=None, chunksize=None,
dtype=None)
| Write records stored in a DataFrame to a SQL database.
|
| 【参数】
| ----------| name : string
| Name of SQL table
| con : SQLAlchemy engine or DBAPI2 connection (legacy mode)
| Using SQLAlchemy makes it possible to use any DB supported by that
| library.
| If a DBAPI2 object, only sqlite3 is supported.
| flavor : {&#39;sqlite&#39;, &#39;mysql&#39;}, default &#39;sqlite&#39;
| The flavor of SQL to use. Ignored when using SQLAlchemy engine.
| &#39;mysql&#39; is deprecated and will be removed in future versions, but it
| will be further supported through SQLAlchemy engines.
| schema : string, default None
| Specify the schema (if database flavor supports this). If None, use
| default schema.
| if_exists : {&#39;fail&#39;, &#39;replace&#39;, &#39;append&#39;}, default &#39;fail&#39;
| - fail: If table exists, do nothing.
| - replace: If table exists, drop it, recreate it, and insert data.
| - append: If table exists, insert data. Create if does not exist.
| index : boolean, default True
| Write DataFrame index as a column.
| index_label : string or sequence, default None
| Column label for index column(s). If None is given (default) and
| `index` is True, then the index names are used.
| A sequence should be given if the DataFrame uses MultiIndex.
| chunksize : int, default None
| If not None, then rows will be written in batches of this size at a
| time. If None, all rows will be written at once.
465
| dtype : dict of column name to SQL type, default None
| Optional specifying the datatype for columns. The SQL type should
| be a SQLAlchemy type, or a string for sqlite3 fallback connection.
|
| truncate(self, before=None, after=None, axis=None, copy=True)
| Truncates a sorted NDFrame before and/or after some particular
| dates.
|
| 【参数】
| ----------| before : date
| Truncate before date
| after : date
| Truncate after date
| axis : the truncation axis, defaults to the stat axis
| copy : boolean, default is True,
| return a copy of the truncated section
|
| 【返回值】
| -------| truncated : type of caller
|
| tshift(self, periods=1, freq=None, axis=0)
| Shift the time index, using the index&#39;s frequency if available
|
| 【参数】
| ----------| periods : int
| Number of periods to move, can be positive or negative
| freq : DateOffset, timedelta, or time rule string, default None
| Increment to use from datetools module or time rule (e.g. &#39;EOM&#39;)
| axis : int or basestring
| Corresponds to the axis that contains the Index
|
| 【注意】
| -----| If freq is not specified then tries to use the freq or inferred_freq
| attributes of the index. If neither of those attributes exist, a
| ValueError is thrown
|
| 【返回值】
| -------| shifted : NDFrame
|
| tz_convert(self, tz, axis=0, level=None, copy=True)
| Convert tz-aware axis to target time zone.
|
| 【参数】
| ----------| tz : string or pytz.timezone object
| axis : the axis to convert
| level : int, str, default None
| If axis ia a MultiIndex, convert a specific level. Otherwise
| must be None
| copy : boolean, default True
| Also make a copy of the underlying data
|
466
| 【返回值】
| -------|
| 【Raises 引发错误】
| ------| TypeError
| If the axis is tz-naive.
|
| tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous=&#39;raise&#39;)
| Localize tz-naive TimeSeries to target time zone
|
| 【参数】
| ----------| tz : string or pytz.timezone object
| axis : the axis to localize
| level : int, str, default None
| If axis ia a MultiIndex, localize a specific level. Otherwise
| must be None
| copy : boolean, default True
| Also make a copy of the underlying data
| ambiguous : &#39;infer&#39;, bool-ndarray, &#39;NaT&#39;, default &#39;raise&#39;
| - &#39;infer&#39; will attempt to infer fall dst-transition hours based on order
| - bool-ndarray where True signifies a DST time, False designates
| a non-DST time (note that this flag is only applicable for ambiguous times)
| - &#39;NaT&#39; will return NaT where there are ambiguous times
| - &#39;raise&#39; will raise an AmbiguousTimeError if there are ambiguous times
| infer_dst : boolean, default False (DEPRECATED)
| Attempt to infer fall dst-transition hours based on order
|
| 【返回值】
| -------|
| 【Raises 引发错误】
| ------| TypeError
| If the TimeSeries is tz-aware and tz is not None.
|
| where(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)
| Return an object of same shape as self and whose corresponding
| entries are from self where cond is True and otherwise are from other.
|
| 【参数】
| ----------| cond : boolean NDFrame or array
| other : scalar or NDFrame
| inplace : boolean, default False
| Whether to perform the operation in place on the data
| axis : alignment axis if needed, default None
| level : alignment level if needed, default None
| try_cast : boolean, default False
| try to cast the result back to the input type (if possible),
| raise_on_error : boolean, default True
| Whether to raise on invalid data types (e.g. trying to where on
| strings)
|
| 【返回值】
| -------
467
| wh : same type as caller
|
| xs(self, key, axis=0, level=None, copy=None, drop_level=True)
| Returns a cross-section (row(s) or column(s)) from the Series/DataFrame.
| Defaults to cross-section on the rows (axis=0).
|
| 【参数】
| ----------| key : object
| Some label contained in the index, or partially in a MultiIndex
| axis : int, default 0
| Axis to retrieve cross-section on
| level : object, defaults to first n levels (n=1 or len(key))
| In case of a key partially contained in a MultiIndex, indicate
| which levels are used. Levels can be referred by label or position.
| copy : boolean [deprecated]
| Whether to make a copy of the data
| drop_level : boolean, default True
| If False, returns object with same levels as self.
|
| 【示例】
| --------| &gt;&gt;&gt; df
| A B C
| a 4 5 2
| b 4 0 9
| c 9 7 3
| &gt;&gt;&gt; df.xs(&#39;a&#39;)
| A 4
| B 5
| C 2
| Name: a
| &gt;&gt;&gt; df.xs(&#39;C&#39;, axis=1)
| a 2
| b 9
| c 3
| Name: C
|
| &gt;&gt;&gt; df
| A B C D
| first second third
| bar one 1 4 1 8 9
| two 1 7 5 5 0
| baz one 1 6 6 8 0
| three 2 5 3 5 3
| &gt;&gt;&gt; df.xs((&#39;baz&#39;, &#39;three&#39;))
| A B C D
| third
| 2 5 3 5 3
| &gt;&gt;&gt; df.xs(&#39;one&#39;, level=1)
| A B C D
| first third
| bar 1 4 1 8 9
| baz 1 6 6 8 0
| &gt;&gt;&gt; df.xs((&#39;baz&#39;, 2), level=[0, &#39;third&#39;])
| A B C D
| second
468
| three 5 3 5 3
|
| 【返回值】
| -------| xs : Series or DataFrame
|
| 【注意】
| -----| xs is only for getting, not setting values.
|
| MultiIndex Slicers is a generic way to get/set values on any level or levels
| it is a superset of xs functionality, see :ref:`MultiIndex Slicers &lt;advanced.mi_slicers&gt;`
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.generic.NDFrame:
|
| at
| Fast label-based scalar accessor
|
| Similarly to</code>loc<code>,</code>at<code>provides **label** based scalar lookups.
| You can also set using these indexers.
|
| blocks
| Internal property, property synonym for as_blocks()
|
| empty
| True if NDFrame is entirely empty [no items]
|
| iat
| Fast integer location scalar accessor.
|
| Similarly to</code>iloc<code>,</code>iat<code>provides **integer** based lookups.
| You can also set using these indexers.
|
| iloc
| Purely integer-location based indexing for selection by position.
|
|</code>.iloc[]<code>is primarily integer position based (from</code>0<code>to
|</code>length-1<code>of the axis), but may also be used with a boolean
| array.
|
| Allowed inputs are:
|
| - An integer, e.g.</code>5<code>.
| - A list or array of integers, e.g.</code>[4, 3, 0]<code>.
| - A slice object with ints, e.g.</code>1:7<code>.
| - A boolean array.
|
|</code>.iloc<code>will raise</code>IndexError<code>if a requested indexer is
| out-of-bounds, except *slice* indexers which allow out-of-bounds
| indexing (this conforms with python/numpy *slice* semantics).
|
| See more at :ref:`Selection by Position &lt;indexing.integer&gt;`
|
| ix
| A primarily label-location based indexer, with integer position
| fallback.
469
|
|</code>.ix[]<code>supports mixed integer and label based access. It is
| primarily label based, but will fall back to integer positional
| access unless the corresponding axis is of integer type.
|
|</code>.ix<code>is the most general indexer and will support any of the
| inputs in</code>.loc<code>and</code>.iloc<code>.</code>.ix<code>also supports floating
| point label schemes.</code>.ix<code>is exceptionally useful when dealing
| with mixed positional and label based hierachical indexes.
|
| However, when an axis is integer based, ONLY label based access
| and not positional access is supported. Thus, in such cases, it&#39;s
| usually better to be explicit and use</code>.iloc<code>or</code>.loc<code>.
|
| See more at :ref:`Advanced Indexing &lt;advanced&gt;`.
|
| loc
| Purely label-location based indexer for selection by label.
|
|</code>.loc[]<code>is primarily label based, but may also be used with a
| boolean array.
|
| Allowed inputs are:
|
| - A single label, e.g.</code>5<code>or</code>‘a’<code>, (note that</code>5<code>is
| interpreted as a *label* of the index, and **never** as an
| integer position along the index).
| - A list or array of labels, e.g.</code>[‘a’, ‘b’, ‘c’]<code>.
| - A slice object with labels, e.g.</code>‘a’:’f’<code>(note that contrary
| to usual python slices, **both** the start and the stop are included!).
| - A boolean array.
|
|</code>.loc<code>will raise a</code>KeyError<code>when the items are not found.
|
| See more at :ref:`Selection by Label &lt;indexing.label&gt;`
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.generic.NDFrame:
|
| is_copy = None
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.PandasObject:
|
| __dir__(self)
| Provide method name lookup and completion
| Only provide &#39;public&#39; methods
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
| Return a string representation for a particular object.
|
| Invoked by bytes(obj) in py3 only.
| Yields a bytestring in both py2/py3.
|
470
| __repr__(self)
| Return a string representation for a particular object.
|
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
SparseArray
SparseArray 模块所属：pandas.sparse.array:
类定义：SparseArray(pandas.core.base.PandasObject, numpy.ndarray)
| Data structure for labeled, sparse floating point data
|
| 【参数】
| ----------| data : {array-like, Series, SparseSeries, dict}
| kind : {&#39;block&#39;, &#39;integer&#39;}
| fill_value : float
| Defaults to NaN (code for missing)
| sparse_index : {BlockIndex, IntIndex}, optional
| Only if you have one. Mainly used internally
|
|【注意】
| -----| SparseArray objects are immutable via the typical Python means. If you
| must change values, convert to dense, make your changes, then convert back
| to sparse
|
| 【方法排序】
| SparseArray
| pandas.core.base.PandasObject
| pandas.core.base.StringMixin
| numpy.ndarray
| 【内置对象】
|
| 【方法定义】
|
| __add__ = add(self, other)
|
| __array_finalize__(self, obj)
| Gets called after any ufunc or other array operations, necessary
| to pass on the index.
|
| __div__ = truediv(self, other)
|
471
| __floordiv__ = floordiv(self, other)
|
| __getitem__(self, key)
|
| __getslice__(self, i, j)
|
| __iadd__ = disable(self, other)
|
| __ifloordiv__ = disable(self, other)
|
| __imul__ = disable(self, other)
|
| __ipow__ = disable(self, other)
|
| __isub__ = disable(self, other)
|
| __iter__(self)
| Implement iter(self).
|
| __itruediv__ = disable(self, other)
|
| __len__(self)
| Return len(self).
|
| __mod__ = mod(self, other)
|
| __mul__ = mul(self, other)
|
| __pow__ = pow(self, other)
|
| __radd__ = radd(self, other)
|
| __rdiv__ = rtruediv(self, other)
|
| __reduce__(self)
| Necessary for making this object picklable
|
| __rfloordiv__ = rfloordiv(self, other)
|
| __rmod__ = rmod(self, other)
|
| __rmul__ = rmul(self, other)
|
| __rpow__ = rpow(self, other)
|
| __rsub__ = rsub(self, other)
|
| __rtruediv__ = rtruediv(self, other)
|
| __setitem__(self, key, value)
| Set self[key] to value.
|
| __setslice__(self, i, j, value)
|
| __setstate__(self, state)
| Necessary for making this object picklable
|
472
| __sub__ = sub(self, other)
|
| __truediv__ = truediv(self, other)
|
| __unicode__(self)
| Return a string representation for a particular object.
|
| Invoked by unicode(obj) in py2 only. Yields a Unicode String in both
| py2/py3.
|
| astype(self, dtype=None)
|
| copy(self, deep=True)
| Make a copy of the SparseSeries. Only the actual sparse values need to
| be copied
|
| count(self)
| Compute sum of non-NA/null observations in SparseSeries. If the
| fill_value is not NaN, the &quot;sparse&quot; locations will be included in the
| observation count
|
| 【返回值】
| -------| nobs : int
|
| cumsum(self, axis=0, dtype=None, out=None)
| Cumulative sum of values. Preserves locations of NaN values
|
| Extra parameters are to preserve ndarray interface.
|
| 【返回值】
| -------| cumsum : Series
|
| disable(self, other)
|
| get_values(self, fill=None)
| return a dense representation
|
| mean(self, axis=None, dtype=None, out=None)
| Mean of non-NA/null values
|
| 【返回值】
| -------| mean : float
|
| sum(self, axis=None, dtype=None, out=None)
| Sum of non-NA/null values
|
| 【返回值】
| -------| sum : float
|
| take(self, indices, axis=0)
| Sparse-compatible version of ndarray.take
|
| 【返回值】
473
| -------| taken : ndarray
|
| to_dense(self, fill=None)
| Convert SparseSeries to (dense) Series
|
| ----------------------------------------------------------------------| Static methods defined here:
|
| __new__(cls, data, sparse_index=None, index=None, kind=&#39;integer&#39;, fill_value=None, dtype=&lt;class &#39;numpy.float64&#39;&gt;,
copy=False)
| Create and return a new object. See help(type) for accurate signature.
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| __dict__
| dictionary for instance variables (if defined)
|
| kind
|
| sp_values
|
| values
| Dense values
|
| ----------------------------------------------------------------------| 其他数据、属性定义：
|
| __array_priority__ = 15
|
| fill_value = None
|
| sp_index = None
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.PandasObject:
|
| __dir__(self)
| Provide method name lookup and completion
| Only provide &#39;public&#39; methods
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
| Return a string representation for a particular object.
|
| Invoked by bytes(obj) in py3 only.
| Yields a bytestring in both py2/py3.
|
| __repr__(self)
| Return a string representation for a particular object.
|
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
474
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.base.StringMixin:
|
| __weakref__
| list of weak references to the object (if defined)
|
| ----------------------------------------------------------------------| Methods inherited from numpy.ndarray:
|
| __abs__(self, /)
| abs(self)
|
| __and__(self, value, /)
| Return self&amp;value.
|
| __array__(...)
| a.__array__(|dtype) -&gt; reference if type unchanged, copy otherwise.
|
| Returns either a new reference to self if dtype is not given or a new array
| of provided data type if dtype is different from the current dtype of the
| array.
|
| __array_prepare__(...)
| a.__array_prepare__(obj) -&gt; Object of same type as ndarray object obj.
|
| __array_wrap__(...)
| a.__array_wrap__(obj) -&gt; Object of same type as ndarray object a.
|
| __bool__(self, /)
| self != 0
|
| __contains__(self, key, /)
| Return key in self.
|
| __copy__(...)
| a.__copy__([order])
|
| Return a copy of the array.
|
| 【参数】
| ----------| order : {&#39;C&#39;, &#39;F&#39;, &#39;A&#39;}, optional
| If order is &#39;C&#39; (False) then the result is contiguous (default).
| If order is &#39;Fortran&#39; (True) then the result has fortran order.
| If order is &#39;Any&#39; (None) then the result has fortran order
| only if the array already is in fortran order.
|
| __deepcopy__(...)
| a.__deepcopy__() -&gt; Deep copy of array.
|
| Used if copy.deepcopy is called on an array.
|
475
| __delitem__(self, key, /)
| Delete self[key].
|
| __divmod__(self, value, /)
| Return divmod(self, value).
|
| __eq__(self, value, /)
| Return self==value.
|
| __float__(self, /)
| float(self)
|
| __ge__(self, value, /)
| Return self&gt;=value.
|
| __gt__(self, value, /)
| Return self&gt;value.
|
| __iand__(self, value, /)
| Return self&amp;=value.
|
| __ilshift__(self, value, /)
| Return self&lt;&lt;=value.
|
| __imod__(self, value, /)
| Return self%=value.
|
| __index__(self, /)
| Return self converted to an integer, if self is suitable for use as an index into a list.
|
| __int__(self, /)
| int(self)
|
| __invert__(self, /)
| ~self
|
| __ior__(self, value, /)
| Return self|=value.
|
| __irshift__(self, value, /)
| Return self&gt;&gt;=value.
|
| __ixor__(self, value, /)
| Return self^=value.
|
| __le__(self, value, /)
| Return self&lt;=value.
|
| __lshift__(self, value, /)
| Return self&lt;&lt;value.
|
| __lt__(self, value, /)
| Return self&lt;value.
|
| __ne__(self, value, /)
| Return self!=value.
|
476
| __neg__(self, /)
| -self
|
| __or__(self, value, /)
| Return self|value.
|
| __pos__(self, /)
| +self
|
| __rand__(self, value, /)
| Return value&amp;self.
|
| __rdivmod__(self, value, /)
| Return divmod(value, self).
|
| __rlshift__(self, value, /)
| Return value&lt;&lt;self.
|
| __ror__(self, value, /)
| Return value|self.
|
| __rrshift__(self, value, /)
| Return value&gt;&gt;self.
|
| __rshift__(self, value, /)
| Return self&gt;&gt;value.
|
| __rxor__(self, value, /)
| Return value^self.
|
| __xor__(self, value, /)
| Return self^value.
|
| all(...)
| a.all(axis=None, out=None)
|
| Returns True if all elements evaluate to True.
|
| Refer to `numpy.all` for full documentation.
|
| 【参见】
| --------| numpy.all : equivalent function
|
| any(...)
| a.any(axis=None, out=None)
|
| Returns True if any of the elements of `a` evaluate to True.
|
| Refer to `numpy.any` for full documentation.
|
| 【参见】
| --------| numpy.any : equivalent function
|
| argmax(...)
| a.argmax(axis=None, out=None)
477
|
| Return indices of the maximum values along the given axis.
|
| Refer to `numpy.argmax` for full documentation.
|
| 【参见】
| --------| numpy.argmax : equivalent function
|
| argmin(...)
| a.argmin(axis=None, out=None)
|
| Return indices of the minimum values along the given axis of `a`.
|
| Refer to `numpy.argmin` for detailed documentation.
|
| 【参见】
| --------| numpy.argmin : equivalent function
|
| argpartition(...)
| a.argpartition(kth, axis=-1, kind=&#39;introselect&#39;, order=None)
|
| Returns the indices that would partition this array.
|
| Refer to `numpy.argpartition` for full documentation.
|
| .. versionadded:: 1.8.0
|
| 【参见】
| --------| numpy.argpartition : equivalent function
|
| argsort(...)
| a.argsort(axis=-1, kind=&#39;quicksort&#39;, order=None)
|
| Returns the indices that would sort this array.
|
| Refer to `numpy.argsort` for full documentation.
|
| 【参见】
| --------| numpy.argsort : equivalent function
|
| byteswap(...)
| a.byteswap(inplace)
|
| Swap the bytes of the array elements
|
| Toggle between low-endian and big-endian data representation by
| returning a byteswapped array, optionally swapped in-place.
|
| 【参数】
| ----------| inplace : bool, optional
| If</code>True<code>, swap bytes in-place, default is</code>False<code>.
|
478
| 【返回值】
| -------| out : ndarray
| The byteswapped array. If `inplace` is</code>True<code>, this is
| a view to self.
|
| 【示例】
| --------| &gt;&gt;&gt; A = np.array([1, 256, 8755], dtype=np.int16)
| &gt;&gt;&gt; map(hex, A)
| [&#39;0x1&#39;, &#39;0x100&#39;, &#39;0x2233&#39;]
| &gt;&gt;&gt; A.byteswap(True)
| array([ 256, 1, 13090], dtype=int16)
| &gt;&gt;&gt; map(hex, A)
| [&#39;0x100&#39;, &#39;0x1&#39;, &#39;0x3322&#39;]
|
| Arrays of strings are not swapped
|
| &gt;&gt;&gt; A = np.array([&#39;ceg&#39;, &#39;fac&#39;])
| &gt;&gt;&gt; A.byteswap()
| array([&#39;ceg&#39;, &#39;fac&#39;],
| dtype=&#39;|S3&#39;)
|
| choose(...)
| a.choose(choices, out=None, mode=&#39;raise&#39;)
|
| Use an index array to construct a new array from a set of choices.
|
| Refer to `numpy.choose` for full documentation.
|
| 【参见】
| --------| numpy.choose : equivalent function
|
| clip(...)
| a.clip(a_min, a_max, out=None)
|
| Return an array whose values are limited to</code>[a_min, a_max]<code>.
|
| Refer to `numpy.clip` for full documentation.
|
| 【参见】
| --------| numpy.clip : equivalent function
|
| compress(...)
| a.compress(condition, axis=None, out=None)
|
| Return selected slices of this array along given axis.
|
| Refer to `numpy.compress` for full documentation.
|
| 【参见】
| --------| numpy.compress : equivalent function
|
| conj(...)
479
| a.conj()
|
| Complex-conjugate all elements.
|
| Refer to `numpy.conjugate` for full documentation.
|
| 【参见】
| --------| numpy.conjugate : equivalent function
|
| conjugate(...)
| a.conjugate()
|
| Return the complex conjugate, element-wise.
|
| Refer to `numpy.conjugate` for full documentation.
|
| 【参见】
| --------| numpy.conjugate : equivalent function
|
| cumprod(...)
| a.cumprod(axis=None, dtype=None, out=None)
|
| Return the cumulative product of the elements along the given axis.
|
| Refer to `numpy.cumprod` for full documentation.
|
| 【参见】
| --------| numpy.cumprod : equivalent function
|
| diagonal(...)
| a.diagonal(offset=0, axis1=0, axis2=1)
|
| Return specified diagonals. In NumPy 1.9 the returned array is a
| read-only view instead of a copy as in previous NumPy versions. In
| NumPy 1.10 the read-only restriction will be removed.
|
| Refer to :func:`numpy.diagonal` for full documentation.
|
| 【参见】
| --------| numpy.diagonal : equivalent function
|
| dot(...)
| a.dot(b, out=None)
|
| Dot product of two arrays.
|
| Refer to `numpy.dot` for full documentation.
|
| 【参见】
| --------| numpy.dot : equivalent function
|
| 【示例】
480
| --------| &gt;&gt;&gt; a = np.eye(2)
| &gt;&gt;&gt; b = np.ones((2, 2)) * 2
| &gt;&gt;&gt; a.dot(b)
| array([[ 2., 2.],
| [ 2., 2.]])
|
| This array method can be conveniently chained:
|
| &gt;&gt;&gt; a.dot(b).dot(b)
| array([[ 8., 8.],
| [ 8., 8.]])
|
| dump(...)
| a.dump(file)
|
| Dump a pickle of the array to the specified file.
| The array can be read back with pickle.load or numpy.load.
|
| 【参数】
| ----------| file : str
| A string naming the dump file.
|
| dumps(...)
| a.dumps()
|
| Returns the pickle of the array as a string.
| pickle.loads or numpy.loads will convert the string back to an array.
|
| 【参数】
| ----------| None
|
| fill(...)
| a.fill(value)
|
| Fill the array with a scalar value.
|
| 【参数】
| ----------| value : scalar
| All elements of `a` will be assigned this value.
|
| 【示例】
| --------| &gt;&gt;&gt; a = np.array([1, 2])
| &gt;&gt;&gt; a.fill(0)
| &gt;&gt;&gt; a
| array([0, 0])
| &gt;&gt;&gt; a = np.empty(2)
| &gt;&gt;&gt; a.fill(1)
| &gt;&gt;&gt; a
| array([ 1., 1.])
|
| flatten(...)
| a.flatten(order=&#39;C&#39;)
481
|
| Return a copy of the array collapsed into one dimension.
|
| 【参数】
| ----------| order : {&#39;C&#39;, &#39;F&#39;, &#39;A&#39;}, optional
| Whether to flatten in C (row-major), Fortran (column-major) order,
| or preserve the C/Fortran ordering from `a`.
| The default is &#39;C&#39;.
|
| 【返回值】
| -------| y : ndarray
| A copy of the input array, flattened to one dimension.
|
| 【参见】
| --------| ravel : Return a flattened array.
| flat : A 1-D flat iterator over the array.
|
| 【示例】
| --------| &gt;&gt;&gt; a = np.array([[1,2], [3,4]])
| &gt;&gt;&gt; a.flatten()
| array([1, 2, 3, 4])
| &gt;&gt;&gt; a.flatten(&#39;F&#39;)
| array([1, 3, 2, 4])
|
| getfield(...)
| a.getfield(dtype, offset=0)
|
| Returns a field of the given array as a certain type.
|
| A field is a view of the array data with a given data-type. The values in
| the view are determined by the given type and the offset into the current
| array in bytes. The offset needs to be such that the view dtype fits in the
| array dtype; for example an array of dtype complex128 has 16-byte elements.
| If taking a view with a 32-bit integer (4 bytes), the offset needs to be
| between 0 and 12 bytes.
|
| 【参数】
| ----------| dtype : str or dtype
| The data type of the view. The dtype size of the view can not be larger
| than that of the array itself.
| offset : int
| Number of bytes to skip before beginning the element view.
|
| 【示例】
| --------| &gt;&gt;&gt; x = np.diag([1.+1.j]*2)
| &gt;&gt;&gt; x[1, 1] = 2 + 4.j
| &gt;&gt;&gt; x
| array([[ 1.+1.j, 0.+0.j],
| [ 0.+0.j, 2.+4.j]])
| &gt;&gt;&gt; x.getfield(np.float64)
| array([[ 1., 0.],
482
| [ 0., 2.]])
|
| By choosing an offset of 8 bytes we can select the complex part of the
| array for our view:
|
| &gt;&gt;&gt; x.getfield(np.float64, offset=8)
| array([[ 1., 0.],
| [ 0., 4.]])
|
| item(...)
| a.item(*args)
|
| Copy an element of an array to a standard Python scalar and return it.
|
| 【参数】
| ----------| \*args : Arguments (variable number and type)
|
| * none: in this case, the method only works for arrays
| with one element (`a.size == 1`), which element is
| copied into a standard Python scalar object and returned.
|
| * int_type: this argument is interpreted as a flat index into
| the array, specifying which element to copy and return.
|
| * tuple of int_types: functions as does a single int_type argument,
| except that the argument is interpreted as an nd-index into the
| array.
|
| 【返回值】
| -------| z : Standard Python scalar object
| A copy of the specified element of the array as a suitable
| Python scalar
|
| 【注意】
| -----| When the data type of `a` is longdouble or clongdouble, item() returns
| a scalar array object because there is no available Python scalar that
| would not lose information. Void arrays return a buffer object for item(),
| unless fields are defined, in which case a tuple is returned.
|
| `item` is very similar to a[args], except, instead of an array scalar,
| a standard Python scalar is returned. This can be useful for speeding up
| access to elements of the array and doing arithmetic on elements of the
| array using Python&#39;s optimized math.
|
| 【示例】
| --------| &gt;&gt;&gt; x = np.random.randint(9, size=(3, 3))
| &gt;&gt;&gt; x
| array([[3, 1, 7],
| [2, 8, 3],
| [8, 5, 3]])
| &gt;&gt;&gt; x.item(3)
| 2
| &gt;&gt;&gt; x.item(7)
483
| 5
| &gt;&gt;&gt; x.item((0, 1))
| 1
| &gt;&gt;&gt; x.item((2, 2))
| 3
|
| itemset(...)
| a.itemset(*args)
|
| Insert scalar into an array (scalar is cast to array&#39;s dtype, if possible)
|
| There must be at least 1 argument, and define the last argument
| as *item*. Then,</code>a.itemset(<em>args)<code>is equivalent to but faster
| than</code>a[args] = item<code>`. The item should be a scalar value and</code>args<code>| must select a single item in the array</code>a`.<br>|<br>| 【参数】<br>| ———-| \</em>args : Arguments<br>| If one argument: a scalar, only used in case <code>a</code> is of size 1.<br>| If two arguments: the last argument is the value to be set<br>| and must be a scalar, the first argument specifies a single array<br>| element location. It is either an int or a tuple.<br>|<br>| 【注意】<br>| —–| Compared to indexing syntax, <code>itemset</code> provides some speed increase<br>| for placing a scalar into a particular location in an <code>ndarray</code>,<br>| if you must do this. However, generally this is discouraged:<br>| among other problems, it complicates the appearance of the code.<br>| Also, when using <code>itemset</code> (and <code>item</code>) inside a loop, be sure<br>| to assign the methods to a local variable to avoid the attribute<br>| look-up at each loop iteration.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; x = np.random.randint(9, size=(3, 3))<br>| &gt;&gt;&gt; x<br>| array([[3, 1, 7],<br>| [2, 8, 3],<br>| [8, 5, 3]])<br>| &gt;&gt;&gt; x.itemset(4, 0)<br>| &gt;&gt;&gt; x.itemset((2, 2), 9)<br>| &gt;&gt;&gt; x<br>| array([[3, 1, 7],<br>| [2, 0, 3],<br>| [8, 5, 9]])<br>|<br>| max(…)<br>| a.max(axis=None, out=None)<br>|<br>| Return the maximum along a given axis.<br>|<br>| Refer to <code>numpy.amax</code> for full documentation.<br>|<br>| 【参见】<br>| ——–<br>484<br>| numpy.amax : equivalent function<br>|<br>| min(…)<br>| a.min(axis=None, out=None)<br>|<br>| Return the minimum along a given axis.<br>|<br>| Refer to <code>numpy.amin</code> for full documentation.<br>|<br>| 【参见】<br>| ——–| numpy.amin : equivalent function<br>|<br>| newbyteorder(…)<br>| arr.newbyteorder(new_order=’S’)<br>|<br>| Return the array with the same data viewed with a different byte order.<br>|<br>| Equivalent to::<br>|<br>| arr.view(arr.dtype.newbytorder(new_order))<br>|<br>| Changes are also made in all fields and sub-arrays of the array data<br>| type.<br>|<br>|<br>|<br>| 【参数】<br>| ———-| new_order : string, optional<br>| Byte order to force; a value from the byte order specifications<br>| above. <code>new_order</code> codes can be any of::<br>|<br>| <em> ‘S’ - swap dtype from current to opposite endian<br>| </em> {‘&lt;’, ‘L’} - little endian<br>| <em> {‘&gt;’, ‘B’} - big endian<br>| </em> {‘=’, ‘N’} - native order<br>| <em> {‘|’, ‘I’} - ignore (no change to byte order)<br>|<br>| The default value (‘S’) results in swapping the current<br>| byte order. The code does a case-insensitive check on the first<br>| letter of <code>new_order</code> for the alternatives above. For example,<br>| any of ‘B’ or ‘b’ or ‘biggish’ are valid to specify big-endian.<br>|<br>|<br>| 【返回值】<br>| ——-| new_arr : array<br>| New array object with the dtype reflecting given change to the<br>| byte order.<br>|<br>| nonzero(…)<br>| a.nonzero()<br>|<br>| Return the indices of the elements that are non-zero.<br>|<br>| Refer to <code>numpy.nonzero</code> for full documentation.<br>485<br>|<br>| 【参见】<br>| ——–| numpy.nonzero : equivalent function<br>|<br>| partition(…)<br>| a.partition(kth, axis=-1, kind=’introselect’, order=None)<br>|<br>| Rearranges the elements in the array in such a way that value of the<br>| element in kth position is in the position it would be in a sorted array.<br>| All elements smaller than the kth element are moved before this element and<br>| all equal or greater are moved behind it. The ordering of the elements in<br>| the two partitions is undefined.<br>|<br>| .. versionadded:: 1.8.0<br>|<br>| 【参数】<br>| ———-| kth : int or sequence of ints<br>| Element index to partition by. The kth element value will be in its<br>| final sorted position and all smaller elements will be moved before it<br>| and all equal or greater elements behind it.<br>| The order all elements in the partitions is undefined.<br>| If provided with a sequence of kth it will partition all elements<br>| indexed by kth of them into their sorted position at once.<br>| axis : int, optional<br>| Axis along which to sort. Default is -1, which means sort along the<br>| last axis.<br>| kind : {‘introselect’}, optional<br>| Selection algorithm. Default is ‘introselect’.<br>| order : list, optional<br>| When <code>a</code> is an array with fields defined, this argument specifies<br>| which fields to compare first, second, etc. Not all fields need be<br>| specified.<br>|<br>| 【参见】<br>| ——–| numpy.partition : Return a parititioned copy of an array.<br>| argpartition : Indirect partition.<br>| sort : Full sort.<br>|<br>| 【注意】<br>| —–| See <code>np.partition</code> for notes on the different algorithms.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; a = np.array([3, 4, 2, 1])<br>| &gt;&gt;&gt; a.partition(a, 3)<br>| &gt;&gt;&gt; a<br>| array([2, 1, 3, 4])<br>|<br>| &gt;&gt;&gt; a.partition((1, 3))<br>| array([1, 2, 3, 4])<br>|<br>| prod(…)<br>| a.prod(axis=None, dtype=None, out=None)<br>486<br>|<br>| Return the product of the array elements over the given axis<br>|<br>| Refer to <code>numpy.prod</code> for full documentation.<br>|<br>| 【参见】<br>| ——–| numpy.prod : equivalent function<br>|<br>| ptp(…)<br>| a.ptp(axis=None, out=None)<br>|<br>| Peak to peak (maximum - minimum) value along a given axis.<br>|<br>| Refer to <code>numpy.ptp</code> for full documentation.<br>|<br>| 【参见】<br>| ——–| numpy.ptp : equivalent function<br>|<br>| put(…)<br>| a.put(indices, values, mode=’raise’)<br>|<br>| Set <code>a.flat[n] = values[n]</code> for all <code>n</code> in indices.<br>|<br>| Refer to <code>numpy.put</code> for full documentation.<br>|<br>| 【参见】<br>| ——–| numpy.put : equivalent function<br>|<br>| ravel(…)<br>| a.ravel([order])<br>|<br>| Return a flattened array.<br>|<br>| Refer to <code>numpy.ravel</code> for full documentation.<br>|<br>| 【参见】<br>| ——–| numpy.ravel : equivalent function<br>|<br>| ndarray.flat : a flat iterator on the array.<br>|<br>| repeat(…)<br>| a.repeat(repeats, axis=None)<br>|<br>| Repeat elements of an array.<br>|<br>| Refer to <code>numpy.repeat</code> for full documentation.<br>|<br>| 【参见】<br>| ——–| numpy.repeat : equivalent function<br>|<br>| reshape(…)<br>| a.reshape(shape, order=’C’)<br>487<br>|<br>| Returns an array containing the same data with a new shape.<br>|<br>| Refer to <code>numpy.reshape</code> for full documentation.<br>|<br>| 【参见】<br>| ——–| numpy.reshape : equivalent function<br>|<br>| resize(…)<br>| a.resize(new_shape, refcheck=True)<br>|<br>| Change shape and size of array in-place.<br>|<br>| 【参数】<br>| ———-| new_shape : tuple of ints, or <code>n</code> ints<br>| Shape of resized array.<br>| refcheck : bool, optional<br>| If False, reference count will not be checked. Default is True.<br>|<br>| 【返回值】<br>| ——-| None<br>|<br>| 【Raises 引发错误】<br>| ——| ValueError<br>| If <code>a</code> does not own its own data or references or views to it exist,<br>| and the data memory must be changed.<br>|<br>| SystemError<br>| If the <code>order</code> keyword argument is specified. This behaviour is a<br>| bug in NumPy.<br>|<br>| 【参见】<br>| ——–| resize : Return a new array with the specified shape.<br>|<br>| 【注意】<br>| —–| This reallocates space for the data area if necessary.<br>|<br>| Only contiguous arrays (data elements consecutive in memory) can be<br>| resized.<br>|<br>| The purpose of the reference count check is to make sure you<br>| do not use this array as a buffer for another Python object and then<br>| reallocate the memory. However, reference counts can increase in<br>| other ways so if you are sure that you have not shared the memory<br>| for this array with another Python object, then you may safely set<br>| <code>refcheck</code> to False.<br>|<br>| 【示例】<br>| ——–| Shrinking an array: array is flattened (in the order that the data are<br>| stored in memory), resized, and reshaped:<br>488<br>|<br>| &gt;&gt;&gt; a = np.array([[0, 1], [2, 3]], order=’C’)<br>| &gt;&gt;&gt; a.resize((2, 1))<br>| &gt;&gt;&gt; a<br>| array([[0],<br>| [1]])<br>|<br>| &gt;&gt;&gt; a = np.array([[0, 1], [2, 3]], order=’F’)<br>| &gt;&gt;&gt; a.resize((2, 1))<br>| &gt;&gt;&gt; a<br>| array([[0],<br>| [2]])<br>|<br>| Enlarging an array: as above, but missing entries are filled with zeros:<br>|<br>| &gt;&gt;&gt; b = np.array([[0, 1], [2, 3]])<br>| &gt;&gt;&gt; b.resize(2, 3) # new_shape parameter doesn’t have to be a tuple<br>| &gt;&gt;&gt; b<br>| array([[0, 1, 2],<br>| [3, 0, 0]])<br>|<br>| Referencing an array prevents resizing…<br>|<br>| &gt;&gt;&gt; c = a<br>| &gt;&gt;&gt; a.resize((1, 1))<br>| Traceback (most recent call last):<br>| …<br>| ValueError: cannot resize an array that has been referenced …<br>|<br>| Unless <code>refcheck</code> is False:<br>|<br>| &gt;&gt;&gt; a.resize((1, 1), refcheck=False)<br>| &gt;&gt;&gt; a<br>| array([[0]])<br>| &gt;&gt;&gt; c<br>| array([[0]])<br>|<br>| round(…)<br>| a.round(decimals=0, out=None)<br>|<br>| Return <code>a</code> with each element rounded to the given number of decimals.<br>|<br>| Refer to <code>numpy.around</code> for full documentation.<br>|<br>| 【参见】<br>| ——–| numpy.around : equivalent function<br>|<br>| searchsorted(…)<br>| a.searchsorted(v, side=’left’, sorter=None)<br>|<br>| Find indices where elements of v should be inserted in a to maintain order.<br>|<br>| For full documentation, see <code>numpy.searchsorted</code><br>|<br>| 【参见】<br>| ——–<br>489<br>| numpy.searchsorted : equivalent function<br>|<br>| setfield(…)<br>| a.setfield(val, dtype, offset=0)<br>|<br>| Put a value into a specified place in a field defined by a data-type.<br>|<br>| Place <code>val</code> into <code>a</code>‘s field defined by <code>dtype</code> and beginning <code>offset</code><br>| bytes into the field.<br>|<br>| 【参数】<br>| ———-| val : object<br>| Value to be placed in field.<br>| dtype : dtype object<br>| Data-type of the field in which to place <code>val</code>.<br>| offset : int, optional<br>| The number of bytes into the field at which to place <code>val</code>.<br>|<br>| 【返回值】<br>| ——-| None<br>|<br>| 【参见】<br>| ——–| getfield<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; x = np.eye(3)<br>| &gt;&gt;&gt; x.getfield(np.float64)<br>| array([[ 1., 0., 0.],<br>| [ 0., 1., 0.],<br>| [ 0., 0., 1.]])<br>| &gt;&gt;&gt; x.setfield(3, np.int32)<br>| &gt;&gt;&gt; x.getfield(np.int32)<br>| array([[3, 3, 3],<br>| [3, 3, 3],<br>| [3, 3, 3]])<br>| &gt;&gt;&gt; x<br>| array([[ 1.00000000e+000, 1.48219694e-323, 1.48219694e-323],<br>| [ 1.48219694e-323, 1.00000000e+000, 1.48219694e-323],<br>| [ 1.48219694e-323, 1.48219694e-323, 1.00000000e+000]])<br>| &gt;&gt;&gt; x.setfield(np.eye(3), np.int32)<br>| &gt;&gt;&gt; x<br>| array([[ 1., 0., 0.],<br>| [ 0., 1., 0.],<br>| [ 0., 0., 1.]])<br>|<br>| setflags(…)<br>| a.setflags(write=None, align=None, uic=None)<br>|<br>| Set array flags WRITEABLE, ALIGNED, and UPDATEIFCOPY, respectively.<br>|<br>| These Boolean-valued flags affect how numpy interprets the memory<br>| area used by <code>a</code> (see Notes below). The ALIGNED flag can only<br>| be set to True if the data is actually aligned according to the type.<br>490<br>| The UPDATEIFCOPY flag can never be set to True. The flag WRITEABLE<br>| can only be set to True if the array owns its own memory, or the<br>| ultimate owner of the memory exposes a writeable buffer interface,<br>| or is a string. (The exception for string is made so that unpickling<br>| can be done without copying memory.)<br>|<br>| 【参数】<br>| ———-| write : bool, optional<br>| Describes whether or not <code>a</code> can be written to.<br>| align : bool, optional<br>| Describes whether or not <code>a</code> is aligned properly for its type.<br>| uic : bool, optional<br>| Describes whether or not <code>a</code> is a copy of another “base” array.<br>|<br>| 【注意】<br>| —–| Array flags provide information about how the memory area used<br>| for the array is to be interpreted. There are 6 Boolean flags<br>| in use, only three of which can be changed by the user:<br>| UPDATEIFCOPY, WRITEABLE, and ALIGNED.<br>|<br>| WRITEABLE (W) the data area can be written to;<br>|<br>| ALIGNED (A) the data and strides are aligned appropriately for the hardware<br>| (as determined by the compiler);<br>|<br>| UPDATEIFCOPY (U) this array is a copy of some other array (referenced<br>| by .base). When this array is deallocated, the base array will be<br>| updated with the contents of this array.<br>|<br>| All flags can be accessed using their first (upper case) letter as well<br>| as the full name.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; y<br>| array([[3, 1, 7],<br>| [2, 0, 0],<br>| [8, 5, 9]])<br>| &gt;&gt;&gt; y.flags<br>| C_CONTIGUOUS : True<br>| F_CONTIGUOUS : False<br>| OWNDATA : True<br>| WRITEABLE : True<br>| ALIGNED : True<br>| UPDATEIFCOPY : False<br>| &gt;&gt;&gt; y.setflags(write=0, align=0)<br>| &gt;&gt;&gt; y.flags<br>| C_CONTIGUOUS : True<br>| F_CONTIGUOUS : False<br>| OWNDATA : True<br>| WRITEABLE : False<br>| ALIGNED : False<br>| UPDATEIFCOPY : False<br>| &gt;&gt;&gt; y.setflags(uic=1)<br>| Traceback (most recent call last):<br>491<br>| File “<stdin>“, line 1, in <module><br>| ValueError: cannot set UPDATEIFCOPY flag to True<br>|<br>| sort(…)<br>| a.sort(axis=-1, kind=’quicksort’, order=None)<br>|<br>| Sort an array, in-place.<br>|<br>| 【参数】<br>| ———-| axis : int, optional<br>| Axis along which to sort. Default is -1, which means sort along the<br>| last axis.<br>| kind : {‘quicksort’, ‘mergesort’, ‘heapsort’}, optional<br>| Sorting algorithm. Default is ‘quicksort’.<br>| order : list, optional<br>| When <code>a</code> is an array with fields defined, this argument specifies<br>| which fields to compare first, second, etc. Not all fields need be<br>| specified.<br>|<br>| 【参见】<br>| ——–| numpy.sort : Return a sorted copy of an array.<br>| argsort : Indirect sort.<br>| lexsort : Indirect stable sort on multiple keys.<br>| searchsorted : Find elements in sorted array.<br>| partition: Partial sort.<br>|<br>| 【注意】<br>| —–| See <code>sort</code> for notes on the different sorting algorithms.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; a = np.array([[1,4], [3,1]])<br>| &gt;&gt;&gt; a.sort(axis=1)<br>| &gt;&gt;&gt; a<br>| array([[1, 4],<br>| [1, 3]])<br>| &gt;&gt;&gt; a.sort(axis=0)<br>| &gt;&gt;&gt; a<br>| array([[1, 3],<br>| [1, 4]])<br>|<br>| Use the <code>order</code> keyword to specify a field to use when sorting a<br>| structured array:<br>|<br>| &gt;&gt;&gt; a = np.array([(‘a’, 2), (‘c’, 1)], dtype=[(‘x’, ‘S1’), (‘y’, int)])<br>| &gt;&gt;&gt; a.sort(order=’y’)<br>| &gt;&gt;&gt; a<br>| array([(‘c’, 1), (‘a’, 2)],<br>| dtype=[(‘x’, ‘|S1’), (‘y’, ‘<i4')]) 492="" |="" squeeze(...)="" a.squeeze(axis="None)" remove="" single-dimensional="" entries="" from="" the="" shape="" of="" `a`.="" refer="" to="" `numpy.squeeze`="" for="" full="" documentation.="" 【参见】="" --------|="" numpy.squeeze="" :="" equivalent="" function="" std(...)="" a.std(axis="None," dtype="None," out="None," ddof="0)" returns="" standard="" deviation="" array="" elements="" along="" given="" axis.="" `numpy.std`="" numpy.std="" swapaxes(...)="" a.swapaxes(axis1,="" axis2)="" return="" a="" view="" with="" `axis1`="" and="" `axis2`="" interchanged.="" `numpy.swapaxes`="" numpy.swapaxes="" tobytes(...)="" a.tobytes(order="C" )="" construct="" python="" bytes="" containing="" raw="" data="" in="" array.="" constructs="" showing="" copy="" contents="" memory.="" object="" can="" be="" produced="" either="" 'c'="" or="" 'fortran',="" 'any'="" order="" (the="" default is="" 'c'-order).="" means="" c-order="" unless="" f_contiguous="" flag="" set,="" which="" case="" it="" 'fortran'="" order.="" ..="" versionadded::="" 1.9.0="" 【参数】="" ----------|="" {'c',="" 'f',="" none},="" optional="" multidimensional="" arrays:="" c,="" fortran,="" same="" as="" original="" 【返回值】="" -------|="" s="" exhibiting="" `a`'s="" data.="" 【示例】="">&gt;&gt; x = np.array([[0, 1], [2, 3]])<br>| &gt;&gt;&gt; x.tobytes()<br>493<br>| b’\x00\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x00\x03\x00\x00\x00’<br>| &gt;&gt;&gt; x.tobytes(‘C’) == x.tobytes()<br>| True<br>| &gt;&gt;&gt; x.tobytes(‘F’)<br>| b’\x00\x00\x00\x00\x02\x00\x00\x00\x01\x00\x00\x00\x03\x00\x00\x00’<br>|<br>| tofile(…)<br>| a.tofile(fid, sep=””, format=”%s”)<br>|<br>| Write array to a file as text or binary (default).<br>|<br>| Data is always written in ‘C’ order, independent of the order of <code>a</code>.<br>| The data produced by this method can be recovered using the function<br>| fromfile().<br>|<br>| 【参数】<br>| ———-| fid : file or str<br>| An open file object, or a string containing a filename.<br>| sep : str<br>| Separator between array items for text output.<br>| If “” (empty), a binary file is written, equivalent to<br>| <code>file.write(a.tobytes())</code>.<br>| format : str<br>| Format string for text file output.<br>| Each entry in the array is formatted to text by first converting<br>| it to the closest Python type, and then using “format” % item.<br>|<br>| 【注意】<br>| —–| This is a convenience function for quick storage of array data.<br>| Information on endianness and precision is lost, so this method is not a<br>| good choice for files intended to archive data or transport data between<br>| machines with different endianness. Some of these problems can be overcome<br>| by outputting the data as text files, at the expense of speed and file<br>| size.<br>|<br>| tolist(…)<br>| a.tolist()<br>|<br>| Return the array as a (possibly nested) list.<br>|<br>| Return a copy of the array data as a (nested) Python list.<br>| Data items are converted to the nearest compatible Python type.<br>|<br>| 【参数】<br>| ———-| none<br>|<br>| 【返回值】<br>| ——-| y : list<br>| The possibly nested list of array elements.<br>|<br>| 【注意】<br>| —–| The array may be recreated, <code>a = np.array(a.tolist())</code>.<br>494<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; a = np.array([1, 2])<br>| &gt;&gt;&gt; a.tolist()<br>| [1, 2]<br>| &gt;&gt;&gt; a = np.array([[1, 2], [3, 4]])<br>| &gt;&gt;&gt; list(a)<br>| [array([1, 2]), array([3, 4])]<br>| &gt;&gt;&gt; a.tolist()<br>| [[1, 2], [3, 4]]<br>|<br>| tostring(…)<br>| a.tostring(order=’C’)<br>|<br>| Construct Python bytes containing the raw data bytes in the array.<br>|<br>| Constructs Python bytes showing a copy of the raw contents of<br>| data memory. The bytes object can be produced in either ‘C’ or ‘Fortran’,<br>| or ‘Any’ order (the default is ‘C’-order). ‘Any’ order means C-order<br>| unless the F_CONTIGUOUS flag in the array is set, in which case it<br>| means ‘Fortran’ order.<br>|<br>| This function is a compatibility alias for tobytes. Despite its name it returns bytes not strings.<br>|<br>| 【参数】<br>| ———-| order : {‘C’, ‘F’, None}, optional<br>| Order of the data for multidimensional arrays:<br>| C, Fortran, or the same as for the original array.<br>|<br>| 【返回值】<br>| ——-| s : bytes<br>| Python bytes exhibiting a copy of <code>a</code>‘s raw data.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; x = np.array([[0, 1], [2, 3]])<br>| &gt;&gt;&gt; x.tobytes()<br>| b’\x00\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x00\x03\x00\x00\x00’<br>| &gt;&gt;&gt; x.tobytes(‘C’) == x.tobytes()<br>| True<br>| &gt;&gt;&gt; x.tobytes(‘F’)<br>| b’\x00\x00\x00\x00\x02\x00\x00\x00\x01\x00\x00\x00\x03\x00\x00\x00’<br>|<br>| trace(…)<br>| a.trace(offset=0, axis1=0, axis2=1, dtype=None, out=None)<br>|<br>| Return the sum along diagonals of the array.<br>|<br>| Refer to <code>numpy.trace</code> for full documentation.<br>|<br>| 【参见】<br>| ——–| numpy.trace : equivalent function<br>|<br>495<br>| transpose(…)<br>| a.transpose(</i4')])></module></stdin></em>axes)<br>|<br>| Returns a view of the array with axes transposed.<br>|<br>| For a 1-D array, this has no effect. (To change between column and<br>| row vectors, first cast the 1-D array into a matrix object.)<br>| For a 2-D array, this is the usual matrix transpose.<br>| For an n-D array, if axes are given, their order indicates how the<br>| axes are permuted (see Examples). If axes are not provided and<br>| <code>a.shape = (i[0], i[1], ... i[n-2], i[n-1])</code>, then<br>| <code>a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0])</code>.<br>|<br>| 【参数】<br>| ———-| axes : None, tuple of ints, or <code>n</code> ints<br>|<br>| <em> None or no argument: reverses the order of the axes.<br>|<br>| </em> tuple of ints: <code>i</code> in the <code>j</code>-th place in the tuple means <code>a</code>‘s<br>| <code>i</code>-th axis becomes <code>a.transpose()</code>‘s <code>j</code>-th axis.<br>|<br>| <em> <code>n</code> ints: same as an n-tuple of the same ints (this form is<br>| intended simply as a “convenience” alternative to the tuple form)<br>|<br>| 【返回值】<br>| ——-| out : ndarray<br>| View of <code>a</code>, with axes suitably permuted.<br>|<br>| 【参见】<br>| ——–| ndarray.T : Array property returning the array transposed.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; a = np.array([[1, 2], [3, 4]])<br>| &gt;&gt;&gt; a<br>| array([[1, 2],<br>| [3, 4]])<br>| &gt;&gt;&gt; a.transpose()<br>| array([[1, 3],<br>| [2, 4]])<br>| &gt;&gt;&gt; a.transpose((1, 0))<br>| array([[1, 3],<br>| [2, 4]])<br>| &gt;&gt;&gt; a.transpose(1, 0)<br>| array([[1, 3],<br>| [2, 4]])<br>|<br>| var(…)<br>| a.var(axis=None, dtype=None, out=None, ddof=0)<br>|<br>| Returns the variance of the array elements, along given axis.<br>|<br>| Refer to <code>numpy.var</code> for full documentation.<br>|<br>496<br>| 【参见】<br>| ——–| numpy.var : equivalent function<br>|<br>| view(…)<br>| a.view(dtype=None, type=None)<br>|<br>| New view of array with the same data.<br>|<br>| 【参数】<br>| ———-| dtype : data-type or ndarray sub-class, optional<br>| Data-type descriptor of the returned view, e.g., float32 or int16. The<br>| default, None, results in the view having the same data-type as <code>a</code>.<br>| This argument can also be specified as an ndarray sub-class, which<br>| then specifies the type of the returned object (this is equivalent to<br>| setting the <code>type</code> parameter).<br>| type : Python type, optional<br>| Type of the returned view, e.g., ndarray or matrix. Again, the<br>| default None results in type preservation.<br>|<br>| 【注意】<br>| —–| <code>a.view()</code> is used two different ways:<br>|<br>| <code>a.view(some_dtype)</code> or <code>a.view(dtype=some_dtype)</code> constructs a view<br>| of the array’s memory with a different data-type. This can cause a<br>| reinterpretation of the bytes of memory.<br>|<br>| <code>a.view(ndarray_subclass)</code> or <code>a.view(type=ndarray_subclass)</code> just<br>| returns an instance of <code>ndarray_subclass</code> that looks at the same array<br>| (same shape, dtype, etc.) This does not cause a reinterpretation of the<br>| memory.<br>|<br>| For <code>a.view(some_dtype)</code>, if <code>some_dtype</code> has a different number of<br>| bytes per entry than the previous dtype (for example, converting a<br>| regular array to a structured array), then the behavior of the view<br>| cannot be predicted just from the superficial appearance of <code>a</code> (shown<br>| by <code>print(a)</code>). It also depends on exactly how <code>a</code> is stored in<br>| memory. Therefore if <code>a</code> is C-ordered versus fortran-ordered, versus<br>| defined as a slice or transpose, etc., the view may give different<br>| results.<br>|<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; x = np.array([(1, 2)], dtype=[(‘a’, np.int8), (‘b’, np.int8)])<br>|<br>| Viewing array data using a different type and dtype:<br>|<br>| &gt;&gt;&gt; y = x.view(dtype=np.int16, type=np.matrix)<br>| &gt;&gt;&gt; y<br>| matrix([[513]], dtype=int16)<br>| &gt;&gt;&gt; print type(y)<br>| <class 'numpy.matrixlib.defmatrix.matrix'=""><br>|<br>| Creating a view on a structured array so it can be used in calculations<br>497<br>|<br>| &gt;&gt;&gt; x = np.array([(1, 2),(3,4)], dtype=[(‘a’, np.int8), (‘b’, np.int8)])<br>| &gt;&gt;&gt; xv = x.view(dtype=np.int8).reshape(-1,2)<br>| &gt;&gt;&gt; xv<br>| array([[1, 2],<br>| [3, 4]], dtype=int8)<br>| &gt;&gt;&gt; xv.mean(0)<br>| array([ 2., 3.])<br>|<br>| Making changes to the view changes the underlying array<br>|<br>| &gt;&gt;&gt; xv[0,1] = 20<br>| &gt;&gt;&gt; print x<br>| [(1, 20) (3, 4)]<br>|<br>| Using a view to convert an array to a record array:<br>|<br>| &gt;&gt;&gt; z = x.view(np.recarray)<br>| &gt;&gt;&gt; z.a<br>| array([1], dtype=int8)<br>|<br>| Views share data:<br>|<br>| &gt;&gt;&gt; x[0] = (9, 10)<br>| &gt;&gt;&gt; z[0]<br>| (9, 10)<br>|<br>| Views that change the dtype size (bytes per entry) should normally be<br>| avoided on arrays defined by slices, transposes, fortran-ordering, etc.:<br>|<br>| &gt;&gt;&gt; x = np.array([[1,2,3],[4,5,6]], dtype=np.int16)<br>| &gt;&gt;&gt; y = x[:, 0:2]<br>| &gt;&gt;&gt; y<br>| array([[1, 2],<br>| [4, 5]], dtype=int16)<br>| &gt;&gt;&gt; y.view(dtype=[(‘width’, np.int16), (‘length’, np.int16)])<br>| Traceback (most recent call last):<br>| File “<stdin>“, line 1, in <module><br>| ValueError: new type not compatible with array.<br>| &gt;&gt;&gt; z = y.copy()<br>| &gt;&gt;&gt; z.view(dtype=[(‘width’, np.int16), (‘length’, np.int16)])<br>| array([[(1, 2)],<br>| [(4, 5)]], dtype=[(‘width’, ‘&lt;i2’), (‘length’, ‘&lt;i2’)])<br>|<br>| ———————————————————————-| Data descriptors inherited from numpy.ndarray:<br>|<br>| T<br>| Same as self.transpose(), except that self is returned if<br>| self.ndim &lt; 2.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; x = np.array([[1.,2.],[3.,4.]])<br>| &gt;&gt;&gt; x<br>| array([[ 1., 2.],<br>| [ 3., 4.]])<br>498<br>| &gt;&gt;&gt; x.T<br>| array([[ 1., 3.],<br>| [ 2., 4.]])<br>| &gt;&gt;&gt; x = np.array([1.,2.,3.,4.])<br>| &gt;&gt;&gt; x<br>| array([ 1., 2., 3., 4.])<br>| &gt;&gt;&gt; x.T<br>| array([ 1., 2., 3., 4.])<br>|<br>| <strong>array_interface</strong><br>| Array protocol: Python side.<br>|<br>| <strong>array_struct</strong><br>| Array protocol: C-struct side.<br>|<br>| base<br>| Base object if memory is from some other object.<br>|<br>| 【示例】<br>| ——–| The base of an array that owns its memory is None:<br>|<br>| &gt;&gt;&gt; x = np.array([1,2,3,4])<br>| &gt;&gt;&gt; x.base is None<br>| True<br>|<br>| Slicing creates a view, whose memory is shared with x:<br>|<br>| &gt;&gt;&gt; y = x[2:]<br>| &gt;&gt;&gt; y.base is x<br>| True<br>|<br>| ctypes<br>| An object to simplify the interaction of the array with the ctypes<br>| module.<br>|<br>| This attribute creates an object that makes it easier to use arrays<br>| when calling shared libraries with the ctypes module. The returned<br>| object has, among others, data, shape, and strides attributes (see<br>| Notes below) which themselves return ctypes objects that can be used<br>| as arguments to a shared library.<br>|<br>| 【参数】<br>| ———-| None<br>|<br>| 【返回值】<br>| ——-| c : Python object<br>| Possessing attributes data, shape, strides, etc.<br>|<br>| 【参见】<br>| ——–| numpy.ctypeslib<br>|<br>| 【注意】<br>| —–<br>499<br>| Below are the public attributes of this object which were documented<br>| in “Guide to NumPy” (we have omitted undocumented public attributes,<br>| as well as documented private attributes):<br>|<br>| </module></stdin></class></em> data: A pointer to the memory area of the array as a Python integer.<br>| This memory area may contain data that is not aligned, or not in correct<br>| byte-order. The memory area may not even be writeable. The array<br>| flags and data-type of this array should be respected when passing this<br>| attribute to arbitrary C-code to avoid trouble that can include Python<br>| crashing. User Beware! The value of this attribute is exactly the same<br>| as self._array<em>interface</em>[‘data’][0].<br>|<br>| <em> shape (c_intp</em>self.ndim): A ctypes array of length self.ndim where<br>| the basetype is the C-integer corresponding to dtype(‘p’) on this<br>| platform. This base-type could be c_int, c_long, or c_longlong<br>| depending on the platform. The c_intp type is defined accordingly in<br>| numpy.ctypeslib. The ctypes array contains the shape of the underlying<br>| array.<br>|<br>| <em> strides (c_intp</em>self.ndim): A ctypes array of length self.ndim where<br>| the basetype is the same as for the shape attribute. This ctypes array<br>| contains the strides information from the underlying array. This strides<br>| information is important for showing how many bytes must be jumped to<br>| get to the next element in the array.<br>|<br>| <em> data_as(obj): Return the data pointer cast to a particular c-types object.<br>| For example, calling self._as<em>parameter</em> is equivalent to<br>| self.data_as(ctypes.c_void_p). Perhaps you want to use the data as a<br>| pointer to a ctypes array of floating-point data:<br>| self.data_as(ctypes.POINTER(ctypes.c_double)).<br>|<br>| </em> shape_as(obj): Return the shape tuple as an array of some other c-types<br>| type. For example: self.shape_as(ctypes.c_short).<br>|<br>| <em> strides_as(obj): Return the strides tuple as an array of some other<br>| c-types type. For example: self.strides_as(ctypes.c_longlong).<br>|<br>| Be careful using the ctypes attribute - especially on temporary<br>| arrays or arrays constructed on the fly. For example, calling<br>| <code>(a+b).ctypes.data_as(ctypes.c_void_p)</code> returns a pointer to memory<br>| that is invalid because the array created as (a+b) is deallocated<br>| before the next Python statement. You can avoid this problem using<br>| either <code>c=a+b</code> or <code>ct=(a+b).ctypes</code>. In the latter case, ct will<br>| hold a reference to the array until ct is deleted or re-assigned.<br>|<br>| If the ctypes module is not available, then the ctypes attribute<br>| of array objects still returns something useful, but ctypes objects<br>| are not returned and errors may be raised instead. In particular,<br>| the object will still have the as parameter attribute which will<br>| return an integer equal to the data attribute.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; import ctypes<br>| &gt;&gt;&gt; x<br>| array([[0, 1],<br>| [2, 3]])<br>500<br>| &gt;&gt;&gt; x.ctypes.data<br>| 30439712<br>| &gt;&gt;&gt; x.ctypes.data_as(ctypes.POINTER(ctypes.c_long))<br>| <ctypes.lp_c_long object="" at="" 0x01f01300=""><br>| &gt;&gt;&gt; x.ctypes.data_as(ctypes.POINTER(ctypes.c_long)).contents<br>| c_long(0)<br>| &gt;&gt;&gt; x.ctypes.data_as(ctypes.POINTER(ctypes.c_longlong)).contents<br>| c_longlong(4294967296L)<br>| &gt;&gt;&gt; x.ctypes.shape<br>| <numpy.core._internal.c_long_array_2 object="" at="" 0x01ffd580=""><br>| &gt;&gt;&gt; x.ctypes.shape_as(ctypes.c_long)<br>| <numpy.core._internal.c_long_array_2 object="" at="" 0x01fce620=""><br>| &gt;&gt;&gt; x.ctypes.strides<br>| <numpy.core._internal.c_long_array_2 object="" at="" 0x01fce620=""><br>| &gt;&gt;&gt; x.ctypes.strides_as(ctypes.c_longlong)<br>| <numpy.core._internal.c_longlong_array_2 object="" at="" 0x01f01300=""><br>|<br>| data<br>| Python buffer object pointing to the start of the array’s data.<br>|<br>| dtype<br>| Data-type of the array’s elements.<br>|<br>| 【参数】<br>| ———-| None<br>|<br>| 【返回值】<br>| ——-| d : numpy dtype object<br>|<br>| 【参见】<br>| ——–| numpy.dtype<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; x<br>| array([[0, 1],<br>| [2, 3]])<br>| &gt;&gt;&gt; x.dtype<br>| dtype(‘int32’)<br>| &gt;&gt;&gt; type(x.dtype)<br>| <type 'numpy.dtype'=""><br>|<br>| flags<br>| Information about the memory layout of the array.<br>|<br>| 【属性】<br>| ———-| C_CONTIGUOUS (C)<br>| The data is in a single, C-style contiguous segment.<br>| F_CONTIGUOUS (F)<br>| The data is in a single, Fortran-style contiguous segment.<br>| OWNDATA (O)<br>| The array owns the memory it uses or borrows it from another object.<br>| WRITEABLE (W)<br>501<br>| The data area can be written to. Setting this to False locks<br>| the data, making it read-only. A view (slice, etc.) inherits WRITEABLE<br>| from its base array at creation time, but a view of a writeable<br>| array may be subsequently locked while the base array remains writeable.<br>| (The opposite is not true, in that a view of a locked array may not<br>| be made writeable. However, currently, locking a base object does not<br>| lock any views that already reference it, so under that circumstance it<br>| is possible to alter the contents of a locked array via a previously<br>| created writeable view onto it.) Attempting to change a non-writeable<br>| array raises a RuntimeError exception.<br>| ALIGNED (A)<br>| The data and all elements are aligned appropriately for the hardware.<br>| UPDATEIFCOPY (U)<br>| This array is a copy of some other array. When this array is<br>| deallocated, the base array will be updated with the contents of<br>| this array.<br>| FNC<br>| F_CONTIGUOUS and not C_CONTIGUOUS.<br>| FORC<br>| F_CONTIGUOUS or C_CONTIGUOUS (one-segment test).<br>| BEHAVED (B)<br>| ALIGNED and WRITEABLE.<br>| CARRAY (CA)<br>| BEHAVED and C_CONTIGUOUS.<br>| FARRAY (FA)<br>| BEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.<br>|<br>| 【注意】<br>| —–| The <code>flags</code> object can be accessed dictionary-like (as in <code>a.flags[&#39;WRITEABLE&#39;]</code>),<br>| or by using lowercased attribute names (as in <code>a.flags.writeable</code>). Short flag<br>| names are only supported in dictionary access.<br>|<br>| Only the UPDATEIFCOPY, WRITEABLE, and ALIGNED flags can be changed by<br>| the user, via direct assignment to the attribute or dictionary entry,<br>| or by calling <code>ndarray.setflags</code>.<br>|<br>| The array flags cannot be set arbitrarily:<br>|<br>| - UPDATEIFCOPY can only be set <code>False</code>.<br>| - ALIGNED can only be set <code>True</code> if the data is truly aligned.<br>| - WRITEABLE can only be set <code>True</code> if the array owns its own memory<br>| or the ultimate owner of the memory exposes a writeable buffer<br>| interface or is a string.<br>|<br>| Arrays can be both C-style and Fortran-style contiguous simultaneously.<br>| This is clear for 1-dimensional arrays, but can also be true for higher<br>| dimensional arrays.<br>|<br>| Even for contiguous arrays a stride for a given dimension<br>| <code>arr.strides[dim]</code> may be </type></numpy.core._internal.c_longlong_array_2></numpy.core._internal.c_long_array_2></numpy.core._internal.c_long_array_2></numpy.core._internal.c_long_array_2></ctypes.lp_c_long></em>arbitrary<em> if <code>arr.shape[dim] == 1</code><br>| or the array has no elements.<br>| It does </em>not<em> generally hold that <code>self.strides[-1] == self.itemsize</code><br>| for C-style contiguous arrays or <code>self.strides[0] == self.itemsize</code> for<br>| Fortran-style contiguous arrays is true.<br>|<br>| flat<br>502<br>| A 1-D iterator over the array.<br>|<br>| This is a <code>numpy.flatiter</code> instance, which acts similarly to, but is not<br>| a subclass of, Python’s built-in iterator object.<br>|<br>| 【参见】<br>| ——–| flatten : Return a copy of the array collapsed into one dimension.<br>|<br>| flatiter<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; x = np.arange(1, 7).reshape(2, 3)<br>| &gt;&gt;&gt; x<br>| array([[1, 2, 3],<br>| [4, 5, 6]])<br>| &gt;&gt;&gt; x.flat[3]<br>| 4<br>| &gt;&gt;&gt; x.T<br>| array([[1, 4],<br>| [2, 5],<br>| [3, 6]])<br>| &gt;&gt;&gt; x.T.flat[3]<br>| 5<br>| &gt;&gt;&gt; type(x.flat)<br>| <type 'numpy.flatiter'=""><br>|<br>| An assignment example:<br>|<br>| &gt;&gt;&gt; x.flat = 3; x<br>| array([[3, 3, 3],<br>| [3, 3, 3]])<br>| &gt;&gt;&gt; x.flat[[1,4]] = 1; x<br>| array([[3, 1, 3],<br>| [3, 1, 3]])<br>|<br>| imag<br>| The imaginary part of the array.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; x = np.sqrt([1+0j, 0+1j])<br>| &gt;&gt;&gt; x.imag<br>| array([ 0. , 0.70710678])<br>| &gt;&gt;&gt; x.imag.dtype<br>| dtype(‘float64’)<br>|<br>| itemsize<br>| Length of one array element in bytes.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; x = np.array([1,2,3], dtype=np.float64)<br>| &gt;&gt;&gt; x.itemsize<br>| 8<br>| &gt;&gt;&gt; x = np.array([1,2,3], dtype=np.complex128)<br>503<br>| &gt;&gt;&gt; x.itemsize<br>| 16<br>|<br>| nbytes<br>| Total bytes consumed by the elements of the array.<br>|<br>| 【注意】<br>| —–| Does not include memory consumed by non-element attributes of the<br>| array object.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; x = np.zeros((3,5,2), dtype=np.complex128)<br>| &gt;&gt;&gt; x.nbytes<br>| 480<br>| &gt;&gt;&gt; np.prod(x.shape) </type></em> x.itemsize<br>| 480<br>|<br>| ndim<br>| Number of array dimensions.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; x = np.array([1, 2, 3])<br>| &gt;&gt;&gt; x.ndim<br>| 1<br>| &gt;&gt;&gt; y = np.zeros((2, 3, 4))<br>| &gt;&gt;&gt; y.ndim<br>| 3<br>|<br>| real<br>| The real part of the array.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; x = np.sqrt([1+0j, 0+1j])<br>| &gt;&gt;&gt; x.real<br>| array([ 1. , 0.70710678])<br>| &gt;&gt;&gt; x.real.dtype<br>| dtype(‘float64’)<br>|<br>| 【参见】<br>| ——–| numpy.real : equivalent function<br>|<br>| shape<br>| Tuple of array dimensions.<br>|<br>| 【注意】<br>| —–| May be used to “reshape” the array, as long as this would not<br>| require a change in the total number of elements<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; x = np.array([1, 2, 3, 4])<br>504<br>| &gt;&gt;&gt; x.shape<br>| (4,)<br>| &gt;&gt;&gt; y = np.zeros((2, 3, 4))<br>| &gt;&gt;&gt; y.shape<br>| (2, 3, 4)<br>| &gt;&gt;&gt; y.shape = (3, 8)<br>| &gt;&gt;&gt; y<br>| array([[ 0., 0., 0., 0., 0., 0., 0., 0.],<br>| [ 0., 0., 0., 0., 0., 0., 0., 0.],<br>| [ 0., 0., 0., 0., 0., 0., 0., 0.]])<br>| &gt;&gt;&gt; y.shape = (3, 6)<br>| Traceback (most recent call last):<br>| File “<stdin>“, line 1, in <module><br>| ValueError: total size of new array must be unchanged<br>|<br>| size<br>| Number of elements in the array.<br>|<br>| Equivalent to <code>np.prod(a.shape)</code>, i.e., the product of the array’s<br>| dimensions.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; x = np.zeros((3, 5, 2), dtype=np.complex128)<br>| &gt;&gt;&gt; x.size<br>| 30<br>| &gt;&gt;&gt; np.prod(x.shape)<br>| 30<br>|<br>| strides<br>| Tuple of bytes to step in each dimension when traversing an array.<br>|<br>| The byte offset of element <code>(i[0], i[1], ..., i[n])</code> in an array <code>a</code><br>| is::<br>|<br>| offset = sum(np.array(i) <em> a.strides)<br>|<br>| A more detailed explanation of strides can be found in the<br>| “ndarray.rst” file in the NumPy reference guide.<br>|<br>| 【注意】<br>| —–| Imagine an array of 32-bit integers (each 4 bytes)::<br>|<br>| x = np.array([[0, 1, 2, 3, 4],<br>| [5, 6, 7, 8, 9]], dtype=np.int32)<br>|<br>| This array is stored in memory as 40 bytes, one after the other<br>| (known as a contiguous block of memory). The strides of an array tell<br>| us how many bytes we have to skip in memory to move to the next position<br>| along a certain axis. For example, we have to skip 4 bytes (1 value) to<br>| move to the next column, but 20 bytes (5 values) to get to the same<br>| position in the next row. As such, the strides for the array <code>x</code> will be<br>| <code>(20, 4)</code>.<br>|<br>| 【参见】<br>| ——–<br>505<br>| numpy.lib.stride_tricks.as_strided<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; y = np.reshape(np.arange(2</em>3<em>4), (2,3,4))<br>| &gt;&gt;&gt; y<br>| array([[[ 0, 1, 2, 3],<br>| [ 4, 5, 6, 7],<br>| [ 8, 9, 10, 11]],<br>| [[12, 13, 14, 15],<br>| [16, 17, 18, 19],<br>| [20, 21, 22, 23]]])<br>| &gt;&gt;&gt; y.strides<br>| (48, 16, 4)<br>| &gt;&gt;&gt; y[1,1,1]<br>| 17<br>| &gt;&gt;&gt; offset=sum(y.strides </em> np.array((1,1,1)))<br>| &gt;&gt;&gt; offset/y.itemsize<br>| 17<br>|<br>| &gt;&gt;&gt; x = np.reshape(np.arange(5<em>6</em>7<em>8), (5,6,7,8)).transpose(2,3,1,0)<br>| &gt;&gt;&gt; x.strides<br>| (32, 4, 224, 1344)<br>| &gt;&gt;&gt; i = np.array([3,5,2,2])<br>| &gt;&gt;&gt; offset = sum(i </em> x.strides)<br>| &gt;&gt;&gt; x[3,5,2,2]<br>| 813<br>| &gt;&gt;&gt; offset / x.itemsize<br>| 813<br>|<br>| ———————————————————————-| Data and other attributes inherited from numpy.ndarray:<br>|<br>| <strong>hash</strong> = None<br>SparseDataFrame<br>SparseDataFrame 模块所属：pandas.sparse.frame:<br>类定义：SparseDataFrame(pandas.core.frame.DataFrame)<br>| DataFrame containing sparse floating point data in the form of SparseSeries<br>| objects<br>|<br>| 【参数】<br>| ———-| data : same types as can be passed to DataFrame<br>| index : array-like, optional<br>| column : array-like, optional<br>| default_kind : {‘block’, ‘integer’}, default ‘block’<br>| Default sparse kind for converting Series to SparseSeries. Will not<br>506<br>| override SparseSeries passed into constructor<br>| default_fill_value : float<br>| Default fill_value for converting Series to SparseSeries. Will not<br>| override SparseSeries passed in<br>|<br>| 【方法排序】<br>| SparseDataFrame<br>| pandas.core.frame.DataFrame<br>| pandas.core.generic.NDFrame<br>| pandas.core.base.PandasObject<br>| pandas.core.base.StringMixin<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>add</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>add</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>and</strong>(self, other, axis=’columns’, level=None, fill_value=None)<br>| Binary operator <strong>and</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>507<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>array_wrap</strong>(self, result)<br>|<br>| <strong>div</strong> = <strong>truediv</strong>(self, other, axis=None, level=None, fill_value=None)<br>|<br>| <strong>eq</strong>(self, other)<br>| Wrapper for comparison method <strong>eq</strong><br>|<br>| <strong>floordiv</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>floordiv</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>ge</strong>(self, other)<br>| Wrapper for comparison method <strong>ge</strong><br>|<br>| <strong>getitem</strong>(self, key)<br>| Retrieve column or slice from DataFrame<br>|<br>| <strong>getstate</strong>(self)<br>|<br>| <strong>gt</strong>(self, other)<br>| Wrapper for comparison method <strong>gt</strong><br>|<br>| <strong>iadd</strong> = f(self, other)<br>|<br>| <strong>imul</strong> = f(self, other)<br>|<br>| <strong>init</strong>(self, data=None, index=None, columns=None, default_kind=None, default_fill_value=None, dtype=None,<br>copy=False)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>508<br>| <strong>ipow</strong> = f(self, other)<br>|<br>| <strong>isub</strong> = f(self, other)<br>|<br>| <strong>itruediv</strong> = f(self, other)<br>|<br>| <strong>le</strong>(self, other)<br>| Wrapper for comparison method <strong>le</strong><br>|<br>| <strong>lt</strong>(self, other)<br>| Wrapper for comparison method <strong>lt</strong><br>|<br>| <strong>mod</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>mod</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>mul</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>mul</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>509<br>| ——-| result : DataFrame<br>|<br>| <strong>ne</strong>(self, other)<br>| Wrapper for comparison method <strong>ne</strong><br>|<br>| <strong>or</strong>(self, other, axis=’columns’, level=None, fill_value=None)<br>| Binary operator <strong>or</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>pow</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>pow</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>radd</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>radd</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>510<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>rand</strong>(self, other, axis=’columns’, level=None, fill_value=None)<br>| Binary operator <strong>rand</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>rdiv</strong> = <strong>rtruediv</strong>(self, other, axis=None, level=None, fill_value=None)<br>|<br>| <strong>rfloordiv</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>rfloordiv</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>511<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>rmod</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>rmod</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>rmul</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>rmul</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>512<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>ror</strong>(self, other, axis=’columns’, level=None, fill_value=None)<br>| Binary operator <strong>ror</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>rpow</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>rpow</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>rsub</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>rsub</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>513<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>rtruediv</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>rtruediv</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>rxor</strong>(self, other, axis=’columns’, level=None, fill_value=None)<br>| Binary operator <strong>rxor</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>514<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>sub</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>sub</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| <strong>truediv</strong>(self, other, axis=None, level=None, fill_value=None)<br>| Binary operator <strong>truediv</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>515<br>| ——-| result : DataFrame<br>|<br>| <strong>xor</strong>(self, other, axis=’columns’, level=None, fill_value=None)<br>| Binary operator <strong>xor</strong> with support to substitute a fill_value for missing data in<br>| one of the inputs<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| add(self, other, axis=’columns’, level=None, fill_value=None)<br>| Addition of dataframe and other, element-wise (binary operator <code>add</code>).<br>|<br>| Equivalent to <code>dataframe + other</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.radd<br>|<br>516<br>| apply(self, func, axis=0, broadcast=False, reduce=False)<br>| Analogous to DataFrame.apply, for SparseDataFrame<br>|<br>| 【参数】<br>| ———-| func : function<br>| Function to apply to each column<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| broadcast : bool, default False<br>| For aggregation functions, return object of same size with values<br>| propagated<br>|<br>| 【返回值】<br>| ——-| applied : Series or SparseDataFrame<br>|<br>| applymap(self, func)<br>| Apply a function to a DataFrame that is intended to operate<br>| elementwise, i.e. like doing map(func, series) for each series in the<br>| DataFrame<br>|<br>| 【参数】<br>| ———-| func : function<br>| Python function, returns a single value from a single value<br>|<br>| 【返回值】<br>| ——-| applied : DataFrame<br>|<br>| astype(self, dtype)<br>| Cast object to input numpy.dtype<br>| Return a copy when copy = True (be really careful with this!)<br>|<br>| 【参数】<br>| ———-| dtype : numpy.dtype or Python type<br>| raise_on_error : raise on invalid input<br>| kwargs : keyword arguments to pass on to the constructor<br>|<br>| 【返回值】<br>| ——-| casted : type of caller<br>|<br>| copy(self, deep=True)<br>| Make a copy of this SparseDataFrame<br>|<br>| count(self, axis=0, <strong>kwds)<br>| Return Series with number of non-NA/null observations over requested<br>| axis. Works with non-floating point data as well (detects NaN and None)<br>|<br>| 【参数】<br>| ———-| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| 0 or ‘index’ for row-wise, 1 or ‘columns’ for column-wise<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>517<br>| particular level, collapsing into a DataFrame<br>| numeric_only : boolean, default False<br>| Include only float, int, boolean data<br>|<br>| 【返回值】<br>| ——-| count : Series (or DataFrame if level specified)<br>|<br>| cumsum(self, axis=0)<br>| Return SparseDataFrame of cumulative sums over requested axis.<br>|<br>| 【参数】<br>| ———-| axis : {0, 1}<br>| 0 for row-wise, 1 for column-wise<br>|<br>| 【返回值】<br>| ——-| y : SparseDataFrame<br>|<br>| div = truediv(self, other, axis=’columns’, level=None, fill_value=None)<br>|<br>| divide = truediv(self, other, axis=’columns’, level=None, fill_value=None)<br>|<br>| eq(self, other, axis=’columns’, level=None)<br>| Wrapper for flexible comparison methods eq<br>|<br>| fillna(self, value=None, method=None, axis=0, inplace=False, limit=None, downcast=None)<br>| Fill NA/NaN values using the specified method<br>|<br>| 【参数】<br>| ———-| value : scalar, dict, Series, or DataFrame<br>| Value to use to fill holes (e.g. 0), alternately a dict/Series/DataFrame of<br>| values specifying which value to use for each index (for a Series) or<br>| column (for a DataFrame). (values not in the dict/Series/DataFrame will not be<br>| filled). This value cannot be a list.<br>| method : {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default None<br>| Method to use for filling holes in reindexed Series<br>| pad / ffill: propagate last valid observation forward to next valid<br>| backfill / bfill: use NEXT valid observation to fill gap<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| inplace : boolean, default False<br>| If True, fill in place. Note: this will modify any<br>| other views on this object, (e.g. a no-copy slice for a column in a<br>| DataFrame).<br>| limit : int, default None<br>| If method is specified, this is the maximum number of consecutive<br>| NaN values to forward/backward fill. In other words, if there is<br>| a gap with more than this number of consecutive NaNs, it will only<br>| be partially filled. If method is not specified, this is the<br>| maximum number of entries along the entire axis where NaNs will be<br>| filled.<br>| downcast : dict, default is None<br>| a dict of item-&gt;dtype of what to downcast if possible,<br>| or the string ‘infer’ which will try to downcast to an appropriate<br>| equal type (e.g. float64 to int64 if possible)<br>518<br>|<br>| 【参见】<br>| ——–| reindex, asfreq<br>|<br>| 【返回值】<br>| ——-| filled : DataFrame<br>|<br>| floordiv(self, other, axis=’columns’, level=None, fill_value=None)<br>| Integer division of dataframe and other, element-wise (binary operator <code>floordiv</code>).<br>|<br>| Equivalent to <code>dataframe // other</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.rfloordiv<br>|<br>| ge(self, other, axis=’columns’, level=None)<br>| Wrapper for flexible comparison methods ge<br>|<br>| get_value(self, index, col, takeable=False)<br>| Quickly retrieve single value at passed column and index<br>|<br>| 【参数】<br>| ———-| index : row label<br>| col : column label<br>| takeable : interpret the index/col as indexers, default False<br>|<br>| 【返回值】<br>| ——-| value : scalar value<br>|<br>| gt(self, other, axis=’columns’, level=None)<br>519<br>| Wrapper for flexible comparison methods gt<br>|<br>| le(self, other, axis=’columns’, level=None)<br>| Wrapper for flexible comparison methods le<br>|<br>| lt(self, other, axis=’columns’, level=None)<br>| Wrapper for flexible comparison methods lt<br>|<br>| mod(self, other, axis=’columns’, level=None, fill_value=None)<br>| Modulo of dataframe and other, element-wise (binary operator <code>mod</code>).<br>|<br>| Equivalent to <code>dataframe % other</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.rmod<br>|<br>| mul(self, other, axis=’columns’, level=None, fill_value=None)<br>| Multiplication of dataframe and other, element-wise (binary operator <code>mul</code>).<br>|<br>| Equivalent to <code>dataframe * other</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>520<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.rmul<br>|<br>| multiply = mul(self, other, axis=’columns’, level=None, fill_value=None)<br>|<br>| ne(self, other, axis=’columns’, level=None)<br>| Wrapper for flexible comparison methods ne<br>|<br>| pow(self, other, axis=’columns’, level=None, fill_value=None)<br>| Exponential power of dataframe and other, element-wise (binary operator <code>pow</code>).<br>|<br>| Equivalent to ``dataframe </strong> other<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other : Series, DataFrame, or constant
| axis : {0, 1, &#39;index&#39;, &#39;columns&#39;}
| For Series input, axis to match Series index on
| fill_value : None or float value, default None
| Fill missing (NaN) values with this value. If both DataFrame locations are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【注意】
| -----| Mismatched indices will be unioned together
|
| 【返回值】
| -------| result : DataFrame
|
| 【参见】
| --------| DataFrame.rpow
|
| radd(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
| Addition of dataframe and other, element-wise (binary operator `radd`).
|
| Equivalent to</code>other + dataframe<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other : Series, DataFrame, or constant
| axis : {0, 1, &#39;index&#39;, &#39;columns&#39;}
| For Series input, axis to match Series index on
521
| fill_value : None or float value, default None
| Fill missing (NaN) values with this value. If both DataFrame locations are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【注意】
| -----| Mismatched indices will be unioned together
|
| 【返回值】
| -------| result : DataFrame
|
| 【参见】
| --------| DataFrame.add
|
| rdiv = rtruediv(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
|
| rfloordiv(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
| Integer division of dataframe and other, element-wise (binary operator `rfloordiv`).
|
| Equivalent to</code>other // dataframe<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other : Series, DataFrame, or constant
| axis : {0, 1, &#39;index&#39;, &#39;columns&#39;}
| For Series input, axis to match Series index on
| fill_value : None or float value, default None
| Fill missing (NaN) values with this value. If both DataFrame locations are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【注意】
| -----| Mismatched indices will be unioned together
|
| 【返回值】
| -------| result : DataFrame
|
| 【参见】
| --------| DataFrame.floordiv
|
| rmod(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
| Modulo of dataframe and other, element-wise (binary operator `rmod`).
|
| Equivalent to</code>other % dataframe<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
522
| 【参数】
| ----------| other : Series, DataFrame, or constant
| axis : {0, 1, &#39;index&#39;, &#39;columns&#39;}
| For Series input, axis to match Series index on
| fill_value : None or float value, default None
| Fill missing (NaN) values with this value. If both DataFrame locations are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【注意】
| -----| Mismatched indices will be unioned together
|
| 【返回值】
| -------| result : DataFrame
|
| 【参见】
| --------| DataFrame.mod
|
| rmul(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
| Multiplication of dataframe and other, element-wise (binary operator `rmul`).
|
| Equivalent to</code>other <em> dataframe<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other : Series, DataFrame, or constant
| axis : {0, 1, &#39;index&#39;, &#39;columns&#39;}
| For Series input, axis to match Series index on
| fill_value : None or float value, default None
| Fill missing (NaN) values with this value. If both DataFrame locations are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【注意】
| -----| Mismatched indices will be unioned together
|
| 【返回值】
| -------| result : DataFrame
|
| 【参见】
| --------| DataFrame.mul
|
| rpow(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
| Exponential power of dataframe and other, element-wise (binary operator `rpow`).
523
|
| Equivalent to</code>other ** dataframe<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other : Series, DataFrame, or constant
| axis : {0, 1, &#39;index&#39;, &#39;columns&#39;}
| For Series input, axis to match Series index on
| fill_value : None or float value, default None
| Fill missing (NaN) values with this value. If both DataFrame locations are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【注意】
| -----| Mismatched indices will be unioned together
|
| 【返回值】
| -------| result : DataFrame
|
| 【参见】
| --------| DataFrame.pow
|
| rsub(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
| Subtraction of dataframe and other, element-wise (binary operator `rsub`).
|
| Equivalent to</code>other - dataframe<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other : Series, DataFrame, or constant
| axis : {0, 1, &#39;index&#39;, &#39;columns&#39;}
| For Series input, axis to match Series index on
| fill_value : None or float value, default None
| Fill missing (NaN) values with this value. If both DataFrame locations are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【注意】
| -----| Mismatched indices will be unioned together
|
| 【返回值】
| -------| result : DataFrame
|
| 【参见】
| --------
524
| DataFrame.sub
|
| rtruediv(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
| Floating division of dataframe and other, element-wise (binary operator `rtruediv`).
|
| Equivalent to</code>other / dataframe``, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.truediv<br>|<br>| set_value(self, index, col, value, takeable=False)<br>| Put single value at passed column and index<br>|<br>| 【参数】<br>| ———-| index : row label<br>| col : column label<br>| value : scalar value<br>| takeable : interpret the index/col as indexers, default False<br>|<br>| 【注意】<br>| —–| This method </em>always<em> returns a new object. It is currently not<br>| particularly efficient (and potentially very expensive) but is provided<br>| for API compatibility with DataFrame<br>|<br>| 【返回值】<br>| ——-| frame : DataFrame<br>|<br>| sub(self, other, axis=’columns’, level=None, fill_value=None)<br>| Subtraction of dataframe and other, element-wise (binary operator <code>sub</code>).<br>|<br>| Equivalent to <code>dataframe - other</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>525<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.rsub<br>|<br>| subtract = sub(self, other, axis=’columns’, level=None, fill_value=None)<br>|<br>| to_dense(self)<br>| Convert to dense DataFrame<br>|<br>| 【返回值】<br>| ——-| df : DataFrame<br>|<br>| transpose(self)<br>| Returns a DataFrame with the rows/columns switched.<br>|<br>| truediv(self, other, axis=’columns’, level=None, fill_value=None)<br>| Floating division of dataframe and other, element-wise (binary operator <code>truediv</code>).<br>|<br>| Equivalent to <code>dataframe / other</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other : Series, DataFrame, or constant<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| For Series input, axis to match Series index on<br>| fill_value : None or float value, default None<br>| Fill missing (NaN) values with this value. If both DataFrame locations are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【注意】<br>| —–<br>526<br>| Mismatched indices will be unioned together<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.rtruediv<br>|<br>| xs(self, key, axis=0, copy=False)<br>| Returns a row (cross-section) from the SparseDataFrame as a Series<br>| object.<br>|<br>| 【参数】<br>| ———-| key : some index contained in the index<br>|<br>| 【返回值】<br>| ——-| xs : Series<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| T<br>| Returns a DataFrame with the rows/columns switched.<br>|<br>| default_fill_value<br>|<br>| default_kind<br>|<br>| density<br>| Ratio of non-sparse points to total (dense) data points<br>| represented in the frame<br>|<br>| ———————————————————————-| Methods inherited from pandas.core.frame.DataFrame:<br>|<br>| <strong>len</strong>(self)<br>| Returns length of info axis, but here we use the index<br>|<br>| <strong>setitem</strong>(self, key, value)<br>|<br>| <strong>unicode</strong>(self)<br>| Return a string representation for a particular DataFrame<br>|<br>| Invoked by unicode(df) in py2 only. Yields a Unicode String in both<br>| py2/py3.<br>|<br>| align(self, other, join=’outer’, axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0,<br>broadcast_axis=None)<br>| Align two object on their axes with the<br>| specified join method for each axis Index<br>|<br>| 【参数】<br>| ———-<br>527<br>| other : DataFrame or Series<br>| join : {‘outer’, ‘inner’, ‘left’, ‘right’}, default ‘outer’<br>| axis : allowed axis of the other object, default None<br>| Align on index (0), columns (1), or both (None)<br>| level : int or level name, default None<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>| copy : boolean, default True<br>| Always returns new objects. If copy=False and no reindexing is<br>| required then original objects are returned.<br>| fill_value : scalar, default np.NaN<br>| Value to use for missing values. Defaults to NaN, but can be any<br>| “compatible” value<br>| method : str, default None<br>| limit : int, default None<br>| fill_axis : {0, 1, ‘index’, ‘columns’}, default 0<br>| Filling axis, method and limit<br>| broadcast_axis : {0, 1, ‘index’, ‘columns’}, default None<br>| Broadcast values along this axis, if aligning two objects of<br>| different dimensions<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【返回值】<br>| ——-| (left, right) : (DataFrame, type of other)<br>| Aligned objects<br>|<br>| all(self, axis=None, bool_only=None, skipna=None, level=None, <strong>kwargs)<br>| Return whether all elements are True over requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| bool_only : boolean, default None<br>| Include only boolean data. If None, will attempt to use everything,<br>| then use only boolean data<br>|<br>| 【返回值】<br>| ——-| all : Series or DataFrame (if level specified)<br>|<br>| any(self, axis=None, bool_only=None, skipna=None, level=None, </strong>kwargs)<br>| Return whether any element is True over requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>528<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| bool_only : boolean, default None<br>| Include only boolean data. If None, will attempt to use everything,<br>| then use only boolean data<br>|<br>| 【返回值】<br>| ——-| any : Series or DataFrame (if level specified)<br>|<br>| append(self, other, ignore_index=False, verify_integrity=False)<br>| Append rows of <code>other</code> to the end of this frame, returning a new<br>| object. Columns not in this frame are added as new columns.<br>|<br>| 【参数】<br>| ———-| other : DataFrame or Series/dict-like object, or list of these<br>| The data to append.<br>| ignore_index : boolean, default False<br>| If True, do not use the index labels.<br>| verify_integrity : boolean, default False<br>| If True, raise ValueError on creating index with duplicates.<br>|<br>| 【返回值】<br>| ——-| appended : DataFrame<br>|<br>| 【注意】<br>| —–| If a list of dict/series is passed and the keys are all contained in the<br>| DataFrame’s index, the order of the columns in the resulting DataFrame<br>| will be unchanged.<br>|<br>| 【参见】<br>| ——–| pandas.concat : General function to concatenate DataFrame, Series<br>| or Panel objects<br>|<br>| 【示例】<br>| ——–|<br>| &gt;&gt;&gt; df = pd.DataFrame([[1, 2], [3, 4]], columns=list(‘AB’))<br>| &gt;&gt;&gt; df<br>| A B<br>| 0 1 2<br>| 1 3 4<br>| &gt;&gt;&gt; df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list(‘AB’))<br>| &gt;&gt;&gt; df.append(df2)<br>| A B<br>| 0 1 2<br>| 1 3 4<br>| 0 5 6<br>| 1 7 8<br>|<br>| With <code>ignore_index</code> set to True:<br>|<br>529<br>| &gt;&gt;&gt; df.append(df2, ignore_index=True)<br>| A B<br>| 0 1 2<br>| 1 3 4<br>| 2 5 6<br>| 3 7 8<br>|<br>| assign(self, <strong>kwargs)<br>| Assign new columns to a DataFrame, returning a new object<br>| (a copy) with all the original columns in addition to the new ones.<br>|<br>| .. versionadded:: 0.16.0<br>|<br>| 【参数】<br>| ———-| kwargs : keyword, value pairs<br>| keywords are the column names. If the values are<br>| callable, they are computed on the DataFrame and<br>| assigned to the new columns. If the values are<br>| not callable, (e.g. a Series, scalar, or array),<br>| they are simply assigned.<br>|<br>| 【返回值】<br>| ——-| df : DataFrame<br>| A new DataFrame with the new columns in addition to<br>| all the existing columns.<br>|<br>| 【注意】<br>| —–| Since <code>kwargs</code> is a dictionary, the order of your<br>| arguments may not be preserved. The make things predicatable,<br>| the columns are inserted in alphabetical order, at the end of<br>| your DataFrame. Assigning multiple columns within the same<br>| <code>assign</code> is possible, but you cannot reference other columns<br>| created within the same <code>assign</code> call.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df = DataFrame({‘A’: range(1, 11), ‘B’: np.random.randn(10)})<br>|<br>| Where the value is a callable, evaluated on <code>df</code>:<br>|<br>| &gt;&gt;&gt; df.assign(ln_A = lambda x: np.log(x.A))<br>| A B ln_A<br>| 0 1 0.426905 0.000000<br>| 1 2 -0.780949 0.693147<br>| 2 3 -0.418711 1.098612<br>| 3 4 -0.269708 1.386294<br>| 4 5 -0.274002 1.609438<br>| 5 6 -0.500792 1.791759<br>| 6 7 1.649697 1.945910<br>| 7 8 -1.495604 2.079442<br>| 8 9 0.549296 2.197225<br>| 9 10 -0.758542 2.302585<br>|<br>| Where the value already exists and is inserted:<br>530<br>|<br>| &gt;&gt;&gt; newcol = np.log(df[‘A’])<br>| &gt;&gt;&gt; df.assign(ln_A=newcol)<br>| A B ln_A<br>| 0 1 0.426905 0.000000<br>| 1 2 -0.780949 0.693147<br>| 2 3 -0.418711 1.098612<br>| 3 4 -0.269708 1.386294<br>| 4 5 -0.274002 1.609438<br>| 5 6 -0.500792 1.791759<br>| 6 7 1.649697 1.945910<br>| 7 8 -1.495604 2.079442<br>| 8 9 0.549296 2.197225<br>| 9 10 -0.758542 2.302585<br>|<br>| boxplot(self, column=None, by=None, ax=None, fontsize=None, rot=0, grid=True, figsize=None, layout=None,<br>return_type=None, </strong>kwds)<br>| Make a box plot from DataFrame column optionally grouped by some columns or<br>| other inputs<br>|<br>| 【参数】<br>| ———-| data : the pandas object holding the data<br>| column : column name or list of names, or vector<br>| Can be any valid input to groupby<br>| by : string or sequence<br>| Column in the DataFrame to group by<br>| ax : Matplotlib axes object, optional<br>| fontsize : int or string<br>| rot : label rotation angle<br>| figsize : A tuple (width, height) in inches<br>| grid : Setting this to True will show the grid<br>| layout : tuple (optional)<br>| (rows, columns) for the layout of the plot<br>| return_type : {‘axes’, ‘dict’, ‘both’}, default ‘dict’<br>| The kind of object to return. ‘dict’ returns a dictionary<br>| whose values are the matplotlib Lines of the boxplot;<br>| ‘axes’ returns the matplotlib axes the boxplot is drawn on;<br>| ‘both’ returns a namedtuple with the axes and dict.<br>|<br>| When grouping with <code>by</code>, a dict mapping columns to <code>return_type</code><br>| is returned.<br>|<br>| kwds : other plotting keyword arguments to be passed to matplotlib boxplot<br>| function<br>|<br>| 【返回值】<br>| ——-| lines : dict<br>| ax : matplotlib Axes<br>| (ax, lines): namedtuple<br>|<br>| 【注意】<br>| —–| Use <code>return_type=&#39;dict&#39;</code> when you want to tweak the appearance<br>| of the lines after plotting. In this case a dict containing the Lines<br>| making up the boxes, caps, fliers, medians, and whiskers is returned.<br>531<br>|<br>| combine(self, other, func, fill_value=None, overwrite=True)<br>| Add two DataFrame objects and do not propagate NaN values, so if for a<br>| (column, time) one frame is missing a value, it will default to the<br>| other frame’s value (which might be NaN as well)<br>|<br>| 【参数】<br>| ———-| other : DataFrame<br>| func : function<br>| fill_value : scalar value<br>| overwrite : boolean, default True<br>| If True then overwrite values for common keys in the calling frame<br>|<br>| 【返回值】<br>| ——-| result : DataFrame<br>|<br>| combineAdd(self, other)<br>| DEPRECATED. Use <code>DataFrame.add(other, fill_value=0.)</code> instead.<br>|<br>| Add two DataFrame objects and do not propagate<br>| NaN values, so if for a (column, time) one frame is missing a<br>| value, it will default to the other frame’s value (which might<br>| be NaN as well)<br>|<br>| 【参数】<br>| ———-| other : DataFrame<br>|<br>| 【返回值】<br>| ——-| DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.add<br>|<br>| combineMult(self, other)<br>| DEPRECATED. Use <code>DataFrame.mul(other, fill_value=1.)</code> instead.<br>|<br>| Multiply two DataFrame objects and do not propagate NaN values, so if<br>| for a (column, time) one frame is missing a value, it will default to<br>| the other frame’s value (which might be NaN as well)<br>|<br>| 【参数】<br>| ———-| other : DataFrame<br>|<br>| 【返回值】<br>| ——-| DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.mul<br>532<br>|<br>| combine_first(self, other)<br>| Combine two DataFrame objects and default to non-null values in frame<br>| calling the method. Result index columns will be the union of the<br>| respective indexes and columns<br>|<br>| 【参数】<br>| ———-| other : DataFrame<br>|<br>| 【示例】<br>| ——–| a’s values prioritized, use values from b to fill holes:<br>|<br>| &gt;&gt;&gt; a.combine_first(b)<br>|<br>|<br>| 【返回值】<br>| ——-| combined : DataFrame<br>|<br>| compound(self, axis=None, skipna=None, level=None)<br>| Return the compound percentage of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| compounded : Series or DataFrame (if level specified)<br>|<br>| corr(self, method=’pearson’, min_periods=1)<br>| Compute pairwise correlation of columns, excluding NA/null values<br>|<br>| 【参数】<br>| ———-| method : {‘pearson’, ‘kendall’, ‘spearman’}<br>| </em> pearson : standard correlation coefficient<br>| <em> kendall : Kendall Tau correlation coefficient<br>| </em> spearman : Spearman rank correlation<br>| min_periods : int, optional<br>| Minimum number of observations required per pair of columns<br>| to have a valid result. Currently only available for pearson<br>| and spearman correlation<br>|<br>| 【返回值】<br>| ——-<br>533<br>| y : DataFrame<br>|<br>| corrwith(self, other, axis=0, drop=False)<br>| Compute pairwise correlation between rows or columns of two DataFrame<br>| objects.<br>|<br>| 【参数】<br>| ———-| other : DataFrame<br>| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| 0 or ‘index’ to compute column-wise, 1 or ‘columns’ for row-wise<br>| drop : boolean, default False<br>| Drop missing indices from result, default returns union of all<br>|<br>| 【返回值】<br>| ——-| correls : Series<br>|<br>| cov(self, min_periods=None)<br>| Compute pairwise covariance of columns, excluding NA/null values<br>|<br>| 【参数】<br>| ———-| min_periods : int, optional<br>| Minimum number of observations required per pair of columns<br>| to have a valid result.<br>|<br>| 【返回值】<br>| ——-| y : DataFrame<br>|<br>| 【注意】<br>| —–| <code>y</code> contains the covariance matrix of the DataFrame’s time series.<br>| The covariance is normalized by N-1 (unbiased estimator).<br>|<br>| cummax = max(self, axis=None, dtype=None, out=None, skipna=True, <strong>kwargs)<br>| Return cumulative max over requested axis.<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>|<br>| 【返回值】<br>| ——-| max : Series<br>|<br>| cummin = min(self, axis=None, dtype=None, out=None, skipna=True, </strong>kwargs)<br>| Return cumulative min over requested axis.<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>534<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>|<br>| 【返回值】<br>| ——-| min : Series<br>|<br>| cumprod = prod(self, axis=None, dtype=None, out=None, skipna=True, <strong>kwargs)<br>| Return cumulative prod over requested axis.<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>|<br>| 【返回值】<br>| ——-| prod : Series<br>|<br>| diff(self, periods=1, axis=0)<br>| 1st discrete difference of object<br>|<br>| 【参数】<br>| ———-| periods : int, default 1<br>| Periods to shift for forming difference<br>| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| Take difference over rows (0) or columns (1).<br>|<br>| .. versionadded: 0.16.1<br>|<br>| 【返回值】<br>| ——-| diffed : DataFrame<br>|<br>| dot(self, other)<br>| Matrix multiplication with DataFrame or Series objects<br>|<br>| 【参数】<br>| ———-| other : DataFrame or Series<br>|<br>| 【返回值】<br>| ——-| dot_product : DataFrame or Series<br>|<br>| drop_duplicates(self, subset=None, keep=’first’, inplace=False)<br>| Return DataFrame with duplicate rows removed, optionally only<br>| considering certain columns<br>|<br>| 【参数】<br>| ———-| subset : column label or sequence of labels, optional<br>535<br>| Only consider certain columns for identifying duplicates, by<br>| default use all of the columns<br>| keep : {‘first’, ‘last’, False}, default ‘first’<br>| - <code>first</code> : Drop duplicates except for the first occurrence.<br>| - <code>last</code> : Drop duplicates except for the last occurrence.<br>| - False : Drop all duplicates.<br>| take_last : deprecated<br>| inplace : boolean, default False<br>| Whether to drop duplicates in place or to return a copy<br>| cols : kwargs only argument of subset [deprecated]<br>|<br>| 【返回值】<br>| ——-| deduplicated : DataFrame<br>|<br>| dropna(self, axis=0, how=’any’, thresh=None, subset=None, inplace=False)<br>| Return object with labels on given axis omitted where alternately any<br>| or all of the data are missing<br>|<br>| 【参数】<br>| ———-| axis : {0 or ‘index’, 1 or ‘columns’}, or tuple/list thereof<br>| Pass tuple or list to drop on multiple axes<br>| how : {‘any’, ‘all’}<br>| <em> any : if any NA values are present, drop that label<br>| </em> all : if all values are NA, drop that label<br>| thresh : int, default None<br>| int value : require that many non-NA values<br>| subset : array-like<br>| Labels along other axis to consider, e.g. if you are dropping rows<br>| these would be a list of columns to include<br>| inplace : boolean, default False<br>| If True, do operation inplace and return None.<br>|<br>| 【返回值】<br>| ——-| dropped : DataFrame<br>|<br>| duplicated(self, subset=None, keep=’first’)<br>| Return boolean Series denoting duplicate rows, optionally only<br>| considering certain columns<br>|<br>| 【参数】<br>| ———-| subset : column label or sequence of labels, optional<br>| Only consider certain columns for identifying duplicates, by<br>| default use all of the columns<br>| keep : {‘first’, ‘last’, False}, default ‘first’<br>| - <code>first</code> : Mark duplicates as <code>True</code> except for the<br>| first occurrence.<br>| - <code>last</code> : Mark duplicates as <code>True</code> except for the<br>| last occurrence.<br>| - False : Mark all duplicates as <code>True</code>.<br>| take_last : deprecated<br>| cols : kwargs only argument of subset [deprecated]<br>|<br>| 【返回值】<br>536<br>| ——-| duplicated : Series<br>|<br>| eval(self, expr, </strong>kwargs)<br>| Evaluate an expression in the context of the calling DataFrame<br>| instance.<br>|<br>| 【参数】<br>| ———-| expr : string<br>| The expression string to evaluate.<br>| kwargs : dict<br>| See the documentation for :func:<code>~pandas.eval</code> for complete details<br>| on the keyword arguments accepted by<br>| :meth:<code>~pandas.DataFrame.query</code>.<br>|<br>| 【返回值】<br>| ——-| ret : ndarray, scalar, or pandas object<br>|<br>| 【参见】<br>| ——–| pandas.DataFrame.query<br>| pandas.eval<br>|<br>| 【注意】<br>| —–| For more details see the API documentation for :func:<code>~pandas.eval</code>.<br>| For detailed examples see :ref:<code>enhancing performance with eval
| &lt;enhancingperf.eval&gt;</code>.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; from numpy.random import randn<br>| &gt;&gt;&gt; from pandas import DataFrame<br>| &gt;&gt;&gt; df = DataFrame(randn(10, 2), columns=list(‘ab’))<br>| &gt;&gt;&gt; df.eval(‘a + b’)<br>| &gt;&gt;&gt; df.eval(‘c = a + b’)<br>|<br>| first_valid_index(self)<br>| Return label for first non-NA/null value<br>|<br>| hist = hist_frame(data, column=None, by=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None,<br>ax=None, sharex=False, sharey=False, figsize=None, layout=None, bins=10, <strong>kwds)<br>| Draw histogram of the DataFrame’s series using matplotlib / pylab.<br>|<br>| 【参数】<br>| ———-| data : DataFrame<br>| column : string or sequence<br>| If passed, will be used to limit data to a subset of columns<br>| by : object, optional<br>| If passed, then used to form histograms for separate groups<br>| grid : boolean, default True<br>| Whether to show axis grid lines<br>| xlabelsize : int, default None<br>| If specified changes the x-axis label size<br>537<br>| xrot : float, default None<br>| rotation of x axis labels<br>| ylabelsize : int, default None<br>| If specified changes the y-axis label size<br>| yrot : float, default None<br>| rotation of y axis labels<br>| ax : matplotlib axes object, default None<br>| sharex : boolean, default True if ax is None else False<br>| In case subplots=True, share x axis and set some x axis labels to<br>| invisible; defaults to True if ax is None otherwise False if an ax<br>| is passed in; Be aware, that passing in both an ax and sharex=True<br>| will alter all x axis labels for all subplots in a figure!<br>| sharey : boolean, default False<br>| In case subplots=True, share y axis and set some y axis labels to<br>| invisible<br>| figsize : tuple<br>| The size of the figure to create in inches by default<br>| layout: (optional) a tuple (rows, columns) for the layout of the histograms<br>| bins: integer, default 10<br>| Number of histogram bins to be used<br>| kwds : other plotting keyword arguments<br>| To be passed to hist function<br>|<br>| icol(self, i)<br>| DEPRECATED. Use <code>.iloc[:, i]</code> instead<br>|<br>| idxmax(self, axis=0, skipna=True)<br>| Return index of first occurrence of maximum over requested axis.<br>| NA/null values are excluded.<br>|<br>| 【参数】<br>| ———-| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| 0 or ‘index’ for row-wise, 1 or ‘columns’ for column-wise<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be first index.<br>|<br>| 【返回值】<br>| ——-| idxmax : Series<br>|<br>| 【注意】<br>| —–| This method is the DataFrame version of <code>ndarray.argmax</code>.<br>|<br>| 【参见】<br>| ——–| Series.idxmax<br>|<br>| idxmin(self, axis=0, skipna=True)<br>| Return index of first occurrence of minimum over requested axis.<br>| NA/null values are excluded.<br>|<br>| 【参数】<br>| ———-| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>538<br>| 0 or ‘index’ for row-wise, 1 or ‘columns’ for column-wise<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>|<br>| 【返回值】<br>| ——-| idxmin : Series<br>|<br>| 【注意】<br>| —–| This method is the DataFrame version of <code>ndarray.argmin</code>.<br>|<br>| 【参见】<br>| ——–| Series.idxmin<br>|<br>| iget_value(self, i, j)<br>| DEPRECATED. Use <code>.iat[i, j]</code> instead<br>|<br>| info(self, verbose=None, buf=None, max_cols=None, memory_usage=None, null_counts=None)<br>| Concise summary of a DataFrame.<br>|<br>| 【参数】<br>| ———-| verbose : {None, True, False}, optional<br>| Whether to print the full summary.<br>| None follows the <code>display.max_info_columns</code> setting.<br>| True or False overrides the <code>display.max_info_columns</code> setting.<br>| buf : writable buffer, defaults to sys.stdout<br>| max_cols : int, default None<br>| Determines whether full summary or short summary is printed.<br>| None follows the <code>display.max_info_columns</code> setting.<br>| memory_usage : boolean/string, default None<br>| Specifies whether total memory usage of the DataFrame<br>| elements (including index) should be displayed. None follows<br>| the <code>display.memory_usage</code> setting. True or False overrides<br>| the <code>display.memory_usage</code> setting. A value of ‘deep’ is equivalent<br>| of True, with deep introspection. Memory usage is shown in<br>| human-readable units (base-2 representation).<br>| null_counts : boolean, default None<br>| Whether to show the non-null counts<br>| If None, then only show if the frame is smaller than max_info_rows and max_info_columns.<br>| If True, always show counts.<br>| If False, never show counts.<br>|<br>| insert(self, loc, column, value, allow_duplicates=False)<br>| Insert column into DataFrame at specified location.<br>|<br>| If <code>allow_duplicates</code> is False, raises Exception if column<br>| is already contained in the DataFrame.<br>|<br>| 【参数】<br>| ———-| loc : int<br>| Must have 0 &lt;= loc &lt;= len(columns)<br>| column : object<br>539<br>| value : int, Series, or array-like<br>|<br>| irow(self, i, copy=False)<br>| DEPRECATED. Use <code>.iloc[i]</code> instead<br>|<br>| isin(self, values)<br>| Return boolean DataFrame showing whether each element in the<br>| DataFrame is contained in values.<br>|<br>| 【参数】<br>| ———-| values : iterable, Series, DataFrame or dictionary<br>| The result will only be true at a location if all the<br>| labels match. If <code>values</code> is a Series, that’s the index. If<br>| <code>values</code> is a dictionary, the keys must be the column names,<br>| which must match. If <code>values</code> is a DataFrame,<br>| then both the index and column labels must match.<br>|<br>| 【返回值】<br>| ——-|<br>| DataFrame of booleans<br>|<br>| 【示例】<br>| ——–| When <code>values</code> is a list:<br>|<br>| &gt;&gt;&gt; df = DataFrame({‘A’: [1, 2, 3], ‘B’: [‘a’, ‘b’, ‘f’]})<br>| &gt;&gt;&gt; df.isin([1, 3, 12, ‘a’])<br>| A B<br>| 0 True True<br>| 1 False False<br>| 2 True False<br>|<br>| When <code>values</code> is a dict:<br>|<br>| &gt;&gt;&gt; df = DataFrame({‘A’: [1, 2, 3], ‘B’: [1, 4, 7]})<br>| &gt;&gt;&gt; df.isin({‘A’: [1, 3], ‘B’: [4, 7, 12]})<br>| A B<br>| 0 True False # Note that B didn’t match the 1 here.<br>| 1 False True<br>| 2 True True<br>|<br>| When <code>values</code> is a Series or DataFrame:<br>|<br>| &gt;&gt;&gt; df = DataFrame({‘A’: [1, 2, 3], ‘B’: [‘a’, ‘b’, ‘f’]})<br>| &gt;&gt;&gt; other = DataFrame({‘A’: [1, 3, 3, 2], ‘B’: [‘e’, ‘f’, ‘f’, ‘e’]})<br>| &gt;&gt;&gt; df.isin(other)<br>| A B<br>| 0 True False<br>| 1 False False # Column A in <code>other</code> has a 3, but not at index 1.<br>| 2 True True<br>|<br>| items = iteritems(self)<br>| Iterator over (column name, Series) pairs.<br>|<br>| 【参见】<br>540<br>| ——–| iterrows : Iterate over the rows of a DataFrame as (index, Series) pairs.<br>| itertuples : Iterate over the rows of a DataFrame as namedtuples of the values.<br>|<br>| iteritems(self)<br>| Iterator over (column name, Series) pairs.<br>|<br>| 【参见】<br>| ——–| iterrows : Iterate over the rows of a DataFrame as (index, Series) pairs.<br>| itertuples : Iterate over the rows of a DataFrame as namedtuples of the values.<br>|<br>| iterrows(self)<br>| Iterate over the rows of a DataFrame as (index, Series) pairs.<br>|<br>| 【注意】<br>| —–|<br>| 1. Because <code>iterrows</code> returns a Series for each row,<br>| it does </strong>not<strong> preserve dtypes across the rows (dtypes are<br>| preserved across columns for DataFrames). For example,<br>|<br>| &gt;&gt;&gt; df = pd.DataFrame([[1, 1.5]], columns=[‘int’, ‘float’])<br>| &gt;&gt;&gt; row = next(df.iterrows())[1]<br>| &gt;&gt;&gt; row<br>| int 1.0<br>| float 1.5<br>| Name: 0, dtype: float64<br>| &gt;&gt;&gt; print(row[‘int’].dtype)<br>| float64<br>| &gt;&gt;&gt; print(df[‘int’].dtype)<br>| int64<br>|<br>| To preserve dtypes while iterating over the rows, it is better<br>| to use :meth:<code>itertuples</code> which returns namedtuples of the values<br>| and which is generally faster as <code>iterrows</code>.<br>|<br>| 2. You should </strong>never modify<strong> something you are iterating over.<br>| This is not guaranteed to work in all cases. Depending on the<br>| data types, the iterator returns a copy and not a view, and writing<br>| to it will have no effect.<br>|<br>| 【返回值】<br>| ——-| it : generator<br>| A generator that iterates over the rows of the frame.<br>|<br>| 【参见】<br>| ——–| itertuples : Iterate over the rows of a DataFrame as namedtuples of the values.<br>| iteritems : Iterate over (column name, Series) pairs.<br>|<br>| itertuples(self, index=True, name=’Pandas’)<br>| Iterate over the rows of DataFrame as namedtuples, with index value<br>| as first element of the tuple.<br>|<br>| 【参数】<br>541<br>| ———-| index : boolean, default True<br>| If True, return the index as the first element of the tuple.<br>| name : string, default “Pandas”<br>| The name of the returned namedtuples or None to return regular tuples.<br>|<br>| 【注意】<br>| —–| The columns names will be renamed to positional names if they are<br>| invalid Python identifiers, repeated, or start with an underscore.<br>| With a large number of columns (&gt;255), regular tuples are returned.<br>|<br>| 【参见】<br>| ——–| iterrows : Iterate over the rows of a DataFrame as (index, Series) pairs.<br>| iteritems : Iterate over (column name, Series) pairs.<br>|<br>| 【示例】<br>| ——–|<br>| &gt;&gt;&gt; df = pd.DataFrame({‘col1’: [1, 2], ‘col2’: [0.1, 0.2]}, index=[‘a’, ‘b’])<br>| &gt;&gt;&gt; df<br>| col1 col2<br>| a 1 0.1<br>| b 2 0.2<br>| &gt;&gt;&gt; for row in df.itertuples():<br>| … print(row)<br>| …<br>| Pandas(Index=’a’, col1=1, col2=0.10000000000000001)<br>| Pandas(Index=’b’, col1=2, col2=0.20000000000000001)<br>|<br>| join(self, other, on=None, how=’left’, lsuffix=’’, rsuffix=’’, sort=False)<br>| Join columns with other DataFrame either on index or on a key<br>| column. Efficiently Join multiple DataFrame objects by index at once by<br>| passing a list.<br>|<br>| 【参数】<br>| ———-| other : DataFrame, Series with name field set, or list of DataFrame<br>| Index should be similar to one of the columns in this one. If a<br>| Series is passed, its name attribute must be set, and that will be<br>| used as the column name in the resulting joined DataFrame<br>| on : column name, tuple/list of column names, or array-like<br>| Column(s) to use for joining, otherwise join on index. If multiples<br>| columns given, the passed DataFrame must have a MultiIndex. Can<br>| pass an array as the join key if not already contained in the<br>| calling DataFrame. Like an Excel VLOOKUP operation<br>| how : {‘left’, ‘right’, ‘outer’, ‘inner’}<br>| How to handle indexes of the two objects. Default: ‘left’<br>| for joining on index, None otherwise<br>|<br>| <em> left: use calling frame’s index<br>| </em> right: use input frame’s index<br>| <em> outer: form union of indexes<br>| </em> inner: use intersection of indexes<br>| lsuffix : string<br>| Suffix to use from left frame’s overlapping columns<br>542<br>| rsuffix : string<br>| Suffix to use from right frame’s overlapping columns<br>| sort : boolean, default False<br>| Order result DataFrame lexicographically by the join key. If False,<br>| preserves the index order of the calling (left) DataFrame<br>|<br>| 【注意】<br>| —–| on, lsuffix, and rsuffix options are not supported when passing a list<br>| of DataFrame objects<br>|<br>| 【返回值】<br>| ——-| joined : DataFrame<br>|<br>| kurt(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| Return unbiased kurtosis over requested axis using Fishers definition of<br>| kurtosis (kurtosis of normal == 0.0). Normalized by N-1<br>|<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| kurt : Series or DataFrame (if level specified)<br>|<br>| kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, <strong>kwargs)<br>| Return unbiased kurtosis over requested axis using Fishers definition of<br>| kurtosis (kurtosis of normal == 0.0). Normalized by N-1<br>|<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-<br>543<br>| kurt : Series or DataFrame (if level specified)<br>|<br>| last_valid_index(self)<br>| Return label for last non-NA/null value<br>|<br>| lookup(self, row_labels, col_labels)<br>| Label-based “fancy indexing” function for DataFrame.<br>| Given equal-length arrays of row and column labels, return an<br>| array of the values corresponding to each (row, col) pair.<br>|<br>| 【参数】<br>| ———-| row_labels : sequence<br>| The row labels to use for lookup<br>| col_labels : sequence<br>| The column labels to use for lookup<br>|<br>| 【注意】<br>| —–| Akin to::<br>|<br>| result = []<br>| for row, col in zip(row_labels, col_labels):<br>| result.append(df.get_value(row, col))<br>|<br>| 【示例】<br>| ——–| values : ndarray<br>| The found values<br>|<br>| mad(self, axis=None, skipna=None, level=None)<br>| Return the mean absolute deviation of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| mad : Series or DataFrame (if level specified)<br>|<br>| max(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| This method returns the maximum of the values in the object. If you<br>| want the <em>index</em> of the maximum, use <code>idxmax</code>. This is the<br>| equivalent of the <code>numpy.ndarray</code> method <code>argmax</code>.<br>|<br>| 【参数】<br>| ———-<br>544<br>| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| max : Series or DataFrame (if level specified)<br>|<br>| mean(self, axis=None, skipna=None, level=None, numeric_only=None, <strong>kwargs)<br>| Return the mean of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| mean : Series or DataFrame (if level specified)<br>|<br>| median(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| Return the median of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| median : Series or DataFrame (if level specified)<br>|<br>| memory_usage(self, index=False, deep=False)<br>| Memory usage of DataFrame columns.<br>545<br>|<br>| 【参数】<br>| ———-| index : bool<br>| Specifies whether to include memory usage of DataFrame’s<br>| index in returned Series. If <code>index=True</code> (default is False)<br>| the first index of the Series is <code>Index</code>.<br>| deep : bool<br>| Introspect the data deeply, interrogate<br>| <code>object</code> dtypes for system-level memory consumption<br>|<br>| 【返回值】<br>| ——-| sizes : Series<br>| A series with column names as index and memory usage of<br>| columns with units of bytes.<br>|<br>| 【注意】<br>| —–| Memory usage does not include memory consumed by elements that<br>| are not components of the array if deep=False<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.nbytes<br>|<br>| merge(self, right, how=’inner’, on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False,<br>suffixes=(‘_x’, ‘_y’), copy=True, indicator=False)<br>| Merge DataFrame objects by performing a database-style join operation by<br>| columns or indexes.<br>|<br>| If joining columns on columns, the DataFrame indexes <em>will be<br>| ignored</em>. Otherwise if joining indexes on indexes or indexes on a column or<br>| columns, the index will be passed on.<br>|<br>| 【参数】<br>| ———-| right : DataFrame<br>| how : {‘left’, ‘right’, ‘outer’, ‘inner’}, default ‘inner’<br>| <em> left: use only keys from left frame (SQL: left outer join)<br>| </em> right: use only keys from right frame (SQL: right outer join)<br>| <em> outer: use union of keys from both frames (SQL: full outer join)<br>| </em> inner: use intersection of keys from both frames (SQL: inner join)<br>| on : label or list<br>| Field names to join on. Must be found in both DataFrames. If on is<br>| None and not merging on indexes, then it merges on the intersection of<br>| the columns by default.<br>| left_on : label or list, or array-like<br>| Field names to join on in left DataFrame. Can be a vector or list of<br>| vectors of the length of the DataFrame to use a particular vector as<br>| the join key instead of columns<br>| right_on : label or list, or array-like<br>| Field names to join on in right DataFrame or vector/list of vectors per<br>| left_on docs<br>| left_index : boolean, default False<br>| Use the index from the left DataFrame as the join key(s). If it is a<br>| MultiIndex, the number of keys in the other DataFrame (either the index<br>546<br>| or a number of columns) must match the number of levels<br>| right_index : boolean, default False<br>| Use the index from the right DataFrame as the join key. Same caveats as<br>| left_index<br>| sort : boolean, default False<br>| Sort the join keys lexicographically in the result DataFrame<br>| suffixes : 2-length sequence (tuple, list, …)<br>| Suffix to apply to overlapping column names in the left and right<br>| side, respectively<br>| copy : boolean, default True<br>| If False, do not copy data unnecessarily<br>| indicator : boolean or string, default False<br>| If True, adds a column to output DataFrame called “_merge” with<br>| information on the source of each row.<br>| If string, column with information on source of each row will be added to<br>| output DataFrame, and column will be named value of string.<br>| Information column is Categorical-type and takes on a value of “left_only”<br>| for observations whose merge key only appears in ‘left’ DataFrame,<br>| “right_only” for observations whose merge key only appears in ‘right’<br>| DataFrame, and “both” if the observation’s merge key is found in both.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【示例】<br>| ——–|<br>| &gt;&gt;&gt; A &gt;&gt;&gt; B<br>| lkey value rkey value<br>| 0 foo 1 0 foo 5<br>| 1 bar 2 1 bar 6<br>| 2 baz 3 2 qux 7<br>| 3 foo 4 3 bar 8<br>|<br>| &gt;&gt;&gt; merge(A, B, left_on=’lkey’, right_on=’rkey’, how=’outer’)<br>| lkey value_x rkey value_y<br>| 0 foo 1 foo 5<br>| 1 foo 4 foo 5<br>| 2 bar 2 bar 6<br>| 3 bar 2 bar 8<br>| 4 baz 3 NaN NaN<br>| 5 NaN NaN qux 7<br>|<br>| 【返回值】<br>| ——-| merged : DataFrame<br>| The output type will the be same as ‘left’, if it is a subclass<br>| of DataFrame.<br>|<br>| min(self, axis=None, skipna=None, level=None, numeric_only=None, <strong>kwargs)<br>| This method returns the minimum of the values in the object. If you<br>| want the <em>index</em> of the minimum, use <code>idxmin</code>. This is the<br>| equivalent of the <code>numpy.ndarray</code> method <code>argmin</code>.<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>547<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| min : Series or DataFrame (if level specified)<br>|<br>| mode(self, axis=0, numeric_only=False)<br>| Gets the mode(s) of each element along the axis selected. Empty if nothing<br>| has 2+ occurrences. Adds a row for each mode per label, fills in gaps<br>| with nan.<br>|<br>| Note that there could be multiple values returned for the selected<br>| axis (when more than one item share the maximum frequency), which is the<br>| reason why a dataframe is returned. If you want to impute missing values<br>| with the mode in a dataframe <code>df</code>, you can just do this:<br>| <code>df.fillna(df.mode().iloc[0])</code><br>|<br>| 【参数】<br>| ———-| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| <em> 0 or ‘index’ : get mode of each column<br>| </em> 1 or ‘columns’ : get mode of each row<br>| numeric_only : boolean, default False<br>| if True, only apply to numeric columns<br>|<br>| 【返回值】<br>| ——-| modes : DataFrame (sorted)<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df = pd.DataFrame({‘A’: [1, 2, 1, 2, 1, 2, 3]})<br>| &gt;&gt;&gt; df.mode()<br>| A<br>| 0 1<br>| 1 2<br>|<br>| nlargest(self, n, columns, keep=’first’)<br>| Get the rows of a DataFrame sorted by the <code>n</code> largest<br>| values of <code>columns</code>.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| n : int<br>| Number of items to retrieve<br>| columns : list or str<br>| Column name or names to order by<br>| keep : {‘first’, ‘last’, False}, default ‘first’<br>548<br>| Where there are duplicate values:<br>| - <code>first</code> : take the first occurrence.<br>| - <code>last</code> : take the last occurrence.<br>|<br>| 【返回值】<br>| ——-| DataFrame<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df = DataFrame({‘a’: [1, 10, 8, 11, -1],<br>| … ‘b’: list(‘abdce’),<br>| … ‘c’: [1.0, 2.0, np.nan, 3.0, 4.0]})<br>| &gt;&gt;&gt; df.nlargest(3, ‘a’)<br>| a b c<br>| 3 11 c 3<br>| 1 10 b 2<br>| 2 8 d NaN<br>|<br>| nsmallest(self, n, columns, keep=’first’)<br>| Get the rows of a DataFrame sorted by the <code>n</code> smallest<br>| values of <code>columns</code>.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| n : int<br>| Number of items to retrieve<br>| columns : list or str<br>| Column name or names to order by<br>| keep : {‘first’, ‘last’, False}, default ‘first’<br>| Where there are duplicate values:<br>| - <code>first</code> : take the first occurrence.<br>| - <code>last</code> : take the last occurrence.<br>|<br>| 【返回值】<br>| ——-| DataFrame<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df = DataFrame({‘a’: [1, 10, 8, 11, -1],<br>| … ‘b’: list(‘abdce’),<br>| … ‘c’: [1.0, 2.0, np.nan, 3.0, 4.0]})<br>| &gt;&gt;&gt; df.nsmallest(3, ‘a’)<br>| a b c<br>| 4 -1 e 4<br>| 0 1 a 1<br>| 2 8 d NaN<br>|<br>| pivot(self, index=None, columns=None, values=None)<br>| Reshape data (produce a “pivot” table) based on column values. Uses<br>| unique values from index / columns to form axes and return either<br>| DataFrame or Panel, depending on whether you request a single value<br>| column (DataFrame) or all columns (Panel)<br>|<br>549<br>| 【参数】<br>| ———-| index : string or object, optional<br>| Column name to use to make new frame’s index. If None, uses<br>| existing index.<br>| columns : string or object<br>| Column name to use to make new frame’s columns<br>| values : string or object, optional<br>| Column name to use for populating new frame’s values<br>|<br>| 【注意】<br>| —–| For finer-tuned control, see hierarchical indexing documentation along<br>| with the related stack/unstack methods<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df<br>| foo bar baz<br>| 0 one A 1.<br>| 1 one B 2.<br>| 2 one C 3.<br>| 3 two A 4.<br>| 4 two B 5.<br>| 5 two C 6.<br>|<br>| &gt;&gt;&gt; df.pivot(‘foo’, ‘bar’, ‘baz’)<br>| A B C<br>| one 1 2 3<br>| two 4 5 6<br>|<br>| &gt;&gt;&gt; df.pivot(‘foo’, ‘bar’)[‘baz’]<br>| A B C<br>| one 1 2 3<br>| two 4 5 6<br>|<br>| 【返回值】<br>| ——-| pivoted : DataFrame<br>| If no values column specified, will have hierarchically indexed<br>| columns<br>|<br>| pivot_table(data, values=None, index=None, columns=None, aggfunc=’mean’, fill_value=None, margins=False,<br>dropna=True, margins_name=’All’)<br>| Create a spreadsheet-style pivot table as a DataFrame. The levels in the<br>| pivot table will be stored in MultiIndex objects (hierarchical indexes) on<br>| the index and columns of the result DataFrame<br>|<br>| 【参数】<br>| ———-| data : DataFrame<br>| values : column to aggregate, optional<br>| index : a column, Grouper, array which has the same length as data, or list of them.<br>| Keys to group by on the pivot table index.<br>| If an array is passed, it is being used as the same manner as column values.<br>| columns : a column, Grouper, array which has the same length as data, or list of them.<br>| Keys to group by on the pivot table column.<br>550<br>| If an array is passed, it is being used as the same manner as column values.<br>| aggfunc : function, default numpy.mean, or list of functions<br>| If list of functions passed, the resulting pivot table will have<br>| hierarchical columns whose top level are the function names (inferred<br>| from the function objects themselves)<br>| fill_value : scalar, default None<br>| Value to replace missing values with<br>| margins : boolean, default False<br>| Add all row / columns (e.g. for subtotal / grand totals)<br>| dropna : boolean, default True<br>| Do not include columns whose entries are all NaN<br>| margins_name : string, default ‘All’<br>| Name of the row / column that will contain the totals<br>| when margins is True.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df<br>| A B C D<br>| 0 foo one small 1<br>| 1 foo one large 2<br>| 2 foo one large 2<br>| 3 foo two small 3<br>| 4 foo two small 3<br>| 5 bar one large 4<br>| 6 bar one small 5<br>| 7 bar two small 6<br>| 8 bar two large 7<br>|<br>| &gt;&gt;&gt; table = pivot_table(df, values=’D’, index=[‘A’, ‘B’],<br>| … columns=[‘C’], aggfunc=np.sum)<br>| &gt;&gt;&gt; table<br>| small large<br>| foo one 1 4<br>| two 6 NaN<br>| bar one 5 4<br>| two 6 7<br>|<br>| 【返回值】<br>| ——-| table : DataFrame<br>|<br>| prod(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| Return the product of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>551<br>|<br>| 【返回值】<br>| ——-| prod : Series or DataFrame (if level specified)<br>|<br>| product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, <strong>kwargs)<br>| Return the product of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| prod : Series or DataFrame (if level specified)<br>|<br>| quantile(self, q=0.5, axis=0, numeric_only=True)<br>| Return values at the given quantile over requested axis, a la<br>| numpy.percentile.<br>|<br>| 【参数】<br>| ———-| q : float or array-like, default 0.5 (50% quantile)<br>| 0 &lt;= q &lt;= 1, the quantile(s) to compute<br>| axis : {0, 1, ‘index’, ‘columns’} (default 0)<br>| 0 or ‘index’ for row-wise, 1 or ‘columns’ for column-wise<br>|<br>|<br>| 【返回值】<br>| ——-| quantiles : Series or DataFrame<br>| If <code>q</code> is an array, a DataFrame will be returned where the<br>| index is <code>q</code>, the columns are the columns of self, and the<br>| values are the quantiles.<br>| If <code>q</code> is a float, a Series will be returned where the<br>| index is the columns of self and the values are the quantiles.<br>|<br>| 【示例】<br>| ——–|<br>| &gt;&gt;&gt; df = DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),<br>| columns=[‘a’, ‘b’])<br>| &gt;&gt;&gt; df.quantile(.1)<br>| a 1.3<br>| b 3.7<br>| dtype: float64<br>| &gt;&gt;&gt; df.quantile([.1, .5])<br>| a b<br>552<br>| 0.1 1.3 3.7<br>| 0.5 2.5 55.0<br>|<br>| query(self, expr, </strong>kwargs)<br>| Query the columns of a frame with a boolean expression.<br>|<br>| .. versionadded:: 0.13<br>|<br>| 【参数】<br>| ———-| expr : string<br>| The query string to evaluate. You can refer to variables<br>| in the environment by prefixing them with an ‘@’ character like<br>| <code>@a + b</code>.<br>| kwargs : dict<br>| See the documentation for :func:<code>pandas.eval</code> for complete details<br>| on the keyword arguments accepted by :meth:<code>DataFrame.query</code>.<br>|<br>| 【返回值】<br>| ——-| q : DataFrame<br>|<br>| 【注意】<br>| —–| The result of the evaluation of this expression is first passed to<br>| :attr:<code>DataFrame.loc</code> and if that fails because of a<br>| multidimensional key (e.g., a DataFrame) then the result will be passed<br>| to :meth:<code>DataFrame.__getitem__</code>.<br>|<br>| This method uses the top-level :func:<code>pandas.eval</code> function to<br>| evaluate the passed query.<br>|<br>| The :meth:<code>~pandas.DataFrame.query</code> method uses a slightly<br>| modified Python syntax by default. For example, the <code>&amp;</code> and <code>|</code><br>| (bitwise) operators have the precedence of their boolean cousins,<br>| :keyword:<code>and</code> and :keyword:<code>or</code>. This <em>is</em> syntactically valid Python,<br>| however the semantics are different.<br>|<br>| You can change the semantics of the expression by passing the keyword<br>| argument <code>parser=&#39;python&#39;</code>. This enforces the same semantics as<br>| evaluation in Python space. Likewise, you can pass <code>engine=&#39;python&#39;</code><br>| to evaluate an expression using Python itself as a backend. This is not<br>| recommended as it is inefficient compared to using <code>numexpr</code> as the<br>| engine.<br>|<br>| The :attr:<code>DataFrame.index</code> and<br>| :attr:<code>DataFrame.columns</code> attributes of the<br>| :class:<code>~pandas.DataFrame</code> instance are placed in the query namespace<br>| by default, which allows you to treat both the index and columns of the<br>| frame as a column in the frame.<br>| The identifier <code>index</code> is used for the frame index; you can also<br>| use the name of the index to identify it in a query.<br>|<br>| For further details and examples see the <code>query</code> documentation in<br>| :ref:<code>indexing &lt;indexing.query&gt;</code>.<br>|<br>| 【参见】<br>553<br>| ——–| pandas.eval<br>| DataFrame.eval<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; from numpy.random import randn<br>| &gt;&gt;&gt; from pandas import DataFrame<br>| &gt;&gt;&gt; df = DataFrame(randn(10, 2), columns=list(‘ab’))<br>| &gt;&gt;&gt; df.query(‘a &gt; b’)<br>| &gt;&gt;&gt; df[df.a &gt; df.b] # same result as the previous expression<br>|<br>| rank(self, axis=0, numeric_only=None, method=’average’, na_option=’keep’, ascending=True, pct=False)<br>| Compute numerical data ranks (1 through n) along axis. Equal values are<br>| assigned a rank that is the average of the ranks of those values<br>|<br>| 【参数】<br>| ———-| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| Ranks over columns (0) or rows (1)<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data<br>| method : {‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}<br>| <em> average: average rank of group<br>| </em> min: lowest rank in group<br>| <em> max: highest rank in group<br>| </em> first: ranks assigned in order they appear in the array<br>| <em> dense: like ‘min’, but rank always increases by 1 between groups<br>| na_option : {‘keep’, ‘top’, ‘bottom’}<br>| </em> keep: leave NA values where they are<br>| <em> top: smallest rank if ascending<br>| </em> bottom: smallest rank if descending<br>| ascending : boolean, default True<br>| False for ranks by high (1) to low (N)<br>| pct : boolean, default False<br>| Computes percentage rank of data<br>|<br>| 【返回值】<br>| ——-| ranks : DataFrame<br>|<br>| reindex(self, index=None, columns=None, <strong>kwargs)<br>| Conform DataFrame to new index with optional filling logic, placing<br>| NA/NaN in locations having no value in the previous index. A new object<br>| is produced unless the new index is equivalent to the current one and<br>| copy=False<br>|<br>| 【参数】<br>| ———-| index, columns : array-like, optional (can be specified in order, or as<br>| keywords)<br>| New labels / index to conform to. Preferably an Index object to<br>| avoid duplicating data<br>| method : {None, ‘backfill’/‘bfill’, ‘pad’/‘ffill’, ‘nearest’}, optional<br>| method to use for filling holes in reindexed DataFrame.<br>| Please note: this is only applicable to DataFrames/Series with a<br>| monotonically increasing/decreasing index.<br>554<br>| <em> default: don’t fill gaps<br>| </em> pad / ffill: propagate last valid observation forward to next valid<br>| <em> backfill / bfill: use next valid observation to fill gap<br>| </em> nearest: use nearest valid observations to fill gap<br>| copy : boolean, default True<br>| Return a new object, even if the passed indexes are the same<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>| fill_value : scalar, default np.NaN<br>| Value to use for missing values. Defaults to NaN, but can be any<br>| “compatible” value<br>| limit : int, default None<br>| Maximum number of consecutive elements to forward or backward fill<br>| tolerance : optional<br>| Maximum distance between original and new labels for inexact<br>| matches. The values of the index at the matching locations most<br>| satisfy the equation <code>abs(index[indexer] - target) &lt;= tolerance</code>.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【示例】<br>| ——–|<br>| Create a dataframe with some fictional data.<br>|<br>| &gt;&gt;&gt; index = [‘Firefox’, ‘Chrome’, ‘Safari’, ‘IE10’, ‘Konqueror’]<br>| &gt;&gt;&gt; df = pd.DataFrame({<br>| … ‘http_status’: [200,200,404,404,301],<br>| … ‘response_time’: [0.04, 0.02, 0.07, 0.08, 1.0]},<br>| … index=index)<br>| &gt;&gt;&gt; df<br>| http_status response_time<br>| Firefox 200 0.04<br>| Chrome 200 0.02<br>| Safari 404 0.07<br>| IE10 404 0.08<br>| Konqueror 301 1.00<br>|<br>| Create a new index and reindex the dataframe. By default<br>| values in the new index that do not have corresponding<br>| records in the dataframe are assigned <code>NaN</code>.<br>|<br>| &gt;&gt;&gt; new_index= [‘Safari’, ‘Iceweasel’, ‘Comodo Dragon’, ‘IE10’,<br>| … ‘Chrome’]<br>| &gt;&gt;&gt; df.reindex(new_index)<br>| http_status response_time<br>| Safari 404 0.07<br>| Iceweasel NaN NaN<br>| Comodo Dragon NaN NaN<br>| IE10 404 0.08<br>| Chrome 200 0.02<br>|<br>| We can fill in the missing values by passing a value to<br>| the keyword <code>fill_value</code>. Because the index is not monotonically<br>| increasing or decreasing, we cannot use arguments to the keyword<br>| <code>method</code> to fill the <code>NaN</code> values.<br>555<br>|<br>| &gt;&gt;&gt; df.reindex(new_index, fill_value=0)<br>| http_status response_time<br>| Safari 404 0.07<br>| Iceweasel 0 0.00<br>| Comodo Dragon 0 0.00<br>| IE10 404 0.08<br>| Chrome 200 0.02<br>|<br>| &gt;&gt;&gt; df.reindex(new_index, fill_value=’missing’)<br>| http_status response_time<br>| Safari 404 0.07<br>| Iceweasel missing missing<br>| Comodo Dragon missing missing<br>| IE10 404 0.08<br>| Chrome 200 0.02<br>|<br>| To further illustrate the filling functionality in<br>| <code>reindex</code>, we will create a dataframe with a<br>| monotonically increasing index (for example, a sequence<br>| of dates).<br>|<br>| &gt;&gt;&gt; date_index = pd.date_range(‘1/1/2010’, periods=6, freq=’D’)<br>| &gt;&gt;&gt; df2 = pd.DataFrame({“prices”: [100, 101, np.nan, 100, 89, 88]},<br>| index=date_index)<br>| &gt;&gt;&gt; df2<br>| prices<br>| 2010-01-01 100<br>| 2010-01-02 101<br>| 2010-01-03 NaN<br>| 2010-01-04 100<br>| 2010-01-05 89<br>| 2010-01-06 88<br>|<br>| Suppose we decide to expand the dataframe to cover a wider<br>| date range.<br>|<br>| &gt;&gt;&gt; date_index2 = pd.date_range(‘12/29/2009’, periods=10, freq=’D’)<br>| &gt;&gt;&gt; df2.reindex(date_index2)<br>| prices<br>| 2009-12-29 NaN<br>| 2009-12-30 NaN<br>| 2009-12-31 NaN<br>| 2010-01-01 100<br>| 2010-01-02 101<br>| 2010-01-03 NaN<br>| 2010-01-04 100<br>| 2010-01-05 89<br>| 2010-01-06 88<br>| 2010-01-07 NaN<br>|<br>| The index entries that did not have a value in the original data frame<br>| (for example, ‘2009-12-29’) are by default filled with <code>NaN</code>.<br>| If desired, we can fill in the missing values using one of several<br>| options.<br>|<br>| For example, to backpropagate the last valid value to fill the <code>NaN</code><br>556<br>| values, pass <code>bfill</code> as an argument to the <code>method</code> keyword.<br>|<br>| &gt;&gt;&gt; df2.reindex(date_index2, method=’bfill’)<br>| prices<br>| 2009-12-29 100<br>| 2009-12-30 100<br>| 2009-12-31 100<br>| 2010-01-01 100<br>| 2010-01-02 101<br>| 2010-01-03 NaN<br>| 2010-01-04 100<br>| 2010-01-05 89<br>| 2010-01-06 88<br>| 2010-01-07 NaN<br>|<br>| Please note that the <code>NaN</code> value present in the original dataframe<br>| (at index value 2010-01-03) will not be filled by any of the<br>| value propagation schemes. This is because filling while reindexing<br>| does not look at dataframe values, but only compares the original and<br>| desired indexes. If you do want to fill in the <code>NaN</code> values present<br>| in the original dataframe, use the <code>fillna()</code> method.<br>|<br>| 【返回值】<br>| ——-| reindexed : DataFrame<br>|<br>| reindex_axis(self, labels, axis=0, method=None, level=None, copy=True, limit=None, fill_value=nan)<br>| Conform input object to new index with optional filling logic,<br>| placing NA/NaN in locations having no value in the previous index. A<br>| new object is produced unless the new index is equivalent to the<br>| current one and copy=False<br>|<br>| 【参数】<br>| ———-| labels : array-like<br>| New labels / index to conform to. Preferably an Index object to<br>| avoid duplicating data<br>| axis : {0, 1, ‘index’, ‘columns’}<br>| method : {None, ‘backfill’/‘bfill’, ‘pad’/‘ffill’, ‘nearest’}, optional<br>| Method to use for filling holes in reindexed DataFrame:<br>| <em> default: don’t fill gaps<br>| </em> pad / ffill: propagate last valid observation forward to next valid<br>| <em> backfill / bfill: use next valid observation to fill gap<br>| </em> nearest: use nearest valid observations to fill gap<br>| copy : boolean, default True<br>| Return a new object, even if the passed indexes are the same<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>| limit : int, default None<br>| Maximum number of consecutive elements to forward or backward fill<br>| tolerance : optional<br>| Maximum distance between original and new labels for inexact<br>| matches. The values of the index at the matching locations most<br>| satisfy the equation <code>abs(index[indexer] - target) &lt;= tolerance</code>.<br>|<br>| .. versionadded:: 0.17.0<br>557<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df.reindex_axis([‘A’, ‘B’, ‘C’], axis=1)<br>|<br>| 【参见】<br>| ——–| reindex, reindex_like<br>|<br>| 【返回值】<br>| ——-| reindexed : DataFrame<br>|<br>| rename(self, index=None, columns=None, </strong>kwargs)<br>| Alter axes input function or functions. Function / dict values must be<br>| unique (1-to-1). Labels not contained in a dict / Series will be left<br>| as-is.<br>|<br>| 【参数】<br>| ———-| index, columns : dict-like or function, optional<br>| Transformation to apply to that axis values<br>|<br>| copy : boolean, default True<br>| Also copy underlying data<br>| inplace : boolean, default False<br>| Whether to return a new DataFrame. If True then value of copy is<br>| ignored.<br>|<br>| 【返回值】<br>| ——-| renamed : DataFrame (new object)<br>|<br>| reorder_levels(self, order, axis=0)<br>| Rearrange index levels using input order.<br>| May not drop or duplicate levels<br>|<br>| 【参数】<br>| ———-| order : list of int or list of str<br>| List representing new level order. Reference level by number<br>| (position) or by key (label).<br>| axis : int<br>| Where to reorder levels.<br>|<br>| 【返回值】<br>| ——-| type of caller (new object)<br>|<br>| reset_index(self, level=None, drop=False, inplace=False, col_level=0, col_fill=’’)<br>| For DataFrame with multi-level index, return new DataFrame with<br>| labeling information in the columns under the index names, defaulting<br>| to ‘level_0’, ‘level_1’, etc. if any are None. For a standard index,<br>| the index name will be used (if set), otherwise a default ‘index’ or<br>| ‘level_0’ (if ‘index’ is already taken) will be used.<br>|<br>558<br>| 【参数】<br>| ———-| level : int, str, tuple, or list, default None<br>| Only remove the given levels from the index. Removes all levels by<br>| default<br>| drop : boolean, default False<br>| Do not try to insert index into dataframe columns. This resets<br>| the index to the default integer index.<br>| inplace : boolean, default False<br>| Modify the DataFrame in place (do not create a new object)<br>| col_level : int or str, default 0<br>| If the columns have multiple levels, determines which level the<br>| labels are inserted into. By default it is inserted into the first<br>| level.<br>| col_fill : object, default ‘’<br>| If the columns have multiple levels, determines how the other<br>| levels are named. If None then the index name is repeated.<br>|<br>| 【返回值】<br>| ——-| resetted : DataFrame<br>|<br>| round(self, decimals=0, out=None)<br>| Round a DataFrame to a variable number of decimal places.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| decimals : int, dict, Series<br>| Number of decimal places to round each column to. If an int is<br>| given, round each column to the same number of places.<br>| Otherwise dict and Series round to variable numbers of places.<br>| Column names should be in the keys if <code>decimals</code> is a<br>| dict-like, or in the index if <code>decimals</code> is a Series. Any<br>| columns not included in <code>decimals</code> will be left as is. Elements<br>| of <code>decimals</code> which are not columns of the input will be<br>| ignored.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df = pd.DataFrame(np.random.random([3, 3]),<br>| … columns=[‘A’, ‘B’, ‘C’], index=[‘first’, ‘second’, ‘third’])<br>| &gt;&gt;&gt; df<br>| A B C<br>| first 0.028208 0.992815 0.173891<br>| second 0.038683 0.645646 0.577595<br>| third 0.877076 0.149370 0.491027<br>| &gt;&gt;&gt; df.round(2)<br>| A B C<br>| first 0.03 0.99 0.17<br>| second 0.04 0.65 0.58<br>| third 0.88 0.15 0.49<br>| &gt;&gt;&gt; df.round({‘A’: 1, ‘C’: 2})<br>| A B C<br>| first 0.0 0.992815 0.17<br>| second 0.0 0.645646 0.58<br>559<br>| third 0.9 0.149370 0.49<br>| &gt;&gt;&gt; decimals = pd.Series([1, 0, 2], index=[‘A’, ‘B’, ‘C’])<br>| &gt;&gt;&gt; df.round(decimals)<br>| A B C<br>| first 0.0 1 0.17<br>| second 0.0 1 0.58<br>| third 0.9 0 0.49<br>|<br>| 【返回值】<br>| ——-| DataFrame object<br>|<br>| select_dtypes(self, include=None, exclude=None)<br>| Return a subset of a DataFrame including/excluding columns based on<br>| their <code>dtype</code>.<br>|<br>| 【参数】<br>| ———-| include, exclude : list-like<br>| A list of dtypes or strings to be included/excluded. You must pass<br>| in a non-empty sequence for at least one of these.<br>|<br>| 【Raises 引发错误】<br>| ——| ValueError<br>| <em> If both of <code>include</code> and <code>exclude</code> are empty<br>| </em> If <code>include</code> and <code>exclude</code> have overlapping elements<br>| <em> If any kind of string dtype is passed in.<br>| TypeError<br>| </em> If either of <code>include</code> or <code>exclude</code> is not a sequence<br>|<br>| 【返回值】<br>| ——-| subset : DataFrame<br>| The subset of the frame including the dtypes in <code>include</code> and<br>| excluding the dtypes in <code>exclude</code>.<br>|<br>| 【注意】<br>| —–| <em> To select all </em>numeric<em> types use the numpy dtype <code>numpy.number</code><br>| </em> To select strings you must use the <code>object</code> dtype, but note that<br>| this will return <em>all</em> object dtype columns<br>| <em> See the <code>numpy dtype hierarchy
| &lt;http://docs.scipy.org/doc/numpy/reference/arrays.scalars.html&gt;</code>__<br>| </em> To select Pandas categorical dtypes, use ‘category’<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df = pd.DataFrame({‘a’: np.random.randn(6).astype(‘f4’),<br>| … ‘b’: [True, False] <em> 3,<br>| … ‘c’: [1.0, 2.0] </em> 3})<br>| &gt;&gt;&gt; df<br>| a b c<br>| 0 0.3962 True 1<br>| 1 0.1459 False 2<br>| 2 0.2623 True 1<br>| 3 0.0764 False 2<br>560<br>| 4 -0.9703 True 1<br>| 5 -1.2094 False 2<br>| &gt;&gt;&gt; df.select_dtypes(include=[‘float64’])<br>| c<br>| 0 1<br>| 1 2<br>| 2 1<br>| 3 2<br>| 4 1<br>| 5 2<br>| &gt;&gt;&gt; df.select_dtypes(exclude=[‘floating’])<br>| b<br>| 0 True<br>| 1 False<br>| 2 True<br>| 3 False<br>| 4 True<br>| 5 False<br>|<br>| sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, <strong>kwargs)<br>| Return unbiased standard error of the mean over requested axis.<br>|<br>| Normalized by N-1 by default. This can be changed using the ddof argument<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| ddof : int, default 1<br>| degrees of freedom<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| sem : Series or DataFrame (if level specified)<br>|<br>| set_index(self, keys, drop=True, append=False, inplace=False, verify_integrity=False)<br>| Set the DataFrame index (row labels) using one or more existing<br>| columns. By default yields a new object.<br>|<br>| 【参数】<br>| ———-| keys : column label or list of column labels / arrays<br>| drop : boolean, default True<br>| Delete columns to be used as the new index<br>| append : boolean, default False<br>| Whether to append columns to existing index<br>| inplace : boolean, default False<br>| Modify the DataFrame in place (do not create a new object)<br>| verify_integrity : boolean, default False<br>561<br>| Check the new index for duplicates. Otherwise defer the check until<br>| necessary. Setting to False will improve the performance of this<br>| method<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; indexed_df = df.set_index([‘A’, ‘B’])<br>| &gt;&gt;&gt; indexed_df2 = df.set_index([‘A’, [0, 1, 2, 0, 1, 2]])<br>| &gt;&gt;&gt; indexed_df3 = df.set_index([[0, 1, 2, 0, 1, 2]])<br>|<br>| 【返回值】<br>| ——-| dataframe : DataFrame<br>|<br>| shift(self, periods=1, freq=None, axis=0)<br>| Shift index by desired number of periods with an optional time freq<br>|<br>| 【参数】<br>| ———-| periods : int<br>| Number of periods to move, can be positive or negative<br>| freq : DateOffset, timedelta, or time rule string, optional<br>| Increment to use from datetools module or time rule (e.g. ‘EOM’).<br>| See Notes.<br>| axis : {0, 1, ‘index’, ‘columns’}<br>|<br>| 【注意】<br>| —–| If freq is specified then the index values are shifted but the data<br>| is not realigned. That is, use freq if you would like to extend the<br>| index when shifting and preserve the original data.<br>|<br>| 【返回值】<br>| ——-| shifted : DataFrame<br>|<br>| skew(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| Return unbiased skew over requested axis<br>| Normalized by N-1<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| skew : Series or DataFrame (if level specified)<br>|<br>562<br>| sort(self, columns=None, axis=0, ascending=True, inplace=False, kind=’quicksort’, na_position=’last’)<br>| DEPRECATED: use :meth:<code>DataFrame.sort_values</code><br>|<br>| Sort DataFrame either by labels (along either axis) or by the values in<br>| column(s)<br>|<br>| 【参数】<br>| ———-| columns : object<br>| Column name(s) in frame. Accepts a column name or a list<br>| for a nested sort. A tuple will be interpreted as the<br>| levels of a multi-index.<br>| ascending : boolean or list, default True<br>| Sort ascending vs. descending. Specify list for multiple sort<br>| orders<br>| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| Sort index/rows versus columns<br>| inplace : boolean, default False<br>| Sort the DataFrame without creating a new instance<br>| kind : {‘quicksort’, ‘mergesort’, ‘heapsort’}, optional<br>| This option is only applied when sorting on a single column or label.<br>| na_position : {‘first’, ‘last’} (optional, default=’last’)<br>| ‘first’ puts NaNs at the beginning<br>| ‘last’ puts NaNs at the end<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; result = df.sort([‘A’, ‘B’], ascending=[1, 0])<br>|<br>| 【返回值】<br>| ——-| sorted : DataFrame<br>|<br>| sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind=’quicksort’, na_position=’last’,<br>sort_remaining=True, by=None)<br>| Sort object by labels (along an axis)<br>|<br>| 【参数】<br>| ———-| axis : index, columns to direct sorting<br>| level : int or level name or list of ints or list of level names<br>| if not None, sort on values in specified index level(s)<br>| ascending : boolean, default True<br>| Sort ascending vs. descending<br>| inplace : bool<br>| if True, perform operation in-place<br>| kind : {<code>quicksort</code>, <code>mergesort</code>, <code>heapsort</code>}<br>| Choice of sorting algorithm. 参见：ndarray.np.sort for more information.<br>| <code>mergesort</code> is the only stable algorithm. For DataFrames, this option is<br>| only applied when sorting on a single column or label.<br>| na_position : {‘first’, ‘last’}<br>| <code>first</code> puts NaNs at the beginning, <code>last</code> puts NaNs at the end<br>| sort_remaining : bool<br>| if true and sorting by level and index is multilevel, sort by other levels<br>| too (in order) after sorting by specified level<br>|<br>| 【返回值】<br>563<br>| ——-| sorted_obj : DataFrame<br>|<br>| sort_values(self, by, axis=0, ascending=True, inplace=False, kind=’quicksort’, na_position=’last’)<br>| Sort by the values along either axis<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| by : string name or list of names which refer to the axis items<br>| axis : index, columns to direct sorting<br>| ascending : bool or list of bool<br>| Sort ascending vs. descending. Specify list for multiple sort orders.<br>| If this is a list of bools, must match the length of the by<br>| inplace : bool<br>| if True, perform operation in-place<br>| kind : {<code>quicksort</code>, <code>mergesort</code>, <code>heapsort</code>}<br>| Choice of sorting algorithm. 参见：ndarray.np.sort for more information.<br>| <code>mergesort</code> is the only stable algorithm. For DataFrames, this option is<br>| only applied when sorting on a single column or label.<br>| na_position : {‘first’, ‘last’}<br>| <code>first</code> puts NaNs at the beginning, <code>last</code> puts NaNs at the end<br>|<br>| 【返回值】<br>| ——-| sorted_obj : DataFrame<br>|<br>| sortlevel(self, level=0, axis=0, ascending=True, inplace=False, sort_remaining=True)<br>| Sort multilevel index by chosen axis and primary level. Data will be<br>| lexicographically sorted by the chosen level followed by the other<br>| levels (in order)<br>|<br>| 【参数】<br>| ———-| level : int<br>| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| ascending : boolean, default True<br>| inplace : boolean, default False<br>| Sort the DataFrame without creating a new instance<br>| sort_remaining : boolean, default True<br>| Sort by the other levels too.<br>|<br>| 【返回值】<br>| ——-| sorted : DataFrame<br>|<br>| 【参见】<br>| ——–| DataFrame.sort_index(level=…)<br>|<br>| stack(self, level=-1, dropna=True)<br>| Pivot a level of the (possibly hierarchical) column labels, returning a<br>| DataFrame (or Series in the case of an object with a single level of<br>| column labels) having a hierarchical index with a new inner-most level<br>| of row labels.<br>| The level involved will automatically get sorted.<br>564<br>|<br>| 【参数】<br>| ———-| level : int, string, or list of these, default last level<br>| Level(s) to stack, can pass level name<br>| dropna : boolean, default True<br>| Whether to drop rows in the resulting Frame/Series with no valid<br>| values<br>|<br>| 【示例】<br>| ———-| &gt;&gt;&gt; s<br>| a b<br>| one 1. 2.<br>| two 3. 4.<br>|<br>| &gt;&gt;&gt; s.stack()<br>| one a 1<br>| b 2<br>| two a 3<br>| b 4<br>|<br>| 【返回值】<br>| ——-| stacked : DataFrame or Series<br>|<br>| std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, <strong>kwargs)<br>| Return unbiased standard deviation over requested axis.<br>|<br>| Normalized by N-1 by default. This can be changed using the ddof argument<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| ddof : int, default 1<br>| degrees of freedom<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| std : Series or DataFrame (if level specified)<br>|<br>| sum(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| Return the sum of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>565<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| sum : Series or DataFrame (if level specified)<br>|<br>| swaplevel(self, i, j, axis=0)<br>| Swap levels i and j in a MultiIndex on a particular axis<br>|<br>| 【参数】<br>| ———-| i, j : int, string (can be mixed)<br>| Level of index to be swapped. Can pass level name as string.<br>|<br>| 【返回值】<br>| ——-| swapped : type of caller (new object)<br>|<br>| to_csv(self, path_or_buf=None, sep=’,’, na_rep=’’, float_format=None, columns=None, header=True, index=True,<br>index_label=None, mode=’w’, encoding=None, compression=None, quoting=None, quotechar=’”‘, line_terminator=’\n’,<br>chunksize=None, tupleize_cols=False, date_format=None, doublequote=True, escapechar=None, decimal=’.’, <strong>kwds)<br>| Write DataFrame to a comma-separated values (csv) file<br>|<br>| 【参数】<br>| ———-| path_or_buf : string or file handle, default None<br>| File path or object, if None is provided the result is returned as<br>| a string.<br>| sep : character, default ‘,’<br>| Field delimiter for the output file.<br>| na_rep : string, default ‘’<br>| Missing data representation<br>| float_format : string, default None<br>| Format string for floating point numbers<br>| columns : sequence, optional<br>| Columns to write<br>| header : boolean or list of string, default True<br>| Write out column names. If a list of string is given it is assumed<br>| to be aliases for the column names<br>| index : boolean, default True<br>| Write row names (index)<br>| index_label : string or sequence, or False, default None<br>| Column label for index column(s) if desired. If None is given, and<br>| <code>header</code> and <code>index</code> are True, then the index names are used. A<br>| sequence should be given if the DataFrame uses MultiIndex. If<br>| False do not print fields for index names. Use index_label=False<br>| for easier importing in R<br>| nanRep : None<br>| deprecated, use na_rep<br>| mode : str<br>566<br>| Python write mode, default ‘w’<br>| encoding : string, optional<br>| A string representing the encoding to use in the output file,<br>| defaults to ‘ascii’ on Python 2 and ‘utf-8’ on Python 3.<br>| compression : string, optional<br>| a string representing the compression to use in the output file,<br>| allowed values are ‘gzip’, ‘bz2’,<br>| only used when the first argument is a filename<br>| line_terminator : string, default ‘\n’<br>| The newline character or character sequence to use in the output<br>| file<br>| quoting : optional constant from csv module<br>| defaults to csv.QUOTE_MINIMAL<br>| quotechar : string (length 1), default ‘“‘<br>| character used to quote fields<br>| doublequote : boolean, default True<br>| Control quoting of <code>quotechar</code> inside a field<br>| escapechar : string (length 1), default None<br>| character used to escape <code>sep</code> and <code>quotechar</code> when appropriate<br>| chunksize : int or None<br>| rows to write at a time<br>| tupleize_cols : boolean, default False<br>| write multi_index columns as a list of tuples (if True)<br>| or new (expanded format) if False)<br>| date_format : string, default None<br>| Format string for datetime objects<br>| decimal: string, default ‘.’<br>| Character recognized as decimal separator. E.g. use ‘,’ for European data<br>|<br>| .. versionadded:: 0.16.0<br>|<br>| to_dict(self, orient=’dict’)<br>| Convert DataFrame to dictionary.<br>|<br>| 【参数】<br>| ———-| orient : str {‘dict’, ‘list’, ‘series’, ‘split’, ‘records’, ‘index’}<br>| Determines the type of the values of the dictionary.<br>|<br>| - dict (default) : dict like {column -&gt; {index -&gt; value}}<br>| - list : dict like {column -&gt; [values]}<br>| - series : dict like {column -&gt; Series(values)}<br>| - split : dict like<br>| {index -&gt; [index], columns -&gt; [columns], data -&gt; [values]}<br>| - records : list like<br>| [{column -&gt; value}, … , {column -&gt; value}]<br>| - index : dict like {index -&gt; {column -&gt; value}}<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| Abbreviations are allowed. <code>s</code> indicates <code>series</code> and <code>sp</code><br>| indicates <code>split</code>.<br>|<br>| 【返回值】<br>| ——-| result : dict like {column -&gt; {index -&gt; value}}<br>|<br>567<br>| to_excel(self, excel_writer, sheet_name=’Sheet1’, na_rep=’’, float_format=None, columns=None, header=True, index=True,<br>index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep=’inf’, verbose=True)<br>| Write DataFrame to a excel sheet<br>|<br>| 【参数】<br>| ———-| excel_writer : string or ExcelWriter object<br>| File path or existing ExcelWriter<br>| sheet_name : string, default ‘Sheet1’<br>| Name of sheet which will contain DataFrame<br>| na_rep : string, default ‘’<br>| Missing data representation<br>| float_format : string, default None<br>| Format string for floating point numbers<br>| columns : sequence, optional<br>| Columns to write<br>| header : boolean or list of string, default True<br>| Write out column names. If a list of string is given it is<br>| assumed to be aliases for the column names<br>| index : boolean, default True<br>| Write row names (index)<br>| index_label : string or sequence, default None<br>| Column label for index column(s) if desired. If None is given, and<br>| <code>header</code> and <code>index</code> are True, then the index names are used. A<br>| sequence should be given if the DataFrame uses MultiIndex.<br>| startrow :<br>| upper left cell row to dump data frame<br>| startcol :<br>| upper left cell column to dump data frame<br>| engine : string, default None<br>| write engine to use - you can also set this via the options<br>| <code>io.excel.xlsx.writer</code>, <code>io.excel.xls.writer</code>, and<br>| <code>io.excel.xlsm.writer</code>.<br>| merge_cells : boolean, default True<br>| Write MultiIndex and Hierarchical Rows as merged cells.<br>| encoding: string, default None<br>| encoding of the resulting excel file. Only necessary for xlwt,<br>| other writers support unicode natively.<br>| inf_rep : string, default ‘inf’<br>| Representation for infinity (there is no native representation for<br>| infinity in Excel)<br>|<br>| 【注意】<br>| —–| If passing an existing ExcelWriter object, then the sheet will be added<br>| to the existing workbook. This can be used to save different<br>| DataFrames to one workbook:<br>|<br>| &gt;&gt;&gt; writer = ExcelWriter(‘output.xlsx’)<br>| &gt;&gt;&gt; df1.to_excel(writer,’Sheet1’)<br>| &gt;&gt;&gt; df2.to_excel(writer,’Sheet2’)<br>| &gt;&gt;&gt; writer.save()<br>|<br>| For compatibility with to_csv, to_excel serializes lists and dicts to<br>| strings before writing.<br>|<br>| to_gbq(self, destination_table, project_id, chunksize=10000, verbose=True, reauth=False, if_exists=’fail’)<br>568<br>| Write a DataFrame to a Google BigQuery table.<br>|<br>| THIS IS AN EXPERIMENTAL LIBRARY<br>|<br>| 【参数】<br>| ———-| dataframe : DataFrame<br>| DataFrame to be written<br>| destination_table : string<br>| Name of table to be written, in the form ‘dataset.tablename’<br>| project_id : str<br>| Google BigQuery Account project ID.<br>| chunksize : int (default 10000)<br>| Number of rows to be inserted in each chunk from the dataframe.<br>| verbose : boolean (default True)<br>| Show percentage complete<br>| reauth : boolean (default False)<br>| Force Google BigQuery to reauthenticate the user. This is useful<br>| if multiple accounts are used.<br>| if_exists : {‘fail’, ‘replace’, ‘append’}, default ‘fail’<br>| ‘fail’: If table exists, do nothing.<br>| ‘replace’: If table exists, drop it, recreate it, and insert data.<br>| ‘append’: If table exists, insert data. Create if does not exist.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| to_html(self, buf=None, columns=None, col_space=None, colSpace=None, header=True, index=True, na_rep=’NaN’,<br>formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, bold_rows=True, classes=None,<br>escape=True, max_rows=None, max_cols=None, show_dimensions=False, notebook=False)<br>| Render a DataFrame as an HTML table.<br>|<br>| <code>to_html</code>-specific options:<br>|<br>| bold_rows : boolean, default True<br>| Make the row labels bold in the output<br>| classes : str or list or tuple, default None<br>| CSS class(es) to apply to the resulting html table<br>| escape : boolean, default True<br>| Convert the characters &lt;, &gt;, and &amp; to HTML-safe sequences.=<br>| max_rows : int, optional<br>| Maximum number of rows to show before truncating. If None, show<br>| all.<br>| max_cols : int, optional<br>| Maximum number of columns to show before truncating. If None, show<br>| all.<br>|<br>|<br>| 【参数】<br>| ———-| buf : StringIO-like, optional<br>| buffer to write to<br>| columns : sequence, optional<br>| the subset of columns to write; default None writes all columns<br>| col_space : int, optional<br>| the minimum width of each column<br>| header : bool, optional<br>| whether to print column labels, default True<br>569<br>| index : bool, optional<br>| whether to print index (row) labels, default True<br>| na_rep : string, optional<br>| string representation of NAN to use, default ‘NaN’<br>| formatters : list or dict of one-parameter functions, optional<br>| formatter functions to apply to columns’ elements by position or name,<br>| default None. The result of each function must be a unicode string.<br>| List must be of length equal to the number of columns.<br>| float_format : one-parameter function, optional<br>| formatter function to apply to columns’ elements if they are floats,<br>| default None. The result of this function must be a unicode string.<br>| sparsify : bool, optional<br>| Set to False for a DataFrame with a hierarchical index to print every<br>| multiindex key at each row, default True<br>| index_names : bool, optional<br>| Prints the names of the indexes, default True<br>| justify : {‘left’, ‘right’}, default None<br>| Left or right-justify the column labels. If None uses the option from<br>| the print configuration (controlled by set_option), ‘right’ out<br>| of the box.<br>|<br>| 【返回值】<br>| ——-| formatted : string (or unicode, depending on data and options)<br>|<br>| to_latex(self, buf=None, columns=None, col_space=None, colSpace=None, header=True, index=True, na_rep=’NaN’,<br>formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=True, column_format=None,<br>longtable=False, escape=True)<br>| Render a DataFrame to a tabular environment table. You can splice<br>| this into a LaTeX document. Requires \usepackage{booktabs}.<br>|<br>| <code>to_latex</code>-specific options:<br>|<br>| bold_rows : boolean, default True<br>| Make the row labels bold in the output<br>| column_format : str, default None<br>| The columns format as specified in <code>LaTeX table format
| &lt;https://en.wikibooks.org/wiki/LaTeX/Tables&gt;</code>__ e.g ‘rcl’ for 3 columns<br>| longtable : boolean, default False<br>| Use a longtable environment instead of tabular. Requires adding<br>| a \usepackage{longtable} to your LaTeX preamble.<br>| escape : boolean, default True<br>| When set to False prevents from escaping latex special<br>| characters in column names.<br>|<br>|<br>| 【参数】<br>| ———-| buf : StringIO-like, optional<br>| buffer to write to<br>| columns : sequence, optional<br>| the subset of columns to write; default None writes all columns<br>| col_space : int, optional<br>| the minimum width of each column<br>| header : bool, optional<br>| whether to print column labels, default True<br>| index : bool, optional<br>570<br>| whether to print index (row) labels, default True<br>| na_rep : string, optional<br>| string representation of NAN to use, default ‘NaN’<br>| formatters : list or dict of one-parameter functions, optional<br>| formatter functions to apply to columns’ elements by position or name,<br>| default None. The result of each function must be a unicode string.<br>| List must be of length equal to the number of columns.<br>| float_format : one-parameter function, optional<br>| formatter function to apply to columns’ elements if they are floats,<br>| default None. The result of this function must be a unicode string.<br>| sparsify : bool, optional<br>| Set to False for a DataFrame with a hierarchical index to print every<br>| multiindex key at each row, default True<br>| index_names : bool, optional<br>| Prints the names of the indexes, default True<br>|<br>| 【返回值】<br>| ——-| formatted : string (or unicode, depending on data and options)<br>|<br>| to_panel(self)<br>| Transform long (stacked) format (DataFrame) into wide (3D, Panel)<br>| format.<br>|<br>| Currently the index of the DataFrame must be a 2-level MultiIndex. This<br>| may be generalized later<br>|<br>| 【返回值】<br>| ——-| panel : Panel<br>|<br>| to_period(self, freq=None, axis=0, copy=True)<br>| Convert DataFrame from DatetimeIndex to PeriodIndex with desired<br>| frequency (inferred from index if not passed)<br>|<br>| 【参数】<br>| ———-| freq : string, default<br>| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| The axis to convert (the index by default)<br>| copy : boolean, default True<br>| If False then underlying input data is not copied<br>|<br>| 【返回值】<br>| ——-| ts : TimeSeries with PeriodIndex<br>|<br>| to_records(self, index=True, convert_datetime64=True)<br>| Convert DataFrame to record array. Index will be put in the<br>| ‘index’ field of the record array if requested<br>|<br>| 【参数】<br>| ———-| index : boolean, default True<br>| Include index in resulting record array, stored in ‘index’ field<br>| convert_datetime64 : boolean, default True<br>| Whether to convert the index to datetime.datetime if it is a<br>571<br>| DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : recarray<br>|<br>| to_sparse(self, fill_value=None, kind=’block’)<br>| Convert to SparseDataFrame<br>|<br>| 【参数】<br>| ———-| fill_value : float, default NaN<br>| kind : {‘block’, ‘integer’}<br>|<br>| 【返回值】<br>| ——-| y : SparseDataFrame<br>|<br>| to_stata(self, fname, convert_dates=None, write_index=True, encoding=’latin-1’, byteorder=None, time_stamp=None,<br>data_label=None)<br>| A class for writing Stata binary dta files from array-like objects<br>|<br>| 【参数】<br>| ———-| fname : file path or buffer<br>| Where to save the dta file.<br>| convert_dates : dict<br>| Dictionary mapping column of datetime types to the stata internal<br>| format that you want to use for the dates. Options are<br>| ‘tc’, ‘td’, ‘tm’, ‘tw’, ‘th’, ‘tq’, ‘ty’. Column can be either a<br>| number or a name.<br>| encoding : str<br>| Default is latin-1. Note that Stata does not support unicode.<br>| byteorder : str<br>| Can be “&gt;”, “&lt;”, “little”, or “big”. The default is None which uses<br>| <code>sys.byteorder</code><br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; writer = StataWriter(‘./data_file.dta’, data)<br>| &gt;&gt;&gt; writer.write_file()<br>|<br>| Or with dates<br>|<br>| &gt;&gt;&gt; writer = StataWriter(‘./date_data_file.dta’, data, {2 : ‘tw’})<br>| &gt;&gt;&gt; writer.write_file()<br>|<br>| to_string(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep=’NaN’, formatters=None,<br>float_format=None, sparsify=None, index_names=True, justify=None, line_width=None, max_rows=None, max_cols=None,<br>show_dimensions=False)<br>| Render a DataFrame to a console-friendly tabular output.<br>|<br>| 【参数】<br>| ———-| buf : StringIO-like, optional<br>| buffer to write to<br>| columns : sequence, optional<br>572<br>| the subset of columns to write; default None writes all columns<br>| col_space : int, optional<br>| the minimum width of each column<br>| header : bool, optional<br>| whether to print column labels, default True<br>| index : bool, optional<br>| whether to print index (row) labels, default True<br>| na_rep : string, optional<br>| string representation of NAN to use, default ‘NaN’<br>| formatters : list or dict of one-parameter functions, optional<br>| formatter functions to apply to columns’ elements by position or name,<br>| default None. The result of each function must be a unicode string.<br>| List must be of length equal to the number of columns.<br>| float_format : one-parameter function, optional<br>| formatter function to apply to columns’ elements if they are floats,<br>| default None. The result of this function must be a unicode string.<br>| sparsify : bool, optional<br>| Set to False for a DataFrame with a hierarchical index to print every<br>| multiindex key at each row, default True<br>| index_names : bool, optional<br>| Prints the names of the indexes, default True<br>| justify : {‘left’, ‘right’}, default None<br>| Left or right-justify the column labels. If None uses the option from<br>| the print configuration (controlled by set_option), ‘right’ out<br>| of the box.<br>|<br>| 【返回值】<br>| ——-| formatted : string (or unicode, depending on data and options)<br>|<br>| to_timestamp(self, freq=None, how=’start’, axis=0, copy=True)<br>| Cast to DatetimeIndex of timestamps, at <em>beginning</em> of period<br>|<br>| 【参数】<br>| ———-| freq : string, default frequency of PeriodIndex<br>| Desired frequency<br>| how : {‘s’, ‘e’, ‘start’, ‘end’}<br>| Convention for converting period to timestamp; start of period<br>| vs. end<br>| axis : {0 or ‘index’, 1 or ‘columns’}, default 0<br>| The axis to convert (the index by default)<br>| copy : boolean, default True<br>| If false then underlying input data is not copied<br>|<br>| 【返回值】<br>| ——-| df : DataFrame with DatetimeIndex<br>|<br>| to_wide = wrapper(*args, </strong>kwargs)<br>|<br>| unstack(self, level=-1)<br>| Pivot a level of the (necessarily hierarchical) index labels, returning<br>| a DataFrame having a new level of column labels whose inner-most level<br>| consists of the pivoted index labels. If the index is not a MultiIndex,<br>| the output will be a Series (the analogue of stack when the columns are<br>| not a MultiIndex).<br>573<br>| The level involved will automatically get sorted.<br>|<br>| 【参数】<br>| ———-| level : int, string, or list of these, default -1 (last level)<br>| Level(s) of index to unstack, can pass level name<br>|<br>| 【参见】<br>| ——–| DataFrame.pivot : Pivot a table based on column values.<br>| DataFrame.stack : Pivot a level of the column labels (inverse operation<br>| from <code>unstack</code>).<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; index = pd.MultiIndex.from_tuples([(‘one’, ‘a’), (‘one’, ‘b’),<br>| … (‘two’, ‘a’), (‘two’, ‘b’)])<br>| &gt;&gt;&gt; s = pd.Series(np.arange(1.0, 5.0), index=index)<br>| &gt;&gt;&gt; s<br>| one a 1<br>| b 2<br>| two a 3<br>| b 4<br>| dtype: float64<br>|<br>| &gt;&gt;&gt; s.unstack(level=-1)<br>| a b<br>| one 1 2<br>| two 3 4<br>|<br>| &gt;&gt;&gt; s.unstack(level=0)<br>| one two<br>| a 1 3<br>| b 2 4<br>|<br>| &gt;&gt;&gt; df = s.unstack(level=0)<br>| &gt;&gt;&gt; df.unstack()<br>| one a 1.<br>| b 3.<br>| two a 2.<br>| b 4.<br>|<br>| 【返回值】<br>| ——-| unstacked : DataFrame or Series<br>|<br>| update(self, other, join=’left’, overwrite=True, filter_func=None, raise_conflict=False)<br>| Modify DataFrame in place using non-NA values from passed<br>| DataFrame. Aligns on indices<br>|<br>| 【参数】<br>| ———-| other : DataFrame, or object coercible into a DataFrame<br>| join : {‘left’}, default ‘left’<br>| overwrite : boolean, default True<br>| If True then overwrite values for common keys in the calling frame<br>| filter_func : callable(1d-array) -&gt; 1d-array<boolean>, default None<br>574<br>| Can choose to replace values other than NA. Return True for values<br>| that should be updated<br>| raise_conflict : boolean<br>| If True, will raise an error if the DataFrame and other both<br>| contain data in the same place.<br>|<br>| var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, <strong>kwargs)<br>| Return unbiased variance over requested axis.<br>|<br>| Normalized by N-1 by default. This can be changed using the ddof argument<br>|<br>| 【参数】<br>| ———-| axis : {index (0), columns (1)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a Series<br>| ddof : int, default 1<br>| degrees of freedom<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| var : Series or DataFrame (if level specified)<br>|<br>| ———————————————————————-| Class methods inherited from pandas.core.frame.DataFrame:<br>|<br>| from_csv(path, header=0, sep=’,’, index_col=0, parse_dates=True, encoding=None, tupleize_cols=False,<br>infer_datetime_format=False) from builtins.type<br>| Read CSV file (DISCOURAGED, please use :func:<code>pandas.read_csv</code> instead).<br>|<br>| It is preferable to use the more powerful :func:<code>pandas.read_csv</code><br>| for most general purposes, but <code>from_csv</code> makes for an easy<br>| roundtrip to and from a file (the exact counterpart of<br>| <code>to_csv</code>), especially with a DataFrame of time series data.<br>|<br>| This method only differs from the preferred :func:<code>pandas.read_csv</code><br>| in some defaults:<br>|<br>| - <code>index_col</code> is <code>0</code> instead of <code>None</code> (take first column as index<br>| by default)<br>| - <code>parse_dates</code> is <code>True</code> instead of <code>False</code> (try parsing the index<br>| as datetime by default)<br>|<br>| So a <code>pd.DataFrame.from_csv(path)</code> can be replaced by<br>| <code>pd.read_csv(path, index_col=0, parse_dates=True)</code>.<br>|<br>| 【参数】<br>| ———-| path : string file path or file handle / StringIO<br>| header : int, default 0<br>575<br>| Row to use as header (skip prior rows)<br>| sep : string, default ‘,’<br>| Field delimiter<br>| index_col : int or sequence, default 0<br>| Column to use for index. If a sequence is given, a MultiIndex<br>| is used. Different default from read_table<br>| parse_dates : boolean, default True<br>| Parse dates. Different default from read_table<br>| tupleize_cols : boolean, default False<br>| write multi_index columns as a list of tuples (if True)<br>| or new (expanded format) if False)<br>| infer_datetime_format: boolean, default False<br>| If True and <code>parse_dates</code> is True for a column, try to infer the<br>| datetime format based on the first datetime string. If the format<br>| can be inferred, there often will be a large parsing speed-up.<br>|<br>| 【参见】<br>| ——–| pandas.read_csv<br>|<br>| 【返回值】<br>| ——-| y : DataFrame<br>|<br>| from_dict(data, orient=’columns’, dtype=None) from builtins.type<br>| Construct DataFrame from dict of array-like or dicts<br>|<br>| 【参数】<br>| ———-| data : dict<br>| {field : array-like} or {field : dict}<br>| orient : {‘columns’, ‘index’}, default ‘columns’<br>| The “orientation” of the data. If the keys of the passed dict<br>| should be the columns of the resulting DataFrame, pass ‘columns’<br>| (default). Otherwise if the keys should be rows, pass ‘index’.<br>| dtype : dtype, default None<br>| Data type to force, otherwise infer<br>|<br>| 【返回值】<br>| ——-| DataFrame<br>|<br>| from_items(items, columns=None, orient=’columns’) from builtins.type<br>| Convert (key, value) pairs to DataFrame. The keys will be the axis<br>| index (usually the columns, but depends on the specified<br>| orientation). The values should be arrays or Series.<br>|<br>| 【参数】<br>| ———-| items : sequence of (key, value) pairs<br>| Values should be arrays or Series.<br>| columns : sequence of column labels, optional<br>| Must be passed if orient=’index’.<br>| orient : {‘columns’, ‘index’}, default ‘columns’<br>| The “orientation” of the data. If the keys of the<br>| input correspond to column labels, pass ‘columns’<br>| (default). Otherwise if the keys correspond to the index,<br>576<br>| pass ‘index’.<br>|<br>| 【返回值】<br>| ——-| frame : DataFrame<br>|<br>| from_records(data, index=None, exclude=None, columns=None, coerce_float=False, nrows=None) from builtins.type<br>| Convert structured or record ndarray to DataFrame<br>|<br>| 【参数】<br>| ———-| data : ndarray (structured dtype), list of tuples, dict, or DataFrame<br>| index : string, list of fields, array-like<br>| Field of array to use as the index, alternately a specific set of<br>| input labels to use<br>| exclude : sequence, default None<br>| Columns or fields to exclude<br>| columns : sequence, default None<br>| Column names to use. If the passed data do not have names<br>| associated with them, this argument provides names for the<br>| columns. Otherwise this argument indicates the order of the columns<br>| in the result (any names not found in the data will become all-NA<br>| columns)<br>| coerce_float : boolean, default False<br>| Attempt to convert values to non-string, non-numeric objects (like<br>| decimal.Decimal) to floating point, useful for SQL result sets<br>|<br>| 【返回值】<br>| ——-| df : DataFrame<br>|<br>| ———————————————————————-| Data descriptors inherited from pandas.core.frame.DataFrame:<br>|<br>| axes<br>| Return a list with the row axis labels and column axis labels as the<br>| only members. They are returned in that order.<br>|<br>| columns<br>|<br>| index<br>|<br>| shape<br>| Return a tuple representing the dimensionality of the DataFrame.<br>|<br>| style<br>| Property returning a Styler object containing methods for<br>| building a styled HTML representation fo the DataFrame.<br>|<br>| 【参见】<br>| ——–| pandas.core.Styler<br>|<br>| ———————————————————————-| Data and other attributes inherited from pandas.core.frame.DataFrame:<br>|<br>| plot = <class 'pandas.tools.plotting.frameplotmethods'=""><br>577<br>| DataFrame plotting accessor and method<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df.plot.line()<br>| &gt;&gt;&gt; df.plot.scatter(‘x’, ‘y’)<br>| &gt;&gt;&gt; df.plot.hexbin()<br>|<br>| These plotting methods can also be accessed by calling the accessor as a<br>| method with the <code>kind</code> argument:<br>| <code>df.plot(kind=&#39;line&#39;)</code> is equivalent to <code>df.plot.line()</code><br>|<br>| ———————————————————————-| Methods inherited from pandas.core.generic.NDFrame:<br>|<br>| <strong>abs</strong>(self)<br>|<br>| <strong>array</strong>(self, dtype=None)<br>|<br>| <strong>bool</strong> = <strong>nonzero</strong>(self)<br>|<br>| <strong>contains</strong>(self, key)<br>| True if the key is in the info axis<br>|<br>| <strong>delitem</strong>(self, key)<br>| Delete item<br>|<br>| <strong>finalize</strong>(self, other, method=None, </class></strong>kwargs)<br>| propagate metadata from other to self<br>|<br>| 【参数】<br>| ———-| other : the object from which to get the attributes that we are going<br>| to propagate<br>| method : optional, a passed method name ; possibly to take different<br>| types of propagation actions based on this<br>|<br>| <strong>getattr</strong>(self, name)<br>| After regular attribute access, try looking up the name<br>| This allows simpler access to columns for interactive use.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>invert</strong>(self)<br>|<br>| <strong>iter</strong>(self)<br>| Iterate over infor axis<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>nonzero</strong>(self)<br>|<br>| <strong>setattr</strong>(self, name, value)<br>| After regular attribute access, try setting the name<br>| This allows simpler access to columns for interactive use.<br>|<br>578<br>| <strong>setstate</strong>(self, state)<br>|<br>| abs(self)<br>| Return an object with absolute value taken. Only applicable to objects<br>| that are all numeric<br>|<br>| 【返回值】<br>| ——-| abs: type of caller<br>|<br>| add_prefix(self, prefix)<br>| Concatenate prefix string with panel items names.<br>|<br>| 【参数】<br>| ———-| prefix : string<br>|<br>| 【返回值】<br>| ——-| with_prefix : type of caller<br>|<br>| add_suffix(self, suffix)<br>| Concatenate suffix string with panel items names<br>|<br>| 【参数】<br>| ———-| suffix : string<br>|<br>| 【返回值】<br>| ——-| with_suffix : type of caller<br>|<br>| as_blocks(self, copy=True)<br>| Convert the frame to a dict of dtype -&gt; Constructor Types that each has<br>| a homogeneous dtype.<br>|<br>| NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in<br>| as_matrix)<br>|<br>| 【参数】<br>| ———-| copy : boolean, default True<br>|<br>| .. versionadded: 0.16.1<br>|<br>| 【返回值】<br>| ——-| values : a dict of dtype -&gt; Constructor Types<br>|<br>| as_matrix(self, columns=None)<br>| Convert the frame to its Numpy-array representation.<br>|<br>| 【参数】<br>| ———-| columns: list, optional, default:None<br>| If None, return all columns, otherwise, returns specified columns.<br>579<br>|<br>| 【返回值】<br>| ——-| values : ndarray<br>| If the caller is heterogeneous and contains booleans or objects,<br>| the result will be of dtype=object. See Notes.<br>|<br>|<br>| 【注意】<br>| —–| Return is NOT a Numpy-matrix, rather, a Numpy-array.<br>|<br>| The dtype will be a lower-common-denominator dtype (implicit<br>| upcasting); that is to say if the dtypes (even of numeric types)<br>| are mixed, the one that accommodates all will be chosen. Use this<br>| with care if you are not dealing with the blocks.<br>|<br>| e.g. If the dtypes are float16 and float32, dtype will be upcast to<br>| float32. If dtypes are int32 and uint8, dtype will be upcase to<br>| int32.<br>|<br>| This method is provided for backwards compatibility. Generally,<br>| it is recommended to use ‘.values’.<br>|<br>| 【参见】<br>| ——–| pandas.DataFrame.values<br>|<br>| asfreq(self, freq, method=None, how=None, normalize=False)<br>| Convert all TimeSeries inside to specified frequency using DateOffset<br>| objects. Optionally provide fill method to pad/backfill missing values.<br>|<br>| 【参数】<br>| ———-| freq : DateOffset object, or string<br>| method : {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}<br>| Method to use for filling holes in reindexed Series<br>| pad / ffill: propagate last valid observation forward to next valid<br>| backfill / bfill: use NEXT valid observation to fill method<br>| how : {‘start’, ‘end’}, default end<br>| For PeriodIndex only, see PeriodIndex.asfreq<br>| normalize : bool, default False<br>| Whether to reset output index to midnight<br>|<br>| 【返回值】<br>| ——-| converted : type of caller<br>|<br>| at_time(self, time, asof=False)<br>| Select values at particular time of day (e.g. 9:30AM)<br>|<br>| 【参数】<br>| ———-| time : datetime.time or string<br>|<br>| 【返回值】<br>| ——-<br>580<br>| values_at_time : type of caller<br>|<br>| between_time(self, start_time, end_time, include_start=True, include_end=True)<br>| Select values between particular times of the day (e.g., 9:00-9:30 AM)<br>|<br>| 【参数】<br>| ———-| start_time : datetime.time or string<br>| end_time : datetime.time or string<br>| include_start : boolean, default True<br>| include_end : boolean, default True<br>|<br>| 【返回值】<br>| ——-| values_between_time : type of caller<br>|<br>| bfill(self, axis=None, inplace=False, limit=None, downcast=None)<br>| Synonym for NDFrame.fillna(method=’bfill’)<br>|<br>| bool(self)<br>| Return the bool of a single element PandasObject<br>| This must be a boolean scalar value, either True or False<br>|<br>| Raise a ValueError if the PandasObject does not have exactly<br>| 1 element, or that element is not boolean<br>|<br>| clip(self, lower=None, upper=None, out=None, axis=None)<br>| Trim values at input threshold(s)<br>|<br>| 【参数】<br>| ———-| lower : float or array_like, default None<br>| upper : float or array_like, default None<br>| axis : int or string axis name, optional<br>| Align object with lower and upper along the given axis.<br>|<br>| 【返回值】<br>| ——-| clipped : Series<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df<br>| 0 1<br>| 0 0.335232 -1.256177<br>| 1 -1.367855 0.746646<br>| 2 0.027753 -1.176076<br>| 3 0.230930 -0.679613<br>| 4 1.261967 0.570967<br>| &gt;&gt;&gt; df.clip(-1.0, 0.5)<br>| 0 1<br>| 0 0.335232 -1.000000<br>| 1 -1.000000 0.500000<br>| 2 0.027753 -1.000000<br>| 3 0.230930 -0.679613<br>| 4 0.500000 0.500000<br>| &gt;&gt;&gt; t<br>581<br>| 0 -0.3<br>| 1 -0.2<br>| 2 -0.1<br>| 3 0.0<br>| 4 0.1<br>| dtype: float64<br>| &gt;&gt;&gt; df.clip(t, t + 1, axis=0)<br>| 0 1<br>| 0 0.335232 -0.300000<br>| 1 -0.200000 0.746646<br>| 2 0.027753 -0.100000<br>| 3 0.230930 0.000000<br>| 4 1.100000 0.570967<br>|<br>| clip_lower(self, threshold, axis=None)<br>| Return copy of the input with values below given value(s) truncated<br>|<br>| 【参数】<br>| ———-| threshold : float or array_like<br>| axis : int or string axis name, optional<br>| Align object with threshold along the given axis.<br>|<br>| 【参见】<br>| ——–| clip<br>|<br>| 【返回值】<br>| ——-| clipped : same type as input<br>|<br>| clip_upper(self, threshold, axis=None)<br>| Return copy of input with values above given value(s) truncated<br>|<br>| 【参数】<br>| ———-| threshold : float or array_like<br>| axis : int or string axis name, optional<br>| Align object with threshold along the given axis.<br>|<br>| 【参见】<br>| ——–| clip<br>|<br>| 【返回值】<br>| ——-| clipped : same type as input<br>|<br>| consolidate(self, inplace=False)<br>| Compute NDFrame with “consolidated” internals (data of each dtype<br>| grouped together in a single ndarray). Mainly an internal API function,<br>| but available here to the savvy user<br>|<br>| 【参数】<br>| ———-| inplace : boolean, default False<br>| If False return new object, otherwise modify existing object<br>582<br>|<br>| 【返回值】<br>| ——-| consolidated : type of caller<br>|<br>| convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)<br>| Attempt to infer better dtype for object columns<br>|<br>| 【参数】<br>| ———-| convert_dates : boolean, default True<br>| If True, convert to date where possible. If ‘coerce’, force<br>| conversion, with unconvertible values becoming NaT.<br>| convert_numeric : boolean, default False<br>| If True, attempt to coerce to numbers (including strings), with<br>| unconvertible values becoming NaN.<br>| convert_timedeltas : boolean, default True<br>| If True, convert to timedelta where possible. If ‘coerce’, force<br>| conversion, with unconvertible values becoming NaT.<br>| copy : boolean, default True<br>| If True, return a copy even if no copy is necessary (e.g. no<br>| conversion was done). Note: This is meant for internal use, and<br>| should not be confused with inplace.<br>|<br>| 【返回值】<br>| ——-| converted : same as input object<br>|<br>| describe(self, percentiles=None, include=None, exclude=None)<br>| Generate various summary statistics, excluding NaN values.<br>|<br>| 【参数】<br>| ———-| percentiles : array-like, optional<br>| The percentiles to include in the output. Should all<br>| be in the interval [0, 1]. By default <code>percentiles</code> is<br>| [.25, .5, .75], returning the 25th, 50th, and 75th percentiles.<br>| include, exclude : list-like, ‘all’, or None (default)<br>| Specify the form of the returned result. Either:<br>|<br>| - None to both (default). The result will include only numeric-typed<br>| columns or, if none are, only categorical columns.<br>| - A list of dtypes or strings to be included/excluded.<br>| To select all numeric types use numpy numpy.number. To select<br>| categorical objects use type object. 参见：the select_dtypes<br>| documentation. eg. df.describe(include=[‘O’])<br>| - If include is the string ‘all’, the output column-set will<br>| match the input one.<br>|<br>| 【返回值】<br>| ——-| summary: NDFrame of summary statistics<br>|<br>| 【注意】<br>| —–| The output DataFrame index depends on the requested dtypes:<br>|<br>583<br>| For numeric dtypes, it will include: count, mean, std, min,<br>| max, and lower, 50, and upper percentiles.<br>|<br>| For object dtypes (e.g. timestamps or strings), the index<br>| will include the count, unique, most common, and frequency of the<br>| most common. Timestamps also include the first and last items.<br>|<br>| For mixed dtypes, the index will be the union of the corresponding<br>| output types. Non-applicable entries will be filled with NaN.<br>| Note that mixed-dtype outputs can only be returned from mixed-dtype<br>| inputs and appropriate use of the include/exclude arguments.<br>|<br>| If multiple values have the highest count, then the<br>| <code>count</code> and <code>most common</code> pair will be arbitrarily chosen from<br>| among those with the highest count.<br>|<br>| The include, exclude arguments are ignored for Series.<br>|<br>| 【参见】<br>| ——–| DataFrame.select_dtypes<br>|<br>| drop(self, labels, axis=0, level=None, inplace=False, errors=’raise’)<br>| Return new object with labels in requested axis removed<br>|<br>| 【参数】<br>| ———-| labels : single label or list-like<br>| axis : int or axis name<br>| level : int or level name, default None<br>| For MultiIndex<br>| inplace : bool, default False<br>| If True, do operation inplace and return None.<br>| errors : {‘ignore’, ‘raise’}, default ‘raise’<br>| If ‘ignore’, suppress error and existing labels are dropped.<br>|<br>| .. versionadded:: 0.16.1<br>|<br>| 【返回值】<br>| ——-| dropped : type of caller<br>|<br>| equals(self, other)<br>| Determines if two NDFrame objects contain the same elements. NaNs in the<br>| same location are considered equal.<br>|<br>| ffill(self, axis=None, inplace=False, limit=None, downcast=None)<br>| Synonym for NDFrame.fillna(method=’ffill’)<br>|<br>| filter(self, items=None, like=None, regex=None, axis=None)<br>| Restrict the info axis to set of items or wildcard<br>|<br>| 【参数】<br>| ———-| items : list-like<br>| List of info axis to restrict to (must not all be present)<br>| like : string<br>584<br>| Keep info axis where “arg in col == True”<br>| regex : string (regular expression)<br>| Keep info axis with re.search(regex, col) == True<br>| axis : int or None<br>| The axis to filter on. By default this is the info axis. The “info<br>| axis” is the axis that is used when indexing with <code>[]</code>. For<br>| example, <code>df = DataFrame({&#39;a&#39;: [1, 2, 3, 4]]}); df[&#39;a&#39;]</code>. So,<br>| the <code>DataFrame</code> columns are the info axis.<br>|<br>| 【注意】<br>| —–| Arguments are mutually exclusive, but this is not checked for<br>|<br>| first(self, offset)<br>| Convenience method for subsetting initial periods of time series data<br>| based on a date offset<br>|<br>| 【参数】<br>| ———-| offset : string, DateOffset, dateutil.relativedelta<br>|<br>| 【示例】<br>| ——–| ts.last(‘10D’) -&gt; First 10 days<br>|<br>| 【返回值】<br>| ——-| subset : type of caller<br>|<br>| get(self, key, default=None)<br>| Get item from object for given key (DataFrame column, Panel slice,<br>| etc.). Returns default value if not found<br>|<br>| 【参数】<br>| ———-| key : object<br>|<br>| 【返回值】<br>| ——-| value : type of items contained in object<br>|<br>| get_dtype_counts(self)<br>| Return the counts of dtypes in this object<br>|<br>| get_ftype_counts(self)<br>| Return the counts of ftypes in this object<br>|<br>| get_values(self)<br>| same as values (but handles sparseness conversions)<br>|<br>| groupby(self, by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False)<br>| Group series using mapper (dict or key function, apply given function<br>| to group, return result as series) or by a series of columns<br>|<br>| 【参数】<br>| ———-| by : mapping function / list of functions, dict, Series, or tuple /<br>585<br>| list of column names.<br>| Called on each element of the object index to determine the groups.<br>| If a dict or Series is passed, the Series or dict VALUES will be<br>| used to determine the groups<br>| axis : int, default 0<br>| level : int, level name, or sequence of such, default None<br>| If the axis is a MultiIndex (hierarchical), group by a particular<br>| level or levels<br>| as_index : boolean, default True<br>| For aggregated output, return object with group labels as the<br>| index. Only relevant for DataFrame input. as_index=False is<br>| effectively “SQL-style” grouped output<br>| sort : boolean, default True<br>| Sort group keys. Get better performance by turning this off.<br>| Note this does not influence the order of observations within each group.<br>| groupby preserves the order of rows within each group.<br>| group_keys : boolean, default True<br>| When calling apply, add group keys to index to identify pieces<br>| squeeze : boolean, default False<br>| reduce the dimensionality of the return type if possible,<br>| otherwise return a consistent type<br>|<br>| 【示例】<br>| ——–| DataFrame results<br>|<br>| &gt;&gt;&gt; data.groupby(func, axis=0).mean()<br>| &gt;&gt;&gt; data.groupby([‘col1’, ‘col2’])[‘col3’].mean()<br>|<br>| DataFrame with hierarchical index<br>|<br>| &gt;&gt;&gt; data.groupby([‘col1’, ‘col2’]).mean()<br>|<br>| 【返回值】<br>| ——-| GroupBy object<br>|<br>| head(self, n=5)<br>| Returns first n rows<br>|<br>| interpolate(self, method=’linear’, axis=0, limit=None, inplace=False, limit_direction=’forward’, downcast=None, <strong>kwargs)<br>| Interpolate values according to different methods.<br>|<br>| Please note that only <code>method=&#39;linear&#39;</code> is supported for DataFrames/Series<br>| with a MultiIndex.<br>|<br>| 【参数】<br>| ———-| method : {‘linear’, ‘time’, ‘index’, ‘values’, ‘nearest’, ‘zero’,<br>| ‘slinear’, ‘quadratic’, ‘cubic’, ‘barycentric’, ‘krogh’,<br>| ‘polynomial’, ‘spline’ ‘piecewise_polynomial’, ‘pchip’}<br>|<br>| <em> ‘linear’: ignore the index and treat the values as equally<br>| spaced. This is the only method supported on MultiIndexes.<br>| default<br>| </em> ‘time’: interpolation works on daily and higher resolution<br>| data to interpolate given length of interval<br>586<br>| <em> ‘index’, ‘values’: use the actual numerical values of the index<br>| </em> ‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’,<br>| ‘barycentric’, ‘polynomial’ is passed to<br>| <code>scipy.interpolate.interp1d</code>. Both ‘polynomial’ and ‘spline’<br>| require that you also specify an <code>order</code> (int),<br>| e.g. df.interpolate(method=’polynomial’, order=4).<br>| These use the actual numerical values of the index.<br>| <em> ‘krogh’, ‘piecewise_polynomial’, ‘spline’, and ‘pchip’ are all<br>| wrappers around the scipy interpolation methods of similar<br>| names. These use the actual numerical values of the index. See<br>| the scipy documentation for more on their behavior<br>| <code>here &lt;http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation&gt;</code><strong><br>| <code>and here &lt;http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html&gt;</code></strong><br>|<br>| axis : {0, 1}, default 0<br>| </em> 0: fill column-by-column<br>| <em> 1: fill row-by-row<br>| limit : int, default None.<br>| Maximum number of consecutive NaNs to fill.<br>| limit_direction : {‘forward’, ‘backward’, ‘both’}, defaults to ‘forward’<br>| If limit is specified, consecutive NaNs will be filled in this<br>| direction.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| inplace : bool, default False<br>| Update the NDFrame in place if possible.<br>| downcast : optional, ‘infer’ or None, defaults to None<br>| Downcast dtypes if possible.<br>| kwargs : keyword arguments to pass on to the interpolating function.<br>|<br>| 【返回值】<br>| ——-| Series or DataFrame of same shape interpolated at the NaNs<br>|<br>| 【参见】<br>| ——–| reindex, replace, fillna<br>|<br>| 【示例】<br>| ——–|<br>| Filling in NaNs<br>|<br>| &gt;&gt;&gt; s = pd.Series([0, 1, np.nan, 3])<br>| &gt;&gt;&gt; s.interpolate()<br>| 0 0<br>| 1 1<br>| 2 2<br>| 3 3<br>| dtype: float64<br>|<br>| isnull(self)<br>| Return a boolean same-sized object indicating if the values are null<br>|<br>| 【参见】<br>| ——–<br>587<br>| notnull : boolean inverse of isnull<br>|<br>| iterkv(self, </em>args, </strong>kwargs)<br>| iteritems alias used to get around 2to3. Deprecated<br>|<br>| keys(self)<br>| Get the ‘info axis’ (see Indexing for more)<br>|<br>| This is index for Series, columns for DataFrame and major_axis for<br>| Panel.<br>|<br>| last(self, offset)<br>| Convenience method for subsetting final periods of time series data<br>| based on a date offset<br>|<br>| 【参数】<br>| ———-| offset : string, DateOffset, dateutil.relativedelta<br>|<br>| 【示例】<br>| ——–| ts.last(‘5M’) -&gt; Last 5 months<br>|<br>| 【返回值】<br>| ——-| subset : type of caller<br>|<br>| mask(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)<br>| Return an object of same shape as self and whose corresponding<br>| entries are from self where cond is False and otherwise are from other.<br>|<br>| 【参数】<br>| ———-| cond : boolean NDFrame or array<br>| other : scalar or NDFrame<br>| inplace : boolean, default False<br>| Whether to perform the operation in place on the data<br>| axis : alignment axis if needed, default None<br>| level : alignment level if needed, default None<br>| try_cast : boolean, default False<br>| try to cast the result back to the input type (if possible),<br>| raise_on_error : boolean, default True<br>| Whether to raise on invalid data types (e.g. trying to where on<br>| strings)<br>|<br>| 【返回值】<br>| ——-| wh : same type as caller<br>|<br>| notnull(self)<br>| Return a boolean same-sized object indicating if the values are<br>| not null<br>|<br>| 【参见】<br>| ——–| isnull : boolean inverse of notnull<br>|<br>588<br>| pct_change(self, periods=1, fill_method=’pad’, limit=None, freq=None, <strong>kwargs)<br>| Percent change over given number of periods.<br>|<br>| 【参数】<br>| ———-| periods : int, default 1<br>| Periods to shift for forming percent change<br>| fill_method : str, default ‘pad’<br>| How to handle NAs before computing percent changes<br>| limit : int, default None<br>| The number of consecutive NAs to fill before stopping<br>| freq : DateOffset, timedelta, or offset alias string, optional<br>| Increment to use from time series API (e.g. ‘M’ or BDay())<br>|<br>| 【返回值】<br>| ——-| chg : NDFrame<br>|<br>| 【注意】<br>| —–|<br>| By default, the percentage change is calculated along the stat<br>| axis: 0, or <code>Index</code>, for <code>DataFrame</code> and 1, or <code>minor</code> for<br>| <code>Panel</code>. You can change this with the <code>axis</code> keyword argument.<br>|<br>| pipe(self, func, *args, </strong>kwargs)<br>| Apply func(self, *args, **kwargs)<br>|<br>| .. versionadded:: 0.16.2<br>|<br>| 【参数】<br>| ———-| func : function<br>| function to apply to the NDFrame.<br>| <code>args</code>, and <code>kwargs</code> are passed into <code>func</code>.<br>| Alternatively a <code>(callable, data_keyword)</code> tuple where<br>| <code>data_keyword</code> is a string indicating the keyword of<br>| <code>callable</code> that expects the NDFrame.<br>| args : positional arguments passed into <code>func</code>.<br>| kwargs : a dictionary of keyword arguments passed into <code>func</code>.<br>|<br>| 【返回值】<br>| ——-| object : the return type of <code>func</code>.<br>|<br>| 【注意】<br>| —–|<br>| Use <code>.pipe</code> when chaining together functions that expect<br>| on Series or DataFrames. Instead of writing<br>|<br>| &gt;&gt;&gt; f(g(h(df), arg1=a), arg2=b, arg3=c)<br>|<br>| You can write<br>|<br>| &gt;&gt;&gt; (df.pipe(h)<br>| … .pipe(g, arg1=a)<br>589<br>| … .pipe(f, arg2=b, arg3=c)<br>| … )<br>|<br>| If you have a function that takes the data as (say) the second<br>| argument, pass a tuple indicating which keyword expects the<br>| data. For example, suppose <code>f</code> takes its data as <code>arg2</code>:<br>|<br>| &gt;&gt;&gt; (df.pipe(h)<br>| … .pipe(g, arg1=a)<br>| … .pipe((f, ‘arg2’), arg1=a, arg3=c)<br>| … )<br>|<br>| 【参见】<br>| ——–| pandas.DataFrame.apply<br>| pandas.DataFrame.applymap<br>| pandas.Series.map<br>|<br>| pop(self, item)<br>| Return item and drop from frame. Raise KeyError if not found.<br>|<br>| reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)<br>| return an object with matching indicies to myself<br>|<br>| 【参数】<br>| ———-| other : Object<br>| method : string or None<br>| copy : boolean, default True<br>| limit : int, default None<br>| Maximum number of consecutive labels to fill for inexact matches.<br>| tolerance : optional<br>| Maximum distance between labels of the other object and this<br>| object for inexact matches.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【注意】<br>| —–| Like calling s.reindex(index=other.index, columns=other.columns,<br>| method=…)<br>|<br>| 【返回值】<br>| ——-| reindexed : same as input<br>|<br>| rename_axis(self, mapper, axis=0, copy=True, inplace=False)<br>| Alter index and / or columns using input function or functions.<br>| Function / dict values must be unique (1-to-1). Labels not contained in<br>| a dict / Series will be left as-is.<br>|<br>| 【参数】<br>| ———-| mapper : dict-like or function, optional<br>| axis : int or string, default 0<br>| copy : boolean, default True<br>| Also copy underlying data<br>590<br>| inplace : boolean, default False<br>|<br>| 【返回值】<br>| ——-| renamed : type of caller<br>|<br>| replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method=’pad’, axis=None)<br>| Replace values given in ‘to_replace’ with ‘value’.<br>|<br>| 【参数】<br>| ———-| to_replace : str, regex, list, dict, Series, numeric, or None<br>|<br>| <em> str or regex:<br>|<br>| - str: string exactly matching <code>to_replace</code> will be replaced<br>| with <code>value</code><br>| - regex: regexs matching <code>to_replace</code> will be replaced with<br>| <code>value</code><br>|<br>| </em> list of str, regex, or numeric:<br>|<br>| - First, if <code>to_replace</code> and <code>value</code> are both lists, they<br>| <strong>must</strong> be the same length.<br>| - Second, if <code>regex=True</code> then all of the strings in <strong>both</strong><br>| lists will be interpreted as regexs otherwise they will match<br>| directly. This doesn’t matter much for <code>value</code> since there<br>| are only a few possible substitution regexes you can use.<br>| - str and regex rules apply as above.<br>|<br>| <em> dict:<br>|<br>| - Nested dictionaries, e.g., {‘a’: {‘b’: nan}}, are read as<br>| follows: look in column ‘a’ for the value ‘b’ and replace it<br>| with nan. You can nest regular expressions as well. Note that<br>| column names (the top-level dictionary keys in a nested<br>| dictionary) <strong>cannot</strong> be regular expressions.<br>| - Keys map to column names and values map to substitution<br>| values. You can treat this as a special case of passing two<br>| lists except that you are specifying the column to search in.<br>|<br>| </em> None:<br>|<br>| - This means that the <code>regex</code> argument must be a string,<br>| compiled regular expression, or list, dict, ndarray or Series<br>| of such elements. If <code>value</code> is also <code>None</code> then this<br>| <strong>must</strong> be a nested dictionary or <code>Series</code>.<br>|<br>| See the examples section for examples of each of these.<br>| value : scalar, dict, list, str, regex, default None<br>| Value to use to fill holes (e.g. 0), alternately a dict of values<br>| specifying which value to use for each column (columns not in the<br>| dict will not be filled). Regular expressions, strings and lists or<br>| dicts of such objects are also allowed.<br>| inplace : boolean, default False<br>| If True, in place. Note: this will modify any<br>| other views on this object (e.g. a column form a DataFrame).<br>591<br>| Returns the caller if this is True.<br>| limit : int, default None<br>| Maximum size gap to forward or backward fill<br>| regex : bool or same types as <code>to_replace</code>, default False<br>| Whether to interpret <code>to_replace</code> and/or <code>value</code> as regular<br>| expressions. If this is <code>True</code> then <code>to_replace</code> <em>must</em> be a<br>| string. Otherwise, <code>to_replace</code> must be <code>None</code> because this<br>| parameter will be interpreted as a regular expression or a list,<br>| dict, or array of regular expressions.<br>| method : string, optional, {‘pad’, ‘ffill’, ‘bfill’}<br>| The method to use when for replacement, when <code>to_replace</code> is a<br>| <code>list</code>.<br>|<br>| 【参见】<br>| ——–| NDFrame.reindex<br>| NDFrame.asfreq<br>| NDFrame.fillna<br>|<br>| 【返回值】<br>| ——-| filled : NDFrame<br>|<br>| 【Raises 引发错误】<br>| ——| AssertionError<br>| <em> If <code>regex</code> is not a <code>bool</code> and <code>to_replace</code> is not <code>None</code>.<br>| TypeError<br>| </em> If <code>to_replace</code> is a <code>dict</code> and <code>value</code> is not a <code>list</code>,<br>| <code>dict</code>, <code>ndarray</code>, or <code>Series</code><br>| <em> If <code>to_replace</code> is <code>None</code> and <code>regex</code> is not compilable into a<br>| regular expression or is a list, dict, ndarray, or Series.<br>| ValueError<br>| </em> If <code>to_replace</code> and <code>value</code> are <code>list</code> s or <code>ndarray</code> s, but<br>| they are not the same length.<br>|<br>| 【注意】<br>| —–| <em> Regex substitution is performed under the hood with <code>re.sub</code>. The<br>| rules for substitution for <code>re.sub</code> are the same.<br>| </em> Regular expressions will only substitute on strings, meaning you<br>| cannot provide, for example, a regular expression matching floating<br>| point numbers and expect the columns in your frame that have a<br>| numeric dtype to be matched. However, if those floating point numbers<br>| <em>are</em> strings, then you can do this.<br>| <em> This method has </em>a lot<em> of options. You are encouraged to experiment<br>| and play with this method to gain intuition about how it works.<br>|<br>| resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention=’start’, kind=None,<br>loffset=None, limit=None, base=0)<br>| Convenience method for frequency conversion and resampling of regular<br>| time-series data.<br>|<br>| 【参数】<br>| ———-| rule : string<br>| the offset string or object representing target conversion<br>592<br>| how : string<br>| method for down- or re-sampling, default to ‘mean’ for<br>| downsampling<br>| axis : int, optional, default 0<br>| fill_method : string, default None<br>| fill_method for upsampling<br>| closed : {‘right’, ‘left’}<br>| Which side of bin interval is closed<br>| label : {‘right’, ‘left’}<br>| Which bin edge label to label bucket with<br>| convention : {‘start’, ‘end’, ‘s’, ‘e’}<br>| kind : “period”/“timestamp”<br>| loffset : timedelta<br>| Adjust the resampled time labels<br>| limit : int, default None<br>| Maximum size gap to when reindexing with fill_method<br>| base : int, default 0<br>| For frequencies that evenly subdivide 1 day, the “origin” of the<br>| aggregated intervals. For example, for ‘5min’ frequency, base could<br>| range from 0 through 4. Defaults to 0<br>|<br>|<br>| 【示例】<br>| ——–|<br>| Start by creating a series with 9 one minute timestamps.<br>|<br>| &gt;&gt;&gt; index = pd.date_range(‘1/1/2000’, periods=9, freq=’T’)<br>| &gt;&gt;&gt; series = pd.Series(range(9), index=index)<br>| &gt;&gt;&gt; series<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:01:00 1<br>| 2000-01-01 00:02:00 2<br>| 2000-01-01 00:03:00 3<br>| 2000-01-01 00:04:00 4<br>| 2000-01-01 00:05:00 5<br>| 2000-01-01 00:06:00 6<br>| 2000-01-01 00:07:00 7<br>| 2000-01-01 00:08:00 8<br>| Freq: T, dtype: int64<br>|<br>| Downsample the series into 3 minute bins and sum the values<br>| of the timestamps falling into a bin.<br>|<br>| &gt;&gt;&gt; series.resample(‘3T’, how=’sum’)<br>| 2000-01-01 00:00:00 3<br>| 2000-01-01 00:03:00 12<br>| 2000-01-01 00:06:00 21<br>| Freq: 3T, dtype: int64<br>|<br>| Downsample the series into 3 minute bins as above, but label each<br>| bin using the right edge instead of the left. Please note that the<br>| value in the bucket used as the label is not included in the bucket,<br>| which it labels. For example, in the original series the<br>| bucket <code>2000-01-01 00:03:00</code> contains the value 3, but the summed<br>| value in the resampled bucket with the label<code>2000-01-01 00:03:00</code><br>| does not include 3 (if it did, the summed value would be 6, not 3).<br>593<br>| To include this value close the right side of the bin interval as<br>| illustrated in the example below this one.<br>|<br>| &gt;&gt;&gt; series.resample(‘3T’, how=’sum’, label=’right’)<br>| 2000-01-01 00:03:00 3<br>| 2000-01-01 00:06:00 12<br>| 2000-01-01 00:09:00 21<br>| Freq: 3T, dtype: int64<br>|<br>| Downsample the series into 3 minute bins as above, but close the right<br>| side of the bin interval.<br>|<br>| &gt;&gt;&gt; series.resample(‘3T’, how=’sum’, label=’right’, closed=’right’)<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:03:00 6<br>| 2000-01-01 00:06:00 15<br>| 2000-01-01 00:09:00 15<br>| Freq: 3T, dtype: int64<br>|<br>| Upsample the series into 30 second bins.<br>|<br>| &gt;&gt;&gt; series.resample(‘30S’)[0:5] #select first 5 rows<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:00:30 NaN<br>| 2000-01-01 00:01:00 1<br>| 2000-01-01 00:01:30 NaN<br>| 2000-01-01 00:02:00 2<br>| Freq: 30S, dtype: float64<br>|<br>| Upsample the series into 30 second bins and fill the <code>NaN</code><br>| values using the <code>pad</code> method.<br>|<br>| &gt;&gt;&gt; series.resample(‘30S’, fill_method=’pad’)[0:5]<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:00:30 0<br>| 2000-01-01 00:01:00 1<br>| 2000-01-01 00:01:30 1<br>| 2000-01-01 00:02:00 2<br>| Freq: 30S, dtype: int64<br>|<br>| Upsample the series into 30 second bins and fill the<br>| <code>NaN</code> values using the <code>bfill</code> method.<br>|<br>| &gt;&gt;&gt; series.resample(‘30S’, fill_method=’bfill’)[0:5]<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:00:30 1<br>| 2000-01-01 00:01:00 1<br>| 2000-01-01 00:01:30 2<br>| 2000-01-01 00:02:00 2<br>| Freq: 30S, dtype: int64<br>|<br>| Pass a custom function to <code>how</code>.<br>|<br>| &gt;&gt;&gt; def custom_resampler(array_like):<br>| … return np.sum(array_like)+5<br>|<br>| &gt;&gt;&gt; series.resample(‘3T’, how=custom_resampler)<br>594<br>| 2000-01-01 00:00:00 8<br>| 2000-01-01 00:03:00 17<br>| 2000-01-01 00:06:00 26<br>| Freq: 3T, dtype: int64<br>|<br>| sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)<br>| Returns a random sample of items from an axis of object.<br>|<br>| .. versionadded:: 0.16.1<br>|<br>| 【参数】<br>| ———-| n : int, optional<br>| Number of items from axis to return. Cannot be used with <code>frac</code>.<br>| Default = 1 if <code>frac</code> = None.<br>| frac : float, optional<br>| Fraction of axis items to return. Cannot be used with <code>n</code>.<br>| replace : boolean, optional<br>| Sample with or without replacement. Default = False.<br>| weights : str or ndarray-like, optional<br>| Default ‘None’ results in equal probability weighting.<br>| If passed a Series, will align with target object on index. Index<br>| values in weights not found in sampled object will be ignored and<br>| index values in sampled object not in weights will be assigned<br>| weights of zero.<br>| If called on a DataFrame, will accept the name of a column<br>| when axis = 0.<br>| Unless weights are a Series, weights must be same length as axis<br>| being sampled.<br>| If weights do not sum to 1, they will be normalized to sum to 1.<br>| Missing values in the weights column will be treated as zero.<br>| inf and -inf values not allowed.<br>| random_state : int or numpy.random.RandomState, optional<br>| Seed for the random number generator (if int), or numpy RandomState<br>| object.<br>| axis : int or string, optional<br>| Axis to sample. Accepts axis number or name. Default is stat axis<br>| for given data type (0 for Series and DataFrames, 1 for Panels).<br>|<br>| 【返回值】<br>| ——-| A new object of same type as caller.<br>|<br>| select(self, crit, axis=0)<br>| Return data corresponding to axis labels matching criteria<br>|<br>| 【参数】<br>| ———-| crit : function<br>| To be called on each index (label). Should return True or False<br>| axis : int<br>|<br>| 【返回值】<br>| ——-| selection : type of caller<br>|<br>| set_axis(self, axis, labels)<br>595<br>| public verson of axis assignment<br>|<br>| slice_shift(self, periods=1, axis=0)<br>| Equivalent to <code>shift</code> without copying data. The shifted data will<br>| not include the dropped periods and the shifted axis will be smaller<br>| than the original.<br>|<br>| 【参数】<br>| ———-| periods : int<br>| Number of periods to move, can be positive or negative<br>|<br>| 【注意】<br>| —–| While the <code>slice_shift</code> is faster than <code>shift</code>, you may pay for it<br>| later during alignment.<br>|<br>| 【返回值】<br>| ——-| shifted : same type as caller<br>|<br>| squeeze(self)<br>| squeeze length 1 dimensions<br>|<br>| swapaxes(self, axis1, axis2, copy=True)<br>| Interchange axes and swap values axes appropriately<br>|<br>| 【返回值】<br>| ——-| y : same as input<br>|<br>| tail(self, n=5)<br>| Returns last n rows<br>|<br>| take(self, indices, axis=0, convert=True, is_copy=True)<br>| Analogous to ndarray.take<br>|<br>| 【参数】<br>| ———-| indices : list / array of ints<br>| axis : int, default 0<br>| convert : translate neg to pos indices (default)<br>| is_copy : mark the returned frame as a copy<br>|<br>| 【返回值】<br>| ——-| taken : type of caller<br>|<br>| to_clipboard(self, excel=None, sep=None, <strong>kwargs)<br>| Attempt to write text representation of object to the system clipboard<br>| This can be pasted into Excel, for example.<br>|<br>| 【参数】<br>| ———-| excel : boolean, defaults to True<br>| if True, use the provided separator, writing in a csv<br>| format for allowing easy pasting into excel.<br>596<br>| if False, write a string representation of the object<br>| to the clipboard<br>| sep : optional, defaults to tab<br>| other keywords are passed to to_csv<br>|<br>| 【注意】<br>| —–| Requirements for your platform<br>| - Linux: xclip, or xsel (with gtk or PyQt4 modules)<br>| - Windows: none<br>| - OS X: none<br>|<br>| to_hdf(self, path_or_buf, key, </strong>kwargs)<br>| activate the HDFStore<br>|<br>| 【参数】<br>| ———-| path_or_buf : the path (string) or HDFStore object<br>| key : string<br>| indentifier for the group in the store<br>| mode : optional, {‘a’, ‘w’, ‘r’, ‘r+’}, default ‘a’<br>|<br>| <code>&#39;r&#39;</code><br>| Read-only; no data can be modified.<br>| <code>&#39;w&#39;</code><br>| Write; a new file is created (an existing file with the same<br>| name would be deleted).<br>| <code>&#39;a&#39;</code><br>| Append; an existing file is opened for reading and writing,<br>| and if the file does not exist it is created.<br>| <code>&#39;r+&#39;</code><br>| It is similar to <code>&#39;a&#39;</code>, but the file must already exist.<br>| format : ‘fixed(f)|table(t)’, default is ‘fixed’<br>| fixed(f) : Fixed format<br>| Fast writing/reading. Not-appendable, nor searchable<br>| table(t) : Table format<br>| Write as a PyTables Table structure which may perform<br>| worse but allow more flexible operations like searching<br>| / selecting subsets of the data<br>| append : boolean, default False<br>| For Table formats, append the input data to the existing<br>| complevel : int, 1-9, default 0<br>| If a complib is specified compression will be applied<br>| where possible<br>| complib : {‘zlib’, ‘bzip2’, ‘lzo’, ‘blosc’, None}, default None<br>| If complevel is &gt; 0 apply compression to objects written<br>| in the store wherever possible<br>| fletcher32 : bool, default False<br>| If applying compression use the fletcher32 checksum<br>| dropna : boolean, default False.<br>| If true, ALL nan rows will not be written to store.<br>|<br>| to_json(self, path_or_buf=None, orient=None, date_format=’epoch’, double_precision=10, force_ascii=True, date_unit=’ms’,<br>default_handler=None)<br>| Convert the object to a JSON string.<br>|<br>| Note NaN’s and None will be converted to null and datetime objects<br>597<br>| will be converted to UNIX timestamps.<br>|<br>| 【参数】<br>| ———-| path_or_buf : the path or buffer to write the result string<br>| if this is None, return a StringIO of the converted string<br>| orient : string<br>|<br>| </em> Series<br>|<br>| - default is ‘index’<br>| - allowed values are: {‘split’,’records’,’index’}<br>|<br>| <em> DataFrame<br>|<br>| - default is ‘columns’<br>| - allowed values are:<br>| {‘split’,’records’,’index’,’columns’,’values’}<br>|<br>| </em> The format of the JSON string<br>|<br>| - split : dict like<br>| {index -&gt; [index], columns -&gt; [columns], data -&gt; [values]}<br>| - records : list like<br>| [{column -&gt; value}, … , {column -&gt; value}]<br>| - index : dict like {index -&gt; {column -&gt; value}}<br>| - columns : dict like {column -&gt; {index -&gt; value}}<br>| - values : just the values array<br>|<br>| date_format : {‘epoch’, ‘iso’}<br>| Type of date conversion. <code>epoch</code> = epoch milliseconds,<br>| <code>iso`` = ISO8601, default is epoch.
| double_precision : The number of decimal places to use when encoding
| floating point values, default 10.
| force_ascii : force encoded string to be ASCII, default True.
| date_unit : string, default &#39;ms&#39; (milliseconds)
| The time unit to encode to, governs timestamp and ISO8601
| precision. One of &#39;s&#39;, &#39;ms&#39;, &#39;us&#39;, &#39;ns&#39; for second, millisecond,
| microsecond, and nanosecond respectively.
| default_handler : callable, default None
| Handler to call if object cannot otherwise be converted to a
| suitable format for JSON. Should receive a single argument which is
| the object to convert and return a serialisable object.
|
| 【返回值】
| -------| same type as input object with filtered info axis
|
| to_msgpack(self, path_or_buf=None, **kwargs)
| msgpack (serialize) object to input file path
|
| THIS IS AN EXPERIMENTAL LIBRARY and the storage format
| may not be stable until a future release.
|
| 【参数】
| ----------| path : string File path, buffer-like, or None
598
| if None, return generated string
| append : boolean whether to append to an existing msgpack
| (default is False)
| compress : type of compressor (zlib or blosc), default to None (no
| compression)
|
| to_pickle(self, path)
| Pickle (serialize) object to input file path
|
| 【参数】
| ----------| path : string
| File path
|
| to_sql(self, name, con, flavor=&#39;sqlite&#39;, schema=None, if_exists=&#39;fail&#39;, index=True, index_label=None, chunksize=None,
dtype=None)
| Write records stored in a DataFrame to a SQL database.
|
| 【参数】
| ----------| name : string
| Name of SQL table
| con : SQLAlchemy engine or DBAPI2 connection (legacy mode)
| Using SQLAlchemy makes it possible to use any DB supported by that
| library.
| If a DBAPI2 object, only sqlite3 is supported.
| flavor : {&#39;sqlite&#39;, &#39;mysql&#39;}, default &#39;sqlite&#39;
| The flavor of SQL to use. Ignored when using SQLAlchemy engine.
| &#39;mysql&#39; is deprecated and will be removed in future versions, but it
| will be further supported through SQLAlchemy engines.
| schema : string, default None
| Specify the schema (if database flavor supports this). If None, use
| default schema.
| if_exists : {&#39;fail&#39;, &#39;replace&#39;, &#39;append&#39;}, default &#39;fail&#39;
| - fail: If table exists, do nothing.
| - replace: If table exists, drop it, recreate it, and insert data.
| - append: If table exists, insert data. Create if does not exist.
| index : boolean, default True
| Write DataFrame index as a column.
| index_label : string or sequence, default None
| Column label for index column(s). If None is given (default) and
|</code>index<code>is True, then the index names are used.
| A sequence should be given if the DataFrame uses MultiIndex.
| chunksize : int, default None
| If not None, then rows will be written in batches of this size at a
| time. If None, all rows will be written at once.
| dtype : dict of column name to SQL type, default None
| Optional specifying the datatype for columns. The SQL type should
| be a SQLAlchemy type, or a string for sqlite3 fallback connection.
|
| truncate(self, before=None, after=None, axis=None, copy=True)
| Truncates a sorted NDFrame before and/or after some particular
| dates.
|
| 【参数】
| ----------| before : date
599
| Truncate before date
| after : date
| Truncate after date
| axis : the truncation axis, defaults to the stat axis
| copy : boolean, default is True,
| return a copy of the truncated section
|
| 【返回值】
| -------| truncated : type of caller
|
| tshift(self, periods=1, freq=None, axis=0)
| Shift the time index, using the index&#39;s frequency if available
|
| 【参数】
| ----------| periods : int
| Number of periods to move, can be positive or negative
| freq : DateOffset, timedelta, or time rule string, default None
| Increment to use from datetools module or time rule (e.g. &#39;EOM&#39;)
| axis : int or basestring
| Corresponds to the axis that contains the Index
|
| 【注意】
| -----| If freq is not specified then tries to use the freq or inferred_freq
| attributes of the index. If neither of those attributes exist, a
| ValueError is thrown
|
| 【返回值】
| -------| shifted : NDFrame
|
| tz_convert(self, tz, axis=0, level=None, copy=True)
| Convert tz-aware axis to target time zone.
|
| 【参数】
| ----------| tz : string or pytz.timezone object
| axis : the axis to convert
| level : int, str, default None
| If axis ia a MultiIndex, convert a specific level. Otherwise
| must be None
| copy : boolean, default True
| Also make a copy of the underlying data
|
| 【返回值】
| -------|
| 【Raises 引发错误】
| ------| TypeError
| If the axis is tz-naive.
|
| tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous=&#39;raise&#39;)
| Localize tz-naive TimeSeries to target time zone
|
600
| 【参数】
| ----------| tz : string or pytz.timezone object
| axis : the axis to localize
| level : int, str, default None
| If axis ia a MultiIndex, localize a specific level. Otherwise
| must be None
| copy : boolean, default True
| Also make a copy of the underlying data
| ambiguous : &#39;infer&#39;, bool-ndarray, &#39;NaT&#39;, default &#39;raise&#39;
| - &#39;infer&#39; will attempt to infer fall dst-transition hours based on order
| - bool-ndarray where True signifies a DST time, False designates
| a non-DST time (note that this flag is only applicable for ambiguous times)
| - &#39;NaT&#39; will return NaT where there are ambiguous times
| - &#39;raise&#39; will raise an AmbiguousTimeError if there are ambiguous times
| infer_dst : boolean, default False (DEPRECATED)
| Attempt to infer fall dst-transition hours based on order
|
| 【返回值】
| -------|
| 【Raises 引发错误】
| ------| TypeError
| If the TimeSeries is tz-aware and tz is not None.
|
| where(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)
| Return an object of same shape as self and whose corresponding
| entries are from self where cond is True and otherwise are from other.
|
| 【参数】
| ----------| cond : boolean NDFrame or array
| other : scalar or NDFrame
| inplace : boolean, default False
| Whether to perform the operation in place on the data
| axis : alignment axis if needed, default None
| level : alignment level if needed, default None
| try_cast : boolean, default False
| try to cast the result back to the input type (if possible),
| raise_on_error : boolean, default True
| Whether to raise on invalid data types (e.g. trying to where on
| strings)
|
| 【返回值】
| -------| wh : same type as caller
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.generic.NDFrame:
|
| at
| Fast label-based scalar accessor
|
| Similarly to ``loc``, ``at`` provides **label** based scalar lookups.
| You can also set using these indexers.
|
601
| blocks
| Internal property, property synonym for as_blocks()
|
| dtypes
| Return the dtypes in this object
|
| empty
| True if NDFrame is entirely empty [no items]
|
| ftypes
| Return the ftypes (indication of sparse/dense and dtype)
| in this object.
|
| iat
| Fast integer location scalar accessor.
|
| Similarly to ``iloc``, ``iat`` provides **integer** based lookups.
| You can also set using these indexers.
|
| iloc
| Purely integer-location based indexing for selection by position.
|
| ``.iloc[]`` is primarily integer position based (from ``0`` to
| ``length-1`` of the axis), but may also be used with a boolean
| array.
|
| Allowed inputs are:
|
| - An integer, e.g. ``5``.
| - A list or array of integers, e.g. ``[4, 3, 0]``.
| - A slice object with ints, e.g. ``1:7``.
| - A boolean array.
|
| ``.iloc`` will raise ``IndexError`` if a requested indexer is
| out-of-bounds, except *slice* indexers which allow out-of-bounds
| indexing (this conforms with python/numpy *slice* semantics).
|
| See more at :ref:</code>Selection by Position <indexing.integer><code>|
| ix
| A primarily label-location based indexer, with integer position
| fallback.
|
| ``.ix[]`` supports mixed integer and label based access. It is
| primarily label based, but will fall back to integer positional
| access unless the corresponding axis is of integer type.
|
| ``.ix`` is the most general indexer and will support any of the
| inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating
| point label schemes. ``.ix`` is exceptionally useful when dealing
| with mixed positional and label based hierachical indexes.
|
| However, when an axis is integer based, ONLY label based access
| and not positional access is supported. Thus, in such cases, it&#39;s
| usually better to be explicit and use ``.iloc`` or ``.loc``.
|
| See more at :ref:</code>Advanced Indexing <advanced><code>.
602
|
| loc
| Purely label-location based indexer for selection by label.
|
| ``.loc[]`` is primarily label based, but may also be used with a
| boolean array.
|
| Allowed inputs are:
|
| - A single label, e.g. ``5`` or ``&#39;a&#39;``, (note that ``5`` is
| interpreted as a *label* of the index, and **never** as an
| integer position along the index).
| - A list or array of labels, e.g. ``[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]``.
| - A slice object with labels, e.g. ``&#39;a&#39;:&#39;f&#39;`` (note that contrary
| to usual python slices, **both** the start and the stop are included!).
| - A boolean array.
|
| ``.loc`` will raise a ``KeyError`` when the items are not found.
|
| See more at :ref:</code>Selection by Label <indexing.label><code>|
| ndim
| Number of axes / array dimensions
|
| size
| number of elements in the NDFrame
|
| values
| Numpy representation of NDFrame
|
| 【注意】
| -----| The dtype will be a lower-common-denominator dtype (implicit
| upcasting); that is to say if the dtypes (even of numeric types)
| are mixed, the one that accommodates all will be chosen. Use this
| with care if you are not dealing with the blocks.
|
| e.g. If the dtypes are float16 and float32, dtype will be upcast to
| float32. If dtypes are int32 and uint8, dtype will be upcase to
| int32.
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.generic.NDFrame:
|
| is_copy = None
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.PandasObject:
|
| __dir__(self)
| Provide method name lookup and completion
| Only provide &#39;public&#39; methods
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
603
| Return a string representation for a particular object.
|
| Invoked by bytes(obj) in py3 only.
| Yields a bytestring in both py2/py3.
|
| __repr__(self)
| Return a string representation for a particular object.
|
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.base.StringMixin:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
SparseList
SparseList 模块所属：pandas.sparse.list:
类定义：SparseList(pandas.core.base.PandasObject)
| Data structure for accumulating data to be converted into a
| SparseArray. Has similar API to the standard Python list
|
| 【参数】
| ----------| data : scalar or array-like
| fill_value : scalar, default NaN
|
| 【方法排序】
| SparseList
| pandas.core.base.PandasObject
| pandas.core.base.StringMixin
| 【内置对象】
|
| 【方法定义】
|
| __getitem__(self, i)
|
| __init__(self, data=None, fill_value=nan)
| Initialize self. See help(type(self)) for accurate signature.
604
|
| __len__(self)
|
| __setitem__(self, i, value)
|
| __unicode__(self)
| Return a string representation for a particular object.
|
| Invoked by unicode(obj) in py2 only. Yields a Unicode String in both
| py2/py3.
|
| append(self, value)
| Append element or array-like chunk of data to the SparseList
|
| 【参数】
| ----------| value: scalar or array-like
|
| consolidate(self, inplace=True)
| Internally consolidate chunks of data
|
| 【参数】
| ----------| inplace : boolean, default True
| Modify the calling object instead of constructing a new one
|
| 【返回值】
| -------| splist : SparseList
| If inplace=False, new object, otherwise reference to existing
| object
|
| copy(self)
| Return copy of the list
|
| 【返回值】
| -------| new_list : SparseList
|
| to_array(self)
| Return SparseArray from data stored in the SparseList
|
| 【返回值】
| -------| sparr : SparseArray
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| is_consolidated
|
| nchunks
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.PandasObject:
|
| __dir__(self)
605
| Provide method name lookup and completion
| Only provide &#39;public&#39; methods
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
| Return a string representation for a particular object.
|
| Invoked by bytes(obj) in py3 only.
| Yields a bytestring in both py2/py3.
|
| __repr__(self)
| Return a string representation for a particular object.
|
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.base.StringMixin:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
SparsePanel
SparsePanel 模块所属：pandas.sparse.panel:
类定义：SparsePanel(pandas.core.panel.Panel)
| Sparse version of Panel
|
| 【参数】
| ----------| frames : dict of DataFrame objects
| items : array-like
| major_axis : array-like
| minor_axis : array-like
| default_kind : {&#39;block&#39;, &#39;integer&#39;}, default &#39;block&#39;
| Default sparse kind for converting Series to SparseSeries. Will not
| override SparseSeries passed into constructor
| default_fill_value : float
| Default fill_value for converting Series to SparseSeries. Will not
606
| override SparseSeries passed in
|
|【注意】
| -----|
| 【方法排序】
| SparsePanel
| pandas.core.panel.Panel
| pandas.core.generic.NDFrame
| pandas.core.base.PandasObject
| pandas.core.base.StringMixin
| 【内置对象】
|
| 【方法定义】
|
| __add__(self, other)
| # work only for scalars
|
| __and__(self, other)
| # work only for scalars
|
| __array_wrap__(self, result)
|
| __delitem__(self, key)
| Delete item
|
| __div__ = __truediv__(self, other)
|
| __eq__(self, other)
| Wrapper for comparison method __eq__
|
| __floordiv__(self, other)
| # work only for scalars
|
| __ge__(self, other)
| Wrapper for comparison method __ge__
|
| __getstate__(self)
|
| __gt__(self, other)
| Wrapper for comparison method __gt__
|
| __iadd__ = f(self, other)
|
| __imul__ = f(self, other)
|
| __init__(self, frames=None, items=None, major_axis=None, minor_axis=None, default_fill_value=nan,
default_kind=&#39;block&#39;, copy=False)
| Initialize self. See help(type(self)) for accurate signature.
|
| __ipow__ = f(self, other)
|
| __isub__ = f(self, other)
|
| __itruediv__ = f(self, other)
|
| __le__(self, other)
607
| Wrapper for comparison method __le__
|
| __lt__(self, other)
| Wrapper for comparison method __lt__
|
| __mod__(self, other)
| # work only for scalars
|
| __mul__(self, other)
| # work only for scalars
|
| __ne__(self, other)
| Wrapper for comparison method __ne__
|
| __or__(self, other)
| # work only for scalars
|
| __pow__(self, other)
| # work only for scalars
|
| __radd__(self, other)
| # work only for scalars
|
| __rand__(self, other)
| # work only for scalars
|
| __rdiv__ = __rtruediv__(self, other)
|
| __rfloordiv__(self, other)
| # work only for scalars
|
| __rmod__(self, other)
| # work only for scalars
|
| __rmul__(self, other)
| # work only for scalars
|
| __ror__(self, other)
| # work only for scalars
|
| __rpow__(self, other)
| # work only for scalars
|
| __rsub__(self, other)
| # work only for scalars
|
| __rtruediv__(self, other)
| # work only for scalars
|
| __rxor__(self, other)
| # work only for scalars
|
| __setitem__(self, key, value)
|
| __setstate__(self, state)
|
| __sub__(self, other)
608
| # work only for scalars
|
| __truediv__(self, other)
| # work only for scalars
|
| __xor__(self, other)
| # work only for scalars
|
| add(self, other, axis=0)
| Addition of series and other, element-wise (binary operator</code>add<code>).
| Equivalent to ``panel + other``.
|
| 【参数】
| ----------| other : DataFrame or SparsePanel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| SparsePanel
|
| 【参见】
| --------| SparsePanel.radd
|
| as_matrix(self)
| Convert the frame to its Numpy-array representation.
|
| 【参数】
| ----------| columns: list, optional, default:None
| If None, return all columns, otherwise, returns specified columns.
|
| 【返回值】
| -------| values : ndarray
| If the caller is heterogeneous and contains booleans or objects,
| the result will be of dtype=object. See Notes.
|
|
| 【注意】
| -----| Return is NOT a Numpy-matrix, rather, a Numpy-array.
|
| The dtype will be a lower-common-denominator dtype (implicit
| upcasting); that is to say if the dtypes (even of numeric types)
| are mixed, the one that accommodates all will be chosen. Use this
| with care if you are not dealing with the blocks.
|
| e.g. If the dtypes are float16 and float32, dtype will be upcast to
| float32. If dtypes are int32 and uint8, dtype will be upcase to
| int32.
|
| This method is provided for backwards compatibility. Generally,
| it is recommended to use &#39;.values&#39;.
|
609
| 【参见】
| --------| pandas.DataFrame.values
|
| copy(self, deep=True)
| Make a copy of the sparse panel
|
| 【返回值】
| -------| copy : SparsePanel
|
| div = truediv(self, other, axis=0)
|
| divide = truediv(self, other, axis=0)
|
| eq(self, other)
| Wrapper for comparison method eq
|
| floordiv(self, other, axis=0)
| Integer division of series and other, element-wise (binary operator</code>floordiv<code>).
| Equivalent to ``panel // other``.
|
| 【参数】
| ----------| other : DataFrame or SparsePanel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| SparsePanel
|
| 【参见】
| --------| SparsePanel.rfloordiv
|
| ge(self, other)
| Wrapper for comparison method ge
|
| gt(self, other)
| Wrapper for comparison method gt
|
| le(self, other)
| Wrapper for comparison method le
|
| lt(self, other)
| Wrapper for comparison method lt
|
| major_xs(self, key)
| Return slice of panel along major axis
|
| 【参数】
| ----------| key : object
| Major axis label
|
| 【返回值】
610
| -------| y : DataFrame
| index -&gt; minor axis, columns -&gt; items
|
| minor_xs(self, key)
| Return slice of panel along minor axis
|
| 【参数】
| ----------| key : object
| Minor axis label
|
| 【返回值】
| -------| y : SparseDataFrame
| index -&gt; major axis, columns -&gt; items
|
| mod(self, val, *args, **kwargs)
| wrapper around</code><strong>mod</strong><code>(only works for scalar values
|
| mul(self, other, axis=0)
| Multiplication of series and other, element-wise (binary operator</code>mul<code>).
| Equivalent to ``panel * other``.
|
| 【参数】
| ----------| other : DataFrame or SparsePanel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| SparsePanel
|
| 【参见】
| --------| SparsePanel.rmul
|
| multiply = mul(self, other, axis=0)
|
| ne(self, other)
| Wrapper for comparison method ne
|
| pow(self, val, *args, **kwargs)
| wrapper around</code><strong>pow</strong><code>(only works for scalar values)
|
| radd(self, other, axis=0)
| Addition of series and other, element-wise (binary operator</code>radd<code>).
| Equivalent to ``other + panel``.
|
| 【参数】
| ----------| other : DataFrame or SparsePanel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
611
| -------| SparsePanel
|
| 【参见】
| --------| SparsePanel.add
|
| rdiv = rtruediv(self, other, axis=0)
|
| reindex(self, major=None, items=None, minor=None, major_axis=None, minor_axis=None, copy=False)
| Conform / reshape panel axis labels to new input labels
|
| 【参数】
| ----------| major : array-like, default None
| items : array-like, default None
| minor : array-like, default None
| copy : boolean, default False
| Copy underlying SparseDataFrame objects
|
| 【返回值】
| -------| reindexed : SparsePanel
|
| rfloordiv(self, other, axis=0)
| Integer division of series and other, element-wise (binary operator</code>rfloordiv<code>).
| Equivalent to ``other // panel``.
|
| 【参数】
| ----------| other : DataFrame or SparsePanel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| SparsePanel
|
| 【参见】
| --------| SparsePanel.floordiv
|
| rmod(self, other, axis=0)
| Modulo of series and other, element-wise (binary operator</code>rmod<code>).
| Equivalent to ``other % panel``.
|
| 【参数】
| ----------| other : DataFrame or SparsePanel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| SparsePanel
|
612
| 【参见】
| --------| SparsePanel.mod
|
| rmul(self, other, axis=0)
| Multiplication of series and other, element-wise (binary operator</code>rmul<code>).
| Equivalent to ``other * panel``.
|
| 【参数】
| ----------| other : DataFrame or SparsePanel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| SparsePanel
|
| 【参见】
| --------| SparsePanel.mul
|
| rpow(self, other, axis=0)
| Exponential power of series and other, element-wise (binary operator</code>rpow<code>).
| Equivalent to ``other ** panel``.
|
| 【参数】
| ----------| other : DataFrame or SparsePanel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| SparsePanel
|
| 【参见】
| --------| SparsePanel.pow
|
| rsub(self, other, axis=0)
| Subtraction of series and other, element-wise (binary operator</code>rsub<code>).
| Equivalent to ``other - panel``.
|
| 【参数】
| ----------| other : DataFrame or SparsePanel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| SparsePanel
|
| 【参见】
| --------
613
| SparsePanel.sub
|
| rtruediv(self, other, axis=0)
| Floating division of series and other, element-wise (binary operator</code>rtruediv<code>).
| Equivalent to ``other / panel``.
|
| 【参数】
| ----------| other : DataFrame or SparsePanel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| SparsePanel
|
| 【参见】
| --------| SparsePanel.truediv
|
| set_value(self, item, major, minor, value)
| Quickly set single value at (item, major, minor) location
|
| 【参数】
| ----------| item : item label (panel item)
| major : major axis label (panel item row)
| minor : minor axis label (panel item column)
| value : scalar
|
| 【注意】
| -----| This method *always* returns a new object. It is not particularly
| efficient but is provided for API compatibility with Panel
|
| 【返回值】
| -------| panel : SparsePanel
|
| sub(self, other, axis=0)
| Subtraction of series and other, element-wise (binary operator</code>sub<code>).
| Equivalent to ``panel - other``.
|
| 【参数】
| ----------| other : DataFrame or SparsePanel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| SparsePanel
|
| 【参见】
| --------| SparsePanel.rsub
614
|
| subtract = sub(self, other, axis=0)
|
| toLong = wrapper(*args, **kwargs)
|
| to_dense(self)
| Convert SparsePanel to (dense) Panel
|
| 【返回值】
| -------| dense : Panel
|
| to_frame(self, filter_observations=True)
| Convert SparsePanel to (dense) DataFrame
|
| 【返回值】
| -------| frame : DataFrame
|
| to_long = wrapper(*args, **kwargs)
|
| truediv(self, other, axis=0)
| Floating division of series and other, element-wise (binary operator</code>truediv<code>).
| Equivalent to ``panel / other``.
|
| 【参数】
| ----------| other : DataFrame or SparsePanel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| SparsePanel
|
| 【参见】
| --------| SparsePanel.rtruediv
|
| ----------------------------------------------------------------------| Class methods defined here:
|
| from_dict(data) from builtins.type
| Analogous to Panel.from_dict
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| items
|
| major_axis
|
| minor_axis
|
| values
| Numpy representation of NDFrame
|
615
| 【注意】
| -----| The dtype will be a lower-common-denominator dtype (implicit
| upcasting); that is to say if the dtypes (even of numeric types)
| are mixed, the one that accommodates all will be chosen. Use this
| with care if you are not dealing with the blocks.
|
| e.g. If the dtypes are float16 and float32, dtype will be upcast to
| float32. If dtypes are int32 and uint8, dtype will be upcase to
| int32.
|
| ----------------------------------------------------------------------| 其他数据、属性定义：
|
| ndim = 3
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.panel.Panel:
|
| __getitem__(self, key)
|
| __unicode__(self)
| Return a string representation for a particular Panel
|
| Invoked by unicode(df) in py2 only.
| Yields a Unicode String in both py2/py3.
|
| align(self, other, **kwargs)
| Align two object on their axes with the
| specified join method for each axis Index
|
| 【参数】
| ----------| other : DataFrame or Series
| join : {&#39;outer&#39;, &#39;inner&#39;, &#39;left&#39;, &#39;right&#39;}, default &#39;outer&#39;
| axis : allowed axis of the other object, default None
| Align on index (0), columns (1), or both (None)
| level : int or level name, default None
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
| copy : boolean, default True
| Always returns new objects. If copy=False and no reindexing is
| required then original objects are returned.
| fill_value : scalar, default np.NaN
| Value to use for missing values. Defaults to NaN, but can be any
| &quot;compatible&quot; value
| method : str, default None
| limit : int, default None
| fill_axis : int or labels for object, default 0
| Filling axis, method and limit
| broadcast_axis : int or labels for object, default None
| Broadcast values along this axis, if aligning two objects of
| different dimensions
|
| .. versionadded:: 0.17.0
|
| 【返回值】
616
| -------| (left, right) : (NDFrame, type of other)
| Aligned objects
|
| all(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)
| Return whether all elements are True over requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| bool_only : boolean, default None
| Include only boolean data. If None, will attempt to use everything,
| then use only boolean data
|
| 【返回值】
| -------| all : DataFrame or Panel (if level specified)
|
| any(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)
| Return whether any element is True over requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| bool_only : boolean, default None
| Include only boolean data. If None, will attempt to use everything,
| then use only boolean data
|
| 【返回值】
| -------| any : DataFrame or Panel (if level specified)
|
| apply(self, func, axis=&#39;major&#39;, **kwargs)
| Applies function along axis (or axes) of the Panel
|
| 【参数】
| ----------| func : function
| Function to apply to each combination of &#39;other&#39; axes
| e.g. if axis = &#39;items&#39;, the combination of major_axis/minor_axis
| will each be passed as a Series; if axis = (&#39;items&#39;, &#39;major&#39;), DataFrames
| of items &amp; major axis will be passed
| axis : {&#39;items&#39;, &#39;minor&#39;, &#39;major&#39;}, or {0, 1, 2}, or a tuple with two axes
| Additional keyword arguments will be passed as keywords to the function
|
617
| 【示例】
| --------|
| Returns a Panel with the square root of each element
|
| &gt;&gt;&gt; p = pd.Panel(np.random.rand(4,3,2))
| &gt;&gt;&gt; p.apply(np.sqrt)
|
| Equivalent to p.sum(1), returning a DataFrame
|
| &gt;&gt;&gt; p.apply(lambda x: x.sum(), axis=1)
|
| Equivalent to previous:
|
| &gt;&gt;&gt; p.apply(lambda x: x.sum(), axis=&#39;minor&#39;)
|
| Return the shapes of each DataFrame over axis 2 (i.e the shapes of items x major), as a Series
|
| &gt;&gt;&gt; p.apply(lambda x: x.shape, axis=(0,1))
|
| 【返回值】
| -------| result : Panel, DataFrame, or Series
|
| compound(self, axis=None, skipna=None, level=None)
| Return the compound percentage of the values for the requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| compounded : DataFrame or Panel (if level specified)
|
| conform(self, frame, axis=&#39;items&#39;)
| Conform input DataFrame to align with chosen axis pair.
|
| 【参数】
| ----------| frame : DataFrame
| axis : {&#39;items&#39;, &#39;major&#39;, &#39;minor&#39;}
|
| Axis the input corresponds to. E.g., if axis=&#39;major&#39;, then
| the frame&#39;s columns would be items, and the index would be
| values of the minor axis
|
| 【返回值】
618
| -------| DataFrame
|
| count(self, axis=&#39;major&#39;)
| Return number of observations over requested axis.
|
| 【参数】
| ----------| axis : {&#39;items&#39;, &#39;major&#39;, &#39;minor&#39;} or {0, 1, 2}
|
| 【返回值】
| -------| count : DataFrame
|
| cummax = max(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative max over requested axis.
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| max : DataFrame
|
| cummin = min(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative min over requested axis.
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| min : DataFrame
|
| cumprod = prod(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative prod over requested axis.
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| prod : DataFrame
|
619
| cumsum = sum(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative sum over requested axis.
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| sum : DataFrame
|
| dropna(self, axis=0, how=&#39;any&#39;, inplace=False)
| Drop 2D from panel, holding passed axis constant
|
| 【参数】
| ----------| axis : int, default 0
| Axis to hold constant. E.g. axis=1 will drop major_axis entries
| having a certain amount of NA data
| how : {&#39;all&#39;, &#39;any&#39;}, default &#39;any&#39;
| &#39;any&#39;: one or more values are NA in the DataFrame along the
| axis. For &#39;all&#39; they all must be.
| inplace : bool, default False
| If True, do operation inplace and return None.
|
| 【返回值】
| -------| dropped : Panel
|
| fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)
| Fill NA/NaN values using the specified method
|
| 【参数】
| ----------| value : scalar, dict, Series, or DataFrame
| Value to use to fill holes (e.g. 0), alternately a dict/Series/DataFrame of
| values specifying which value to use for each index (for a Series) or
| column (for a DataFrame). (values not in the dict/Series/DataFrame will not be
| filled). This value cannot be a list.
| method : {&#39;backfill&#39;, &#39;bfill&#39;, &#39;pad&#39;, &#39;ffill&#39;, None}, default None
| Method to use for filling holes in reindexed Series
| pad / ffill: propagate last valid observation forward to next valid
| backfill / bfill: use NEXT valid observation to fill gap
| axis : {0, 1, 2, &#39;items&#39;, &#39;major_axis&#39;, &#39;minor_axis&#39;}
| inplace : boolean, default False
| If True, fill in place. Note: this will modify any
| other views on this object, (e.g. a no-copy slice for a column in a
| DataFrame).
| limit : int, default None
| If method is specified, this is the maximum number of consecutive
| NaN values to forward/backward fill. In other words, if there is
| a gap with more than this number of consecutive NaNs, it will only
| be partially filled. If method is not specified, this is the
| maximum number of entries along the entire axis where NaNs will be
620
| filled.
| downcast : dict, default is None
| a dict of item-&gt;dtype of what to downcast if possible,
| or the string &#39;infer&#39; which will try to downcast to an appropriate
| equal type (e.g. float64 to int64 if possible)
|
| 【参见】
| --------| reindex, asfreq
|
| 【返回值】
| -------| filled : Panel
|
| get_value(self, *args, **kwargs)
| Quickly retrieve single value at (item, major, minor) location
|
| 【参数】
| ----------| item : item label (panel item)
| major : major axis label (panel item row)
| minor : minor axis label (panel item column)
| takeable : interpret the passed labels as indexers, default False
|
| 【返回值】
| -------| value : scalar value
|
| groupby(self, function, axis=&#39;major&#39;)
| Group data on given axis, returning GroupBy object
|
| 【参数】
| ----------| function : callable
| Mapping function for chosen access
| axis : {&#39;major&#39;, &#39;minor&#39;, &#39;items&#39;}, default &#39;major&#39;
|
| 【返回值】
| -------| grouped : PanelGroupBy
|
| head(self, n=5)
| Returns first n rows
|
| join(self, other, how=&#39;left&#39;, lsuffix=&#39;&#39;, rsuffix=&#39;&#39;)
| Join items with other Panel either on major and minor axes column
|
| 【参数】
| ----------| other : Panel or list of Panels
| Index should be similar to one of the columns in this one
| how : {&#39;left&#39;, &#39;right&#39;, &#39;outer&#39;, &#39;inner&#39;}
| How to handle indexes of the two objects. Default: &#39;left&#39;
| for joining on index, None otherwise
| * left: use calling frame&#39;s index
| * right: use input frame&#39;s index
| * outer: form union of indexes
621
| * inner: use intersection of indexes
| lsuffix : string
| Suffix to use from left frame&#39;s overlapping columns
| rsuffix : string
| Suffix to use from right frame&#39;s overlapping columns
|
| 【返回值】
| -------| joined : Panel
|
| kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return unbiased kurtosis over requested axis using Fishers definition of
| kurtosis (kurtosis of normal == 0.0). Normalized by N-1
|
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| kurt : DataFrame or Panel (if level specified)
|
| kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return unbiased kurtosis over requested axis using Fishers definition of
| kurtosis (kurtosis of normal == 0.0). Normalized by N-1
|
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| kurt : DataFrame or Panel (if level specified)
|
| mad(self, axis=None, skipna=None, level=None)
| Return the mean absolute deviation of the values for the requested axis
|
622
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| mad : DataFrame or Panel (if level specified)
|
| max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| This method returns the maximum of the values in the object. If you
| want the *index* of the maximum, use ``idxmax``. This is the
| equivalent of the ``numpy.ndarray`` method ``argmax``.
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| max : DataFrame or Panel (if level specified)
|
| mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the mean of the values for the requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------
623
| mean : DataFrame or Panel (if level specified)
|
| median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the median of the values for the requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| median : DataFrame or Panel (if level specified)
|
| min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| This method returns the minimum of the values in the object. If you
| want the *index* of the minimum, use ``idxmin``. This is the
| equivalent of the ``numpy.ndarray`` method ``argmin``.
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| min : DataFrame or Panel (if level specified)
|
| prod(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the product of the values for the requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
624
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| prod : DataFrame or Panel (if level specified)
|
| product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the product of the values for the requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| prod : DataFrame or Panel (if level specified)
|
| reindex_axis(self, labels, axis=0, method=None, level=None, copy=True, limit=None, fill_value=nan)
| Conform input object to new index with optional filling logic,
| placing NA/NaN in locations having no value in the previous index. A
| new object is produced unless the new index is equivalent to the
| current one and copy=False
|
| 【参数】
| ----------| labels : array-like
| New labels / index to conform to. Preferably an Index object to
| avoid duplicating data
| axis : {0, 1, 2, &#39;items&#39;, &#39;major_axis&#39;, &#39;minor_axis&#39;}
| method : {None, &#39;backfill&#39;/&#39;bfill&#39;, &#39;pad&#39;/&#39;ffill&#39;, &#39;nearest&#39;}, optional
| Method to use for filling holes in reindexed DataFrame:
| * default: don&#39;t fill gaps
| * pad / ffill: propagate last valid observation forward to next valid
| * backfill / bfill: use next valid observation to fill gap
| * nearest: use nearest valid observations to fill gap
| copy : boolean, default True
| Return a new object, even if the passed indexes are the same
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
| limit : int, default None
| Maximum number of consecutive elements to forward or backward fill
| tolerance : optional
| Maximum distance between original and new labels for inexact
| matches. The values of the index at the matching locations most
| satisfy the equation ``abs(index[indexer] - target) &lt;= tolerance``.
|
625
| .. versionadded:: 0.17.0
|
| 【示例】
| --------| &gt;&gt;&gt; df.reindex_axis([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;], axis=1)
|
| 【参见】
| --------| reindex, reindex_like
|
| 【返回值】
| -------| reindexed : Panel
|
| rename(self, items=None, major_axis=None, minor_axis=None, **kwargs)
| Alter axes input function or functions. Function / dict values must be
| unique (1-to-1). Labels not contained in a dict / Series will be left
| as-is.
|
| 【参数】
| ----------| items, major_axis, minor_axis : dict-like or function, optional
| Transformation to apply to that axis values
|
| copy : boolean, default True
| Also copy underlying data
| inplace : boolean, default False
| Whether to return a new Panel. If True then value of copy is
| ignored.
|
| 【返回值】
| -------| renamed : Panel (new object)
|
| sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)
| Return unbiased standard error of the mean over requested axis.
|
| Normalized by N-1 by default. This can be changed using the ddof argument
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| ddof : int, default 1
| degrees of freedom
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| sem : DataFrame or Panel (if level specified)
626
|
| shift(self, periods=1, freq=None, axis=&#39;major&#39;)
| Shift index by desired number of periods with an optional time freq.
| The shifted data will not include the dropped periods and the
| shifted axis will be smaller than the original. This is different
| from the behavior of DataFrame.shift()
|
| 【参数】
| ----------| periods : int
| Number of periods to move, can be positive or negative
| freq : DateOffset, timedelta, or time rule string, optional
| axis : {&#39;items&#39;, &#39;major&#39;, &#39;minor&#39;} or {0, 1, 2}
|
| 【返回值】
| -------| shifted : Panel
|
| skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return unbiased skew over requested axis
| Normalized by N-1
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| skew : DataFrame or Panel (if level specified)
|
| std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)
| Return unbiased standard deviation over requested axis.
|
| Normalized by N-1 by default. This can be changed using the ddof argument
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| ddof : int, default 1
| degrees of freedom
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
627
| everything, then use only numeric data
|
| 【返回值】
| -------| std : DataFrame or Panel (if level specified)
|
| sum(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the sum of the values for the requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| sum : DataFrame or Panel (if level specified)
|
| tail(self, n=5)
| Returns last n rows
|
| to_excel(self, path, na_rep=&#39;&#39;, engine=None, **kwargs)
| Write each DataFrame in Panel to a separate excel sheet
|
| 【参数】
| ----------| path : string or ExcelWriter object
| File path or existing ExcelWriter
| na_rep : string, default &#39;&#39;
| Missing data representation
| engine : string, default None
| write engine to use - you can also set this via the options
| ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and
| ``io.excel.xlsm.writer``.
|
| Other【参数】
| ----------------| float_format : string, default None
| Format string for floating point numbers
| cols : sequence, optional
| Columns to write
| header : boolean or list of string, default True
| Write out column names. If a list of string is given it is
| assumed to be aliases for the column names
| index : boolean, default True
| Write row names (index)
| index_label : string or sequence, default None
| Column label for index column(s) if desired. If None is given, and
|</code>header<code>and</code>index<code>are True, then the index names are used. A
628
| sequence should be given if the DataFrame uses MultiIndex.
| startrow : upper left cell row to dump data frame
| startcol : upper left cell column to dump data frame
|
| 【注意】
| -----| Keyword arguments (and na_rep) are passed to the ``to_excel`` method
| for each DataFrame written.
|
| to_sparse(self, fill_value=None, kind=&#39;block&#39;)
| Convert to SparsePanel
|
| 【参数】
| ----------| fill_value : float, default NaN
| kind : {&#39;block&#39;, &#39;integer&#39;}
|
| 【返回值】
| -------| y : SparseDataFrame
|
| transpose(self, *args, **kwargs)
| Permute the dimensions of the Panel
|
| 【参数】
| ----------| args : three positional arguments: each oneof
| {0, 1, 2, &#39;items&#39;, &#39;major_axis&#39;, &#39;minor_axis&#39;}
| copy : boolean, default False
| Make a copy of the underlying data. Mixed-dtype data will
| always result in a copy
|
| 【示例】
| --------| &gt;&gt;&gt; p.transpose(2, 0, 1)
| &gt;&gt;&gt; p.transpose(2, 0, 1, copy=True)
|
| 【返回值】
| -------| y : same as input
|
| tshift(self, periods=1, freq=None, axis=&#39;major&#39;)
| Shift the time index, using the index&#39;s frequency if available
|
| 【参数】
| ----------| periods : int
| Number of periods to move, can be positive or negative
| freq : DateOffset, timedelta, or time rule string, default None
| Increment to use from datetools module or time rule (e.g. &#39;EOM&#39;)
| axis : int or basestring
| Corresponds to the axis that contains the Index
|
| 【注意】
| -----| If freq is not specified then tries to use the freq or inferred_freq
629
| attributes of the index. If neither of those attributes exist, a
| ValueError is thrown
|
| 【返回值】
| -------| shifted : NDFrame
|
| update(self, other, join=&#39;left&#39;, overwrite=True, filter_func=None, raise_conflict=False)
| Modify Panel in place using non-NA values from passed
| Panel, or object coercible to Panel. Aligns on items
|
| 【参数】
| ----------| other : Panel, or object coercible to Panel
| join : How to join individual DataFrames
| {&#39;left&#39;, &#39;right&#39;, &#39;outer&#39;, &#39;inner&#39;}, default &#39;left&#39;
| overwrite : boolean, default True
| If True then overwrite values for common keys in the calling panel
| filter_func : callable(1d-array) -&gt; 1d-array&lt;boolean&gt;, default None
| Can choose to replace values other than NA. Return True for values
| that should be updated
| raise_conflict : bool
| If True, will raise an error if a DataFrame and other both
| contain data in the same place.
|
| var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)
| Return unbiased variance over requested axis.
|
| Normalized by N-1 by default. This can be changed using the ddof argument
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| ddof : int, default 1
| degrees of freedom
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| var : DataFrame or Panel (if level specified)
|
| xs(self, key, axis=1, copy=None)
| Return slice of panel along selected axis
|
| 【参数】
| ----------| key : object
| Label
| axis : {&#39;items&#39;, &#39;major&#39;, &#39;minor}, default 1/&#39;major&#39;
630
| copy : boolean [deprecated]
| Whether to make a copy of the data
|
| 【返回值】
| -------| y : ndim(self)-1
|
| 【注意】
| -----| xs is only for getting, not setting values.
|
| MultiIndex Slicers is a generic way to get/set values on any level or levels
| it is a superset of xs functionality, see :ref:</code>MultiIndex Slicers <advanced.mi_slicers><code>|
| ----------------------------------------------------------------------| Class methods inherited from pandas.core.panel.Panel:
|
| fromDict = from_dict(data, intersect=False, orient=&#39;items&#39;, dtype=None) from builtins.type
| Construct Panel from dict of DataFrame objects
|
| 【参数】
| ----------| data : dict
| {field : DataFrame}
| intersect : boolean
| Intersect indexes of input DataFrames
| orient : {&#39;items&#39;, &#39;minor&#39;}, default &#39;items&#39;
| The &quot;orientation&quot; of the data. If the keys of the passed dict
| should be the items of the result panel, pass &#39;items&#39;
| (default). Otherwise if the columns of the values of the passed
| DataFrame objects should be the items (which in the case of
| mixed-dtype data you should do), instead pass &#39;minor&#39;
| dtype : dtype, default None
| Data type to force, otherwise infer
|
| 【返回值】
| -------| Panel
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.generic.NDFrame:
|
| __abs__(self)
|
| __array__(self, dtype=None)
|
| __bool__ = __nonzero__(self)
|
| __contains__(self, key)
| True if the key is in the info axis
|
| __finalize__(self, other, method=None, **kwargs)
| propagate metadata from other to self
|
| 【参数】
| ----------| other : the object from which to get the attributes that we are going
631
| to propagate
| method : optional, a passed method name ; possibly to take different
| types of propagation actions based on this
|
| __getattr__(self, name)
| After regular attribute access, try looking up the name
| This allows simpler access to columns for interactive use.
|
| __hash__(self)
| Return hash(self).
|
| __invert__(self)
|
| __iter__(self)
| Iterate over infor axis
|
| __len__(self)
| Returns length of info axis
|
| __neg__(self)
|
| __nonzero__(self)
|
| __setattr__(self, name, value)
| After regular attribute access, try setting the name
| This allows simpler access to columns for interactive use.
|
| abs(self)
| Return an object with absolute value taken. Only applicable to objects
| that are all numeric
|
| 【返回值】
| -------| abs: type of caller
|
| add_prefix(self, prefix)
| Concatenate prefix string with panel items names.
|
| 【参数】
| ----------| prefix : string
|
| 【返回值】
| -------| with_prefix : type of caller
|
| add_suffix(self, suffix)
| Concatenate suffix string with panel items names
|
| 【参数】
| ----------| suffix : string
|
| 【返回值】
| -------| with_suffix : type of caller
|
632
| as_blocks(self, copy=True)
| Convert the frame to a dict of dtype -&gt; Constructor Types that each has
| a homogeneous dtype.
|
| NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in
| as_matrix)
|
| 【参数】
| ----------| copy : boolean, default True
|
| .. versionadded: 0.16.1
|
| 【返回值】
| -------| values : a dict of dtype -&gt; Constructor Types
|
| asfreq(self, freq, method=None, how=None, normalize=False)
| Convert all TimeSeries inside to specified frequency using DateOffset
| objects. Optionally provide fill method to pad/backfill missing values.
|
| 【参数】
| ----------| freq : DateOffset object, or string
| method : {&#39;backfill&#39;, &#39;bfill&#39;, &#39;pad&#39;, &#39;ffill&#39;, None}
| Method to use for filling holes in reindexed Series
| pad / ffill: propagate last valid observation forward to next valid
| backfill / bfill: use NEXT valid observation to fill method
| how : {&#39;start&#39;, &#39;end&#39;}, default end
| For PeriodIndex only, see PeriodIndex.asfreq
| normalize : bool, default False
| Whether to reset output index to midnight
|
| 【返回值】
| -------| converted : type of caller
|
| astype(self, dtype, copy=True, raise_on_error=True, **kwargs)
| Cast object to input numpy.dtype
| Return a copy when copy = True (be really careful with this!)
|
| 【参数】
| ----------| dtype : numpy.dtype or Python type
| raise_on_error : raise on invalid input
| kwargs : keyword arguments to pass on to the constructor
|
| 【返回值】
| -------| casted : type of caller
|
| at_time(self, time, asof=False)
| Select values at particular time of day (e.g. 9:30AM)
|
| 【参数】
| ----------| time : datetime.time or string
633
|
| 【返回值】
| -------| values_at_time : type of caller
|
| between_time(self, start_time, end_time, include_start=True, include_end=True)
| Select values between particular times of the day (e.g., 9:00-9:30 AM)
|
| 【参数】
| ----------| start_time : datetime.time or string
| end_time : datetime.time or string
| include_start : boolean, default True
| include_end : boolean, default True
|
| 【返回值】
| -------| values_between_time : type of caller
|
| bfill(self, axis=None, inplace=False, limit=None, downcast=None)
| Synonym for NDFrame.fillna(method=&#39;bfill&#39;)
|
| bool(self)
| Return the bool of a single element PandasObject
| This must be a boolean scalar value, either True or False
|
| Raise a ValueError if the PandasObject does not have exactly
| 1 element, or that element is not boolean
|
| clip(self, lower=None, upper=None, out=None, axis=None)
| Trim values at input threshold(s)
|
| 【参数】
| ----------| lower : float or array_like, default None
| upper : float or array_like, default None
| axis : int or string axis name, optional
| Align object with lower and upper along the given axis.
|
| 【返回值】
| -------| clipped : Series
|
| 【示例】
| --------| &gt;&gt;&gt; df
| 0 1
| 0 0.335232 -1.256177
| 1 -1.367855 0.746646
| 2 0.027753 -1.176076
| 3 0.230930 -0.679613
| 4 1.261967 0.570967
| &gt;&gt;&gt; df.clip(-1.0, 0.5)
| 0 1
| 0 0.335232 -1.000000
| 1 -1.000000 0.500000
| 2 0.027753 -1.000000
634
| 3 0.230930 -0.679613
| 4 0.500000 0.500000
| &gt;&gt;&gt; t
| 0 -0.3
| 1 -0.2
| 2 -0.1
| 3 0.0
| 4 0.1
| dtype: float64
| &gt;&gt;&gt; df.clip(t, t + 1, axis=0)
| 0 1
| 0 0.335232 -0.300000
| 1 -0.200000 0.746646
| 2 0.027753 -0.100000
| 3 0.230930 0.000000
| 4 1.100000 0.570967
|
| clip_lower(self, threshold, axis=None)
| Return copy of the input with values below given value(s) truncated
|
| 【参数】
| ----------| threshold : float or array_like
| axis : int or string axis name, optional
| Align object with threshold along the given axis.
|
| 【参见】
| --------| clip
|
| 【返回值】
| -------| clipped : same type as input
|
| clip_upper(self, threshold, axis=None)
| Return copy of input with values above given value(s) truncated
|
| 【参数】
| ----------| threshold : float or array_like
| axis : int or string axis name, optional
| Align object with threshold along the given axis.
|
| 【参见】
| --------| clip
|
| 【返回值】
| -------| clipped : same type as input
|
| consolidate(self, inplace=False)
| Compute NDFrame with &quot;consolidated&quot; internals (data of each dtype
| grouped together in a single ndarray). Mainly an internal API function,
| but available here to the savvy user
|
| 【参数】
635
| ----------| inplace : boolean, default False
| If False return new object, otherwise modify existing object
|
| 【返回值】
| -------| consolidated : type of caller
|
| convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)
| Attempt to infer better dtype for object columns
|
| 【参数】
| ----------| convert_dates : boolean, default True
| If True, convert to date where possible. If &#39;coerce&#39;, force
| conversion, with unconvertible values becoming NaT.
| convert_numeric : boolean, default False
| If True, attempt to coerce to numbers (including strings), with
| unconvertible values becoming NaN.
| convert_timedeltas : boolean, default True
| If True, convert to timedelta where possible. If &#39;coerce&#39;, force
| conversion, with unconvertible values becoming NaT.
| copy : boolean, default True
| If True, return a copy even if no copy is necessary (e.g. no
| conversion was done). Note: This is meant for internal use, and
| should not be confused with inplace.
|
| 【返回值】
| -------| converted : same as input object
|
| describe(self, percentiles=None, include=None, exclude=None)
| Generate various summary statistics, excluding NaN values.
|
| 【参数】
| ----------| percentiles : array-like, optional
| The percentiles to include in the output. Should all
| be in the interval [0, 1]. By default</code>percentiles<code>is
| [.25, .5, .75], returning the 25th, 50th, and 75th percentiles.
| include, exclude : list-like, &#39;all&#39;, or None (default)
| Specify the form of the returned result. Either:
|
| - None to both (default). The result will include only numeric-typed
| columns or, if none are, only categorical columns.
| - A list of dtypes or strings to be included/excluded.
| To select all numeric types use numpy numpy.number. To select
| categorical objects use type object. 参见：the select_dtypes
| documentation. eg. df.describe(include=[&#39;O&#39;])
| - If include is the string &#39;all&#39;, the output column-set will
| match the input one.
|
| 【返回值】
| -------| summary: NDFrame of summary statistics
|
| 【注意】
636
| -----| The output DataFrame index depends on the requested dtypes:
|
| For numeric dtypes, it will include: count, mean, std, min,
| max, and lower, 50, and upper percentiles.
|
| For object dtypes (e.g. timestamps or strings), the index
| will include the count, unique, most common, and frequency of the
| most common. Timestamps also include the first and last items.
|
| For mixed dtypes, the index will be the union of the corresponding
| output types. Non-applicable entries will be filled with NaN.
| Note that mixed-dtype outputs can only be returned from mixed-dtype
| inputs and appropriate use of the include/exclude arguments.
|
| If multiple values have the highest count, then the
|</code>count<code>and</code>most common<code>pair will be arbitrarily chosen from
| among those with the highest count.
|
| The include, exclude arguments are ignored for Series.
|
| 【参见】
| --------| DataFrame.select_dtypes
|
| drop(self, labels, axis=0, level=None, inplace=False, errors=&#39;raise&#39;)
| Return new object with labels in requested axis removed
|
| 【参数】
| ----------| labels : single label or list-like
| axis : int or axis name
| level : int or level name, default None
| For MultiIndex
| inplace : bool, default False
| If True, do operation inplace and return None.
| errors : {&#39;ignore&#39;, &#39;raise&#39;}, default &#39;raise&#39;
| If &#39;ignore&#39;, suppress error and existing labels are dropped.
|
| .. versionadded:: 0.16.1
|
| 【返回值】
| -------| dropped : type of caller
|
| equals(self, other)
| Determines if two NDFrame objects contain the same elements. NaNs in the
| same location are considered equal.
|
| ffill(self, axis=None, inplace=False, limit=None, downcast=None)
| Synonym for NDFrame.fillna(method=&#39;ffill&#39;)
|
| filter(self, items=None, like=None, regex=None, axis=None)
| Restrict the info axis to set of items or wildcard
|
| 【参数】
| ----------
637
| items : list-like
| List of info axis to restrict to (must not all be present)
| like : string
| Keep info axis where &quot;arg in col == True&quot;
| regex : string (regular expression)
| Keep info axis with re.search(regex, col) == True
| axis : int or None
| The axis to filter on. By default this is the info axis. The &quot;info
| axis&quot; is the axis that is used when indexing with ``[]``. For
| example, ``df = DataFrame({&#39;a&#39;: [1, 2, 3, 4]]}); df[&#39;a&#39;]``. So,
| the ``DataFrame`` columns are the info axis.
|
| 【注意】
| -----| Arguments are mutually exclusive, but this is not checked for
|
| first(self, offset)
| Convenience method for subsetting initial periods of time series data
| based on a date offset
|
| 【参数】
| ----------| offset : string, DateOffset, dateutil.relativedelta
|
| 【示例】
| --------| ts.last(&#39;10D&#39;) -&gt; First 10 days
|
| 【返回值】
| -------| subset : type of caller
|
| get(self, key, default=None)
| Get item from object for given key (DataFrame column, Panel slice,
| etc.). Returns default value if not found
|
| 【参数】
| ----------| key : object
|
| 【返回值】
| -------| value : type of items contained in object
|
| get_dtype_counts(self)
| Return the counts of dtypes in this object
|
| get_ftype_counts(self)
| Return the counts of ftypes in this object
|
| get_values(self)
| same as values (but handles sparseness conversions)
|
| interpolate(self, method=&#39;linear&#39;, axis=0, limit=None, inplace=False, limit_direction=&#39;forward&#39;, downcast=None, **kwargs)
| Interpolate values according to different methods.
|
| Please note that only ``method=&#39;linear&#39;`` is supported for DataFrames/Series
638
| with a MultiIndex.
|
| 【参数】
| ----------| method : {&#39;linear&#39;, &#39;time&#39;, &#39;index&#39;, &#39;values&#39;, &#39;nearest&#39;, &#39;zero&#39;,
| &#39;slinear&#39;, &#39;quadratic&#39;, &#39;cubic&#39;, &#39;barycentric&#39;, &#39;krogh&#39;,
| &#39;polynomial&#39;, &#39;spline&#39; &#39;piecewise_polynomial&#39;, &#39;pchip&#39;}
|
| * &#39;linear&#39;: ignore the index and treat the values as equally
| spaced. This is the only method supported on MultiIndexes.
| default
| * &#39;time&#39;: interpolation works on daily and higher resolution
| data to interpolate given length of interval
| * &#39;index&#39;, &#39;values&#39;: use the actual numerical values of the index
| * &#39;nearest&#39;, &#39;zero&#39;, &#39;slinear&#39;, &#39;quadratic&#39;, &#39;cubic&#39;,
| &#39;barycentric&#39;, &#39;polynomial&#39; is passed to
| ``scipy.interpolate.interp1d``. Both &#39;polynomial&#39; and &#39;spline&#39;
| require that you also specify an</code>order<code>(int),
| e.g. df.interpolate(method=&#39;polynomial&#39;, order=4).
| These use the actual numerical values of the index.
| * &#39;krogh&#39;, &#39;piecewise_polynomial&#39;, &#39;spline&#39;, and &#39;pchip&#39; are all
| wrappers around the scipy interpolation methods of similar
| names. These use the actual numerical values of the index. See
| the scipy documentation for more on their behavior
|</code>here <a href="http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation" target="_blank" rel="external">http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation</a><code>__
|</code>and here <a href="http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html" target="_blank" rel="external">http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html</a><code>__
|
| axis : {0, 1}, default 0
| * 0: fill column-by-column
| * 1: fill row-by-row
| limit : int, default None.
| Maximum number of consecutive NaNs to fill.
| limit_direction : {&#39;forward&#39;, &#39;backward&#39;, &#39;both&#39;}, defaults to &#39;forward&#39;
| If limit is specified, consecutive NaNs will be filled in this
| direction.
|
| .. versionadded:: 0.17.0
|
| inplace : bool, default False
| Update the NDFrame in place if possible.
| downcast : optional, &#39;infer&#39; or None, defaults to None
| Downcast dtypes if possible.
| kwargs : keyword arguments to pass on to the interpolating function.
|
| 【返回值】
| -------| Series or DataFrame of same shape interpolated at the NaNs
|
| 【参见】
| --------| reindex, replace, fillna
|
| 【示例】
| --------|
| Filling in NaNs
|
639
| &gt;&gt;&gt; s = pd.Series([0, 1, np.nan, 3])
| &gt;&gt;&gt; s.interpolate()
| 0 0
| 1 1
| 2 2
| 3 3
| dtype: float64
|
| isnull(self)
| Return a boolean same-sized object indicating if the values are null
|
| 【参见】
| --------| notnull : boolean inverse of isnull
|
| iteritems(self)
| Iterate over (label, values) on info axis
|
| This is index for Series, columns for DataFrame, major_axis for Panel,
| and so on.
|
| iterkv(self, *args, **kwargs)
| iteritems alias used to get around 2to3. Deprecated
|
| keys(self)
| Get the &#39;info axis&#39; (see Indexing for more)
|
| This is index for Series, columns for DataFrame and major_axis for
| Panel.
|
| last(self, offset)
| Convenience method for subsetting final periods of time series data
| based on a date offset
|
| 【参数】
| ----------| offset : string, DateOffset, dateutil.relativedelta
|
| 【示例】
| --------| ts.last(&#39;5M&#39;) -&gt; Last 5 months
|
| 【返回值】
| -------| subset : type of caller
|
| mask(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)
| Return an object of same shape as self and whose corresponding
| entries are from self where cond is False and otherwise are from other.
|
| 【参数】
| ----------| cond : boolean NDFrame or array
| other : scalar or NDFrame
| inplace : boolean, default False
| Whether to perform the operation in place on the data
| axis : alignment axis if needed, default None
640
| level : alignment level if needed, default None
| try_cast : boolean, default False
| try to cast the result back to the input type (if possible),
| raise_on_error : boolean, default True
| Whether to raise on invalid data types (e.g. trying to where on
| strings)
|
| 【返回值】
| -------| wh : same type as caller
|
| notnull(self)
| Return a boolean same-sized object indicating if the values are
| not null
|
| 【参见】
| --------| isnull : boolean inverse of notnull
|
| pct_change(self, periods=1, fill_method=&#39;pad&#39;, limit=None, freq=None, **kwargs)
| Percent change over given number of periods.
|
| 【参数】
| ----------| periods : int, default 1
| Periods to shift for forming percent change
| fill_method : str, default &#39;pad&#39;
| How to handle NAs before computing percent changes
| limit : int, default None
| The number of consecutive NAs to fill before stopping
| freq : DateOffset, timedelta, or offset alias string, optional
| Increment to use from time series API (e.g. &#39;M&#39; or BDay())
|
| 【返回值】
| -------| chg : NDFrame
|
| 【注意】
| -----|
| By default, the percentage change is calculated along the stat
| axis: 0, or ``Index``, for ``DataFrame`` and 1, or ``minor`` for
| ``Panel``. You can change this with the ``axis`` keyword argument.
|
| pipe(self, func, *args, **kwargs)
| Apply func(self, \*args, \*\*kwargs)
|
| .. versionadded:: 0.16.2
|
| 【参数】
| ----------| func : function
| function to apply to the NDFrame.
| ``args``, and ``kwargs`` are passed into ``func``.
| Alternatively a ``(callable, data_keyword)`` tuple where
| ``data_keyword`` is a string indicating the keyword of
| ``callable`` that expects the NDFrame.
641
| args : positional arguments passed into ``func``.
| kwargs : a dictionary of keyword arguments passed into ``func``.
|
| 【返回值】
| -------| object : the return type of ``func``.
|
| 【注意】
| -----|
| Use ``.pipe`` when chaining together functions that expect
| on Series or DataFrames. Instead of writing
|
| &gt;&gt;&gt; f(g(h(df), arg1=a), arg2=b, arg3=c)
|
| You can write
|
| &gt;&gt;&gt; (df.pipe(h)
| ... .pipe(g, arg1=a)
| ... .pipe(f, arg2=b, arg3=c)
| ... )
|
| If you have a function that takes the data as (say) the second
| argument, pass a tuple indicating which keyword expects the
| data. For example, suppose ``f`` takes its data as ``arg2``:
|
| &gt;&gt;&gt; (df.pipe(h)
| ... .pipe(g, arg1=a)
| ... .pipe((f, &#39;arg2&#39;), arg1=a, arg3=c)
| ... )
|
| 【参见】
| --------| pandas.DataFrame.apply
| pandas.DataFrame.applymap
| pandas.Series.map
|
| pop(self, item)
| Return item and drop from frame. Raise KeyError if not found.
|
| reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)
| return an object with matching indicies to myself
|
| 【参数】
| ----------| other : Object
| method : string or None
| copy : boolean, default True
| limit : int, default None
| Maximum number of consecutive labels to fill for inexact matches.
| tolerance : optional
| Maximum distance between labels of the other object and this
| object for inexact matches.
|
| .. versionadded:: 0.17.0
|
| 【注意】
642
| -----| Like calling s.reindex(index=other.index, columns=other.columns,
| method=...)
|
| 【返回值】
| -------| reindexed : same as input
|
| rename_axis(self, mapper, axis=0, copy=True, inplace=False)
| Alter index and / or columns using input function or functions.
| Function / dict values must be unique (1-to-1). Labels not contained in
| a dict / Series will be left as-is.
|
| 【参数】
| ----------| mapper : dict-like or function, optional
| axis : int or string, default 0
| copy : boolean, default True
| Also copy underlying data
| inplace : boolean, default False
|
| 【返回值】
| -------| renamed : type of caller
|
| replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method=&#39;pad&#39;, axis=None)
| Replace values given in &#39;to_replace&#39; with &#39;value&#39;.
|
| 【参数】
| ----------| to_replace : str, regex, list, dict, Series, numeric, or None
|
| * str or regex:
|
| - str: string exactly matching</code>to_replace<code>will be replaced
| with</code>value<code>| - regex: regexs matching</code>to_replace<code>will be replaced with
|</code>value<code>|
| * list of str, regex, or numeric:
|
| - First, if</code>to_replace<code>and</code>value<code>are both lists, they
| **must** be the same length.
| - Second, if ``regex=True`` then all of the strings in **both**
| lists will be interpreted as regexs otherwise they will match
| directly. This doesn&#39;t matter much for</code>value<code>since there
| are only a few possible substitution regexes you can use.
| - str and regex rules apply as above.
|
| * dict:
|
| - Nested dictionaries, e.g., {&#39;a&#39;: {&#39;b&#39;: nan}}, are read as
| follows: look in column &#39;a&#39; for the value &#39;b&#39; and replace it
| with nan. You can nest regular expressions as well. Note that
| column names (the top-level dictionary keys in a nested
| dictionary) **cannot** be regular expressions.
| - Keys map to column names and values map to substitution
643
| values. You can treat this as a special case of passing two
| lists except that you are specifying the column to search in.
|
| * None:
|
| - This means that the ``regex`` argument must be a string,
| compiled regular expression, or list, dict, ndarray or Series
| of such elements. If</code>value<code>is also ``None`` then this
| **must** be a nested dictionary or ``Series``.
|
| See the examples section for examples of each of these.
| value : scalar, dict, list, str, regex, default None
| Value to use to fill holes (e.g. 0), alternately a dict of values
| specifying which value to use for each column (columns not in the
| dict will not be filled). Regular expressions, strings and lists or
| dicts of such objects are also allowed.
| inplace : boolean, default False
| If True, in place. Note: this will modify any
| other views on this object (e.g. a column form a DataFrame).
| Returns the caller if this is True.
| limit : int, default None
| Maximum size gap to forward or backward fill
| regex : bool or same types as</code>to_replace<code>, default False
| Whether to interpret</code>to_replace<code>and/or</code>value<code>as regular
| expressions. If this is ``True`` then</code>to_replace<code>*must* be a
| string. Otherwise,</code>to_replace<code>must be ``None`` because this
| parameter will be interpreted as a regular expression or a list,
| dict, or array of regular expressions.
| method : string, optional, {&#39;pad&#39;, &#39;ffill&#39;, &#39;bfill&#39;}
| The method to use when for replacement, when ``to_replace`` is a
| ``list``.
|
| 【参见】
| --------| NDFrame.reindex
| NDFrame.asfreq
| NDFrame.fillna
|
| 【返回值】
| -------| filled : NDFrame
|
| 【Raises 引发错误】
| ------| AssertionError
| * If</code>regex<code>is not a ``bool`` and</code>to_replace<code>is not ``None``.
| TypeError
| * If</code>to_replace<code>is a ``dict`` and</code>value<code>is not a ``list``,
| ``dict``, ``ndarray``, or ``Series``
| * If</code>to_replace<code>is ``None`` and</code>regex<code>is not compilable into a
| regular expression or is a list, dict, ndarray, or Series.
| ValueError
| * If</code>to_replace<code>and</code>value<code>are ``list`` s or ``ndarray`` s, but
| they are not the same length.
|
| 【注意】
| -----
644
| * Regex substitution is performed under the hood with ``re.sub``. The
| rules for substitution for ``re.sub`` are the same.
| * Regular expressions will only substitute on strings, meaning you
| cannot provide, for example, a regular expression matching floating
| point numbers and expect the columns in your frame that have a
| numeric dtype to be matched. However, if those floating point numbers
| *are* strings, then you can do this.
| * This method has *a lot* of options. You are encouraged to experiment
| and play with this method to gain intuition about how it works.
|
| resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention=&#39;start&#39;, kind=None,
loffset=None, limit=None, base=0)
| Convenience method for frequency conversion and resampling of regular
| time-series data.
|
| 【参数】
| ----------| rule : string
| the offset string or object representing target conversion
| how : string
| method for down- or re-sampling, default to &#39;mean&#39; for
| downsampling
| axis : int, optional, default 0
| fill_method : string, default None
| fill_method for upsampling
| closed : {&#39;right&#39;, &#39;left&#39;}
| Which side of bin interval is closed
| label : {&#39;right&#39;, &#39;left&#39;}
| Which bin edge label to label bucket with
| convention : {&#39;start&#39;, &#39;end&#39;, &#39;s&#39;, &#39;e&#39;}
| kind : &quot;period&quot;/&quot;timestamp&quot;
| loffset : timedelta
| Adjust the resampled time labels
| limit : int, default None
| Maximum size gap to when reindexing with fill_method
| base : int, default 0
| For frequencies that evenly subdivide 1 day, the &quot;origin&quot; of the
| aggregated intervals. For example, for &#39;5min&#39; frequency, base could
| range from 0 through 4. Defaults to 0
|
|
| 【示例】
| --------|
| Start by creating a series with 9 one minute timestamps.
|
| &gt;&gt;&gt; index = pd.date_range(&#39;1/1/2000&#39;, periods=9, freq=&#39;T&#39;)
| &gt;&gt;&gt; series = pd.Series(range(9), index=index)
| &gt;&gt;&gt; series
| 2000-01-01 00:00:00 0
| 2000-01-01 00:01:00 1
| 2000-01-01 00:02:00 2
| 2000-01-01 00:03:00 3
| 2000-01-01 00:04:00 4
| 2000-01-01 00:05:00 5
| 2000-01-01 00:06:00 6
| 2000-01-01 00:07:00 7
645
| 2000-01-01 00:08:00 8
| Freq: T, dtype: int64
|
| Downsample the series into 3 minute bins and sum the values
| of the timestamps falling into a bin.
|
| &gt;&gt;&gt; series.resample(&#39;3T&#39;, how=&#39;sum&#39;)
| 2000-01-01 00:00:00 3
| 2000-01-01 00:03:00 12
| 2000-01-01 00:06:00 21
| Freq: 3T, dtype: int64
|
| Downsample the series into 3 minute bins as above, but label each
| bin using the right edge instead of the left. Please note that the
| value in the bucket used as the label is not included in the bucket,
| which it labels. For example, in the original series the
| bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed
| value in the resampled bucket with the label``2000-01-01 00:03:00``
| does not include 3 (if it did, the summed value would be 6, not 3).
| To include this value close the right side of the bin interval as
| illustrated in the example below this one.
|
| &gt;&gt;&gt; series.resample(&#39;3T&#39;, how=&#39;sum&#39;, label=&#39;right&#39;)
| 2000-01-01 00:03:00 3
| 2000-01-01 00:06:00 12
| 2000-01-01 00:09:00 21
| Freq: 3T, dtype: int64
|
| Downsample the series into 3 minute bins as above, but close the right
| side of the bin interval.
|
| &gt;&gt;&gt; series.resample(&#39;3T&#39;, how=&#39;sum&#39;, label=&#39;right&#39;, closed=&#39;right&#39;)
| 2000-01-01 00:00:00 0
| 2000-01-01 00:03:00 6
| 2000-01-01 00:06:00 15
| 2000-01-01 00:09:00 15
| Freq: 3T, dtype: int64
|
| Upsample the series into 30 second bins.
|
| &gt;&gt;&gt; series.resample(&#39;30S&#39;)[0:5] #select first 5 rows
| 2000-01-01 00:00:00 0
| 2000-01-01 00:00:30 NaN
| 2000-01-01 00:01:00 1
| 2000-01-01 00:01:30 NaN
| 2000-01-01 00:02:00 2
| Freq: 30S, dtype: float64
|
| Upsample the series into 30 second bins and fill the ``NaN``
| values using the ``pad`` method.
|
| &gt;&gt;&gt; series.resample(&#39;30S&#39;, fill_method=&#39;pad&#39;)[0:5]
| 2000-01-01 00:00:00 0
| 2000-01-01 00:00:30 0
| 2000-01-01 00:01:00 1
| 2000-01-01 00:01:30 1
| 2000-01-01 00:02:00 2
646
| Freq: 30S, dtype: int64
|
| Upsample the series into 30 second bins and fill the
| ``NaN`` values using the ``bfill`` method.
|
| &gt;&gt;&gt; series.resample(&#39;30S&#39;, fill_method=&#39;bfill&#39;)[0:5]
| 2000-01-01 00:00:00 0
| 2000-01-01 00:00:30 1
| 2000-01-01 00:01:00 1
| 2000-01-01 00:01:30 2
| 2000-01-01 00:02:00 2
| Freq: 30S, dtype: int64
|
| Pass a custom function to ``how``.
|
| &gt;&gt;&gt; def custom_resampler(array_like):
| ... return np.sum(array_like)+5
|
| &gt;&gt;&gt; series.resample(&#39;3T&#39;, how=custom_resampler)
| 2000-01-01 00:00:00 8
| 2000-01-01 00:03:00 17
| 2000-01-01 00:06:00 26
| Freq: 3T, dtype: int64
|
| sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)
| Returns a random sample of items from an axis of object.
|
| .. versionadded:: 0.16.1
|
| 【参数】
| ----------| n : int, optional
| Number of items from axis to return. Cannot be used with</code>frac<code>.
| Default = 1 if</code>frac<code>= None.
| frac : float, optional
| Fraction of axis items to return. Cannot be used with</code>n<code>.
| replace : boolean, optional
| Sample with or without replacement. Default = False.
| weights : str or ndarray-like, optional
| Default &#39;None&#39; results in equal probability weighting.
| If passed a Series, will align with target object on index. Index
| values in weights not found in sampled object will be ignored and
| index values in sampled object not in weights will be assigned
| weights of zero.
| If called on a DataFrame, will accept the name of a column
| when axis = 0.
| Unless weights are a Series, weights must be same length as axis
| being sampled.
| If weights do not sum to 1, they will be normalized to sum to 1.
| Missing values in the weights column will be treated as zero.
| inf and -inf values not allowed.
| random_state : int or numpy.random.RandomState, optional
| Seed for the random number generator (if int), or numpy RandomState
| object.
| axis : int or string, optional
| Axis to sample. Accepts axis number or name. Default is stat axis
| for given data type (0 for Series and DataFrames, 1 for Panels).
647
|
| 【返回值】
| -------| A new object of same type as caller.
|
| select(self, crit, axis=0)
| Return data corresponding to axis labels matching criteria
|
| 【参数】
| ----------| crit : function
| To be called on each index (label). Should return True or False
| axis : int
|
| 【返回值】
| -------| selection : type of caller
|
| set_axis(self, axis, labels)
| public verson of axis assignment
|
| slice_shift(self, periods=1, axis=0)
| Equivalent to</code>shift<code>without copying data. The shifted data will
| not include the dropped periods and the shifted axis will be smaller
| than the original.
|
| 【参数】
| ----------| periods : int
| Number of periods to move, can be positive or negative
|
| 【注意】
| -----| While the</code>slice_shift<code>is faster than</code>shift<code>, you may pay for it
| later during alignment.
|
| 【返回值】
| -------| shifted : same type as caller
|
| sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind=&#39;quicksort&#39;, na_position=&#39;last&#39;,
sort_remaining=True)
| Sort object by labels (along an axis)
|
| 【参数】
| ----------| axis : axes to direct sorting
| level : int or level name or list of ints or list of level names
| if not None, sort on values in specified index level(s)
| ascending : boolean, default True
| Sort ascending vs. descending
| inplace : bool
| if True, perform operation in-place
| kind : {</code>quicksort<code>,</code>mergesort<code>,</code>heapsort<code>}
| Choice of sorting algorithm. 参见：ndarray.np.sort for more information.
|</code>mergesort<code>is the only stable algorithm. For DataFrames, this option is
648
| only applied when sorting on a single column or label.
| na_position : {&#39;first&#39;, &#39;last&#39;}
|</code>first<code>puts NaNs at the beginning,</code>last<code>puts NaNs at the end
| sort_remaining : bool
| if true and sorting by level and index is multilevel, sort by other levels
| too (in order) after sorting by specified level
|
| 【返回值】
| -------| sorted_obj : NDFrame
|
| sort_values(self, by, axis=0, ascending=True, inplace=False, kind=&#39;quicksort&#39;, na_position=&#39;last&#39;)
|
| squeeze(self)
| squeeze length 1 dimensions
|
| swapaxes(self, axis1, axis2, copy=True)
| Interchange axes and swap values axes appropriately
|
| 【返回值】
| -------| y : same as input
|
| swaplevel(self, i, j, axis=0)
| Swap levels i and j in a MultiIndex on a particular axis
|
| 【参数】
| ----------| i, j : int, string (can be mixed)
| Level of index to be swapped. Can pass level name as string.
|
| 【返回值】
| -------| swapped : type of caller (new object)
|
| take(self, indices, axis=0, convert=True, is_copy=True)
| Analogous to ndarray.take
|
| 【参数】
| ----------| indices : list / array of ints
| axis : int, default 0
| convert : translate neg to pos indices (default)
| is_copy : mark the returned frame as a copy
|
| 【返回值】
| -------| taken : type of caller
|
| to_clipboard(self, excel=None, sep=None, **kwargs)
| Attempt to write text representation of object to the system clipboard
| This can be pasted into Excel, for example.
|
| 【参数】
| ----------| excel : boolean, defaults to True
| if True, use the provided separator, writing in a csv
649
| format for allowing easy pasting into excel.
| if False, write a string representation of the object
| to the clipboard
| sep : optional, defaults to tab
| other keywords are passed to to_csv
|
| 【注意】
| -----| Requirements for your platform
| - Linux: xclip, or xsel (with gtk or PyQt4 modules)
| - Windows: none
| - OS X: none
|
| to_hdf(self, path_or_buf, key, **kwargs)
| activate the HDFStore
|
| 【参数】
| ----------| path_or_buf : the path (string) or HDFStore object
| key : string
| indentifier for the group in the store
| mode : optional, {&#39;a&#39;, &#39;w&#39;, &#39;r&#39;, &#39;r+&#39;}, default &#39;a&#39;
|
| ``&#39;r&#39;``
| Read-only; no data can be modified.
| ``&#39;w&#39;``
| Write; a new file is created (an existing file with the same
| name would be deleted).
| ``&#39;a&#39;``
| Append; an existing file is opened for reading and writing,
| and if the file does not exist it is created.
| ``&#39;r+&#39;``
| It is similar to ``&#39;a&#39;``, but the file must already exist.
| format : &#39;fixed(f)|table(t)&#39;, default is &#39;fixed&#39;
| fixed(f) : Fixed format
| Fast writing/reading. Not-appendable, nor searchable
| table(t) : Table format
| Write as a PyTables Table structure which may perform
| worse but allow more flexible operations like searching
| / selecting subsets of the data
| append : boolean, default False
| For Table formats, append the input data to the existing
| complevel : int, 1-9, default 0
| If a complib is specified compression will be applied
| where possible
| complib : {&#39;zlib&#39;, &#39;bzip2&#39;, &#39;lzo&#39;, &#39;blosc&#39;, None}, default None
| If complevel is &gt; 0 apply compression to objects written
| in the store wherever possible
| fletcher32 : bool, default False
| If applying compression use the fletcher32 checksum
| dropna : boolean, default False.
| If true, ALL nan rows will not be written to store.
|
| to_json(self, path_or_buf=None, orient=None, date_format=&#39;epoch&#39;, double_precision=10, force_ascii=True, date_unit=&#39;ms&#39;,
default_handler=None)
| Convert the object to a JSON string.
|
650
| Note NaN&#39;s and None will be converted to null and datetime objects
| will be converted to UNIX timestamps.
|
| 【参数】
| ----------| path_or_buf : the path or buffer to write the result string
| if this is None, return a StringIO of the converted string
| orient : string
|
| * Series
|
| - default is &#39;index&#39;
| - allowed values are: {&#39;split&#39;,&#39;records&#39;,&#39;index&#39;}
|
| * DataFrame
|
| - default is &#39;columns&#39;
| - allowed values are:
| {&#39;split&#39;,&#39;records&#39;,&#39;index&#39;,&#39;columns&#39;,&#39;values&#39;}
|
| * The format of the JSON string
|
| - split : dict like
| {index -&gt; [index], columns -&gt; [columns], data -&gt; [values]}
| - records : list like
| [{column -&gt; value}, ... , {column -&gt; value}]
| - index : dict like {index -&gt; {column -&gt; value}}
| - columns : dict like {column -&gt; {index -&gt; value}}
| - values : just the values array
|
| date_format : {&#39;epoch&#39;, &#39;iso&#39;}
| Type of date conversion.</code>epoch<code>= epoch milliseconds,
|</code>iso<code>= ISO8601, default is epoch.
| double_precision : The number of decimal places to use when encoding
| floating point values, default 10.
| force_ascii : force encoded string to be ASCII, default True.
| date_unit : string, default &#39;ms&#39; (milliseconds)
| The time unit to encode to, governs timestamp and ISO8601
| precision. One of &#39;s&#39;, &#39;ms&#39;, &#39;us&#39;, &#39;ns&#39; for second, millisecond,
| microsecond, and nanosecond respectively.
| default_handler : callable, default None
| Handler to call if object cannot otherwise be converted to a
| suitable format for JSON. Should receive a single argument which is
| the object to convert and return a serialisable object.
|
| 【返回值】
| -------| same type as input object with filtered info axis
|
| to_msgpack(self, path_or_buf=None, **kwargs)
| msgpack (serialize) object to input file path
|
| THIS IS AN EXPERIMENTAL LIBRARY and the storage format
| may not be stable until a future release.
|
| 【参数】
| ----------
651
| path : string File path, buffer-like, or None
| if None, return generated string
| append : boolean whether to append to an existing msgpack
| (default is False)
| compress : type of compressor (zlib or blosc), default to None (no
| compression)
|
| to_pickle(self, path)
| Pickle (serialize) object to input file path
|
| 【参数】
| ----------| path : string
| File path
|
| to_sql(self, name, con, flavor=&#39;sqlite&#39;, schema=None, if_exists=&#39;fail&#39;, index=True, index_label=None, chunksize=None,
dtype=None)
| Write records stored in a DataFrame to a SQL database.
|
| 【参数】
| ----------| name : string
| Name of SQL table
| con : SQLAlchemy engine or DBAPI2 connection (legacy mode)
| Using SQLAlchemy makes it possible to use any DB supported by that
| library.
| If a DBAPI2 object, only sqlite3 is supported.
| flavor : {&#39;sqlite&#39;, &#39;mysql&#39;}, default &#39;sqlite&#39;
| The flavor of SQL to use. Ignored when using SQLAlchemy engine.
| &#39;mysql&#39; is deprecated and will be removed in future versions, but it
| will be further supported through SQLAlchemy engines.
| schema : string, default None
| Specify the schema (if database flavor supports this). If None, use
| default schema.
| if_exists : {&#39;fail&#39;, &#39;replace&#39;, &#39;append&#39;}, default &#39;fail&#39;
| - fail: If table exists, do nothing.
| - replace: If table exists, drop it, recreate it, and insert data.
| - append: If table exists, insert data. Create if does not exist.
| index : boolean, default True
| Write DataFrame index as a column.
| index_label : string or sequence, default None
| Column label for index column(s). If None is given (default) and
| `index` is True, then the index names are used.
| A sequence should be given if the DataFrame uses MultiIndex.
| chunksize : int, default None
| If not None, then rows will be written in batches of this size at a
| time. If None, all rows will be written at once.
| dtype : dict of column name to SQL type, default None
| Optional specifying the datatype for columns. The SQL type should
| be a SQLAlchemy type, or a string for sqlite3 fallback connection.
|
| truncate(self, before=None, after=None, axis=None, copy=True)
| Truncates a sorted NDFrame before and/or after some particular
| dates.
|
| 【参数】
| ----------
652
| before : date
| Truncate before date
| after : date
| Truncate after date
| axis : the truncation axis, defaults to the stat axis
| copy : boolean, default is True,
| return a copy of the truncated section
|
| 【返回值】
| -------| truncated : type of caller
|
| tz_convert(self, tz, axis=0, level=None, copy=True)
| Convert tz-aware axis to target time zone.
|
| 【参数】
| ----------| tz : string or pytz.timezone object
| axis : the axis to convert
| level : int, str, default None
| If axis ia a MultiIndex, convert a specific level. Otherwise
| must be None
| copy : boolean, default True
| Also make a copy of the underlying data
|
| 【返回值】
| -------|
| 【Raises 引发错误】
| ------| TypeError
| If the axis is tz-naive.
|
| tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous=&#39;raise&#39;)
| Localize tz-naive TimeSeries to target time zone
|
| 【参数】
| ----------| tz : string or pytz.timezone object
| axis : the axis to localize
| level : int, str, default None
| If axis ia a MultiIndex, localize a specific level. Otherwise
| must be None
| copy : boolean, default True
| Also make a copy of the underlying data
| ambiguous : &#39;infer&#39;, bool-ndarray, &#39;NaT&#39;, default &#39;raise&#39;
| - &#39;infer&#39; will attempt to infer fall dst-transition hours based on order
| - bool-ndarray where True signifies a DST time, False designates
| a non-DST time (note that this flag is only applicable for ambiguous times)
| - &#39;NaT&#39; will return NaT where there are ambiguous times
| - &#39;raise&#39; will raise an AmbiguousTimeError if there are ambiguous times
| infer_dst : boolean, default False (DEPRECATED)
| Attempt to infer fall dst-transition hours based on order
|
| 【返回值】
| -------|
653
| 【Raises 引发错误】
| ------| TypeError
| If the TimeSeries is tz-aware and tz is not None.
|
| where(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)
| Return an object of same shape as self and whose corresponding
| entries are from self where cond is True and otherwise are from other.
|
| 【参数】
| ----------| cond : boolean NDFrame or array
| other : scalar or NDFrame
| inplace : boolean, default False
| Whether to perform the operation in place on the data
| axis : alignment axis if needed, default None
| level : alignment level if needed, default None
| try_cast : boolean, default False
| try to cast the result back to the input type (if possible),
| raise_on_error : boolean, default True
| Whether to raise on invalid data types (e.g. trying to where on
| strings)
|
| 【返回值】
| -------| wh : same type as caller
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.generic.NDFrame:
|
| at
| Fast label-based scalar accessor
|
| Similarly to</code>loc<code>,</code>at<code>provides **label** based scalar lookups.
| You can also set using these indexers.
|
| axes
| Return index label(s) of the internal NDFrame
|
| blocks
| Internal property, property synonym for as_blocks()
|
| dtypes
| Return the dtypes in this object
|
| empty
| True if NDFrame is entirely empty [no items]
|
| ftypes
| Return the ftypes (indication of sparse/dense and dtype)
| in this object.
|
| iat
| Fast integer location scalar accessor.
|
| Similarly to</code>iloc<code>,</code>iat<code>provides **integer** based lookups.
| You can also set using these indexers.
654
|
| iloc
| Purely integer-location based indexing for selection by position.
|
|</code>.iloc[]<code>is primarily integer position based (from</code>0<code>to
|</code>length-1<code>of the axis), but may also be used with a boolean
| array.
|
| Allowed inputs are:
|
| - An integer, e.g.</code>5<code>.
| - A list or array of integers, e.g.</code>[4, 3, 0]<code>.
| - A slice object with ints, e.g.</code>1:7<code>.
| - A boolean array.
|
|</code>.iloc<code>will raise</code>IndexError<code>if a requested indexer is
| out-of-bounds, except *slice* indexers which allow out-of-bounds
| indexing (this conforms with python/numpy *slice* semantics).
|
| See more at :ref:`Selection by Position &lt;indexing.integer&gt;`
|
| ix
| A primarily label-location based indexer, with integer position
| fallback.
|
|</code>.ix[]<code>supports mixed integer and label based access. It is
| primarily label based, but will fall back to integer positional
| access unless the corresponding axis is of integer type.
|
|</code>.ix<code>is the most general indexer and will support any of the
| inputs in</code>.loc<code>and</code>.iloc<code>.</code>.ix<code>also supports floating
| point label schemes.</code>.ix<code>is exceptionally useful when dealing
| with mixed positional and label based hierachical indexes.
|
| However, when an axis is integer based, ONLY label based access
| and not positional access is supported. Thus, in such cases, it&#39;s
| usually better to be explicit and use</code>.iloc<code>or</code>.loc<code>.
|
| See more at :ref:`Advanced Indexing &lt;advanced&gt;`.
|
| loc
| Purely label-location based indexer for selection by label.
|
|</code>.loc[]<code>is primarily label based, but may also be used with a
| boolean array.
|
| Allowed inputs are:
|
| - A single label, e.g.</code>5<code>or</code>‘a’<code>, (note that</code>5<code>is
| interpreted as a *label* of the index, and **never** as an
| integer position along the index).
| - A list or array of labels, e.g.</code>[‘a’, ‘b’, ‘c’]<code>.
| - A slice object with labels, e.g.</code>‘a’:’f’<code>(note that contrary
| to usual python slices, **both** the start and the stop are included!).
| - A boolean array.
|
|</code>.loc<code>will raise a</code>KeyError<code>when the items are not found.
655
|
| See more at :ref:`Selection by Label &lt;indexing.label&gt;`
|
| shape
| Return a tuple of axis dimensions
|
| size
| number of elements in the NDFrame
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.generic.NDFrame:
|
| is_copy = None
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.PandasObject:
|
| __dir__(self)
| Provide method name lookup and completion
| Only provide &#39;public&#39; methods
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
| Return a string representation for a particular object.
|
| Invoked by bytes(obj) in py3 only.
| Yields a bytestring in both py2/py3.
|
| __repr__(self)
| Return a string representation for a particular object.
|
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.base.StringMixin:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
SparseSeries
656
SparseSeries 模块所属：pandas.sparse.series:
类定义：SparseSeries(pandas.core.series.Series)
| Data structure for labeled, sparse floating point data
|
| 【参数】
| ----------| data : {array-like, Series, SparseSeries, dict}
| kind : {&#39;block&#39;, &#39;integer&#39;}
| fill_value : float
| Defaults to NaN (code for missing)
| sparse_index : {BlockIndex, IntIndex}, optional
| Only if you have one. Mainly used internally
|
|【注意】
| -----| SparseSeries objects are immutable via the typical Python means. If you
| must change values, convert to dense, make your changes, then convert back
| to sparse
|
| 【方法排序】
| SparseSeries
| pandas.core.series.Series
| pandas.core.base.IndexOpsMixin
| pandas.core.strings.StringAccessorMixin
| pandas.core.generic.NDFrame
| pandas.core.base.PandasObject
| pandas.core.base.StringMixin
| 【内置对象】
|
| 【方法定义】
|
| __add__(self, other)
|
| __and__ = wrapper(self, other)
|
| __array__(self, result=None)
| the array interface, return my values
|
| __array_finalize__(self, obj)
| Gets called after any ufunc or other array operations, necessary
| to pass on the index.
|
| __array_wrap__(self, result)
| Gets called prior to a ufunc (and after)
|
| __div__ = __truediv__(self, other)
|
| __eq__ = wrapper(self, other, axis=None)
|
| __floordiv__(self, other)
|
| __ge__ = wrapper(self, other, axis=None)
|
| __getitem__(self, key)
|
657
| __getstate__(self)
|
| __gt__ = wrapper(self, other, axis=None)
|
| __iadd__ = f(self, other)
|
| __imul__ = f(self, other)
|
| __init__(self, data=None, index=None, sparse_index=None, kind=&#39;block&#39;, fill_value=None, name=None, dtype=None,
copy=False, fastpath=False)
| Initialize self. See help(type(self)) for accurate signature.
|
| __ipow__ = f(self, other)
|
| __isub__ = f(self, other)
|
| __iter__(self)
| forward to the array
|
| __itruediv__ = f(self, other)
|
| __le__ = wrapper(self, other, axis=None)
|
| __len__(self)
| return the length of the Series
|
| __lt__ = wrapper(self, other, axis=None)
|
| __mod__(self, other)
|
| __mul__(self, other)
|
| __ne__ = wrapper(self, other, axis=None)
|
| __or__ = wrapper(self, other)
|
| __pow__(self, other)
|
| __radd__(self, other)
|
| __rand__ = wrapper(self, other)
|
| __rdiv__ = __rtruediv__(self, other)
|
| __rfloordiv__(self, other)
|
| __rmod__(self, other)
|
| __rmul__(self, other)
|
| __ror__ = wrapper(self, other)
|
| __rpow__(self, other)
|
| __rsub__(self, other)
|
| __rtruediv__(self, other)
658
|
| __rxor__ = wrapper(self, other)
|
| __sub__(self, other)
|
| __truediv__(self, other)
|
| __unicode__(self)
| Return a string representation for a particular DataFrame
|
| Invoked by unicode(df) in py2 only. Yields a Unicode String in both
| py2/py3.
|
| __xor__ = wrapper(self, other)
|
| abs(self)
| Return an object with absolute value taken. Only applicable to objects
| that are all numeric
|
| 【返回值】
| -------| abs: type of caller
|
| add(self, other, level=None, fill_value=None, axis=0)
| Addition of series and other, element-wise (binary operator `add`).
|
| Equivalent to</code>series + other<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.radd
|
| as_sparse_array(self, kind=None, fill_value=None, copy=False)
| return my self as a sparse array, do not copy by default
|
| combine_first(self, other)
| Combine Series values, choosing the calling Series&#39;s values
| first. Result index will be the union of the two indexes
|
| 【参数】
| ----------| other : Series
659
|
| 【返回值】
| -------| y : Series
|
| copy(self, deep=True)
| Make a copy of the SparseSeries. Only the actual sparse values need to
| be copied
|
| cumsum(self, axis=0, dtype=None, out=None)
| Cumulative sum of values. Preserves locations of NaN values
|
| 【返回值】
| -------| cumsum : Series or SparseSeries
|
| div = truediv(self, other, level=None, fill_value=None, axis=0)
|
| divide = truediv(self, other, level=None, fill_value=None, axis=0)
|
| dropna(self, axis=0, inplace=False, **kwargs)
| Analogous to Series.dropna. If fill_value=NaN, returns a dense Series
|
| eq = wrapper(self, other, axis=None)
|
| floordiv(self, other, level=None, fill_value=None, axis=0)
| Integer division of series and other, element-wise (binary operator `floordiv`).
|
| Equivalent to</code>series // other<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rfloordiv
|
| ge = wrapper(self, other, axis=None)
|
| get(self, label, default=None)
| Returns value occupying requested label, default to specified
| missing value if not present. Analogous to dict.get
|
| 【参数】
| ----------
660
| label : object
| Label value looking for
| default : object, optional
| Value to return if label not in index
|
| 【返回值】
| -------| y : scalar
|
| get_value(self, label, takeable=False)
| Retrieve single value at passed index label
|
| 【参数】
| ----------| index : label
| takeable : interpret the index as indexers, default False
|
| 【返回值】
| -------| value : scalar value
|
| get_values(self)
| same as values
|
| gt = wrapper(self, other, axis=None)
|
| le = wrapper(self, other, axis=None)
|
| lt = wrapper(self, other, axis=None)
|
| mod(self, other, level=None, fill_value=None, axis=0)
| Modulo of series and other, element-wise (binary operator `mod`).
|
| Equivalent to</code>series % other<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rmod
|
| mul(self, other, level=None, fill_value=None, axis=0)
| Multiplication of series and other, element-wise (binary operator `mul`).
|
661
| Equivalent to</code>series <em> other<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rmul
|
| multiply = mul(self, other, level=None, fill_value=None, axis=0)
|
| ne = wrapper(self, other, axis=None)
|
| pow(self, other, level=None, fill_value=None, axis=0)
| Exponential power of series and other, element-wise (binary operator `pow`).
|
| Equivalent to</code>series ** other<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rpow
|
| radd(self, other, level=None, fill_value=None, axis=0)
| Addition of series and other, element-wise (binary operator `radd`).
|
| Equivalent to</code>other + series<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------
662
| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.add
|
| rdiv = rtruediv(self, other, level=None, fill_value=None, axis=0)
|
| reindex(self, index=None, method=None, copy=True, limit=None)
| Conform SparseSeries to new Index
|
| See Series.reindex docstring for general behavior
|
| 【返回值】
| -------| reindexed : SparseSeries
|
| rfloordiv(self, other, level=None, fill_value=None, axis=0)
| Integer division of series and other, element-wise (binary operator `rfloordiv`).
|
| Equivalent to</code>other // series<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.floordiv
|
| rmod(self, other, level=None, fill_value=None, axis=0)
| Modulo of series and other, element-wise (binary operator `rmod`).
|
| Equivalent to</code>other % series<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
663
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.mod
|
| rmul(self, other, level=None, fill_value=None, axis=0)
| Multiplication of series and other, element-wise (binary operator `rmul`).
|
| Equivalent to</code>other </em> series<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.mul
|
| rpow(self, other, level=None, fill_value=None, axis=0)
| Exponential power of series and other, element-wise (binary operator `rpow`).
|
| Equivalent to</code>other <strong> series<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
664
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.pow
|
| rsub(self, other, level=None, fill_value=None, axis=0)
| Subtraction of series and other, element-wise (binary operator `rsub`).
|
| Equivalent to</code>other - series<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.sub
|
| rtruediv(self, other, level=None, fill_value=None, axis=0)
| Floating division of series and other, element-wise (binary operator `rtruediv`).
|
| Equivalent to</code>other / series<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.truediv
665
|
| set_value(self, label, value, takeable=False)
| Quickly set single value at passed label. If label is not contained, a
| new object is created with the label placed at the end of the result
| index
|
| 【参数】
| ----------| label : object
| Partial indexing with MultiIndex not allowed
| value : object
| Scalar value
| takeable : interpret the index as indexers, default False
|
| 【注意】
| -----| This method *always* returns a new object. It is not particularly
| efficient but is provided for API compatibility with Series
|
| 【返回值】
| -------| series : SparseSeries
|
| shift(self, periods, freq=None)
| Analogous to Series.shift
|
| sparse_reindex(self, new_index)
| Conform sparse values to new SparseIndex
|
| 【参数】
| ----------| new_index : {BlockIndex, IntIndex}
|
| 【返回值】
| -------| reindexed : SparseSeries
|
| sub(self, other, level=None, fill_value=None, axis=0)
| Subtraction of series and other, element-wise (binary operator `sub`).
|
| Equivalent to</code>series - other<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
666
| 【参见】
| --------| Series.rsub
|
| subtract = sub(self, other, level=None, fill_value=None, axis=0)
|
| take(self, indices, axis=0, convert=True)
| Sparse-compatible version of ndarray.take
|
| 【返回值】
| -------| taken : ndarray
|
| to_coo(self, row_levels=(0,), column_levels=(1,), sort_labels=False)
| Create a scipy.sparse.coo_matrix from a SparseSeries with MultiIndex.
|
| Use row_levels and column_levels to determine the row and column coordinates respectively.
| row_levels and column_levels are the names (labels) or numbers of the levels.
| {row_levels, column_levels} must be a partition of the MultiIndex level names (or numbers).
|
| .. versionadded:: 0.16.0
|
| 【参数】
| ----------| row_levels : tuple/list
| column_levels : tuple/list
| sort_labels : bool, default False
| Sort the row and column labels before forming the sparse matrix.
|
| 【返回值】
| -------| y : scipy.sparse.coo_matrix
| rows : list (row labels)
| columns : list (column labels)
|
| 【示例】
| --------| &gt;&gt;&gt; from numpy import nan
| &gt;&gt;&gt; s = Series([3.0, nan, 1.0, 3.0, nan, nan])
| &gt;&gt;&gt; s.index = MultiIndex.from_tuples([(1, 2, &#39;a&#39;, 0),
| (1, 2, &#39;a&#39;, 1),
| (1, 1, &#39;b&#39;, 0),
| (1, 1, &#39;b&#39;, 1),
| (2, 1, &#39;b&#39;, 0),
| (2, 1, &#39;b&#39;, 1)],
| names=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;])
| &gt;&gt;&gt; ss = s.to_sparse()
| &gt;&gt;&gt; A, rows, columns = ss.to_coo(row_levels=[&#39;A&#39;, &#39;B&#39;],
| column_levels=[&#39;C&#39;, &#39;D&#39;],
| sort_labels=True)
| &gt;&gt;&gt; A
| &lt;3x4 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;
| with 3 stored elements in COOrdinate format&gt;
| &gt;&gt;&gt; A.todense()
| matrix([[ 0., 0., 1., 3.],
| [ 3., 0., 0., 0.],
| [ 0., 0., 0., 0.]])
667
| &gt;&gt;&gt; rows
| [(1, 1), (1, 2), (2, 1)]
| &gt;&gt;&gt; columns
| [(&#39;a&#39;, 0), (&#39;a&#39;, 1), (&#39;b&#39;, 0), (&#39;b&#39;, 1)]
|
| to_dense(self, sparse_only=False)
| Convert SparseSeries to (dense) Series
|
| truediv(self, other, level=None, fill_value=None, axis=0)
| Floating division of series and other, element-wise (binary operator `truediv`).
|
| Equivalent to</code>series / other``, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other: Series or scalar value<br>| fill_value : None or float value, default None (NaN)<br>| Fill missing (NaN) values with this value. If both Series are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【返回值】<br>| ——-| result : Series<br>|<br>| 【参见】<br>| ——–| Series.rtruediv<br>|<br>| ———————————————————————-| Class methods defined here:<br>|<br>| from_array(arr, index=None, name=None, copy=False, fill_value=None, fastpath=False) from builtins.type<br>| Simplified alternate constructor<br>|<br>| from_coo(A, dense_index=False) from builtins.type<br>| Create a SparseSeries from a scipy.sparse.coo_matrix.<br>|<br>| .. versionadded:: 0.16.0<br>|<br>| 【参数】<br>| ———-| A : scipy.sparse.coo_matrix<br>| dense_index : bool, default False<br>| If False (default), the SparseSeries index consists of only the coords of the non-null entries of the original<br>coo_matrix.<br>| If True, the SparseSeries index consists of the full sorted (row, col) coordinates of the coo_matrix.<br>|<br>| 【返回值】<br>| ——-| s : SparseSeries<br>|<br>| 【示例】<br>| ———<br>668<br>| &gt;&gt;&gt; from scipy import sparse<br>| &gt;&gt;&gt; A = sparse.coo_matrix(([3.0, 1.0, 2.0], ([1, 0, 0], [0, 2, 3])),<br>| shape=(3, 4))<br>| &gt;&gt;&gt; A<br>| <3x4 sparse="" matrix="" of="" type="" '<class="" 'numpy.float64'="">'
| with 3 stored elements in COOrdinate format><br>| &gt;&gt;&gt; A.todense()<br>| matrix([[ 0., 0., 1., 2.],<br>| [ 3., 0., 0., 0.],<br>| [ 0., 0., 0., 0.]])<br>| &gt;&gt;&gt; ss = SparseSeries.from_coo(A)<br>| &gt;&gt;&gt; ss<br>| 0 2 1<br>| 3 2<br>| 1 0 3<br>| dtype: float64<br>| BlockIndex<br>| Block locations: array([0], dtype=int32)<br>| Block lengths: array([3], dtype=int32)<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| block<br>|<br>| density<br>|<br>| fill_value<br>|<br>| kind<br>|<br>| npoints<br>|<br>| sp_index<br>|<br>| sp_values<br>|<br>| values<br>| return the array<br>|<br>| ———————————————————————-| Methods inherited from pandas.core.series.Series:<br>|<br>| <strong>array_prepare</strong>(self, result, context=None)<br>| Gets called prior to a ufunc<br>|<br>| <strong>float</strong> = wrapper(self)<br>|<br>| <strong>int</strong> = wrapper(self)<br>|<br>| <strong>long</strong> = wrapper(self)<br>|<br>| <strong>setitem</strong>(self, key, value)<br>|<br>| align(self, other, join=’outer’, axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0,<br>broadcast_axis=None)<br>| Align two object on their axes with the<br>669<br>| specified join method for each axis Index<br>|<br>| 【参数】<br>| ———-| other : DataFrame or Series<br>| join : {‘outer’, ‘inner’, ‘left’, ‘right’}, default ‘outer’<br>| axis : allowed axis of the other object, default None<br>| Align on index (0), columns (1), or both (None)<br>| level : int or level name, default None<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>| copy : boolean, default True<br>| Always returns new objects. If copy=False and no reindexing is<br>| required then original objects are returned.<br>| fill_value : scalar, default np.NaN<br>| Value to use for missing values. Defaults to NaN, but can be any<br>| “compatible” value<br>| method : str, default None<br>| limit : int, default None<br>| fill_axis : {0, ‘index’}, default 0<br>| Filling axis, method and limit<br>| broadcast_axis : {0, ‘index’}, default None<br>| Broadcast values along this axis, if aligning two objects of<br>| different dimensions<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【返回值】<br>| ——-| (left, right) : (Series, type of other)<br>| Aligned objects<br>|<br>| all(self, axis=None, bool_only=None, skipna=None, level=None, </3x4></strong>kwargs)<br>| Return whether all elements are True over requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| bool_only : boolean, default None<br>| Include only boolean data. If None, will attempt to use everything,<br>| then use only boolean data<br>|<br>| 【返回值】<br>| ——-| all : scalar or Series (if level specified)<br>|<br>| any(self, axis=None, bool_only=None, skipna=None, level=None, <strong>kwargs)<br>| Return whether any element is True over requested axis<br>|<br>| 【参数】<br>| ———-<br>670<br>| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| bool_only : boolean, default None<br>| Include only boolean data. If None, will attempt to use everything,<br>| then use only boolean data<br>|<br>| 【返回值】<br>| ——-| any : scalar or Series (if level specified)<br>|<br>| append(self, to_append, verify_integrity=False)<br>| Concatenate two or more Series.<br>|<br>| 【参数】<br>| ———-| to_append : Series or list/tuple of Series<br>| verify_integrity : boolean, default False<br>| If True, raise Exception on creating index with duplicates<br>|<br>| 【返回值】<br>| ——-| appended : Series<br>|<br>| apply(self, func, convert_dtype=True, args=(), </strong>kwds)<br>| Invoke function on values of Series. Can be ufunc (a NumPy function<br>| that applies to the entire Series) or a Python function that only works<br>| on single values<br>|<br>| 【参数】<br>| ———-| func : function<br>| convert_dtype : boolean, default True<br>| Try to find better dtype for elementwise function results. If<br>| False, leave as dtype=object<br>| args : tuple<br>| Positional arguments to pass to function in addition to the value<br>| Additional keyword arguments will be passed as keywords to the function<br>|<br>| 【返回值】<br>| ——-| y : Series or DataFrame if func returns a Series<br>|<br>| 【参见】<br>| ——–| Series.map: For element-wise operations<br>|<br>| 【示例】<br>| ——–|<br>| Create a series with typical summer temperatures for each city.<br>|<br>| &gt;&gt;&gt; import pandas as pd<br>671<br>| &gt;&gt;&gt; import numpy as np<br>| &gt;&gt;&gt; series = pd.Series([20, 21, 12], index=[‘London’,<br>| … ‘New York’,’Helsinki’])<br>| London 20<br>| New York 21<br>| Helsinki 12<br>| dtype: int64<br>|<br>| Square the values by defining a function and passing it as an<br>| argument to <code>apply()</code>.<br>|<br>| &gt;&gt;&gt; def square(x):<br>| … return x<strong>2<br>| &gt;&gt;&gt; series.apply(square)<br>| London 400<br>| New York 441<br>| Helsinki 144<br>| dtype: int64<br>|<br>| Square the values by passing an anonymous function as an<br>| argument to <code>apply()</code>.<br>|<br>| &gt;&gt;&gt; series.apply(lambda x: x</strong>2)<br>| London 400<br>| New York 441<br>| Helsinki 144<br>| dtype: int64<br>|<br>| Define a custom function that needs additional positional<br>| arguments and pass these additional arguments using the<br>| <code>args</code> keyword.<br>|<br>| &gt;&gt;&gt; def subtract_custom_value(x, custom_value):<br>| … return x-custom_value<br>|<br>| &gt;&gt;&gt; series.apply(subtract_custom_value, args=(5,))<br>| London 15<br>| New York 16<br>| Helsinki 7<br>| dtype: int64<br>|<br>| Define a custom function that takes keyword arguments<br>| and pass these arguments to <code>apply</code>.<br>|<br>| &gt;&gt;&gt; def add_custom_values(x, <strong>kwargs):<br>| … for month in kwargs:<br>| … x+=kwargs[month]<br>| … return x<br>|<br>| &gt;&gt;&gt; series.apply(add_custom_values, june=30, july=20, august=25)<br>| London 95<br>| New York 96<br>| Helsinki 87<br>| dtype: int64<br>|<br>| Use a function from the Numpy library.<br>|<br>672<br>| &gt;&gt;&gt; series.apply(np.log)<br>| London 2.995732<br>| New York 3.044522<br>| Helsinki 2.484907<br>| dtype: float64<br>|<br>| argmax = idxmax(self, axis=None, out=None, skipna=True)<br>| Index of first occurrence of maximum of values.<br>|<br>| 【参数】<br>| ———-| skipna : boolean, default True<br>| Exclude NA/null values<br>|<br>| 【返回值】<br>| ——-| idxmax : Index of maximum of values<br>|<br>| 【注意】<br>| —–| This method is the Series version of <code>ndarray.argmax</code>.<br>|<br>| 【参见】<br>| ——–| DataFrame.idxmax<br>| numpy.ndarray.argmax<br>|<br>| argmin = idxmin(self, axis=None, out=None, skipna=True)<br>| Index of first occurrence of minimum of values.<br>|<br>| 【参数】<br>| ———-| skipna : boolean, default True<br>| Exclude NA/null values<br>|<br>| 【返回值】<br>| ——-| idxmin : Index of minimum of values<br>|<br>| 【注意】<br>| —–| This method is the Series version of <code>ndarray.argmin</code>.<br>|<br>| 【参见】<br>| ——–| DataFrame.idxmin<br>| numpy.ndarray.argmin<br>|<br>| argsort(self, axis=0, kind=’quicksort’, order=None)<br>| Overrides ndarray.argsort. Argsorts the value, omitting NA/null values,<br>| and places the result in the same locations as the non-NA values<br>|<br>| 【参数】<br>| ———-| axis : int (can only be zero)<br>| kind : {‘mergesort’, ‘quicksort’, ‘heapsort’}, default ‘quicksort’<br>673<br>| Choice of sorting algorithm. See np.sort for more<br>| information. ‘mergesort’ is the only stable algorithm<br>| order : ignored<br>|<br>| 【返回值】<br>| ——-| argsorted : Series, with -1 indicated where nan values are present<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.argsort<br>|<br>| asof(self, where)<br>| Return last good (non-NaN) value in Series if value is NaN for<br>| requested date.<br>|<br>| If there is no good value, NaN is returned.<br>|<br>| 【参数】<br>| ———-| where : date or array of dates<br>|<br>| 【注意】<br>| —–| Dates are assumed to be sorted<br>|<br>| 【返回值】<br>| ——-| value or NaN<br>|<br>| autocorr(self, lag=1)<br>| Lag-N autocorrelation<br>|<br>| 【参数】<br>| ———-| lag : int, default 1<br>| Number of lags to apply before performing autocorrelation.<br>|<br>| 【返回值】<br>| ——-| autocorr : float<br>|<br>| between(self, left, right, inclusive=True)<br>| Return boolean Series equivalent to left &lt;= series &lt;= right. NA values<br>| will be treated as False<br>|<br>| 【参数】<br>| ———-| left : scalar<br>| Left boundary<br>| right : scalar<br>| Right boundary<br>|<br>| 【返回值】<br>| ——-| is_between : Series<br>674<br>|<br>| combine(self, other, func, fill_value=nan)<br>| Perform elementwise binary operation on two Series using given function<br>| with optional fill value when an index is missing from one Series or<br>| the other<br>|<br>| 【参数】<br>| ———-| other : Series or scalar value<br>| func : function<br>| fill_value : scalar value<br>|<br>| 【返回值】<br>| ——-| result : Series<br>|<br>| compound(self, axis=None, skipna=None, level=None)<br>| Return the compound percentage of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| compounded : scalar or Series (if level specified)<br>|<br>| compress(self, condition, axis=0, out=None, </strong>kwargs)<br>| Return selected slices of an array along given axis as a Series<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.compress<br>|<br>| corr(self, other, method=’pearson’, min_periods=None)<br>| Compute correlation with <code>other</code> Series, excluding missing values<br>|<br>| 【参数】<br>| ———-| other : Series<br>| method : {‘pearson’, ‘kendall’, ‘spearman’}<br>| <em> pearson : standard correlation coefficient<br>| </em> kendall : Kendall Tau correlation coefficient<br>| <em> spearman : Spearman rank correlation<br>| min_periods : int, optional<br>| Minimum number of observations needed to have a valid result<br>|<br>|<br>675<br>| 【返回值】<br>| ——-| correlation : float<br>|<br>| count(self, level=None)<br>| Return number of non-NA/null observations in the Series<br>|<br>| 【参数】<br>| ———-| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a smaller Series<br>|<br>| 【返回值】<br>| ——-| nobs : int or Series (if level specified)<br>|<br>| cov(self, other, min_periods=None)<br>| Compute covariance with Series, excluding missing values<br>|<br>| 【参数】<br>| ———-| other : Series<br>| min_periods : int, optional<br>| Minimum number of observations needed to have a valid result<br>|<br>| 【返回值】<br>| ——-| covariance : float<br>|<br>| Normalized by N-1 (unbiased estimator).<br>|<br>| cummax = max(self, axis=None, dtype=None, out=None, skipna=True, <strong>kwargs)<br>| Return cumulative max over requested axis.<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>|<br>| 【返回值】<br>| ——-| max : scalar<br>|<br>| cummin = min(self, axis=None, dtype=None, out=None, skipna=True, </strong>kwargs)<br>| Return cumulative min over requested axis.<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>|<br>676<br>| 【返回值】<br>| ——-| min : scalar<br>|<br>| cumprod = prod(self, axis=None, dtype=None, out=None, skipna=True, <strong>kwargs)<br>| Return cumulative prod over requested axis.<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>|<br>| 【返回值】<br>| ——-| prod : scalar<br>|<br>| diff(self, periods=1)<br>| 1st discrete difference of object<br>|<br>| 【参数】<br>| ———-| periods : int, default 1<br>| Periods to shift for forming difference<br>|<br>| 【返回值】<br>| ——-| diffed : Series<br>|<br>| dot(self, other)<br>| Matrix multiplication with DataFrame or inner-product with Series<br>| objects<br>|<br>| 【参数】<br>| ———-| other : Series or DataFrame<br>|<br>| 【返回值】<br>| ——-| dot_product : scalar or Series<br>|<br>| drop_duplicates(self, keep=’first’, inplace=False)<br>| Return Series with duplicate values removed<br>|<br>| 【参数】<br>| ———-|<br>| keep : {‘first’, ‘last’, False}, default ‘first’<br>| - <code>first</code> : Drop duplicates except for the first occurrence.<br>| - <code>last</code> : Drop duplicates except for the last occurrence.<br>| - False : Drop all duplicates.<br>| take_last : deprecated<br>| inplace : boolean, default False<br>| If True, performs operation inplace and returns None.<br>|<br>677<br>| 【返回值】<br>| ——-| deduplicated : Series<br>|<br>| duplicated(self, keep=’first’)<br>| Return boolean Series denoting duplicate values<br>|<br>| 【参数】<br>| ———-| keep : {‘first’, ‘last’, False}, default ‘first’<br>| - <code>first</code> : Mark duplicates as <code>True</code> except for the first occurrence.<br>| - <code>last</code> : Mark duplicates as <code>True</code> except for the last occurrence.<br>| - False : Mark all duplicates as <code>True</code>.<br>| take_last : deprecated<br>|<br>| 【返回值】<br>| ——-| duplicated : Series<br>|<br>| fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, </strong>kwargs)<br>| Fill NA/NaN values using the specified method<br>|<br>| 【参数】<br>| ———-| value : scalar, dict, Series, or DataFrame<br>| Value to use to fill holes (e.g. 0), alternately a dict/Series/DataFrame of<br>| values specifying which value to use for each index (for a Series) or<br>| column (for a DataFrame). (values not in the dict/Series/DataFrame will not be<br>| filled). This value cannot be a list.<br>| method : {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default None<br>| Method to use for filling holes in reindexed Series<br>| pad / ffill: propagate last valid observation forward to next valid<br>| backfill / bfill: use NEXT valid observation to fill gap<br>| axis : {0, ‘index’}<br>| inplace : boolean, default False<br>| If True, fill in place. Note: this will modify any<br>| other views on this object, (e.g. a no-copy slice for a column in a<br>| DataFrame).<br>| limit : int, default None<br>| If method is specified, this is the maximum number of consecutive<br>| NaN values to forward/backward fill. In other words, if there is<br>| a gap with more than this number of consecutive NaNs, it will only<br>| be partially filled. If method is not specified, this is the<br>| maximum number of entries along the entire axis where NaNs will be<br>| filled.<br>| downcast : dict, default is None<br>| a dict of item-&gt;dtype of what to downcast if possible,<br>| or the string ‘infer’ which will try to downcast to an appropriate<br>| equal type (e.g. float64 to int64 if possible)<br>|<br>| 【参见】<br>| ——–| reindex, asfreq<br>|<br>| 【返回值】<br>| ——-| filled : Series<br>678<br>|<br>| first_valid_index(self)<br>| Return label for first non-NA/null value<br>|<br>| hist = hist_series(self, by=None, ax=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None,<br>figsize=None, bins=10, **kwds)<br>| Draw histogram of the input series using matplotlib<br>|<br>| 【参数】<br>| ———-| by : object, optional<br>| If passed, then used to form histograms for separate groups<br>| ax : matplotlib axis object<br>| If not passed, uses gca()<br>| grid : boolean, default True<br>| Whether to show axis grid lines<br>| xlabelsize : int, default None<br>| If specified changes the x-axis label size<br>| xrot : float, default None<br>| rotation of x axis labels<br>| ylabelsize : int, default None<br>| If specified changes the y-axis label size<br>| yrot : float, default None<br>| rotation of y axis labels<br>| figsize : tuple, default None<br>| figure size in inches by default<br>| bins: integer, default 10<br>| Number of histogram bins to be used<br>| kwds : keywords<br>| To be passed to the actual plotting function<br>|<br>| 【注意】<br>| —–| See matplotlib documentation online for more on this<br>|<br>| idxmax(self, axis=None, out=None, skipna=True)<br>| Index of first occurrence of maximum of values.<br>|<br>| 【参数】<br>| ———-| skipna : boolean, default True<br>| Exclude NA/null values<br>|<br>| 【返回值】<br>| ——-| idxmax : Index of maximum of values<br>|<br>| 【注意】<br>| —–| This method is the Series version of <code>ndarray.argmax</code>.<br>|<br>| 【参见】<br>| ——–| DataFrame.idxmax<br>| numpy.ndarray.argmax<br>|<br>| idxmin(self, axis=None, out=None, skipna=True)<br>679<br>| Index of first occurrence of minimum of values.<br>|<br>| 【参数】<br>| ———-| skipna : boolean, default True<br>| Exclude NA/null values<br>|<br>| 【返回值】<br>| ——-| idxmin : Index of minimum of values<br>|<br>| 【注意】<br>| —–| This method is the Series version of <code>ndarray.argmin</code>.<br>|<br>| 【参见】<br>| ——–| DataFrame.idxmin<br>| numpy.ndarray.argmin<br>|<br>| iget(self, i, axis=0)<br>| DEPRECATED. Use <code>.iloc[i]</code> or <code>.iat[i]</code> instead<br>|<br>| iget_value(self, i, axis=0)<br>| DEPRECATED. Use <code>.iloc[i]</code> or <code>.iat[i]</code> instead<br>|<br>| irow(self, i, axis=0)<br>| DEPRECATED. Use <code>.iloc[i]</code> or <code>.iat[i]</code> instead<br>|<br>| isin(self, values)<br>| Return a boolean :class:<code>~pandas.Series</code> showing whether each element<br>| in the :class:<code>~pandas.Series</code> is exactly contained in the passed<br>| sequence of <code>values</code>.<br>|<br>| 【参数】<br>| ———-| values : list-like<br>| The sequence of values to test. Passing in a single string will<br>| raise a <code>TypeError</code>. Instead, turn a single string into a<br>| <code>list</code> of one element.<br>|<br>| 【返回值】<br>| ——-| isin : Series (bool dtype)<br>|<br>| 【Raises 引发错误】<br>| ——| TypeError<br>| </em> If <code>values</code> is a string<br>|<br>| 【参见】<br>| ——–| pandas.DataFrame.isin<br>|<br>| 【示例】<br>| ——–<br>680<br>|<br>| &gt;&gt;&gt; s = pd.Series(list(‘abc’))<br>| &gt;&gt;&gt; s.isin([‘a’, ‘c’, ‘e’])<br>| 0 True<br>| 1 False<br>| 2 True<br>| dtype: bool<br>|<br>| Passing a single string as <code>s.isin(&#39;a&#39;)</code> will raise an error. Use<br>| a list of one element instead:<br>|<br>| &gt;&gt;&gt; s.isin([‘a’])<br>| 0 True<br>| 1 False<br>| 2 False<br>| dtype: bool<br>|<br>| items = iteritems(self)<br>| Lazily iterate over (index, value) tuples<br>|<br>| iteritems(self)<br>| Lazily iterate over (index, value) tuples<br>|<br>| keys(self)<br>| Alias for index<br>|<br>| kurt(self, axis=None, skipna=None, level=None, numeric_only=None, <strong>kwargs)<br>| Return unbiased kurtosis over requested axis using Fishers definition of<br>| kurtosis (kurtosis of normal == 0.0). Normalized by N-1<br>|<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| kurt : scalar or Series (if level specified)<br>|<br>| kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| Return unbiased kurtosis over requested axis using Fishers definition of<br>| kurtosis (kurtosis of normal == 0.0). Normalized by N-1<br>|<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>681<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| kurt : scalar or Series (if level specified)<br>|<br>| last_valid_index(self)<br>| Return label for last non-NA/null value<br>|<br>| mad(self, axis=None, skipna=None, level=None)<br>| Return the mean absolute deviation of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| mad : scalar or Series (if level specified)<br>|<br>| map(self, arg, na_action=None)<br>| Map values of Series using input correspondence (which can be<br>| a dict, Series, or function)<br>|<br>| 【参数】<br>| ———-| arg : function, dict, or Series<br>| na_action : {None, ‘ignore’}<br>| If ‘ignore’, propagate NA values<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; x<br>| one 1<br>| two 2<br>| three 3<br>|<br>| &gt;&gt;&gt; y<br>| 1 foo<br>| 2 bar<br>| 3 baz<br>682<br>|<br>| &gt;&gt;&gt; x.map(y)<br>| one foo<br>| two bar<br>| three baz<br>|<br>| 【返回值】<br>| ——-| y : Series<br>| same index as caller<br>|<br>| max(self, axis=None, skipna=None, level=None, numeric_only=None, <strong>kwargs)<br>| This method returns the maximum of the values in the object. If you<br>| want the <em>index</em> of the maximum, use <code>idxmax</code>. This is the<br>| equivalent of the <code>numpy.ndarray</code> method <code>argmax</code>.<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| max : scalar or Series (if level specified)<br>|<br>| mean(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| Return the mean of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| mean : scalar or Series (if level specified)<br>|<br>| median(self, axis=None, skipna=None, level=None, numeric_only=None, <strong>kwargs)<br>| Return the median of the values for the requested axis<br>|<br>| 【参数】<br>683<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| median : scalar or Series (if level specified)<br>|<br>| memory_usage(self, index=False, deep=False)<br>| Memory usage of the Series<br>|<br>| 【参数】<br>| ———-| index : bool<br>| Specifies whether to include memory usage of Series index<br>| deep : bool<br>| Introspect the data deeply, interrogate<br>| <code>object</code> dtypes for system-level memory consumption<br>|<br>| 【返回值】<br>| ——-| scalar bytes of memory consumed<br>|<br>| 【注意】<br>| —–| Memory usage does not include memory consumed by elements that<br>| are not components of the array if deep=False<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.nbytes<br>|<br>| min(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| This method returns the minimum of the values in the object. If you<br>| want the <em>index</em> of the minimum, use <code>idxmin</code>. This is the<br>| equivalent of the <code>numpy.ndarray</code> method <code>argmin</code>.<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>684<br>|<br>| 【返回值】<br>| ——-| min : scalar or Series (if level specified)<br>|<br>| mode(self)<br>| Returns the mode(s) of the dataset.<br>|<br>| Empty if nothing occurs at least 2 times. Always returns Series even<br>| if only one value.<br>|<br>| 【参数】<br>| ———-| sort : bool, default True<br>| If True, will lexicographically sort values, if False skips<br>| sorting. Result ordering when <code>sort=False</code> is not defined.<br>|<br>| 【返回值】<br>| ——-| modes : Series (sorted)<br>|<br>| nlargest(self, n=5, keep=’first’)<br>| Return the largest <code>n</code> elements.<br>|<br>| 【参数】<br>| ———-| n : int<br>| Return this many descending sorted values<br>| keep : {‘first’, ‘last’, False}, default ‘first’<br>| Where there are duplicate values:<br>| - <code>first</code> : take the first occurrence.<br>| - <code>last</code> : take the last occurrence.<br>| take_last : deprecated<br>|<br>| 【返回值】<br>| ——-| top_n : Series<br>| The n largest values in the Series, in sorted order<br>|<br>| 【注意】<br>| —–| Faster than <code>.sort_values(ascending=False).head(n)</code> for small <code>n</code> relative<br>| to the size of the <code>Series</code> object.<br>|<br>| 【参见】<br>| ——–| Series.nsmallest<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; import pandas as pd<br>| &gt;&gt;&gt; import numpy as np<br>| &gt;&gt;&gt; s = pd.Series(np.random.randn(1e6))<br>| &gt;&gt;&gt; s.nlargest(10) # only sorts up to the N requested<br>|<br>| nonzero(self)<br>685<br>| Return the indices of the elements that are non-zero<br>|<br>| This method is equivalent to calling <code>numpy.nonzero</code> on the<br>| series data. For compatability with NumPy, the return value is<br>| the same (a tuple with an array of indices for each dimension),<br>| but it will always be a one-item tuple because series only have<br>| one dimension.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; s = pd.Series([0, 3, 0, 4])<br>| &gt;&gt;&gt; s.nonzero()<br>| (array([1, 3]),)<br>| &gt;&gt;&gt; s.iloc[s.nonzero()[0]]<br>| 1 3<br>| 3 4<br>| dtype: int64<br>|<br>| 【参见】<br>| ——–| numpy.nonzero<br>|<br>| nsmallest(self, n=5, keep=’first’)<br>| Return the smallest <code>n</code> elements.<br>|<br>| 【参数】<br>| ———-| n : int<br>| Return this many ascending sorted values<br>| keep : {‘first’, ‘last’, False}, default ‘first’<br>| Where there are duplicate values:<br>| - <code>first</code> : take the first occurrence.<br>| - <code>last</code> : take the last occurrence.<br>| take_last : deprecated<br>|<br>| 【返回值】<br>| ——-| bottom_n : Series<br>| The n smallest values in the Series, in sorted order<br>|<br>| 【注意】<br>| —–| Faster than <code>.sort_values().head(n)</code> for small <code>n</code> relative to<br>| the size of the <code>Series</code> object.<br>|<br>| 【参见】<br>| ——–| Series.nlargest<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; import pandas as pd<br>| &gt;&gt;&gt; import numpy as np<br>| &gt;&gt;&gt; s = pd.Series(np.random.randn(1e6))<br>| &gt;&gt;&gt; s.nsmallest(10) # only sorts up to the N requested<br>|<br>| order(self, na_last=None, ascending=True, kind=’quicksort’, na_position=’last’, inplace=False)<br>686<br>| DEPRECATED: use :meth:<code>Series.sort_values</code><br>|<br>| Sorts Series object, by value, maintaining index-value link.<br>| This will return a new Series by default. Series.sort is the equivalent but as an inplace method.<br>|<br>| 【参数】<br>| ———-| na_last : boolean (optional, default=True) (DEPRECATED; use na_position)<br>| Put NaN’s at beginning or end<br>| ascending : boolean, default True<br>| Sort ascending. Passing False sorts descending<br>| kind : {‘mergesort’, ‘quicksort’, ‘heapsort’}, default ‘quicksort’<br>| Choice of sorting algorithm. See np.sort for more<br>| information. ‘mergesort’ is the only stable algorithm<br>| na_position : {‘first’, ‘last’} (optional, default=’last’)<br>| ‘first’ puts NaNs at the beginning<br>| ‘last’ puts NaNs at the end<br>| inplace : boolean, default False<br>| Do operation in place.<br>|<br>| 【返回值】<br>| ——-| y : Series<br>|<br>| 【参见】<br>| ——–| Series.sort_values<br>|<br>| prod(self, axis=None, skipna=None, level=None, numeric_only=None, <strong>kwargs)<br>| Return the product of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| prod : scalar or Series (if level specified)<br>|<br>| product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| Return the product of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>687<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| prod : scalar or Series (if level specified)<br>|<br>| ptp(self, axis=None, skipna=None, level=None, numeric_only=None, <strong>kwargs)<br>| Returns the difference between the maximum value and the minimum<br>| value in the object. This is the equivalent of the <code>numpy.ndarray</code><br>| method <code>ptp</code>.<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| ptp : scalar or Series (if level specified)<br>|<br>| put(self, *args, </strong>kwargs)<br>| return a ndarray with the values put<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.put<br>|<br>| quantile(self, q=0.5)<br>| Return value at the given quantile, a la numpy.percentile.<br>|<br>| 【参数】<br>| ———-| q : float or array-like, default 0.5 (50% quantile)<br>| 0 &lt;= q &lt;= 1, the quantile(s) to compute<br>|<br>| 【返回值】<br>| ——-| quantile : float or Series<br>| if <code>q</code> is an array, a Series will be returned where the<br>| index is <code>q</code> and the values are the quantiles.<br>|<br>| 【示例】<br>| ——–|<br>688<br>| &gt;&gt;&gt; s = Series([1, 2, 3, 4])<br>| &gt;&gt;&gt; s.quantile(.5)<br>| 2.5<br>| &gt;&gt;&gt; s.quantile([.25, .5, .75])<br>| 0.25 1.75<br>| 0.50 2.50<br>| 0.75 3.25<br>| dtype: float64<br>|<br>| rank(self, method=’average’, na_option=’keep’, ascending=True, pct=False)<br>| Compute data ranks (1 through n). Equal values are assigned a rank that<br>| is the average of the ranks of those values<br>|<br>| 【参数】<br>| ———-| method : {‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}<br>| <em> average: average rank of group<br>| </em> min: lowest rank in group<br>| <em> max: highest rank in group<br>| </em> first: ranks assigned in order they appear in the array<br>| <em> dense: like ‘min’, but rank always increases by 1 between groups<br>| na_option : {‘keep’}<br>| keep: leave NA values where they are<br>| ascending : boolean, default True<br>| False for ranks by high (1) to low (N)<br>| pct : boolean, default False<br>| Computes percentage rank of data<br>|<br>| 【返回值】<br>| ——-| ranks : Series<br>|<br>| ravel(self, order=’C’)<br>| Return the flattened underlying data as an ndarray<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.ravel<br>|<br>| reindex_axis(self, labels, axis=0, <strong>kwargs)<br>| for compatibility with higher dims<br>|<br>| rename(self, index=None, </strong>kwargs)<br>| Alter axes input function or functions. Function / dict values must be<br>| unique (1-to-1). Labels not contained in a dict / Series will be left<br>| as-is.<br>|<br>| 【参数】<br>| ———-| index : dict-like or function, optional<br>| Transformation to apply to that axis values<br>|<br>| copy : boolean, default True<br>| Also copy underlying data<br>| inplace : boolean, default False<br>| Whether to return a new Series. If True then value of copy is<br>| ignored.<br>689<br>|<br>| 【返回值】<br>| ——-| renamed : Series (new object)<br>|<br>| reorder_levels(self, order)<br>| Rearrange index levels using input order. May not drop or duplicate<br>| levels<br>|<br>| 【参数】<br>| ———-| order: list of int representing new level order.<br>| (reference level by number or key)<br>| axis: where to reorder levels<br>|<br>| 【返回值】<br>| ——-| type of caller (new object)<br>|<br>| repeat(self, reps)<br>| return a new Series with the values repeated reps times<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.repeat<br>|<br>| reset_index(self, level=None, drop=False, name=None, inplace=False)<br>| Analogous to the :meth:<code>pandas.DataFrame.reset_index</code> function, see<br>| docstring there.<br>|<br>| 【参数】<br>| ———-| level : int, str, tuple, or list, default None<br>| Only remove the given levels from the index. Removes all levels by<br>| default<br>| drop : boolean, default False<br>| Do not try to insert index into dataframe columns<br>| name : object, default None<br>| The name of the column corresponding to the Series values<br>| inplace : boolean, default False<br>| Modify the Series in place (do not create a new object)<br>|<br>| 【返回值】<br>| ———-| resetted : DataFrame, or Series if drop == True<br>|<br>| reshape(self, </em>args, <strong>kwargs)<br>| return an ndarray with the values shape<br>| if the specified shape matches exactly the current shape, then<br>| return self (for compat)<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.take<br>|<br>| round(self, decimals=0, out=None)<br>| a.round(decimals=0, out=None)<br>690<br>|<br>| Return <code>a</code> with each element rounded to the given number of decimals.<br>|<br>| Refer to <code>numpy.around</code> for full documentation.<br>|<br>| 【参见】<br>| ——–| numpy.around : equivalent function<br>|<br>| searchsorted(self, v, side=’left’, sorter=None)<br>| Find indices where elements should be inserted to maintain order.<br>|<br>| Find the indices into a sorted Series <code>self</code> such that, if the<br>| corresponding elements in <code>v</code> were inserted before the indices, the<br>| order of <code>self</code> would be preserved.<br>|<br>| 【参数】<br>| ———-| v : array_like<br>| Values to insert into <code>a</code>.<br>| side : {‘left’, ‘right’}, optional<br>| If ‘left’, the index of the first suitable location found is given.<br>| If ‘right’, return the last such index. If there is no suitable<br>| index, return either 0 or N (where N is the length of <code>a</code>).<br>| sorter : 1-D array_like, optional<br>| Optional array of integer indices that sort <code>self</code> into ascending<br>| order. They are typically the result of <code>np.argsort</code>.<br>|<br>| 【返回值】<br>| ——-| indices : array of ints<br>| Array of insertion points with the same shape as <code>v</code>.<br>|<br>| 【参见】<br>| ——–| Series.sort_values<br>| numpy.searchsorted<br>|<br>| 【注意】<br>| —–| Binary search is used to find the required insertion points.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; x = pd.Series([1, 2, 3])<br>| &gt;&gt;&gt; x<br>| 0 1<br>| 1 2<br>| 2 3<br>| dtype: int64<br>| &gt;&gt;&gt; x.searchsorted(4)<br>| array([3])<br>| &gt;&gt;&gt; x.searchsorted([0, 4])<br>| array([0, 3])<br>| &gt;&gt;&gt; x.searchsorted([1, 3], side=’left’)<br>| array([0, 2])<br>| &gt;&gt;&gt; x.searchsorted([1, 3], side=’right’)<br>691<br>| array([1, 3])<br>| &gt;&gt;&gt; x.searchsorted([1, 2], side=’right’, sorter=[0, 2, 1])<br>| array([1, 3])<br>|<br>| sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, </strong>kwargs)<br>| Return unbiased standard error of the mean over requested axis.<br>|<br>| Normalized by N-1 by default. This can be changed using the ddof argument<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| ddof : int, default 1<br>| degrees of freedom<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| sem : scalar or Series (if level specified)<br>|<br>| skew(self, axis=None, skipna=None, level=None, numeric_only=None, <strong>kwargs)<br>| Return unbiased skew over requested axis<br>| Normalized by N-1<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| skew : scalar or Series (if level specified)<br>|<br>| sort(self, axis=0, ascending=True, kind=’quicksort’, na_position=’last’, inplace=True)<br>| DEPRECATED: use :meth:<code>Series.sort_values(inplace=True)</code> for INPLACE sorting<br>|<br>| Sort values and index labels by value. This is an inplace sort by default.<br>| Series.order is the equivalent but returns a new Series.<br>|<br>| 【参数】<br>| ———-<br>692<br>| axis : int (can only be zero)<br>| ascending : boolean, default True<br>| Sort ascending. Passing False sorts descending<br>| kind : {‘mergesort’, ‘quicksort’, ‘heapsort’}, default ‘quicksort’<br>| Choice of sorting algorithm. See np.sort for more<br>| information. ‘mergesort’ is the only stable algorithm<br>| na_position : {‘first’, ‘last’} (optional, default=’last’)<br>| ‘first’ puts NaNs at the beginning<br>| ‘last’ puts NaNs at the end<br>| inplace : boolean, default True<br>| Do operation in place.<br>|<br>| 【参见】<br>| ——–| Series.sort_values<br>|<br>| sort_index(self, axis=0, level=None, ascending=True, inplace=False, sort_remaining=True)<br>| Sort object by labels (along an axis)<br>|<br>| 【参数】<br>| ———-| axis : index to direct sorting<br>| level : int or level name or list of ints or list of level names<br>| if not None, sort on values in specified index level(s)<br>| ascending : boolean, default True<br>| Sort ascending vs. descending<br>| inplace : bool<br>| if True, perform operation in-place<br>| kind : {<code>quicksort</code>, <code>mergesort</code>, <code>heapsort</code>}<br>| Choice of sorting algorithm. 参见：ndarray.np.sort for more information.<br>| <code>mergesort</code> is the only stable algorithm. For DataFrames, this option is<br>| only applied when sorting on a single column or label.<br>| na_position : {‘first’, ‘last’}<br>| <code>first</code> puts NaNs at the beginning, <code>last</code> puts NaNs at the end<br>| sort_remaining : bool<br>| if true and sorting by level and index is multilevel, sort by other levels<br>| too (in order) after sorting by specified level<br>|<br>| 【返回值】<br>| ——-| sorted_obj : Series<br>|<br>| sort_values(self, axis=0, ascending=True, inplace=False, kind=’quicksort’, na_position=’last’)<br>| Sort by the values along either axis<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| by : string name or list of names which refer to the axis items<br>| axis : index to direct sorting<br>| ascending : bool or list of bool<br>| Sort ascending vs. descending. Specify list for multiple sort orders.<br>| If this is a list of bools, must match the length of the by<br>| inplace : bool<br>| if True, perform operation in-place<br>| kind : {<code>quicksort</code>, <code>mergesort</code>, <code>heapsort</code>}<br>693<br>| Choice of sorting algorithm. 参见：ndarray.np.sort for more information.<br>| <code>mergesort</code> is the only stable algorithm. For DataFrames, this option is<br>| only applied when sorting on a single column or label.<br>| na_position : {‘first’, ‘last’}<br>| <code>first</code> puts NaNs at the beginning, <code>last</code> puts NaNs at the end<br>|<br>| 【返回值】<br>| ——-| sorted_obj : Series<br>|<br>| sortlevel(self, level=0, ascending=True, sort_remaining=True)<br>| Sort Series with MultiIndex by chosen level. Data will be<br>| lexicographically sorted by the chosen level followed by the other<br>| levels (in order)<br>|<br>| 【参数】<br>| ———-| level : int or level name, default None<br>| ascending : bool, default True<br>|<br>| 【返回值】<br>| ——-| sorted : Series<br>|<br>| 【参见】<br>| ——–| Series.sort_index(level=…)<br>|<br>| std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, </strong>kwargs)<br>| Return unbiased standard deviation over requested axis.<br>|<br>| Normalized by N-1 by default. This can be changed using the ddof argument<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| ddof : int, default 1<br>| degrees of freedom<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| std : scalar or Series (if level specified)<br>|<br>| sum(self, axis=None, skipna=None, level=None, numeric_only=None, <strong>kwargs)<br>| Return the sum of the values for the requested axis<br>|<br>| 【参数】<br>694<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| sum : scalar or Series (if level specified)<br>|<br>| swaplevel(self, i, j, copy=True)<br>| Swap levels i and j in a MultiIndex<br>|<br>| 【参数】<br>| ———-| i, j : int, string (can be mixed)<br>| Level of index to be swapped. Can pass level name as string.<br>|<br>| 【返回值】<br>| ——-| swapped : Series<br>|<br>| to_csv(self, path, index=True, sep=’,’, na_rep=’’, float_format=None, header=False, index_label=None, mode=’w’,<br>nanRep=None, encoding=None, date_format=None, decimal=’.’)<br>| Write Series to a comma-separated values (csv) file<br>|<br>| 【参数】<br>| ———-| path : string file path or file handle / StringIO. If None is provided<br>| the result is returned as a string.<br>| na_rep : string, default ‘’<br>| Missing data representation<br>| float_format : string, default None<br>| Format string for floating point numbers<br>| header : boolean, default False<br>| Write out series name<br>| index : boolean, default True<br>| Write row names (index)<br>| index_label : string or sequence, default None<br>| Column label for index column(s) if desired. If None is given, and<br>| <code>header</code> and <code>index</code> are True, then the index names are used. A<br>| sequence should be given if the DataFrame uses MultiIndex.<br>| mode : Python write mode, default ‘w’<br>| sep : character, default “,”<br>| Field delimiter for the output file.<br>| encoding : string, optional<br>| a string representing the encoding to use if the contents are<br>| non-ascii, for python versions prior to 3<br>| date_format: string, default None<br>| Format string for datetime objects.<br>| decimal: string, default ‘.’<br>695<br>| Character recognized as decimal separator. E.g. use ‘,’ for European data<br>|<br>| to_dict(self)<br>| Convert Series to {label -&gt; value} dict<br>|<br>| 【返回值】<br>| ——-| value_dict : dict<br>|<br>| to_frame(self, name=None)<br>| Convert Series to DataFrame<br>|<br>| 【参数】<br>| ———-| name : object, default None<br>| The passed name should substitute for the series name (if it has<br>| one).<br>|<br>| 【返回值】<br>| ——-| data_frame : DataFrame<br>|<br>| to_period(self, freq=None, copy=True)<br>| Convert Series from DatetimeIndex to PeriodIndex with desired<br>| frequency (inferred from index if not passed)<br>|<br>| 【参数】<br>| ———-| freq : string, default<br>|<br>| 【返回值】<br>| ——-| ts : Series with PeriodIndex<br>|<br>| to_sparse(self, kind=’block’, fill_value=None)<br>| Convert Series to SparseSeries<br>|<br>| 【参数】<br>| ———-| kind : {‘block’, ‘integer’}<br>| fill_value : float, defaults to NaN (missing)<br>|<br>| 【返回值】<br>| ——-| sp : SparseSeries<br>|<br>| to_string(self, buf=None, na_rep=’NaN’, float_format=None, header=True, length=False, dtype=False, name=False,<br>max_rows=None)<br>| Render a string representation of the Series<br>|<br>| 【参数】<br>| ———-| buf : StringIO-like, optional<br>| buffer to write to<br>| na_rep : string, optional<br>| string representation of NAN to use, default ‘NaN’<br>696<br>| float_format : one-parameter function, optional<br>| formatter function to apply to columns’ elements if they are floats<br>| default None<br>| header: boolean, default True<br>| Add the Series header (index name)<br>| length : boolean, default False<br>| Add the Series length<br>| dtype : boolean, default False<br>| Add the Series dtype<br>| name : boolean, default False<br>| Add the Series name if not None<br>| max_rows : int, optional<br>| Maximum number of rows to show before truncating. If None, show<br>| all.<br>|<br>| 【返回值】<br>| ——-| formatted : string (if not buffer passed)<br>|<br>| to_timestamp(self, freq=None, how=’start’, copy=True)<br>| Cast to datetimeindex of timestamps, at <em>beginning</em> of period<br>|<br>| 【参数】<br>| ———-| freq : string, default frequency of PeriodIndex<br>| Desired frequency<br>| how : {‘s’, ‘e’, ‘start’, ‘end’}<br>| Convention for converting period to timestamp; start of period<br>| vs. end<br>|<br>| 【返回值】<br>| ——-| ts : Series with DatetimeIndex<br>|<br>| tolist(self)<br>| Convert Series to a nested list<br>|<br>| unstack(self, level=-1)<br>| Unstack, a.k.a. pivot, Series with MultiIndex to produce DataFrame.<br>| The level involved will automatically get sorted.<br>|<br>| 【参数】<br>| ———-| level : int, string, or list of these, default last level<br>| Level(s) to unstack, can pass level name<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; s<br>| one a 1.<br>| one b 2.<br>| two a 3.<br>| two b 4.<br>|<br>| &gt;&gt;&gt; s.unstack(level=-1)<br>| a b<br>| one 1. 2.<br>697<br>| two 3. 4.<br>|<br>| &gt;&gt;&gt; s.unstack(level=0)<br>| one two<br>| a 1. 2.<br>| b 3. 4.<br>|<br>| 【返回值】<br>| ——-| unstacked : DataFrame<br>|<br>| update(self, other)<br>| Modify Series in place using non-NA values from passed<br>| Series. Aligns on index<br>|<br>| 【参数】<br>| ———-| other : Series<br>|<br>| valid lambda self, inplace=False, </strong>kwargs<br>|<br>| var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, <strong>kwargs)<br>| Return unbiased variance over requested axis.<br>|<br>| Normalized by N-1 by default. This can be changed using the ddof argument<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| ddof : int, default 1<br>| degrees of freedom<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| var : scalar or Series (if level specified)<br>|<br>| view(self, dtype=None)<br>|<br>| ———————————————————————-| Class methods inherited from pandas.core.series.Series:<br>|<br>| from_csv(path, sep=’,’, parse_dates=True, header=None, index_col=0, encoding=None, infer_datetime_format=False) from<br>builtins.type<br>| Read CSV file (DISCOURAGED, please use :func:<code>pandas.read_csv</code> instead).<br>|<br>| It is preferable to use the more powerful :func:<code>pandas.read_csv</code><br>| for most general purposes, but <code>from_csv</code> makes for an easy<br>| roundtrip to and from a file (the exact counterpart of<br>698<br>| <code>to_csv</code>), especially with a time Series.<br>|<br>| This method only differs from :func:<code>pandas.read_csv</code> in some defaults:<br>|<br>| - <code>index_col</code> is <code>0</code> instead of <code>None</code> (take first column as index<br>| by default)<br>| - <code>header</code> is <code>None</code> instead of <code>0</code> (the first row is not used as<br>| the column names)<br>| - <code>parse_dates</code> is <code>True</code> instead of <code>False</code> (try parsing the index<br>| as datetime by default)<br>|<br>| With :func:<code>pandas.read_csv</code>, the option <code>squeeze=True</code> can be used<br>| to return a Series like <code>from_csv</code>.<br>|<br>| 【参数】<br>| ———-| path : string file path or file handle / StringIO<br>| sep : string, default ‘,’<br>| Field delimiter<br>| parse_dates : boolean, default True<br>| Parse dates. Different default from read_table<br>| header : int, default None<br>| Row to use as header (skip prior rows)<br>| index_col : int or sequence, default 0<br>| Column to use for index. If a sequence is given, a MultiIndex<br>| is used. Different default from read_table<br>| encoding : string, optional<br>| a string representing the encoding to use if the contents are<br>| non-ascii, for python versions prior to 3<br>| infer_datetime_format: boolean, default False<br>| If True and <code>parse_dates</code> is True for a column, try to infer the<br>| datetime format based on the first datetime string. If the format<br>| can be inferred, there often will be a large parsing speed-up.<br>|<br>| 【参见】<br>| ——–| pandas.read_csv<br>|<br>| 【返回值】<br>| ——-| y : Series<br>|<br>| ———————————————————————-| Data descriptors inherited from pandas.core.series.Series:<br>|<br>| axes<br>| Return a list of the row axis labels<br>|<br>| dtype<br>| return the dtype object of the underlying data<br>|<br>| dtypes<br>| return the dtype object of the underlying data<br>|<br>| ftype<br>| return if the data is sparse|dense<br>|<br>699<br>| ftypes<br>| return if the data is sparse|dense<br>|<br>| imag<br>|<br>| index<br>|<br>| is_time_series<br>|<br>| real<br>|<br>| ———————————————————————-| Data and other attributes inherited from pandas.core.series.Series:<br>|<br>| cat = <class 'pandas.core.categorical.categoricalaccessor'=""><br>| Accessor object for categorical properties of the Series values.<br>|<br>| Be aware that assigning to <code>categories</code> is a inplace operation, while all methods return<br>| new categorical data per default (but can be called with <code>inplace=True</code>).<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; s.cat.categories<br>| &gt;&gt;&gt; s.cat.categories = list(‘abc’)<br>| &gt;&gt;&gt; s.cat.rename_categories(list(‘cab’))<br>| &gt;&gt;&gt; s.cat.reorder_categories(list(‘cab’))<br>| &gt;&gt;&gt; s.cat.add_categories([‘d’,’e’])<br>| &gt;&gt;&gt; s.cat.remove_categories([‘d’])<br>| &gt;&gt;&gt; s.cat.remove_unused_categories()<br>| &gt;&gt;&gt; s.cat.set_categories(list(‘abcde’))<br>| &gt;&gt;&gt; s.cat.as_ordered()<br>| &gt;&gt;&gt; s.cat.as_unordered()<br>|<br>| dt = <class 'pandas.tseries.common.combineddatetimelikeproperties'=""><br>| Accessor object for datetimelike properties of the Series values.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; s.dt.hour<br>| &gt;&gt;&gt; s.dt.second<br>| &gt;&gt;&gt; s.dt.quarter<br>|<br>| Returns a Series indexed like the original Series.<br>| Raises TypeError if the Series does not contain datetimelike values.<br>|<br>| plot = <class 'pandas.tools.plotting.seriesplotmethods'=""><br>| Series plotting accessor and method<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; s.plot.line()<br>| &gt;&gt;&gt; s.plot.bar()<br>| &gt;&gt;&gt; s.plot.hist()<br>|<br>| Plotting methods can also be accessed by calling the accessor as a method<br>| with the <code>kind</code> argument:<br>| <code>s.plot(kind=&#39;line&#39;)</code> is equivalent to <code>s.plot.line()</code><br>700<br>|<br>| ———————————————————————-| Methods inherited from pandas.core.base.IndexOpsMixin:<br>|<br>| factorize(self, sort=False, na_sentinel=-1)<br>| Encode the object as an enumerated type or categorical variable<br>|<br>| 【参数】<br>| ———-| sort : boolean, default False<br>| Sort by values<br>| na_sentinel: int, default -1<br>| Value to mark “not found”<br>|<br>| 【返回值】<br>| ——-| labels : the indexer to the original array<br>| uniques : the unique Index<br>|<br>| item(self)<br>| return the first element of the underlying data as a python scalar<br>|<br>| nunique(self, dropna=True)<br>| Return number of unique elements in the object.<br>|<br>| Excludes NA values by default.<br>|<br>| 【参数】<br>| ———-| dropna : boolean, default True<br>| Don’t include NaN in the count.<br>|<br>| 【返回值】<br>| ——-| nunique : int<br>|<br>| transpose(self)<br>| return the transpose, which is by definition self<br>|<br>| unique(self)<br>| Return array of unique values in the object. Significantly faster than<br>| numpy.unique. Includes NA values.<br>|<br>| 【返回值】<br>| ——-| uniques : ndarray<br>|<br>| value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)<br>| Returns object containing counts of unique values.<br>|<br>| The resulting object will be in descending order so that the<br>| first element is the most frequently-occurring element.<br>| Excludes NA values by default.<br>|<br>| 【参数】<br>| ———-| normalize : boolean, default False<br>701<br>| If True then the object returned will contain the relative<br>| frequencies of the unique values.<br>| sort : boolean, default True<br>| Sort by values<br>| ascending : boolean, default False<br>| Sort in ascending order<br>| bins : integer, optional<br>| Rather than count values, group them into half-open bins,<br>| a convenience for pd.cut, only works with numeric data<br>| dropna : boolean, default True<br>| Don’t include counts of NaN.<br>|<br>| 【返回值】<br>| ——-| counts : Series<br>|<br>| ———————————————————————-| Data descriptors inherited from pandas.core.base.IndexOpsMixin:<br>|<br>| T<br>| return the transpose, which is by definition self<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| base<br>| return the base object if the memory of the underlying data is shared<br>|<br>| data<br>| return the data pointer of the underlying data<br>|<br>| flags<br>| return the ndarray.flags for the underlying data<br>|<br>| hasnans<br>|<br>| itemsize<br>| return the size of the dtype of the item of the underlying data<br>|<br>| nbytes<br>| return the number of bytes in the underlying data<br>|<br>| ndim<br>| return the number of dimensions of the underlying data, by definition 1<br>|<br>| shape<br>| return a tuple of the shape of the underlying data<br>|<br>| size<br>| return the number of elements in the underlying data<br>|<br>| strides<br>| return the strides of the underlying data<br>|<br>702<br>| ———————————————————————-| Data and other attributes inherited from pandas.core.base.IndexOpsMixin:<br>|<br>| <strong>array_priority</strong> = 1000<br>|<br>| ———————————————————————-| Data and other attributes inherited from pandas.core.strings.StringAccessorMixin:<br>|<br>| str = <class 'pandas.core.strings.stringmethods'=""><br>| Vectorized string functions for Series and Index. NAs stay NA unless<br>| handled otherwise by a particular method. Patterned after Python’s string<br>| methods, with some inspiration from R’s stringr package.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; s.str.split(‘<em>‘)<br>| &gt;&gt;&gt; s.str.replace(‘</em>‘, ‘’)<br>|<br>| ———————————————————————-| Methods inherited from pandas.core.generic.NDFrame:<br>|<br>| <strong>abs</strong>(self)<br>|<br>| <strong>bool</strong> = <strong>nonzero</strong>(self)<br>|<br>| <strong>contains</strong>(self, key)<br>| True if the key is in the info axis<br>|<br>| <strong>delitem</strong>(self, key)<br>| Delete item<br>|<br>| <strong>finalize</strong>(self, other, method=None, </class></class></class></class></strong>kwargs)<br>| propagate metadata from other to self<br>|<br>| 【参数】<br>| ———-| other : the object from which to get the attributes that we are going<br>| to propagate<br>| method : optional, a passed method name ; possibly to take different<br>| types of propagation actions based on this<br>|<br>| <strong>getattr</strong>(self, name)<br>| After regular attribute access, try looking up the name<br>| This allows simpler access to columns for interactive use.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>invert</strong>(self)<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>nonzero</strong>(self)<br>|<br>| <strong>setattr</strong>(self, name, value)<br>| After regular attribute access, try setting the name<br>| This allows simpler access to columns for interactive use.<br>703<br>|<br>| <strong>setstate</strong>(self, state)<br>|<br>| add_prefix(self, prefix)<br>| Concatenate prefix string with panel items names.<br>|<br>| 【参数】<br>| ———-| prefix : string<br>|<br>| 【返回值】<br>| ——-| with_prefix : type of caller<br>|<br>| add_suffix(self, suffix)<br>| Concatenate suffix string with panel items names<br>|<br>| 【参数】<br>| ———-| suffix : string<br>|<br>| 【返回值】<br>| ——-| with_suffix : type of caller<br>|<br>| as_blocks(self, copy=True)<br>| Convert the frame to a dict of dtype -&gt; Constructor Types that each has<br>| a homogeneous dtype.<br>|<br>| NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in<br>| as_matrix)<br>|<br>| 【参数】<br>| ———-| copy : boolean, default True<br>|<br>| .. versionadded: 0.16.1<br>|<br>| 【返回值】<br>| ——-| values : a dict of dtype -&gt; Constructor Types<br>|<br>| as_matrix(self, columns=None)<br>| Convert the frame to its Numpy-array representation.<br>|<br>| 【参数】<br>| ———-| columns: list, optional, default:None<br>| If None, return all columns, otherwise, returns specified columns.<br>|<br>| 【返回值】<br>| ——-| values : ndarray<br>| If the caller is heterogeneous and contains booleans or objects,<br>| the result will be of dtype=object. See Notes.<br>|<br>704<br>|<br>| 【注意】<br>| —–| Return is NOT a Numpy-matrix, rather, a Numpy-array.<br>|<br>| The dtype will be a lower-common-denominator dtype (implicit<br>| upcasting); that is to say if the dtypes (even of numeric types)<br>| are mixed, the one that accommodates all will be chosen. Use this<br>| with care if you are not dealing with the blocks.<br>|<br>| e.g. If the dtypes are float16 and float32, dtype will be upcast to<br>| float32. If dtypes are int32 and uint8, dtype will be upcase to<br>| int32.<br>|<br>| This method is provided for backwards compatibility. Generally,<br>| it is recommended to use ‘.values’.<br>|<br>| 【参见】<br>| ——–| pandas.DataFrame.values<br>|<br>| asfreq(self, freq, method=None, how=None, normalize=False)<br>| Convert all TimeSeries inside to specified frequency using DateOffset<br>| objects. Optionally provide fill method to pad/backfill missing values.<br>|<br>| 【参数】<br>| ———-| freq : DateOffset object, or string<br>| method : {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}<br>| Method to use for filling holes in reindexed Series<br>| pad / ffill: propagate last valid observation forward to next valid<br>| backfill / bfill: use NEXT valid observation to fill method<br>| how : {‘start’, ‘end’}, default end<br>| For PeriodIndex only, see PeriodIndex.asfreq<br>| normalize : bool, default False<br>| Whether to reset output index to midnight<br>|<br>| 【返回值】<br>| ——-| converted : type of caller<br>|<br>| astype(self, dtype, copy=True, raise_on_error=True, <strong>kwargs)<br>| Cast object to input numpy.dtype<br>| Return a copy when copy = True (be really careful with this!)<br>|<br>| 【参数】<br>| ———-| dtype : numpy.dtype or Python type<br>| raise_on_error : raise on invalid input<br>| kwargs : keyword arguments to pass on to the constructor<br>|<br>| 【返回值】<br>| ——-| casted : type of caller<br>|<br>| at_time(self, time, asof=False)<br>| Select values at particular time of day (e.g. 9:30AM)<br>705<br>|<br>| 【参数】<br>| ———-| time : datetime.time or string<br>|<br>| 【返回值】<br>| ——-| values_at_time : type of caller<br>|<br>| between_time(self, start_time, end_time, include_start=True, include_end=True)<br>| Select values between particular times of the day (e.g., 9:00-9:30 AM)<br>|<br>| 【参数】<br>| ———-| start_time : datetime.time or string<br>| end_time : datetime.time or string<br>| include_start : boolean, default True<br>| include_end : boolean, default True<br>|<br>| 【返回值】<br>| ——-| values_between_time : type of caller<br>|<br>| bfill(self, axis=None, inplace=False, limit=None, downcast=None)<br>| Synonym for NDFrame.fillna(method=’bfill’)<br>|<br>| bool(self)<br>| Return the bool of a single element PandasObject<br>| This must be a boolean scalar value, either True or False<br>|<br>| Raise a ValueError if the PandasObject does not have exactly<br>| 1 element, or that element is not boolean<br>|<br>| clip(self, lower=None, upper=None, out=None, axis=None)<br>| Trim values at input threshold(s)<br>|<br>| 【参数】<br>| ———-| lower : float or array_like, default None<br>| upper : float or array_like, default None<br>| axis : int or string axis name, optional<br>| Align object with lower and upper along the given axis.<br>|<br>| 【返回值】<br>| ——-| clipped : Series<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df<br>| 0 1<br>| 0 0.335232 -1.256177<br>| 1 -1.367855 0.746646<br>| 2 0.027753 -1.176076<br>| 3 0.230930 -0.679613<br>| 4 1.261967 0.570967<br>| &gt;&gt;&gt; df.clip(-1.0, 0.5)<br>706<br>| 0 1<br>| 0 0.335232 -1.000000<br>| 1 -1.000000 0.500000<br>| 2 0.027753 -1.000000<br>| 3 0.230930 -0.679613<br>| 4 0.500000 0.500000<br>| &gt;&gt;&gt; t<br>| 0 -0.3<br>| 1 -0.2<br>| 2 -0.1<br>| 3 0.0<br>| 4 0.1<br>| dtype: float64<br>| &gt;&gt;&gt; df.clip(t, t + 1, axis=0)<br>| 0 1<br>| 0 0.335232 -0.300000<br>| 1 -0.200000 0.746646<br>| 2 0.027753 -0.100000<br>| 3 0.230930 0.000000<br>| 4 1.100000 0.570967<br>|<br>| clip_lower(self, threshold, axis=None)<br>| Return copy of the input with values below given value(s) truncated<br>|<br>| 【参数】<br>| ———-| threshold : float or array_like<br>| axis : int or string axis name, optional<br>| Align object with threshold along the given axis.<br>|<br>| 【参见】<br>| ——–| clip<br>|<br>| 【返回值】<br>| ——-| clipped : same type as input<br>|<br>| clip_upper(self, threshold, axis=None)<br>| Return copy of input with values above given value(s) truncated<br>|<br>| 【参数】<br>| ———-| threshold : float or array_like<br>| axis : int or string axis name, optional<br>| Align object with threshold along the given axis.<br>|<br>| 【参见】<br>| ——–| clip<br>|<br>| 【返回值】<br>| ——-| clipped : same type as input<br>|<br>| consolidate(self, inplace=False)<br>| Compute NDFrame with “consolidated” internals (data of each dtype<br>707<br>| grouped together in a single ndarray). Mainly an internal API function,<br>| but available here to the savvy user<br>|<br>| 【参数】<br>| ———-| inplace : boolean, default False<br>| If False return new object, otherwise modify existing object<br>|<br>| 【返回值】<br>| ——-| consolidated : type of caller<br>|<br>| convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)<br>| Attempt to infer better dtype for object columns<br>|<br>| 【参数】<br>| ———-| convert_dates : boolean, default True<br>| If True, convert to date where possible. If ‘coerce’, force<br>| conversion, with unconvertible values becoming NaT.<br>| convert_numeric : boolean, default False<br>| If True, attempt to coerce to numbers (including strings), with<br>| unconvertible values becoming NaN.<br>| convert_timedeltas : boolean, default True<br>| If True, convert to timedelta where possible. If ‘coerce’, force<br>| conversion, with unconvertible values becoming NaT.<br>| copy : boolean, default True<br>| If True, return a copy even if no copy is necessary (e.g. no<br>| conversion was done). Note: This is meant for internal use, and<br>| should not be confused with inplace.<br>|<br>| 【返回值】<br>| ——-| converted : same as input object<br>|<br>| describe(self, percentiles=None, include=None, exclude=None)<br>| Generate various summary statistics, excluding NaN values.<br>|<br>| 【参数】<br>| ———-| percentiles : array-like, optional<br>| The percentiles to include in the output. Should all<br>| be in the interval [0, 1]. By default <code>percentiles</code> is<br>| [.25, .5, .75], returning the 25th, 50th, and 75th percentiles.<br>| include, exclude : list-like, ‘all’, or None (default)<br>| Specify the form of the returned result. Either:<br>|<br>| - None to both (default). The result will include only numeric-typed<br>| columns or, if none are, only categorical columns.<br>| - A list of dtypes or strings to be included/excluded.<br>| To select all numeric types use numpy numpy.number. To select<br>| categorical objects use type object. 参见：the select_dtypes<br>| documentation. eg. df.describe(include=[‘O’])<br>| - If include is the string ‘all’, the output column-set will<br>| match the input one.<br>|<br>| 【返回值】<br>708<br>| ——-| summary: NDFrame of summary statistics<br>|<br>| 【注意】<br>| —–| The output DataFrame index depends on the requested dtypes:<br>|<br>| For numeric dtypes, it will include: count, mean, std, min,<br>| max, and lower, 50, and upper percentiles.<br>|<br>| For object dtypes (e.g. timestamps or strings), the index<br>| will include the count, unique, most common, and frequency of the<br>| most common. Timestamps also include the first and last items.<br>|<br>| For mixed dtypes, the index will be the union of the corresponding<br>| output types. Non-applicable entries will be filled with NaN.<br>| Note that mixed-dtype outputs can only be returned from mixed-dtype<br>| inputs and appropriate use of the include/exclude arguments.<br>|<br>| If multiple values have the highest count, then the<br>| <code>count</code> and <code>most common</code> pair will be arbitrarily chosen from<br>| among those with the highest count.<br>|<br>| The include, exclude arguments are ignored for Series.<br>|<br>| 【参见】<br>| ——–| DataFrame.select_dtypes<br>|<br>| drop(self, labels, axis=0, level=None, inplace=False, errors=’raise’)<br>| Return new object with labels in requested axis removed<br>|<br>| 【参数】<br>| ———-| labels : single label or list-like<br>| axis : int or axis name<br>| level : int or level name, default None<br>| For MultiIndex<br>| inplace : bool, default False<br>| If True, do operation inplace and return None.<br>| errors : {‘ignore’, ‘raise’}, default ‘raise’<br>| If ‘ignore’, suppress error and existing labels are dropped.<br>|<br>| .. versionadded:: 0.16.1<br>|<br>| 【返回值】<br>| ——-| dropped : type of caller<br>|<br>| equals(self, other)<br>| Determines if two NDFrame objects contain the same elements. NaNs in the<br>| same location are considered equal.<br>|<br>| ffill(self, axis=None, inplace=False, limit=None, downcast=None)<br>| Synonym for NDFrame.fillna(method=’ffill’)<br>|<br>| filter(self, items=None, like=None, regex=None, axis=None)<br>709<br>| Restrict the info axis to set of items or wildcard<br>|<br>| 【参数】<br>| ———-| items : list-like<br>| List of info axis to restrict to (must not all be present)<br>| like : string<br>| Keep info axis where “arg in col == True”<br>| regex : string (regular expression)<br>| Keep info axis with re.search(regex, col) == True<br>| axis : int or None<br>| The axis to filter on. By default this is the info axis. The “info<br>| axis” is the axis that is used when indexing with <code>[]</code>. For<br>| example, <code>df = DataFrame({&#39;a&#39;: [1, 2, 3, 4]]}); df[&#39;a&#39;]</code>. So,<br>| the <code>DataFrame</code> columns are the info axis.<br>|<br>| 【注意】<br>| —–| Arguments are mutually exclusive, but this is not checked for<br>|<br>| first(self, offset)<br>| Convenience method for subsetting initial periods of time series data<br>| based on a date offset<br>|<br>| 【参数】<br>| ———-| offset : string, DateOffset, dateutil.relativedelta<br>|<br>| 【示例】<br>| ——–| ts.last(‘10D’) -&gt; First 10 days<br>|<br>| 【返回值】<br>| ——-| subset : type of caller<br>|<br>| get_dtype_counts(self)<br>| Return the counts of dtypes in this object<br>|<br>| get_ftype_counts(self)<br>| Return the counts of ftypes in this object<br>|<br>| groupby(self, by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False)<br>| Group series using mapper (dict or key function, apply given function<br>| to group, return result as series) or by a series of columns<br>|<br>| 【参数】<br>| ———-| by : mapping function / list of functions, dict, Series, or tuple /<br>| list of column names.<br>| Called on each element of the object index to determine the groups.<br>| If a dict or Series is passed, the Series or dict VALUES will be<br>| used to determine the groups<br>| axis : int, default 0<br>| level : int, level name, or sequence of such, default None<br>| If the axis is a MultiIndex (hierarchical), group by a particular<br>| level or levels<br>710<br>| as_index : boolean, default True<br>| For aggregated output, return object with group labels as the<br>| index. Only relevant for DataFrame input. as_index=False is<br>| effectively “SQL-style” grouped output<br>| sort : boolean, default True<br>| Sort group keys. Get better performance by turning this off.<br>| Note this does not influence the order of observations within each group.<br>| groupby preserves the order of rows within each group.<br>| group_keys : boolean, default True<br>| When calling apply, add group keys to index to identify pieces<br>| squeeze : boolean, default False<br>| reduce the dimensionality of the return type if possible,<br>| otherwise return a consistent type<br>|<br>| 【示例】<br>| ——–| DataFrame results<br>|<br>| &gt;&gt;&gt; data.groupby(func, axis=0).mean()<br>| &gt;&gt;&gt; data.groupby([‘col1’, ‘col2’])[‘col3’].mean()<br>|<br>| DataFrame with hierarchical index<br>|<br>| &gt;&gt;&gt; data.groupby([‘col1’, ‘col2’]).mean()<br>|<br>| 【返回值】<br>| ——-| GroupBy object<br>|<br>| head(self, n=5)<br>| Returns first n rows<br>|<br>| interpolate(self, method=’linear’, axis=0, limit=None, inplace=False, limit_direction=’forward’, downcast=None, </strong>kwargs)<br>| Interpolate values according to different methods.<br>|<br>| Please note that only <code>method=&#39;linear&#39;</code> is supported for DataFrames/Series<br>| with a MultiIndex.<br>|<br>| 【参数】<br>| ———-| method : {‘linear’, ‘time’, ‘index’, ‘values’, ‘nearest’, ‘zero’,<br>| ‘slinear’, ‘quadratic’, ‘cubic’, ‘barycentric’, ‘krogh’,<br>| ‘polynomial’, ‘spline’ ‘piecewise_polynomial’, ‘pchip’}<br>|<br>| <em> ‘linear’: ignore the index and treat the values as equally<br>| spaced. This is the only method supported on MultiIndexes.<br>| default<br>| </em> ‘time’: interpolation works on daily and higher resolution<br>| data to interpolate given length of interval<br>| <em> ‘index’, ‘values’: use the actual numerical values of the index<br>| </em> ‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’,<br>| ‘barycentric’, ‘polynomial’ is passed to<br>| <code>scipy.interpolate.interp1d</code>. Both ‘polynomial’ and ‘spline’<br>| require that you also specify an <code>order</code> (int),<br>| e.g. df.interpolate(method=’polynomial’, order=4).<br>| These use the actual numerical values of the index.<br>| <em> ‘krogh’, ‘piecewise_polynomial’, ‘spline’, and ‘pchip’ are all<br>711<br>| wrappers around the scipy interpolation methods of similar<br>| names. These use the actual numerical values of the index. See<br>| the scipy documentation for more on their behavior<br>| <code>here &lt;http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation&gt;</code><strong><br>| <code>and here &lt;http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html&gt;</code></strong><br>|<br>| axis : {0, 1}, default 0<br>| </em> 0: fill column-by-column<br>| <em> 1: fill row-by-row<br>| limit : int, default None.<br>| Maximum number of consecutive NaNs to fill.<br>| limit_direction : {‘forward’, ‘backward’, ‘both’}, defaults to ‘forward’<br>| If limit is specified, consecutive NaNs will be filled in this<br>| direction.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| inplace : bool, default False<br>| Update the NDFrame in place if possible.<br>| downcast : optional, ‘infer’ or None, defaults to None<br>| Downcast dtypes if possible.<br>| kwargs : keyword arguments to pass on to the interpolating function.<br>|<br>| 【返回值】<br>| ——-| Series or DataFrame of same shape interpolated at the NaNs<br>|<br>| 【参见】<br>| ——–| reindex, replace, fillna<br>|<br>| 【示例】<br>| ——–|<br>| Filling in NaNs<br>|<br>| &gt;&gt;&gt; s = pd.Series([0, 1, np.nan, 3])<br>| &gt;&gt;&gt; s.interpolate()<br>| 0 0<br>| 1 1<br>| 2 2<br>| 3 3<br>| dtype: float64<br>|<br>| isnull(self)<br>| Return a boolean same-sized object indicating if the values are null<br>|<br>| 【参见】<br>| ——–| notnull : boolean inverse of isnull<br>|<br>| iterkv(self, </em>args, <strong>kwargs)<br>| iteritems alias used to get around 2to3. Deprecated<br>|<br>| last(self, offset)<br>| Convenience method for subsetting final periods of time series data<br>| based on a date offset<br>712<br>|<br>| 【参数】<br>| ———-| offset : string, DateOffset, dateutil.relativedelta<br>|<br>| 【示例】<br>| ——–| ts.last(‘5M’) -&gt; Last 5 months<br>|<br>| 【返回值】<br>| ——-| subset : type of caller<br>|<br>| mask(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)<br>| Return an object of same shape as self and whose corresponding<br>| entries are from self where cond is False and otherwise are from other.<br>|<br>| 【参数】<br>| ———-| cond : boolean NDFrame or array<br>| other : scalar or NDFrame<br>| inplace : boolean, default False<br>| Whether to perform the operation in place on the data<br>| axis : alignment axis if needed, default None<br>| level : alignment level if needed, default None<br>| try_cast : boolean, default False<br>| try to cast the result back to the input type (if possible),<br>| raise_on_error : boolean, default True<br>| Whether to raise on invalid data types (e.g. trying to where on<br>| strings)<br>|<br>| 【返回值】<br>| ——-| wh : same type as caller<br>|<br>| notnull(self)<br>| Return a boolean same-sized object indicating if the values are<br>| not null<br>|<br>| 【参见】<br>| ——–| isnull : boolean inverse of notnull<br>|<br>| pct_change(self, periods=1, fill_method=’pad’, limit=None, freq=None, </strong>kwargs)<br>| Percent change over given number of periods.<br>|<br>| 【参数】<br>| ———-| periods : int, default 1<br>| Periods to shift for forming percent change<br>| fill_method : str, default ‘pad’<br>| How to handle NAs before computing percent changes<br>| limit : int, default None<br>| The number of consecutive NAs to fill before stopping<br>| freq : DateOffset, timedelta, or offset alias string, optional<br>| Increment to use from time series API (e.g. ‘M’ or BDay())<br>|<br>713<br>| 【返回值】<br>| ——-| chg : NDFrame<br>|<br>| 【注意】<br>| —–|<br>| By default, the percentage change is calculated along the stat<br>| axis: 0, or <code>Index</code>, for <code>DataFrame</code> and 1, or <code>minor</code> for<br>| <code>Panel</code>. You can change this with the <code>axis</code> keyword argument.<br>|<br>| pipe(self, func, <em>args, **kwargs)<br>| Apply func(self, \</em>args, **kwargs)<br>|<br>| .. versionadded:: 0.16.2<br>|<br>| 【参数】<br>| ———-| func : function<br>| function to apply to the NDFrame.<br>| <code>args</code>, and <code>kwargs</code> are passed into <code>func</code>.<br>| Alternatively a <code>(callable, data_keyword)</code> tuple where<br>| <code>data_keyword</code> is a string indicating the keyword of<br>| <code>callable</code> that expects the NDFrame.<br>| args : positional arguments passed into <code>func</code>.<br>| kwargs : a dictionary of keyword arguments passed into <code>func</code>.<br>|<br>| 【返回值】<br>| ——-| object : the return type of <code>func</code>.<br>|<br>| 【注意】<br>| —–|<br>| Use <code>.pipe</code> when chaining together functions that expect<br>| on Series or DataFrames. Instead of writing<br>|<br>| &gt;&gt;&gt; f(g(h(df), arg1=a), arg2=b, arg3=c)<br>|<br>| You can write<br>|<br>| &gt;&gt;&gt; (df.pipe(h)<br>| … .pipe(g, arg1=a)<br>| … .pipe(f, arg2=b, arg3=c)<br>| … )<br>|<br>| If you have a function that takes the data as (say) the second<br>| argument, pass a tuple indicating which keyword expects the<br>| data. For example, suppose <code>f</code> takes its data as <code>arg2</code>:<br>|<br>| &gt;&gt;&gt; (df.pipe(h)<br>| … .pipe(g, arg1=a)<br>| … .pipe((f, ‘arg2’), arg1=a, arg3=c)<br>| … )<br>|<br>| 【参见】<br>| ——–<br>714<br>| pandas.DataFrame.apply<br>| pandas.DataFrame.applymap<br>| pandas.Series.map<br>|<br>| pop(self, item)<br>| Return item and drop from frame. Raise KeyError if not found.<br>|<br>| reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)<br>| return an object with matching indicies to myself<br>|<br>| 【参数】<br>| ———-| other : Object<br>| method : string or None<br>| copy : boolean, default True<br>| limit : int, default None<br>| Maximum number of consecutive labels to fill for inexact matches.<br>| tolerance : optional<br>| Maximum distance between labels of the other object and this<br>| object for inexact matches.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【注意】<br>| —–| Like calling s.reindex(index=other.index, columns=other.columns,<br>| method=…)<br>|<br>| 【返回值】<br>| ——-| reindexed : same as input<br>|<br>| rename_axis(self, mapper, axis=0, copy=True, inplace=False)<br>| Alter index and / or columns using input function or functions.<br>| Function / dict values must be unique (1-to-1). Labels not contained in<br>| a dict / Series will be left as-is.<br>|<br>| 【参数】<br>| ———-| mapper : dict-like or function, optional<br>| axis : int or string, default 0<br>| copy : boolean, default True<br>| Also copy underlying data<br>| inplace : boolean, default False<br>|<br>| 【返回值】<br>| ——-| renamed : type of caller<br>|<br>| replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method=’pad’, axis=None)<br>| Replace values given in ‘to_replace’ with ‘value’.<br>|<br>| 【参数】<br>| ———-| to_replace : str, regex, list, dict, Series, numeric, or None<br>|<br>| <em> str or regex:<br>715<br>|<br>| - str: string exactly matching <code>to_replace</code> will be replaced<br>| with <code>value</code><br>| - regex: regexs matching <code>to_replace</code> will be replaced with<br>| <code>value</code><br>|<br>| </em> list of str, regex, or numeric:<br>|<br>| - First, if <code>to_replace</code> and <code>value</code> are both lists, they<br>| <strong>must</strong> be the same length.<br>| - Second, if <code>regex=True</code> then all of the strings in <strong>both</strong><br>| lists will be interpreted as regexs otherwise they will match<br>| directly. This doesn’t matter much for <code>value</code> since there<br>| are only a few possible substitution regexes you can use.<br>| - str and regex rules apply as above.<br>|<br>| <em> dict:<br>|<br>| - Nested dictionaries, e.g., {‘a’: {‘b’: nan}}, are read as<br>| follows: look in column ‘a’ for the value ‘b’ and replace it<br>| with nan. You can nest regular expressions as well. Note that<br>| column names (the top-level dictionary keys in a nested<br>| dictionary) <strong>cannot</strong> be regular expressions.<br>| - Keys map to column names and values map to substitution<br>| values. You can treat this as a special case of passing two<br>| lists except that you are specifying the column to search in.<br>|<br>| </em> None:<br>|<br>| - This means that the <code>regex</code> argument must be a string,<br>| compiled regular expression, or list, dict, ndarray or Series<br>| of such elements. If <code>value</code> is also <code>None</code> then this<br>| <strong>must</strong> be a nested dictionary or <code>Series</code>.<br>|<br>| See the examples section for examples of each of these.<br>| value : scalar, dict, list, str, regex, default None<br>| Value to use to fill holes (e.g. 0), alternately a dict of values<br>| specifying which value to use for each column (columns not in the<br>| dict will not be filled). Regular expressions, strings and lists or<br>| dicts of such objects are also allowed.<br>| inplace : boolean, default False<br>| If True, in place. Note: this will modify any<br>| other views on this object (e.g. a column form a DataFrame).<br>| Returns the caller if this is True.<br>| limit : int, default None<br>| Maximum size gap to forward or backward fill<br>| regex : bool or same types as <code>to_replace</code>, default False<br>| Whether to interpret <code>to_replace</code> and/or <code>value</code> as regular<br>| expressions. If this is <code>True</code> then <code>to_replace</code> <em>must</em> be a<br>| string. Otherwise, <code>to_replace</code> must be <code>None</code> because this<br>| parameter will be interpreted as a regular expression or a list,<br>| dict, or array of regular expressions.<br>| method : string, optional, {‘pad’, ‘ffill’, ‘bfill’}<br>| The method to use when for replacement, when <code>to_replace</code> is a<br>| <code>list</code>.<br>|<br>| 【参见】<br>716<br>| ——–| NDFrame.reindex<br>| NDFrame.asfreq<br>| NDFrame.fillna<br>|<br>| 【返回值】<br>| ——-| filled : NDFrame<br>|<br>| 【Raises 引发错误】<br>| ——| AssertionError<br>| <em> If <code>regex</code> is not a <code>bool</code> and <code>to_replace</code> is not <code>None</code>.<br>| TypeError<br>| </em> If <code>to_replace</code> is a <code>dict</code> and <code>value</code> is not a <code>list</code>,<br>| <code>dict</code>, <code>ndarray</code>, or <code>Series</code><br>| <em> If <code>to_replace</code> is <code>None</code> and <code>regex</code> is not compilable into a<br>| regular expression or is a list, dict, ndarray, or Series.<br>| ValueError<br>| </em> If <code>to_replace</code> and <code>value</code> are <code>list</code> s or <code>ndarray</code> s, but<br>| they are not the same length.<br>|<br>| 【注意】<br>| —–| <em> Regex substitution is performed under the hood with <code>re.sub</code>. The<br>| rules for substitution for <code>re.sub</code> are the same.<br>| </em> Regular expressions will only substitute on strings, meaning you<br>| cannot provide, for example, a regular expression matching floating<br>| point numbers and expect the columns in your frame that have a<br>| numeric dtype to be matched. However, if those floating point numbers<br>| <em>are</em> strings, then you can do this.<br>| <em> This method has </em>a lot<em> of options. You are encouraged to experiment<br>| and play with this method to gain intuition about how it works.<br>|<br>| resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention=’start’, kind=None,<br>loffset=None, limit=None, base=0)<br>| Convenience method for frequency conversion and resampling of regular<br>| time-series data.<br>|<br>| 【参数】<br>| ———-| rule : string<br>| the offset string or object representing target conversion<br>| how : string<br>| method for down- or re-sampling, default to ‘mean’ for<br>| downsampling<br>| axis : int, optional, default 0<br>| fill_method : string, default None<br>| fill_method for upsampling<br>| closed : {‘right’, ‘left’}<br>| Which side of bin interval is closed<br>| label : {‘right’, ‘left’}<br>| Which bin edge label to label bucket with<br>| convention : {‘start’, ‘end’, ‘s’, ‘e’}<br>| kind : “period”/“timestamp”<br>| loffset : timedelta<br>| Adjust the resampled time labels<br>717<br>| limit : int, default None<br>| Maximum size gap to when reindexing with fill_method<br>| base : int, default 0<br>| For frequencies that evenly subdivide 1 day, the “origin” of the<br>| aggregated intervals. For example, for ‘5min’ frequency, base could<br>| range from 0 through 4. Defaults to 0<br>|<br>|<br>| 【示例】<br>| ——–|<br>| Start by creating a series with 9 one minute timestamps.<br>|<br>| &gt;&gt;&gt; index = pd.date_range(‘1/1/2000’, periods=9, freq=’T’)<br>| &gt;&gt;&gt; series = pd.Series(range(9), index=index)<br>| &gt;&gt;&gt; series<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:01:00 1<br>| 2000-01-01 00:02:00 2<br>| 2000-01-01 00:03:00 3<br>| 2000-01-01 00:04:00 4<br>| 2000-01-01 00:05:00 5<br>| 2000-01-01 00:06:00 6<br>| 2000-01-01 00:07:00 7<br>| 2000-01-01 00:08:00 8<br>| Freq: T, dtype: int64<br>|<br>| Downsample the series into 3 minute bins and sum the values<br>| of the timestamps falling into a bin.<br>|<br>| &gt;&gt;&gt; series.resample(‘3T’, how=’sum’)<br>| 2000-01-01 00:00:00 3<br>| 2000-01-01 00:03:00 12<br>| 2000-01-01 00:06:00 21<br>| Freq: 3T, dtype: int64<br>|<br>| Downsample the series into 3 minute bins as above, but label each<br>| bin using the right edge instead of the left. Please note that the<br>| value in the bucket used as the label is not included in the bucket,<br>| which it labels. For example, in the original series the<br>| bucket <code>2000-01-01 00:03:00</code> contains the value 3, but the summed<br>| value in the resampled bucket with the label<code>2000-01-01 00:03:00</code><br>| does not include 3 (if it did, the summed value would be 6, not 3).<br>| To include this value close the right side of the bin interval as<br>| illustrated in the example below this one.<br>|<br>| &gt;&gt;&gt; series.resample(‘3T’, how=’sum’, label=’right’)<br>| 2000-01-01 00:03:00 3<br>| 2000-01-01 00:06:00 12<br>| 2000-01-01 00:09:00 21<br>| Freq: 3T, dtype: int64<br>|<br>| Downsample the series into 3 minute bins as above, but close the right<br>| side of the bin interval.<br>|<br>| &gt;&gt;&gt; series.resample(‘3T’, how=’sum’, label=’right’, closed=’right’)<br>| 2000-01-01 00:00:00 0<br>718<br>| 2000-01-01 00:03:00 6<br>| 2000-01-01 00:06:00 15<br>| 2000-01-01 00:09:00 15<br>| Freq: 3T, dtype: int64<br>|<br>| Upsample the series into 30 second bins.<br>|<br>| &gt;&gt;&gt; series.resample(‘30S’)[0:5] #select first 5 rows<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:00:30 NaN<br>| 2000-01-01 00:01:00 1<br>| 2000-01-01 00:01:30 NaN<br>| 2000-01-01 00:02:00 2<br>| Freq: 30S, dtype: float64<br>|<br>| Upsample the series into 30 second bins and fill the <code>NaN</code><br>| values using the <code>pad</code> method.<br>|<br>| &gt;&gt;&gt; series.resample(‘30S’, fill_method=’pad’)[0:5]<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:00:30 0<br>| 2000-01-01 00:01:00 1<br>| 2000-01-01 00:01:30 1<br>| 2000-01-01 00:02:00 2<br>| Freq: 30S, dtype: int64<br>|<br>| Upsample the series into 30 second bins and fill the<br>| <code>NaN</code> values using the <code>bfill</code> method.<br>|<br>| &gt;&gt;&gt; series.resample(‘30S’, fill_method=’bfill’)[0:5]<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:00:30 1<br>| 2000-01-01 00:01:00 1<br>| 2000-01-01 00:01:30 2<br>| 2000-01-01 00:02:00 2<br>| Freq: 30S, dtype: int64<br>|<br>| Pass a custom function to <code>how</code>.<br>|<br>| &gt;&gt;&gt; def custom_resampler(array_like):<br>| … return np.sum(array_like)+5<br>|<br>| &gt;&gt;&gt; series.resample(‘3T’, how=custom_resampler)<br>| 2000-01-01 00:00:00 8<br>| 2000-01-01 00:03:00 17<br>| 2000-01-01 00:06:00 26<br>| Freq: 3T, dtype: int64<br>|<br>| sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)<br>| Returns a random sample of items from an axis of object.<br>|<br>| .. versionadded:: 0.16.1<br>|<br>| 【参数】<br>| ———-| n : int, optional<br>| Number of items from axis to return. Cannot be used with <code>frac</code>.<br>719<br>| Default = 1 if <code>frac</code> = None.<br>| frac : float, optional<br>| Fraction of axis items to return. Cannot be used with <code>n</code>.<br>| replace : boolean, optional<br>| Sample with or without replacement. Default = False.<br>| weights : str or ndarray-like, optional<br>| Default ‘None’ results in equal probability weighting.<br>| If passed a Series, will align with target object on index. Index<br>| values in weights not found in sampled object will be ignored and<br>| index values in sampled object not in weights will be assigned<br>| weights of zero.<br>| If called on a DataFrame, will accept the name of a column<br>| when axis = 0.<br>| Unless weights are a Series, weights must be same length as axis<br>| being sampled.<br>| If weights do not sum to 1, they will be normalized to sum to 1.<br>| Missing values in the weights column will be treated as zero.<br>| inf and -inf values not allowed.<br>| random_state : int or numpy.random.RandomState, optional<br>| Seed for the random number generator (if int), or numpy RandomState<br>| object.<br>| axis : int or string, optional<br>| Axis to sample. Accepts axis number or name. Default is stat axis<br>| for given data type (0 for Series and DataFrames, 1 for Panels).<br>|<br>| 【返回值】<br>| ——-| A new object of same type as caller.<br>|<br>| select(self, crit, axis=0)<br>| Return data corresponding to axis labels matching criteria<br>|<br>| 【参数】<br>| ———-| crit : function<br>| To be called on each index (label). Should return True or False<br>| axis : int<br>|<br>| 【返回值】<br>| ——-| selection : type of caller<br>|<br>| set_axis(self, axis, labels)<br>| public verson of axis assignment<br>|<br>| slice_shift(self, periods=1, axis=0)<br>| Equivalent to <code>shift</code> without copying data. The shifted data will<br>| not include the dropped periods and the shifted axis will be smaller<br>| than the original.<br>|<br>| 【参数】<br>| ———-| periods : int<br>| Number of periods to move, can be positive or negative<br>|<br>| 【注意】<br>| —–<br>720<br>| While the <code>slice_shift</code> is faster than <code>shift</code>, you may pay for it<br>| later during alignment.<br>|<br>| 【返回值】<br>| ——-| shifted : same type as caller<br>|<br>| squeeze(self)<br>| squeeze length 1 dimensions<br>|<br>| swapaxes(self, axis1, axis2, copy=True)<br>| Interchange axes and swap values axes appropriately<br>|<br>| 【返回值】<br>| ——-| y : same as input<br>|<br>| tail(self, n=5)<br>| Returns last n rows<br>|<br>| to_clipboard(self, excel=None, sep=None, <strong>kwargs)<br>| Attempt to write text representation of object to the system clipboard<br>| This can be pasted into Excel, for example.<br>|<br>| 【参数】<br>| ———-| excel : boolean, defaults to True<br>| if True, use the provided separator, writing in a csv<br>| format for allowing easy pasting into excel.<br>| if False, write a string representation of the object<br>| to the clipboard<br>| sep : optional, defaults to tab<br>| other keywords are passed to to_csv<br>|<br>| 【注意】<br>| —–| Requirements for your platform<br>| - Linux: xclip, or xsel (with gtk or PyQt4 modules)<br>| - Windows: none<br>| - OS X: none<br>|<br>| to_hdf(self, path_or_buf, key, </strong>kwargs)<br>| activate the HDFStore<br>|<br>| 【参数】<br>| ———-| path_or_buf : the path (string) or HDFStore object<br>| key : string<br>| indentifier for the group in the store<br>| mode : optional, {‘a’, ‘w’, ‘r’, ‘r+’}, default ‘a’<br>|<br>| <code>&#39;r&#39;</code><br>| Read-only; no data can be modified.<br>| <code>&#39;w&#39;</code><br>| Write; a new file is created (an existing file with the same<br>| name would be deleted).<br>| <code>&#39;a&#39;</code><br>721<br>| Append; an existing file is opened for reading and writing,<br>| and if the file does not exist it is created.<br>| <code>&#39;r+&#39;</code><br>| It is similar to <code>&#39;a&#39;</code>, but the file must already exist.<br>| format : ‘fixed(f)|table(t)’, default is ‘fixed’<br>| fixed(f) : Fixed format<br>| Fast writing/reading. Not-appendable, nor searchable<br>| table(t) : Table format<br>| Write as a PyTables Table structure which may perform<br>| worse but allow more flexible operations like searching<br>| / selecting subsets of the data<br>| append : boolean, default False<br>| For Table formats, append the input data to the existing<br>| complevel : int, 1-9, default 0<br>| If a complib is specified compression will be applied<br>| where possible<br>| complib : {‘zlib’, ‘bzip2’, ‘lzo’, ‘blosc’, None}, default None<br>| If complevel is &gt; 0 apply compression to objects written<br>| in the store wherever possible<br>| fletcher32 : bool, default False<br>| If applying compression use the fletcher32 checksum<br>| dropna : boolean, default False.<br>| If true, ALL nan rows will not be written to store.<br>|<br>| to_json(self, path_or_buf=None, orient=None, date_format=’epoch’, double_precision=10, force_ascii=True, date_unit=’ms’,<br>default_handler=None)<br>| Convert the object to a JSON string.<br>|<br>| Note NaN’s and None will be converted to null and datetime objects<br>| will be converted to UNIX timestamps.<br>|<br>| 【参数】<br>| ———-| path_or_buf : the path or buffer to write the result string<br>| if this is None, return a StringIO of the converted string<br>| orient : string<br>|<br>| </em> Series<br>|<br>| - default is ‘index’<br>| - allowed values are: {‘split’,’records’,’index’}<br>|<br>| <em> DataFrame<br>|<br>| - default is ‘columns’<br>| - allowed values are:<br>| {‘split’,’records’,’index’,’columns’,’values’}<br>|<br>| </em> The format of the JSON string<br>|<br>| - split : dict like<br>| {index -&gt; [index], columns -&gt; [columns], data -&gt; [values]}<br>| - records : list like<br>| [{column -&gt; value}, … , {column -&gt; value}]<br>| - index : dict like {index -&gt; {column -&gt; value}}<br>| - columns : dict like {column -&gt; {index -&gt; value}}<br>| - values : just the values array<br>722<br>|<br>| date_format : {‘epoch’, ‘iso’}<br>| Type of date conversion. <code>epoch</code> = epoch milliseconds,<br>| <code>iso`` = ISO8601, default is epoch.
| double_precision : The number of decimal places to use when encoding
| floating point values, default 10.
| force_ascii : force encoded string to be ASCII, default True.
| date_unit : string, default &#39;ms&#39; (milliseconds)
| The time unit to encode to, governs timestamp and ISO8601
| precision. One of &#39;s&#39;, &#39;ms&#39;, &#39;us&#39;, &#39;ns&#39; for second, millisecond,
| microsecond, and nanosecond respectively.
| default_handler : callable, default None
| Handler to call if object cannot otherwise be converted to a
| suitable format for JSON. Should receive a single argument which is
| the object to convert and return a serialisable object.
|
| 【返回值】
| -------| same type as input object with filtered info axis
|
| to_msgpack(self, path_or_buf=None, **kwargs)
| msgpack (serialize) object to input file path
|
| THIS IS AN EXPERIMENTAL LIBRARY and the storage format
| may not be stable until a future release.
|
| 【参数】
| ----------| path : string File path, buffer-like, or None
| if None, return generated string
| append : boolean whether to append to an existing msgpack
| (default is False)
| compress : type of compressor (zlib or blosc), default to None (no
| compression)
|
| to_pickle(self, path)
| Pickle (serialize) object to input file path
|
| 【参数】
| ----------| path : string
| File path
|
| to_sql(self, name, con, flavor=&#39;sqlite&#39;, schema=None, if_exists=&#39;fail&#39;, index=True, index_label=None, chunksize=None,
dtype=None)
| Write records stored in a DataFrame to a SQL database.
|
| 【参数】
| ----------| name : string
| Name of SQL table
| con : SQLAlchemy engine or DBAPI2 connection (legacy mode)
| Using SQLAlchemy makes it possible to use any DB supported by that
| library.
| If a DBAPI2 object, only sqlite3 is supported.
| flavor : {&#39;sqlite&#39;, &#39;mysql&#39;}, default &#39;sqlite&#39;
| The flavor of SQL to use. Ignored when using SQLAlchemy engine.
723
| &#39;mysql&#39; is deprecated and will be removed in future versions, but it
| will be further supported through SQLAlchemy engines.
| schema : string, default None
| Specify the schema (if database flavor supports this). If None, use
| default schema.
| if_exists : {&#39;fail&#39;, &#39;replace&#39;, &#39;append&#39;}, default &#39;fail&#39;
| - fail: If table exists, do nothing.
| - replace: If table exists, drop it, recreate it, and insert data.
| - append: If table exists, insert data. Create if does not exist.
| index : boolean, default True
| Write DataFrame index as a column.
| index_label : string or sequence, default None
| Column label for index column(s). If None is given (default) and
|</code>index<code>is True, then the index names are used.
| A sequence should be given if the DataFrame uses MultiIndex.
| chunksize : int, default None
| If not None, then rows will be written in batches of this size at a
| time. If None, all rows will be written at once.
| dtype : dict of column name to SQL type, default None
| Optional specifying the datatype for columns. The SQL type should
| be a SQLAlchemy type, or a string for sqlite3 fallback connection.
|
| truncate(self, before=None, after=None, axis=None, copy=True)
| Truncates a sorted NDFrame before and/or after some particular
| dates.
|
| 【参数】
| ----------| before : date
| Truncate before date
| after : date
| Truncate after date
| axis : the truncation axis, defaults to the stat axis
| copy : boolean, default is True,
| return a copy of the truncated section
|
| 【返回值】
| -------| truncated : type of caller
|
| tshift(self, periods=1, freq=None, axis=0)
| Shift the time index, using the index&#39;s frequency if available
|
| 【参数】
| ----------| periods : int
| Number of periods to move, can be positive or negative
| freq : DateOffset, timedelta, or time rule string, default None
| Increment to use from datetools module or time rule (e.g. &#39;EOM&#39;)
| axis : int or basestring
| Corresponds to the axis that contains the Index
|
| 【注意】
| -----| If freq is not specified then tries to use the freq or inferred_freq
| attributes of the index. If neither of those attributes exist, a
| ValueError is thrown
724
|
| 【返回值】
| -------| shifted : NDFrame
|
| tz_convert(self, tz, axis=0, level=None, copy=True)
| Convert tz-aware axis to target time zone.
|
| 【参数】
| ----------| tz : string or pytz.timezone object
| axis : the axis to convert
| level : int, str, default None
| If axis ia a MultiIndex, convert a specific level. Otherwise
| must be None
| copy : boolean, default True
| Also make a copy of the underlying data
|
| 【返回值】
| -------|
| 【Raises 引发错误】
| ------| TypeError
| If the axis is tz-naive.
|
| tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous=&#39;raise&#39;)
| Localize tz-naive TimeSeries to target time zone
|
| 【参数】
| ----------| tz : string or pytz.timezone object
| axis : the axis to localize
| level : int, str, default None
| If axis ia a MultiIndex, localize a specific level. Otherwise
| must be None
| copy : boolean, default True
| Also make a copy of the underlying data
| ambiguous : &#39;infer&#39;, bool-ndarray, &#39;NaT&#39;, default &#39;raise&#39;
| - &#39;infer&#39; will attempt to infer fall dst-transition hours based on order
| - bool-ndarray where True signifies a DST time, False designates
| a non-DST time (note that this flag is only applicable for ambiguous times)
| - &#39;NaT&#39; will return NaT where there are ambiguous times
| - &#39;raise&#39; will raise an AmbiguousTimeError if there are ambiguous times
| infer_dst : boolean, default False (DEPRECATED)
| Attempt to infer fall dst-transition hours based on order
|
| 【返回值】
| -------|
| 【Raises 引发错误】
| ------| TypeError
| If the TimeSeries is tz-aware and tz is not None.
|
| where(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)
| Return an object of same shape as self and whose corresponding
725
| entries are from self where cond is True and otherwise are from other.
|
| 【参数】
| ----------| cond : boolean NDFrame or array
| other : scalar or NDFrame
| inplace : boolean, default False
| Whether to perform the operation in place on the data
| axis : alignment axis if needed, default None
| level : alignment level if needed, default None
| try_cast : boolean, default False
| try to cast the result back to the input type (if possible),
| raise_on_error : boolean, default True
| Whether to raise on invalid data types (e.g. trying to where on
| strings)
|
| 【返回值】
| -------| wh : same type as caller
|
| xs(self, key, axis=0, level=None, copy=None, drop_level=True)
| Returns a cross-section (row(s) or column(s)) from the Series/DataFrame.
| Defaults to cross-section on the rows (axis=0).
|
| 【参数】
| ----------| key : object
| Some label contained in the index, or partially in a MultiIndex
| axis : int, default 0
| Axis to retrieve cross-section on
| level : object, defaults to first n levels (n=1 or len(key))
| In case of a key partially contained in a MultiIndex, indicate
| which levels are used. Levels can be referred by label or position.
| copy : boolean [deprecated]
| Whether to make a copy of the data
| drop_level : boolean, default True
| If False, returns object with same levels as self.
|
| 【示例】
| --------| &gt;&gt;&gt; df
| A B C
| a 4 5 2
| b 4 0 9
| c 9 7 3
| &gt;&gt;&gt; df.xs(&#39;a&#39;)
| A 4
| B 5
| C 2
| Name: a
| &gt;&gt;&gt; df.xs(&#39;C&#39;, axis=1)
| a 2
| b 9
| c 3
| Name: C
|
| &gt;&gt;&gt; df
726
| A B C D
| first second third
| bar one 1 4 1 8 9
| two 1 7 5 5 0
| baz one 1 6 6 8 0
| three 2 5 3 5 3
| &gt;&gt;&gt; df.xs((&#39;baz&#39;, &#39;three&#39;))
| A B C D
| third
| 2 5 3 5 3
| &gt;&gt;&gt; df.xs(&#39;one&#39;, level=1)
| A B C D
| first third
| bar 1 4 1 8 9
| baz 1 6 6 8 0
| &gt;&gt;&gt; df.xs((&#39;baz&#39;, 2), level=[0, &#39;third&#39;])
| A B C D
| second
| three 5 3 5 3
|
| 【返回值】
| -------| xs : Series or DataFrame
|
| 【注意】
| -----| xs is only for getting, not setting values.
|
| MultiIndex Slicers is a generic way to get/set values on any level or levels
| it is a superset of xs functionality, see :ref:</code>MultiIndex Slicers <advanced.mi_slicers><code>|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.generic.NDFrame:
|
| at
| Fast label-based scalar accessor
|
| Similarly to ``loc``, ``at`` provides **label** based scalar lookups.
| You can also set using these indexers.
|
| blocks
| Internal property, property synonym for as_blocks()
|
| empty
| True if NDFrame is entirely empty [no items]
|
| iat
| Fast integer location scalar accessor.
|
| Similarly to ``iloc``, ``iat`` provides **integer** based lookups.
| You can also set using these indexers.
|
| iloc
| Purely integer-location based indexing for selection by position.
|
| ``.iloc[]`` is primarily integer position based (from ``0`` to
| ``length-1`` of the axis), but may also be used with a boolean
727
| array.
|
| Allowed inputs are:
|
| - An integer, e.g. ``5``.
| - A list or array of integers, e.g. ``[4, 3, 0]``.
| - A slice object with ints, e.g. ``1:7``.
| - A boolean array.
|
| ``.iloc`` will raise ``IndexError`` if a requested indexer is
| out-of-bounds, except *slice* indexers which allow out-of-bounds
| indexing (this conforms with python/numpy *slice* semantics).
|
| See more at :ref:</code>Selection by Position <indexing.integer><code>|
| ix
| A primarily label-location based indexer, with integer position
| fallback.
|
| ``.ix[]`` supports mixed integer and label based access. It is
| primarily label based, but will fall back to integer positional
| access unless the corresponding axis is of integer type.
|
| ``.ix`` is the most general indexer and will support any of the
| inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating
| point label schemes. ``.ix`` is exceptionally useful when dealing
| with mixed positional and label based hierachical indexes.
|
| However, when an axis is integer based, ONLY label based access
| and not positional access is supported. Thus, in such cases, it&#39;s
| usually better to be explicit and use ``.iloc`` or ``.loc``.
|
| See more at :ref:</code>Advanced Indexing <advanced><code>.
|
| loc
| Purely label-location based indexer for selection by label.
|
| ``.loc[]`` is primarily label based, but may also be used with a
| boolean array.
|
| Allowed inputs are:
|
| - A single label, e.g. ``5`` or ``&#39;a&#39;``, (note that ``5`` is
| interpreted as a *label* of the index, and **never** as an
| integer position along the index).
| - A list or array of labels, e.g. ``[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]``.
| - A slice object with labels, e.g. ``&#39;a&#39;:&#39;f&#39;`` (note that contrary
| to usual python slices, **both** the start and the stop are included!).
| - A boolean array.
|
| ``.loc`` will raise a ``KeyError`` when the items are not found.
|
| See more at :ref:</code>Selection by Label <indexing.label><code>|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.generic.NDFrame:
|
728
| is_copy = None
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.PandasObject:
|
| __dir__(self)
| Provide method name lookup and completion
| Only provide &#39;public&#39; methods
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
| Return a string representation for a particular object.
|
| Invoked by bytes(obj) in py3 only.
| Yields a bytestring in both py2/py3.
|
| __repr__(self)
| Return a string representation for a particular object.
|
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
SparseTimeSeries
SparseTimeSeries 模块所属：pandas.sparse.series:
类定义：SparseTimeSeries(SparseSeries)
| Data structure for labeled, sparse floating point data
|
| 【参数】
| ----------| data : {array-like, Series, SparseSeries, dict}
| kind : {&#39;block&#39;, &#39;integer&#39;}
| fill_value : float
| Defaults to NaN (code for missing)
| sparse_index : {BlockIndex, IntIndex}, optional
| Only if you have one. Mainly used internally
|
|【注意】
| -----| SparseSeries objects are immutable via the typical Python means. If you
| must change values, convert to dense, make your changes, then convert back
| to sparse
729
|
| 【方法排序】
| SparseTimeSeries
| SparseSeries
| pandas.core.series.Series
| pandas.core.base.IndexOpsMixin
| pandas.core.strings.StringAccessorMixin
| pandas.core.generic.NDFrame
| pandas.core.base.PandasObject
| pandas.core.base.StringMixin
| 【内置对象】
|
| 【方法定义】
|
| __init__(self, *args, **kwargs)
| Initialize self. See help(type(self)) for accurate signature.
|
| ----------------------------------------------------------------------| Methods inherited from SparseSeries:
|
| __add__(self, other)
|
| __and__ = wrapper(self, other)
|
| __array__(self, result=None)
| the array interface, return my values
|
| __array_finalize__(self, obj)
| Gets called after any ufunc or other array operations, necessary
| to pass on the index.
|
| __array_wrap__(self, result)
| Gets called prior to a ufunc (and after)
|
| __div__ = __truediv__(self, other)
|
| __eq__ = wrapper(self, other, axis=None)
|
| __floordiv__(self, other)
|
| __ge__ = wrapper(self, other, axis=None)
|
| __getitem__(self, key)
|
| __getstate__(self)
|
| __gt__ = wrapper(self, other, axis=None)
|
| __iadd__ = f(self, other)
|
| __imul__ = f(self, other)
|
| __ipow__ = f(self, other)
|
| __isub__ = f(self, other)
|
| __iter__(self)
730
| forward to the array
|
| __itruediv__ = f(self, other)
|
| __le__ = wrapper(self, other, axis=None)
|
| __len__(self)
| return the length of the Series
|
| __lt__ = wrapper(self, other, axis=None)
|
| __mod__(self, other)
|
| __mul__(self, other)
|
| __ne__ = wrapper(self, other, axis=None)
|
| __or__ = wrapper(self, other)
|
| __pow__(self, other)
|
| __radd__(self, other)
|
| __rand__ = wrapper(self, other)
|
| __rdiv__ = __rtruediv__(self, other)
|
| __rfloordiv__(self, other)
|
| __rmod__(self, other)
|
| __rmul__(self, other)
|
| __ror__ = wrapper(self, other)
|
| __rpow__(self, other)
|
| __rsub__(self, other)
|
| __rtruediv__(self, other)
|
| __rxor__ = wrapper(self, other)
|
| __sub__(self, other)
|
| __truediv__(self, other)
|
| __unicode__(self)
| Return a string representation for a particular DataFrame
|
| Invoked by unicode(df) in py2 only. Yields a Unicode String in both
| py2/py3.
|
| __xor__ = wrapper(self, other)
|
| abs(self)
| Return an object with absolute value taken. Only applicable to objects
731
| that are all numeric
|
| 【返回值】
| -------| abs: type of caller
|
| add(self, other, level=None, fill_value=None, axis=0)
| Addition of series and other, element-wise (binary operator</code>add<code>).
|
| Equivalent to ``series + other``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.radd
|
| as_sparse_array(self, kind=None, fill_value=None, copy=False)
| return my self as a sparse array, do not copy by default
|
| combine_first(self, other)
| Combine Series values, choosing the calling Series&#39;s values
| first. Result index will be the union of the two indexes
|
| 【参数】
| ----------| other : Series
|
| 【返回值】
| -------| y : Series
|
| copy(self, deep=True)
| Make a copy of the SparseSeries. Only the actual sparse values need to
| be copied
|
| cumsum(self, axis=0, dtype=None, out=None)
| Cumulative sum of values. Preserves locations of NaN values
|
| 【返回值】
| -------| cumsum : Series or SparseSeries
|
| div = truediv(self, other, level=None, fill_value=None, axis=0)
732
| Floating division of series and other, element-wise (binary operator</code>truediv<code>).
|
| Equivalent to ``series / other``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rtruediv
|
| divide = truediv(self, other, level=None, fill_value=None, axis=0)
| Floating division of series and other, element-wise (binary operator</code>truediv<code>).
|
| Equivalent to ``series / other``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rtruediv
|
| dropna(self, axis=0, inplace=False, **kwargs)
| Analogous to Series.dropna. If fill_value=NaN, returns a dense Series
|
| eq = wrapper(self, other, axis=None)
|
| floordiv(self, other, level=None, fill_value=None, axis=0)
| Integer division of series and other, element-wise (binary operator</code>floordiv<code>).
|
| Equivalent to ``series // other``, but with support to substitute a fill_value for
| missing data in one of the inputs.
733
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rfloordiv
|
| ge = wrapper(self, other, axis=None)
|
| get(self, label, default=None)
| Returns value occupying requested label, default to specified
| missing value if not present. Analogous to dict.get
|
| 【参数】
| ----------| label : object
| Label value looking for
| default : object, optional
| Value to return if label not in index
|
| 【返回值】
| -------| y : scalar
|
| get_value(self, label, takeable=False)
| Retrieve single value at passed index label
|
| 【参数】
| ----------| index : label
| takeable : interpret the index as indexers, default False
|
| 【返回值】
| -------| value : scalar value
|
| get_values(self)
| same as values
|
| gt = wrapper(self, other, axis=None)
|
| le = wrapper(self, other, axis=None)
|
| lt = wrapper(self, other, axis=None)
|
734
| mod(self, other, level=None, fill_value=None, axis=0)
| Modulo of series and other, element-wise (binary operator</code>mod<code>).
|
| Equivalent to ``series % other``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rmod
|
| mul(self, other, level=None, fill_value=None, axis=0)
| Multiplication of series and other, element-wise (binary operator</code>mul<code>).
|
| Equivalent to ``series * other``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rmul
|
| multiply = mul(self, other, level=None, fill_value=None, axis=0)
| Multiplication of series and other, element-wise (binary operator</code>mul<code>).
|
| Equivalent to ``series * other``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
735
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rmul
|
| ne = wrapper(self, other, axis=None)
|
| pow(self, other, level=None, fill_value=None, axis=0)
| Exponential power of series and other, element-wise (binary operator</code>pow<code>).
|
| Equivalent to ``series ** other``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rpow
|
| radd(self, other, level=None, fill_value=None, axis=0)
| Addition of series and other, element-wise (binary operator</code>radd<code>).
|
| Equivalent to ``other + series``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
736
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.add
|
| rdiv = rtruediv(self, other, level=None, fill_value=None, axis=0)
| Floating division of series and other, element-wise (binary operator</code>rtruediv<code>).
|
| Equivalent to ``other / series``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.truediv
|
| reindex(self, index=None, method=None, copy=True, limit=None)
| Conform SparseSeries to new Index
|
| See Series.reindex docstring for general behavior
|
| 【返回值】
| -------| reindexed : SparseSeries
|
| rfloordiv(self, other, level=None, fill_value=None, axis=0)
| Integer division of series and other, element-wise (binary operator</code>rfloordiv<code>).
|
| Equivalent to ``other // series``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
737
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.floordiv
|
| rmod(self, other, level=None, fill_value=None, axis=0)
| Modulo of series and other, element-wise (binary operator</code>rmod<code>).
|
| Equivalent to ``other % series``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.mod
|
| rmul(self, other, level=None, fill_value=None, axis=0)
| Multiplication of series and other, element-wise (binary operator</code>rmul<code>).
|
| Equivalent to ``other * series``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.mul
|
738
| rpow(self, other, level=None, fill_value=None, axis=0)
| Exponential power of series and other, element-wise (binary operator</code>rpow<code>).
|
| Equivalent to ``other ** series``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.pow
|
| rsub(self, other, level=None, fill_value=None, axis=0)
| Subtraction of series and other, element-wise (binary operator</code>rsub<code>).
|
| Equivalent to ``other - series``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.sub
|
| rtruediv(self, other, level=None, fill_value=None, axis=0)
| Floating division of series and other, element-wise (binary operator</code>rtruediv<code>).
|
| Equivalent to ``other / series``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
739
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.truediv
|
| set_value(self, label, value, takeable=False)
| Quickly set single value at passed label. If label is not contained, a
| new object is created with the label placed at the end of the result
| index
|
| 【参数】
| ----------| label : object
| Partial indexing with MultiIndex not allowed
| value : object
| Scalar value
| takeable : interpret the index as indexers, default False
|
| 【注意】
| -----| This method *always* returns a new object. It is not particularly
| efficient but is provided for API compatibility with Series
|
| 【返回值】
| -------| series : SparseSeries
|
| shift(self, periods, freq=None)
| Analogous to Series.shift
|
| sparse_reindex(self, new_index)
| Conform sparse values to new SparseIndex
|
| 【参数】
| ----------| new_index : {BlockIndex, IntIndex}
|
| 【返回值】
| -------| reindexed : SparseSeries
|
| sub(self, other, level=None, fill_value=None, axis=0)
| Subtraction of series and other, element-wise (binary operator</code>sub<code>).
|
| Equivalent to ``series - other``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
740
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rsub
|
| subtract = sub(self, other, level=None, fill_value=None, axis=0)
| Subtraction of series and other, element-wise (binary operator</code>sub<code>).
|
| Equivalent to ``series - other``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rsub
|
| take(self, indices, axis=0, convert=True)
| Sparse-compatible version of ndarray.take
|
| 【返回值】
| -------| taken : ndarray
|
| to_coo(self, row_levels=(0,), column_levels=(1,), sort_labels=False)
| Create a scipy.sparse.coo_matrix from a SparseSeries with MultiIndex.
|
| Use row_levels and column_levels to determine the row and column coordinates respectively.
| row_levels and column_levels are the names (labels) or numbers of the levels.
| {row_levels, column_levels} must be a partition of the MultiIndex level names (or numbers).
|
| .. versionadded:: 0.16.0
741
|
| 【参数】
| ----------| row_levels : tuple/list
| column_levels : tuple/list
| sort_labels : bool, default False
| Sort the row and column labels before forming the sparse matrix.
|
| 【返回值】
| -------| y : scipy.sparse.coo_matrix
| rows : list (row labels)
| columns : list (column labels)
|
| 【示例】
| --------| &gt;&gt;&gt; from numpy import nan
| &gt;&gt;&gt; s = Series([3.0, nan, 1.0, 3.0, nan, nan])
| &gt;&gt;&gt; s.index = MultiIndex.from_tuples([(1, 2, &#39;a&#39;, 0),
| (1, 2, &#39;a&#39;, 1),
| (1, 1, &#39;b&#39;, 0),
| (1, 1, &#39;b&#39;, 1),
| (2, 1, &#39;b&#39;, 0),
| (2, 1, &#39;b&#39;, 1)],
| names=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;])
| &gt;&gt;&gt; ss = s.to_sparse()
| &gt;&gt;&gt; A, rows, columns = ss.to_coo(row_levels=[&#39;A&#39;, &#39;B&#39;],
| column_levels=[&#39;C&#39;, &#39;D&#39;],
| sort_labels=True)
| &gt;&gt;&gt; A
| &lt;3x4 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;
| with 3 stored elements in COOrdinate format&gt;
| &gt;&gt;&gt; A.todense()
| matrix([[ 0., 0., 1., 3.],
| [ 3., 0., 0., 0.],
| [ 0., 0., 0., 0.]])
| &gt;&gt;&gt; rows
| [(1, 1), (1, 2), (2, 1)]
| &gt;&gt;&gt; columns
| [(&#39;a&#39;, 0), (&#39;a&#39;, 1), (&#39;b&#39;, 0), (&#39;b&#39;, 1)]
|
| to_dense(self, sparse_only=False)
| Convert SparseSeries to (dense) Series
|
| truediv(self, other, level=None, fill_value=None, axis=0)
| Floating division of series and other, element-wise (binary operator</code>truediv<code>).
|
| Equivalent to ``series / other``, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
742
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rtruediv
|
| ----------------------------------------------------------------------| Class methods inherited from SparseSeries:
|
| from_array(arr, index=None, name=None, copy=False, fill_value=None, fastpath=False) from builtins.type
| Simplified alternate constructor
|
| from_coo(A, dense_index=False) from builtins.type
| Create a SparseSeries from a scipy.sparse.coo_matrix.
|
| .. versionadded:: 0.16.0
|
| 【参数】
| ----------| A : scipy.sparse.coo_matrix
| dense_index : bool, default False
| If False (default), the SparseSeries index consists of only the coords of the non-null entries of the original
coo_matrix.
| If True, the SparseSeries index consists of the full sorted (row, col) coordinates of the coo_matrix.
|
| 【返回值】
| -------| s : SparseSeries
|
| 【示例】
| ---------| &gt;&gt;&gt; from scipy import sparse
| &gt;&gt;&gt; A = sparse.coo_matrix(([3.0, 1.0, 2.0], ([1, 0, 0], [0, 2, 3])),
| shape=(3, 4))
| &gt;&gt;&gt; A
| &lt;3x4 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;
| with 3 stored elements in COOrdinate format&gt;
| &gt;&gt;&gt; A.todense()
| matrix([[ 0., 0., 1., 2.],
| [ 3., 0., 0., 0.],
| [ 0., 0., 0., 0.]])
| &gt;&gt;&gt; ss = SparseSeries.from_coo(A)
| &gt;&gt;&gt; ss
| 0 2 1
| 3 2
| 1 0 3
| dtype: float64
| BlockIndex
| Block locations: array([0], dtype=int32)
| Block lengths: array([3], dtype=int32)
|
| ----------------------------------------------------------------------
743
| Data descriptors inherited from SparseSeries:
|
| block
|
| density
|
| fill_value
|
| kind
|
| npoints
|
| sp_index
|
| sp_values
|
| values
| return the array
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.series.Series:
|
| __array_prepare__(self, result, context=None)
| Gets called prior to a ufunc
|
| __float__ = wrapper(self)
|
| __int__ = wrapper(self)
|
| __long__ = wrapper(self)
|
| __setitem__(self, key, value)
|
| align(self, other, join=&#39;outer&#39;, axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0,
broadcast_axis=None)
| Align two object on their axes with the
| specified join method for each axis Index
|
| 【参数】
| ----------| other : DataFrame or Series
| join : {&#39;outer&#39;, &#39;inner&#39;, &#39;left&#39;, &#39;right&#39;}, default &#39;outer&#39;
| axis : allowed axis of the other object, default None
| Align on index (0), columns (1), or both (None)
| level : int or level name, default None
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
| copy : boolean, default True
| Always returns new objects. If copy=False and no reindexing is
| required then original objects are returned.
| fill_value : scalar, default np.NaN
| Value to use for missing values. Defaults to NaN, but can be any
| &quot;compatible&quot; value
| method : str, default None
| limit : int, default None
| fill_axis : {0, &#39;index&#39;}, default 0
| Filling axis, method and limit
744
| broadcast_axis : {0, &#39;index&#39;}, default None
| Broadcast values along this axis, if aligning two objects of
| different dimensions
|
| .. versionadded:: 0.17.0
|
| 【返回值】
| -------| (left, right) : (Series, type of other)
| Aligned objects
|
| all(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)
| Return whether all elements are True over requested axis
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| bool_only : boolean, default None
| Include only boolean data. If None, will attempt to use everything,
| then use only boolean data
|
| 【返回值】
| -------| all : scalar or Series (if level specified)
|
| any(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)
| Return whether any element is True over requested axis
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| bool_only : boolean, default None
| Include only boolean data. If None, will attempt to use everything,
| then use only boolean data
|
| 【返回值】
| -------| any : scalar or Series (if level specified)
|
| append(self, to_append, verify_integrity=False)
| Concatenate two or more Series.
|
| 【参数】
| ----------| to_append : Series or list/tuple of Series
745
| verify_integrity : boolean, default False
| If True, raise Exception on creating index with duplicates
|
| 【返回值】
| -------| appended : Series
|
| apply(self, func, convert_dtype=True, args=(), **kwds)
| Invoke function on values of Series. Can be ufunc (a NumPy function
| that applies to the entire Series) or a Python function that only works
| on single values
|
| 【参数】
| ----------| func : function
| convert_dtype : boolean, default True
| Try to find better dtype for elementwise function results. If
| False, leave as dtype=object
| args : tuple
| Positional arguments to pass to function in addition to the value
| Additional keyword arguments will be passed as keywords to the function
|
| 【返回值】
| -------| y : Series or DataFrame if func returns a Series
|
| 【参见】
| --------| Series.map: For element-wise operations
|
| 【示例】
| --------|
| Create a series with typical summer temperatures for each city.
|
| &gt;&gt;&gt; import pandas as pd
| &gt;&gt;&gt; import numpy as np
| &gt;&gt;&gt; series = pd.Series([20, 21, 12], index=[&#39;London&#39;,
| ... &#39;New York&#39;,&#39;Helsinki&#39;])
| London 20
| New York 21
| Helsinki 12
| dtype: int64
|
| Square the values by defining a function and passing it as an
| argument to ``apply()``.
|
| &gt;&gt;&gt; def square(x):
| ... return x**2
| &gt;&gt;&gt; series.apply(square)
| London 400
| New York 441
| Helsinki 144
| dtype: int64
|
| Square the values by passing an anonymous function as an
| argument to ``apply()``.
746
|
| &gt;&gt;&gt; series.apply(lambda x: x**2)
| London 400
| New York 441
| Helsinki 144
| dtype: int64
|
| Define a custom function that needs additional positional
| arguments and pass these additional arguments using the
| ``args`` keyword.
|
| &gt;&gt;&gt; def subtract_custom_value(x, custom_value):
| ... return x-custom_value
|
| &gt;&gt;&gt; series.apply(subtract_custom_value, args=(5,))
| London 15
| New York 16
| Helsinki 7
| dtype: int64
|
| Define a custom function that takes keyword arguments
| and pass these arguments to ``apply``.
|
| &gt;&gt;&gt; def add_custom_values(x, **kwargs):
| ... for month in kwargs:
| ... x+=kwargs[month]
| ... return x
|
| &gt;&gt;&gt; series.apply(add_custom_values, june=30, july=20, august=25)
| London 95
| New York 96
| Helsinki 87
| dtype: int64
|
| Use a function from the Numpy library.
|
| &gt;&gt;&gt; series.apply(np.log)
| London 2.995732
| New York 3.044522
| Helsinki 2.484907
| dtype: float64
|
| argmax = idxmax(self, axis=None, out=None, skipna=True)
| Index of first occurrence of maximum of values.
|
| 【参数】
| ----------| skipna : boolean, default True
| Exclude NA/null values
|
| 【返回值】
| -------| idxmax : Index of maximum of values
|
| 【注意】
| -----| This method is the Series version of ``ndarray.argmax``.
747
|
| 【参见】
| --------| DataFrame.idxmax
| numpy.ndarray.argmax
|
| argmin = idxmin(self, axis=None, out=None, skipna=True)
| Index of first occurrence of minimum of values.
|
| 【参数】
| ----------| skipna : boolean, default True
| Exclude NA/null values
|
| 【返回值】
| -------| idxmin : Index of minimum of values
|
| 【注意】
| -----| This method is the Series version of ``ndarray.argmin``.
|
| 【参见】
| --------| DataFrame.idxmin
| numpy.ndarray.argmin
|
| argsort(self, axis=0, kind=&#39;quicksort&#39;, order=None)
| Overrides ndarray.argsort. Argsorts the value, omitting NA/null values,
| and places the result in the same locations as the non-NA values
|
| 【参数】
| ----------| axis : int (can only be zero)
| kind : {&#39;mergesort&#39;, &#39;quicksort&#39;, &#39;heapsort&#39;}, default &#39;quicksort&#39;
| Choice of sorting algorithm. See np.sort for more
| information. &#39;mergesort&#39; is the only stable algorithm
| order : ignored
|
| 【返回值】
| -------| argsorted : Series, with -1 indicated where nan values are present
|
| 【参见】
| --------| numpy.ndarray.argsort
|
| asof(self, where)
| Return last good (non-NaN) value in Series if value is NaN for
| requested date.
|
| If there is no good value, NaN is returned.
|
| 【参数】
| ----------| where : date or array of dates
748
|
| 【注意】
| -----| Dates are assumed to be sorted
|
| 【返回值】
| -------| value or NaN
|
| autocorr(self, lag=1)
| Lag-N autocorrelation
|
| 【参数】
| ----------| lag : int, default 1
| Number of lags to apply before performing autocorrelation.
|
| 【返回值】
| -------| autocorr : float
|
| between(self, left, right, inclusive=True)
| Return boolean Series equivalent to left &lt;= series &lt;= right. NA values
| will be treated as False
|
| 【参数】
| ----------| left : scalar
| Left boundary
| right : scalar
| Right boundary
|
| 【返回值】
| -------| is_between : Series
|
| combine(self, other, func, fill_value=nan)
| Perform elementwise binary operation on two Series using given function
| with optional fill value when an index is missing from one Series or
| the other
|
| 【参数】
| ----------| other : Series or scalar value
| func : function
| fill_value : scalar value
|
| 【返回值】
| -------| result : Series
|
| compound(self, axis=None, skipna=None, level=None)
| Return the compound percentage of the values for the requested axis
|
| 【参数】
| ----------
749
| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| compounded : scalar or Series (if level specified)
|
| compress(self, condition, axis=0, out=None, **kwargs)
| Return selected slices of an array along given axis as a Series
|
| 【参见】
| --------| numpy.ndarray.compress
|
| corr(self, other, method=&#39;pearson&#39;, min_periods=None)
| Compute correlation with</code>other<code>Series, excluding missing values
|
| 【参数】
| ----------| other : Series
| method : {&#39;pearson&#39;, &#39;kendall&#39;, &#39;spearman&#39;}
| * pearson : standard correlation coefficient
| * kendall : Kendall Tau correlation coefficient
| * spearman : Spearman rank correlation
| min_periods : int, optional
| Minimum number of observations needed to have a valid result
|
|
| 【返回值】
| -------| correlation : float
|
| count(self, level=None)
| Return number of non-NA/null observations in the Series
|
| 【参数】
| ----------| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a smaller Series
|
| 【返回值】
| -------| nobs : int or Series (if level specified)
|
| cov(self, other, min_periods=None)
| Compute covariance with Series, excluding missing values
|
| 【参数】
750
| ----------| other : Series
| min_periods : int, optional
| Minimum number of observations needed to have a valid result
|
| 【返回值】
| -------| covariance : float
|
| Normalized by N-1 (unbiased estimator).
|
| cummax = max(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative max over requested axis.
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| max : scalar
|
| cummin = min(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative min over requested axis.
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| min : scalar
|
| cumprod = prod(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative prod over requested axis.
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| prod : scalar
|
| diff(self, periods=1)
| 1st discrete difference of object
|
751
| 【参数】
| ----------| periods : int, default 1
| Periods to shift for forming difference
|
| 【返回值】
| -------| diffed : Series
|
| dot(self, other)
| Matrix multiplication with DataFrame or inner-product with Series
| objects
|
| 【参数】
| ----------| other : Series or DataFrame
|
| 【返回值】
| -------| dot_product : scalar or Series
|
| drop_duplicates(self, keep=&#39;first&#39;, inplace=False)
| Return Series with duplicate values removed
|
| 【参数】
| ----------|
| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| - ``first`` : Drop duplicates except for the first occurrence.
| - ``last`` : Drop duplicates except for the last occurrence.
| - False : Drop all duplicates.
| take_last : deprecated
| inplace : boolean, default False
| If True, performs operation inplace and returns None.
|
| 【返回值】
| -------| deduplicated : Series
|
| duplicated(self, keep=&#39;first&#39;)
| Return boolean Series denoting duplicate values
|
| 【参数】
| ----------| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| - ``first`` : Mark duplicates as ``True`` except for the first occurrence.
| - ``last`` : Mark duplicates as ``True`` except for the last occurrence.
| - False : Mark all duplicates as ``True``.
| take_last : deprecated
|
| 【返回值】
| -------| duplicated : Series
|
| fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)
| Fill NA/NaN values using the specified method
752
|
| 【参数】
| ----------| value : scalar, dict, Series, or DataFrame
| Value to use to fill holes (e.g. 0), alternately a dict/Series/DataFrame of
| values specifying which value to use for each index (for a Series) or
| column (for a DataFrame). (values not in the dict/Series/DataFrame will not be
| filled). This value cannot be a list.
| method : {&#39;backfill&#39;, &#39;bfill&#39;, &#39;pad&#39;, &#39;ffill&#39;, None}, default None
| Method to use for filling holes in reindexed Series
| pad / ffill: propagate last valid observation forward to next valid
| backfill / bfill: use NEXT valid observation to fill gap
| axis : {0, &#39;index&#39;}
| inplace : boolean, default False
| If True, fill in place. Note: this will modify any
| other views on this object, (e.g. a no-copy slice for a column in a
| DataFrame).
| limit : int, default None
| If method is specified, this is the maximum number of consecutive
| NaN values to forward/backward fill. In other words, if there is
| a gap with more than this number of consecutive NaNs, it will only
| be partially filled. If method is not specified, this is the
| maximum number of entries along the entire axis where NaNs will be
| filled.
| downcast : dict, default is None
| a dict of item-&gt;dtype of what to downcast if possible,
| or the string &#39;infer&#39; which will try to downcast to an appropriate
| equal type (e.g. float64 to int64 if possible)
|
| 【参见】
| --------| reindex, asfreq
|
| 【返回值】
| -------| filled : Series
|
| first_valid_index(self)
| Return label for first non-NA/null value
|
| hist = hist_series(self, by=None, ax=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None,
figsize=None, bins=10, **kwds)
| Draw histogram of the input series using matplotlib
|
| 【参数】
| ----------| by : object, optional
| If passed, then used to form histograms for separate groups
| ax : matplotlib axis object
| If not passed, uses gca()
| grid : boolean, default True
| Whether to show axis grid lines
| xlabelsize : int, default None
| If specified changes the x-axis label size
| xrot : float, default None
| rotation of x axis labels
| ylabelsize : int, default None
753
| If specified changes the y-axis label size
| yrot : float, default None
| rotation of y axis labels
| figsize : tuple, default None
| figure size in inches by default
| bins: integer, default 10
| Number of histogram bins to be used
| kwds : keywords
| To be passed to the actual plotting function
|
| 【注意】
| -----| See matplotlib documentation online for more on this
|
| idxmax(self, axis=None, out=None, skipna=True)
| Index of first occurrence of maximum of values.
|
| 【参数】
| ----------| skipna : boolean, default True
| Exclude NA/null values
|
| 【返回值】
| -------| idxmax : Index of maximum of values
|
| 【注意】
| -----| This method is the Series version of ``ndarray.argmax``.
|
| 【参见】
| --------| DataFrame.idxmax
| numpy.ndarray.argmax
|
| idxmin(self, axis=None, out=None, skipna=True)
| Index of first occurrence of minimum of values.
|
| 【参数】
| ----------| skipna : boolean, default True
| Exclude NA/null values
|
| 【返回值】
| -------| idxmin : Index of minimum of values
|
| 【注意】
| -----| This method is the Series version of ``ndarray.argmin``.
|
| 【参见】
| --------| DataFrame.idxmin
| numpy.ndarray.argmin
|
754
| iget(self, i, axis=0)
| DEPRECATED. Use ``.iloc[i]`` or ``.iat[i]`` instead
|
| iget_value(self, i, axis=0)
| DEPRECATED. Use ``.iloc[i]`` or ``.iat[i]`` instead
|
| irow(self, i, axis=0)
| DEPRECATED. Use ``.iloc[i]`` or ``.iat[i]`` instead
|
| isin(self, values)
| Return a boolean :class:</code>~pandas.Series<code>showing whether each element
| in the :class:</code>~pandas.Series<code>is exactly contained in the passed
| sequence of ``values``.
|
| 【参数】
| ----------| values : list-like
| The sequence of values to test. Passing in a single string will
| raise a ``TypeError``. Instead, turn a single string into a
| ``list`` of one element.
|
| 【返回值】
| -------| isin : Series (bool dtype)
|
| 【Raises 引发错误】
| ------| TypeError
| * If ``values`` is a string
|
| 【参见】
| --------| pandas.DataFrame.isin
|
| 【示例】
| --------|
| &gt;&gt;&gt; s = pd.Series(list(&#39;abc&#39;))
| &gt;&gt;&gt; s.isin([&#39;a&#39;, &#39;c&#39;, &#39;e&#39;])
| 0 True
| 1 False
| 2 True
| dtype: bool
|
| Passing a single string as ``s.isin(&#39;a&#39;)`` will raise an error. Use
| a list of one element instead:
|
| &gt;&gt;&gt; s.isin([&#39;a&#39;])
| 0 True
| 1 False
| 2 False
| dtype: bool
|
| items = iteritems(self)
| Lazily iterate over (index, value) tuples
|
| iteritems(self)
755
| Lazily iterate over (index, value) tuples
|
| keys(self)
| Alias for index
|
| kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return unbiased kurtosis over requested axis using Fishers definition of
| kurtosis (kurtosis of normal == 0.0). Normalized by N-1
|
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| kurt : scalar or Series (if level specified)
|
| kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return unbiased kurtosis over requested axis using Fishers definition of
| kurtosis (kurtosis of normal == 0.0). Normalized by N-1
|
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| kurt : scalar or Series (if level specified)
|
| last_valid_index(self)
| Return label for last non-NA/null value
|
| mad(self, axis=None, skipna=None, level=None)
| Return the mean absolute deviation of the values for the requested axis
|
| 【参数】
| ----------
756
| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| mad : scalar or Series (if level specified)
|
| map(self, arg, na_action=None)
| Map values of Series using input correspondence (which can be
| a dict, Series, or function)
|
| 【参数】
| ----------| arg : function, dict, or Series
| na_action : {None, &#39;ignore&#39;}
| If &#39;ignore&#39;, propagate NA values
|
| 【示例】
| --------| &gt;&gt;&gt; x
| one 1
| two 2
| three 3
|
| &gt;&gt;&gt; y
| 1 foo
| 2 bar
| 3 baz
|
| &gt;&gt;&gt; x.map(y)
| one foo
| two bar
| three baz
|
| 【返回值】
| -------| y : Series
| same index as caller
|
| max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| This method returns the maximum of the values in the object. If you
| want the *index* of the maximum, use ``idxmax``. This is the
| equivalent of the ``numpy.ndarray`` method ``argmax``.
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
757
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| max : scalar or Series (if level specified)
|
| mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the mean of the values for the requested axis
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| mean : scalar or Series (if level specified)
|
| median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the median of the values for the requested axis
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| median : scalar or Series (if level specified)
|
| memory_usage(self, index=False, deep=False)
| Memory usage of the Series
|
| 【参数】
| ----------
758
| index : bool
| Specifies whether to include memory usage of Series index
| deep : bool
| Introspect the data deeply, interrogate
|</code>object<code>dtypes for system-level memory consumption
|
| 【返回值】
| -------| scalar bytes of memory consumed
|
| 【注意】
| -----| Memory usage does not include memory consumed by elements that
| are not components of the array if deep=False
|
| 【参见】
| --------| numpy.ndarray.nbytes
|
| min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| This method returns the minimum of the values in the object. If you
| want the *index* of the minimum, use ``idxmin``. This is the
| equivalent of the ``numpy.ndarray`` method ``argmin``.
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| min : scalar or Series (if level specified)
|
| mode(self)
| Returns the mode(s) of the dataset.
|
| Empty if nothing occurs at least 2 times. Always returns Series even
| if only one value.
|
| 【参数】
| ----------| sort : bool, default True
| If True, will lexicographically sort values, if False skips
| sorting. Result ordering when ``sort=False`` is not defined.
|
| 【返回值】
| -------| modes : Series (sorted)
|
759
| nlargest(self, n=5, keep=&#39;first&#39;)
| Return the largest</code>n<code>elements.
|
| 【参数】
| ----------| n : int
| Return this many descending sorted values
| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| Where there are duplicate values:
| - ``first`` : take the first occurrence.
| - ``last`` : take the last occurrence.
| take_last : deprecated
|
| 【返回值】
| -------| top_n : Series
| The n largest values in the Series, in sorted order
|
| 【注意】
| -----| Faster than ``.sort_values(ascending=False).head(n)`` for small</code>n<code>relative
| to the size of the ``Series`` object.
|
| 【参见】
| --------| Series.nsmallest
|
| 【示例】
| --------| &gt;&gt;&gt; import pandas as pd
| &gt;&gt;&gt; import numpy as np
| &gt;&gt;&gt; s = pd.Series(np.random.randn(1e6))
| &gt;&gt;&gt; s.nlargest(10) # only sorts up to the N requested
|
| nonzero(self)
| Return the indices of the elements that are non-zero
|
| This method is equivalent to calling</code>numpy.nonzero<code>on the
| series data. For compatability with NumPy, the return value is
| the same (a tuple with an array of indices for each dimension),
| but it will always be a one-item tuple because series only have
| one dimension.
|
| 【示例】
| --------| &gt;&gt;&gt; s = pd.Series([0, 3, 0, 4])
| &gt;&gt;&gt; s.nonzero()
| (array([1, 3]),)
| &gt;&gt;&gt; s.iloc[s.nonzero()[0]]
| 1 3
| 3 4
| dtype: int64
|
| 【参见】
| --------| numpy.nonzero
|
760
| nsmallest(self, n=5, keep=&#39;first&#39;)
| Return the smallest</code>n<code>elements.
|
| 【参数】
| ----------| n : int
| Return this many ascending sorted values
| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| Where there are duplicate values:
| - ``first`` : take the first occurrence.
| - ``last`` : take the last occurrence.
| take_last : deprecated
|
| 【返回值】
| -------| bottom_n : Series
| The n smallest values in the Series, in sorted order
|
| 【注意】
| -----| Faster than ``.sort_values().head(n)`` for small</code>n<code>relative to
| the size of the ``Series`` object.
|
| 【参见】
| --------| Series.nlargest
|
| 【示例】
| --------| &gt;&gt;&gt; import pandas as pd
| &gt;&gt;&gt; import numpy as np
| &gt;&gt;&gt; s = pd.Series(np.random.randn(1e6))
| &gt;&gt;&gt; s.nsmallest(10) # only sorts up to the N requested
|
| order(self, na_last=None, ascending=True, kind=&#39;quicksort&#39;, na_position=&#39;last&#39;, inplace=False)
| DEPRECATED: use :meth:</code>Series.sort_values<code>|
| Sorts Series object, by value, maintaining index-value link.
| This will return a new Series by default. Series.sort is the equivalent but as an inplace method.
|
| 【参数】
| ----------| na_last : boolean (optional, default=True) (DEPRECATED; use na_position)
| Put NaN&#39;s at beginning or end
| ascending : boolean, default True
| Sort ascending. Passing False sorts descending
| kind : {&#39;mergesort&#39;, &#39;quicksort&#39;, &#39;heapsort&#39;}, default &#39;quicksort&#39;
| Choice of sorting algorithm. See np.sort for more
| information. &#39;mergesort&#39; is the only stable algorithm
| na_position : {&#39;first&#39;, &#39;last&#39;} (optional, default=&#39;last&#39;)
| &#39;first&#39; puts NaNs at the beginning
| &#39;last&#39; puts NaNs at the end
| inplace : boolean, default False
| Do operation in place.
|
| 【返回值】
| -------
761
| y : Series
|
| 【参见】
| --------| Series.sort_values
|
| prod(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the product of the values for the requested axis
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| prod : scalar or Series (if level specified)
|
| product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the product of the values for the requested axis
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| prod : scalar or Series (if level specified)
|
| ptp(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Returns the difference between the maximum value and the minimum
| value in the object. This is the equivalent of the ``numpy.ndarray``
| method ``ptp``.
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
762
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| ptp : scalar or Series (if level specified)
|
| put(self, *args, **kwargs)
| return a ndarray with the values put
|
| 【参见】
| --------| numpy.ndarray.put
|
| quantile(self, q=0.5)
| Return value at the given quantile, a la numpy.percentile.
|
| 【参数】
| ----------| q : float or array-like, default 0.5 (50% quantile)
| 0 &lt;= q &lt;= 1, the quantile(s) to compute
|
| 【返回值】
| -------| quantile : float or Series
| if ``q`` is an array, a Series will be returned where the
| index is ``q`` and the values are the quantiles.
|
| 【示例】
| --------|
| &gt;&gt;&gt; s = Series([1, 2, 3, 4])
| &gt;&gt;&gt; s.quantile(.5)
| 2.5
| &gt;&gt;&gt; s.quantile([.25, .5, .75])
| 0.25 1.75
| 0.50 2.50
| 0.75 3.25
| dtype: float64
|
| rank(self, method=&#39;average&#39;, na_option=&#39;keep&#39;, ascending=True, pct=False)
| Compute data ranks (1 through n). Equal values are assigned a rank that
| is the average of the ranks of those values
|
| 【参数】
| ----------| method : {&#39;average&#39;, &#39;min&#39;, &#39;max&#39;, &#39;first&#39;, &#39;dense&#39;}
| * average: average rank of group
| * min: lowest rank in group
| * max: highest rank in group
| * first: ranks assigned in order they appear in the array
| * dense: like &#39;min&#39;, but rank always increases by 1 between groups
| na_option : {&#39;keep&#39;}
763
| keep: leave NA values where they are
| ascending : boolean, default True
| False for ranks by high (1) to low (N)
| pct : boolean, default False
| Computes percentage rank of data
|
| 【返回值】
| -------| ranks : Series
|
| ravel(self, order=&#39;C&#39;)
| Return the flattened underlying data as an ndarray
|
| 【参见】
| --------| numpy.ndarray.ravel
|
| reindex_axis(self, labels, axis=0, **kwargs)
| for compatibility with higher dims
|
| rename(self, index=None, **kwargs)
| Alter axes input function or functions. Function / dict values must be
| unique (1-to-1). Labels not contained in a dict / Series will be left
| as-is.
|
| 【参数】
| ----------| index : dict-like or function, optional
| Transformation to apply to that axis values
|
| copy : boolean, default True
| Also copy underlying data
| inplace : boolean, default False
| Whether to return a new Series. If True then value of copy is
| ignored.
|
| 【返回值】
| -------| renamed : Series (new object)
|
| reorder_levels(self, order)
| Rearrange index levels using input order. May not drop or duplicate
| levels
|
| 【参数】
| ----------| order: list of int representing new level order.
| (reference level by number or key)
| axis: where to reorder levels
|
| 【返回值】
| -------| type of caller (new object)
|
| repeat(self, reps)
| return a new Series with the values repeated reps times
|
764
| 【参见】
| --------| numpy.ndarray.repeat
|
| reset_index(self, level=None, drop=False, name=None, inplace=False)
| Analogous to the :meth:</code>pandas.DataFrame.reset_index<code>function, see
| docstring there.
|
| 【参数】
| ----------| level : int, str, tuple, or list, default None
| Only remove the given levels from the index. Removes all levels by
| default
| drop : boolean, default False
| Do not try to insert index into dataframe columns
| name : object, default None
| The name of the column corresponding to the Series values
| inplace : boolean, default False
| Modify the Series in place (do not create a new object)
|
| 【返回值】
| ----------| resetted : DataFrame, or Series if drop == True
|
| reshape(self, *args, **kwargs)
| return an ndarray with the values shape
| if the specified shape matches exactly the current shape, then
| return self (for compat)
|
| 【参见】
| --------| numpy.ndarray.take
|
| round(self, decimals=0, out=None)
| a.round(decimals=0, out=None)
|
| Return</code>a<code>with each element rounded to the given number of decimals.
|
| Refer to</code>numpy.around<code>for full documentation.
|
| 【参见】
| --------| numpy.around : equivalent function
|
| searchsorted(self, v, side=&#39;left&#39;, sorter=None)
| Find indices where elements should be inserted to maintain order.
|
| Find the indices into a sorted Series</code>self<code>such that, if the
| corresponding elements in</code>v<code>were inserted before the indices, the
| order of</code>self<code>would be preserved.
|
| 【参数】
| ----------| v : array_like
| Values to insert into</code>a<code>.
| side : {&#39;left&#39;, &#39;right&#39;}, optional
| If &#39;left&#39;, the index of the first suitable location found is given.
765
| If &#39;right&#39;, return the last such index. If there is no suitable
| index, return either 0 or N (where N is the length of</code>a<code>).
| sorter : 1-D array_like, optional
| Optional array of integer indices that sort</code>self<code>into ascending
| order. They are typically the result of ``np.argsort``.
|
| 【返回值】
| -------| indices : array of ints
| Array of insertion points with the same shape as</code>v<code>.
|
| 【参见】
| --------| Series.sort_values
| numpy.searchsorted
|
| 【注意】
| -----| Binary search is used to find the required insertion points.
|
| 【示例】
| --------| &gt;&gt;&gt; x = pd.Series([1, 2, 3])
| &gt;&gt;&gt; x
| 0 1
| 1 2
| 2 3
| dtype: int64
| &gt;&gt;&gt; x.searchsorted(4)
| array([3])
| &gt;&gt;&gt; x.searchsorted([0, 4])
| array([0, 3])
| &gt;&gt;&gt; x.searchsorted([1, 3], side=&#39;left&#39;)
| array([0, 2])
| &gt;&gt;&gt; x.searchsorted([1, 3], side=&#39;right&#39;)
| array([1, 3])
| &gt;&gt;&gt; x.searchsorted([1, 2], side=&#39;right&#39;, sorter=[0, 2, 1])
| array([1, 3])
|
| sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)
| Return unbiased standard error of the mean over requested axis.
|
| Normalized by N-1 by default. This can be changed using the ddof argument
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| ddof : int, default 1
| degrees of freedom
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
766
| everything, then use only numeric data
|
| 【返回值】
| -------| sem : scalar or Series (if level specified)
|
| skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return unbiased skew over requested axis
| Normalized by N-1
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| skew : scalar or Series (if level specified)
|
| sort(self, axis=0, ascending=True, kind=&#39;quicksort&#39;, na_position=&#39;last&#39;, inplace=True)
| DEPRECATED: use :meth:</code>Series.sort_values(inplace=True)<code>for INPLACE sorting
|
| Sort values and index labels by value. This is an inplace sort by default.
| Series.order is the equivalent but returns a new Series.
|
| 【参数】
| ----------| axis : int (can only be zero)
| ascending : boolean, default True
| Sort ascending. Passing False sorts descending
| kind : {&#39;mergesort&#39;, &#39;quicksort&#39;, &#39;heapsort&#39;}, default &#39;quicksort&#39;
| Choice of sorting algorithm. See np.sort for more
| information. &#39;mergesort&#39; is the only stable algorithm
| na_position : {&#39;first&#39;, &#39;last&#39;} (optional, default=&#39;last&#39;)
| &#39;first&#39; puts NaNs at the beginning
| &#39;last&#39; puts NaNs at the end
| inplace : boolean, default True
| Do operation in place.
|
| 【参见】
| --------| Series.sort_values
|
| sort_index(self, axis=0, level=None, ascending=True, inplace=False, sort_remaining=True)
| Sort object by labels (along an axis)
|
| 【参数】
| ----------| axis : index to direct sorting
767
| level : int or level name or list of ints or list of level names
| if not None, sort on values in specified index level(s)
| ascending : boolean, default True
| Sort ascending vs. descending
| inplace : bool
| if True, perform operation in-place
| kind : {</code>quicksort<code>,</code>mergesort<code>,</code>heapsort<code>}
| Choice of sorting algorithm. 参见：ndarray.np.sort for more information.
|</code>mergesort<code>is the only stable algorithm. For DataFrames, this option is
| only applied when sorting on a single column or label.
| na_position : {&#39;first&#39;, &#39;last&#39;}
|</code>first<code>puts NaNs at the beginning,</code>last<code>puts NaNs at the end
| sort_remaining : bool
| if true and sorting by level and index is multilevel, sort by other levels
| too (in order) after sorting by specified level
|
| 【返回值】
| -------| sorted_obj : Series
|
| sort_values(self, axis=0, ascending=True, inplace=False, kind=&#39;quicksort&#39;, na_position=&#39;last&#39;)
| Sort by the values along either axis
|
| .. versionadded:: 0.17.0
|
| 【参数】
| ----------| by : string name or list of names which refer to the axis items
| axis : index to direct sorting
| ascending : bool or list of bool
| Sort ascending vs. descending. Specify list for multiple sort orders.
| If this is a list of bools, must match the length of the by
| inplace : bool
| if True, perform operation in-place
| kind : {</code>quicksort<code>,</code>mergesort<code>,</code>heapsort<code>}
| Choice of sorting algorithm. 参见：ndarray.np.sort for more information.
|</code>mergesort<code>is the only stable algorithm. For DataFrames, this option is
| only applied when sorting on a single column or label.
| na_position : {&#39;first&#39;, &#39;last&#39;}
|</code>first<code>puts NaNs at the beginning,</code>last<code>puts NaNs at the end
|
| 【返回值】
| -------| sorted_obj : Series
|
| sortlevel(self, level=0, ascending=True, sort_remaining=True)
| Sort Series with MultiIndex by chosen level. Data will be
| lexicographically sorted by the chosen level followed by the other
| levels (in order)
|
| 【参数】
| ----------| level : int or level name, default None
| ascending : bool, default True
|
| 【返回值】
| -------
768
| sorted : Series
|
| 【参见】
| --------| Series.sort_index(level=...)
|
| std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)
| Return unbiased standard deviation over requested axis.
|
| Normalized by N-1 by default. This can be changed using the ddof argument
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| ddof : int, default 1
| degrees of freedom
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| std : scalar or Series (if level specified)
|
| sum(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the sum of the values for the requested axis
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| sum : scalar or Series (if level specified)
|
| swaplevel(self, i, j, copy=True)
| Swap levels i and j in a MultiIndex
|
| 【参数】
| ----------| i, j : int, string (can be mixed)
| Level of index to be swapped. Can pass level name as string.
769
|
| 【返回值】
| -------| swapped : Series
|
| to_csv(self, path, index=True, sep=&#39;,&#39;, na_rep=&#39;&#39;, float_format=None, header=False, index_label=None, mode=&#39;w&#39;,
nanRep=None, encoding=None, date_format=None, decimal=&#39;.&#39;)
| Write Series to a comma-separated values (csv) file
|
| 【参数】
| ----------| path : string file path or file handle / StringIO. If None is provided
| the result is returned as a string.
| na_rep : string, default &#39;&#39;
| Missing data representation
| float_format : string, default None
| Format string for floating point numbers
| header : boolean, default False
| Write out series name
| index : boolean, default True
| Write row names (index)
| index_label : string or sequence, default None
| Column label for index column(s) if desired. If None is given, and
|</code>header<code>and</code>index<code>are True, then the index names are used. A
| sequence should be given if the DataFrame uses MultiIndex.
| mode : Python write mode, default &#39;w&#39;
| sep : character, default &quot;,&quot;
| Field delimiter for the output file.
| encoding : string, optional
| a string representing the encoding to use if the contents are
| non-ascii, for python versions prior to 3
| date_format: string, default None
| Format string for datetime objects.
| decimal: string, default &#39;.&#39;
| Character recognized as decimal separator. E.g. use &#39;,&#39; for European data
|
| to_dict(self)
| Convert Series to {label -&gt; value} dict
|
| 【返回值】
| -------| value_dict : dict
|
| to_frame(self, name=None)
| Convert Series to DataFrame
|
| 【参数】
| ----------| name : object, default None
| The passed name should substitute for the series name (if it has
| one).
|
| 【返回值】
| -------| data_frame : DataFrame
|
| to_period(self, freq=None, copy=True)
770
| Convert Series from DatetimeIndex to PeriodIndex with desired
| frequency (inferred from index if not passed)
|
| 【参数】
| ----------| freq : string, default
|
| 【返回值】
| -------| ts : Series with PeriodIndex
|
| to_sparse(self, kind=&#39;block&#39;, fill_value=None)
| Convert Series to SparseSeries
|
| 【参数】
| ----------| kind : {&#39;block&#39;, &#39;integer&#39;}
| fill_value : float, defaults to NaN (missing)
|
| 【返回值】
| -------| sp : SparseSeries
|
| to_string(self, buf=None, na_rep=&#39;NaN&#39;, float_format=None, header=True, length=False, dtype=False, name=False,
max_rows=None)
| Render a string representation of the Series
|
| 【参数】
| ----------| buf : StringIO-like, optional
| buffer to write to
| na_rep : string, optional
| string representation of NAN to use, default &#39;NaN&#39;
| float_format : one-parameter function, optional
| formatter function to apply to columns&#39; elements if they are floats
| default None
| header: boolean, default True
| Add the Series header (index name)
| length : boolean, default False
| Add the Series length
| dtype : boolean, default False
| Add the Series dtype
| name : boolean, default False
| Add the Series name if not None
| max_rows : int, optional
| Maximum number of rows to show before truncating. If None, show
| all.
|
| 【返回值】
| -------| formatted : string (if not buffer passed)
|
| to_timestamp(self, freq=None, how=&#39;start&#39;, copy=True)
| Cast to datetimeindex of timestamps, at *beginning* of period
|
| 【参数】
| ----------
771
| freq : string, default frequency of PeriodIndex
| Desired frequency
| how : {&#39;s&#39;, &#39;e&#39;, &#39;start&#39;, &#39;end&#39;}
| Convention for converting period to timestamp; start of period
| vs. end
|
| 【返回值】
| -------| ts : Series with DatetimeIndex
|
| tolist(self)
| Convert Series to a nested list
|
| unstack(self, level=-1)
| Unstack, a.k.a. pivot, Series with MultiIndex to produce DataFrame.
| The level involved will automatically get sorted.
|
| 【参数】
| ----------| level : int, string, or list of these, default last level
| Level(s) to unstack, can pass level name
|
| 【示例】
| --------| &gt;&gt;&gt; s
| one a 1.
| one b 2.
| two a 3.
| two b 4.
|
| &gt;&gt;&gt; s.unstack(level=-1)
| a b
| one 1. 2.
| two 3. 4.
|
| &gt;&gt;&gt; s.unstack(level=0)
| one two
| a 1. 2.
| b 3. 4.
|
| 【返回值】
| -------| unstacked : DataFrame
|
| update(self, other)
| Modify Series in place using non-NA values from passed
| Series. Aligns on index
|
| 【参数】
| ----------| other : Series
|
| valid lambda self, inplace=False, **kwargs
|
| var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)
| Return unbiased variance over requested axis.
|
772
| Normalized by N-1 by default. This can be changed using the ddof argument
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| ddof : int, default 1
| degrees of freedom
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| var : scalar or Series (if level specified)
|
| view(self, dtype=None)
|
| ----------------------------------------------------------------------| Class methods inherited from pandas.core.series.Series:
|
| from_csv(path, sep=&#39;,&#39;, parse_dates=True, header=None, index_col=0, encoding=None, infer_datetime_format=False) from
builtins.type
| Read CSV file (DISCOURAGED, please use :func:</code>pandas.read_csv<code>instead).
|
| It is preferable to use the more powerful :func:</code>pandas.read_csv<code>| for most general purposes, but ``from_csv`` makes for an easy
| roundtrip to and from a file (the exact counterpart of
| ``to_csv``), especially with a time Series.
|
| This method only differs from :func:</code>pandas.read_csv<code>in some defaults:
|
| -</code>index_col<code>is ``0`` instead of ``None`` (take first column as index
| by default)
| -</code>header<code>is ``None`` instead of ``0`` (the first row is not used as
| the column names)
| -</code>parse_dates<code>is ``True`` instead of ``False`` (try parsing the index
| as datetime by default)
|
| With :func:</code>pandas.read_csv<code>, the option ``squeeze=True`` can be used
| to return a Series like ``from_csv``.
|
| 【参数】
| ----------| path : string file path or file handle / StringIO
| sep : string, default &#39;,&#39;
| Field delimiter
| parse_dates : boolean, default True
| Parse dates. Different default from read_table
| header : int, default None
| Row to use as header (skip prior rows)
| index_col : int or sequence, default 0
773
| Column to use for index. If a sequence is given, a MultiIndex
| is used. Different default from read_table
| encoding : string, optional
| a string representing the encoding to use if the contents are
| non-ascii, for python versions prior to 3
| infer_datetime_format: boolean, default False
| If True and</code>parse_dates<code>is True for a column, try to infer the
| datetime format based on the first datetime string. If the format
| can be inferred, there often will be a large parsing speed-up.
|
| 【参见】
| --------| pandas.read_csv
|
| 【返回值】
| -------| y : Series
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.series.Series:
|
| axes
| Return a list of the row axis labels
|
| dtype
| return the dtype object of the underlying data
|
| dtypes
| return the dtype object of the underlying data
|
| ftype
| return if the data is sparse|dense
|
| ftypes
| return if the data is sparse|dense
|
| imag
|
| index
|
| is_time_series
|
| real
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.series.Series:
|
| cat = &lt;class &#39;pandas.core.categorical.CategoricalAccessor&#39;&gt;
| Accessor object for categorical properties of the Series values.
|
| Be aware that assigning to</code>categories<code>is a inplace operation, while all methods return
| new categorical data per default (but can be called with</code>inplace=True<code>).
|
| 【示例】
| --------| &gt;&gt;&gt; s.cat.categories
| &gt;&gt;&gt; s.cat.categories = list(&#39;abc&#39;)
774
| &gt;&gt;&gt; s.cat.rename_categories(list(&#39;cab&#39;))
| &gt;&gt;&gt; s.cat.reorder_categories(list(&#39;cab&#39;))
| &gt;&gt;&gt; s.cat.add_categories([&#39;d&#39;,&#39;e&#39;])
| &gt;&gt;&gt; s.cat.remove_categories([&#39;d&#39;])
| &gt;&gt;&gt; s.cat.remove_unused_categories()
| &gt;&gt;&gt; s.cat.set_categories(list(&#39;abcde&#39;))
| &gt;&gt;&gt; s.cat.as_ordered()
| &gt;&gt;&gt; s.cat.as_unordered()
|
| dt = &lt;class &#39;pandas.tseries.common.CombinedDatetimelikeProperties&#39;&gt;
| Accessor object for datetimelike properties of the Series values.
|
| 【示例】
| --------| &gt;&gt;&gt; s.dt.hour
| &gt;&gt;&gt; s.dt.second
| &gt;&gt;&gt; s.dt.quarter
|
| Returns a Series indexed like the original Series.
| Raises TypeError if the Series does not contain datetimelike values.
|
| plot = &lt;class &#39;pandas.tools.plotting.SeriesPlotMethods&#39;&gt;
| Series plotting accessor and method
|
| 【示例】
| --------| &gt;&gt;&gt; s.plot.line()
| &gt;&gt;&gt; s.plot.bar()
| &gt;&gt;&gt; s.plot.hist()
|
| Plotting methods can also be accessed by calling the accessor as a method
| with the ``kind`` argument:
| ``s.plot(kind=&#39;line&#39;)`` is equivalent to ``s.plot.line()``
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.IndexOpsMixin:
|
| factorize(self, sort=False, na_sentinel=-1)
| Encode the object as an enumerated type or categorical variable
|
| 【参数】
| ----------| sort : boolean, default False
| Sort by values
| na_sentinel: int, default -1
| Value to mark &quot;not found&quot;
|
| 【返回值】
| -------| labels : the indexer to the original array
| uniques : the unique Index
|
| item(self)
| return the first element of the underlying data as a python scalar
|
| nunique(self, dropna=True)
| Return number of unique elements in the object.
775
|
| Excludes NA values by default.
|
| 【参数】
| ----------| dropna : boolean, default True
| Don&#39;t include NaN in the count.
|
| 【返回值】
| -------| nunique : int
|
| transpose(self)
| return the transpose, which is by definition self
|
| unique(self)
| Return array of unique values in the object. Significantly faster than
| numpy.unique. Includes NA values.
|
| 【返回值】
| -------| uniques : ndarray
|
| value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)
| Returns object containing counts of unique values.
|
| The resulting object will be in descending order so that the
| first element is the most frequently-occurring element.
| Excludes NA values by default.
|
| 【参数】
| ----------| normalize : boolean, default False
| If True then the object returned will contain the relative
| frequencies of the unique values.
| sort : boolean, default True
| Sort by values
| ascending : boolean, default False
| Sort in ascending order
| bins : integer, optional
| Rather than count values, group them into half-open bins,
| a convenience for pd.cut, only works with numeric data
| dropna : boolean, default True
| Don&#39;t include counts of NaN.
|
| 【返回值】
| -------| counts : Series
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.base.IndexOpsMixin:
|
| T
| return the transpose, which is by definition self
|
| __dict__
| dictionary for instance variables (if defined)
776
|
| __weakref__
| list of weak references to the object (if defined)
|
| base
| return the base object if the memory of the underlying data is shared
|
| data
| return the data pointer of the underlying data
|
| flags
| return the ndarray.flags for the underlying data
|
| hasnans
|
| itemsize
| return the size of the dtype of the item of the underlying data
|
| nbytes
| return the number of bytes in the underlying data
|
| ndim
| return the number of dimensions of the underlying data, by definition 1
|
| shape
| return a tuple of the shape of the underlying data
|
| size
| return the number of elements in the underlying data
|
| strides
| return the strides of the underlying data
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.base.IndexOpsMixin:
|
| __array_priority__ = 1000
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.strings.StringAccessorMixin:
|
| str = &lt;class &#39;pandas.core.strings.StringMethods&#39;&gt;
| Vectorized string functions for Series and Index. NAs stay NA unless
| handled otherwise by a particular method. Patterned after Python&#39;s string
| methods, with some inspiration from R&#39;s stringr package.
|
| 【示例】
| --------| &gt;&gt;&gt; s.str.split(&#39;_&#39;)
| &gt;&gt;&gt; s.str.replace(&#39;_&#39;, &#39;&#39;)
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.generic.NDFrame:
|
| __abs__(self)
|
| __bool__ = __nonzero__(self)
777
|
| __contains__(self, key)
| True if the key is in the info axis
|
| __delitem__(self, key)
| Delete item
|
| __finalize__(self, other, method=None, **kwargs)
| propagate metadata from other to self
|
| 【参数】
| ----------| other : the object from which to get the attributes that we are going
| to propagate
| method : optional, a passed method name ; possibly to take different
| types of propagation actions based on this
|
| __getattr__(self, name)
| After regular attribute access, try looking up the name
| This allows simpler access to columns for interactive use.
|
| __hash__(self)
| Return hash(self).
|
| __invert__(self)
|
| __neg__(self)
|
| __nonzero__(self)
|
| __setattr__(self, name, value)
| After regular attribute access, try setting the name
| This allows simpler access to columns for interactive use.
|
| __setstate__(self, state)
|
| add_prefix(self, prefix)
| Concatenate prefix string with panel items names.
|
| 【参数】
| ----------| prefix : string
|
| 【返回值】
| -------| with_prefix : type of caller
|
| add_suffix(self, suffix)
| Concatenate suffix string with panel items names
|
| 【参数】
| ----------| suffix : string
|
| 【返回值】
| -------| with_suffix : type of caller
778
|
| as_blocks(self, copy=True)
| Convert the frame to a dict of dtype -&gt; Constructor Types that each has
| a homogeneous dtype.
|
| NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in
| as_matrix)
|
| 【参数】
| ----------| copy : boolean, default True
|
| .. versionadded: 0.16.1
|
| 【返回值】
| -------| values : a dict of dtype -&gt; Constructor Types
|
| as_matrix(self, columns=None)
| Convert the frame to its Numpy-array representation.
|
| 【参数】
| ----------| columns: list, optional, default:None
| If None, return all columns, otherwise, returns specified columns.
|
| 【返回值】
| -------| values : ndarray
| If the caller is heterogeneous and contains booleans or objects,
| the result will be of dtype=object. See Notes.
|
|
| 【注意】
| -----| Return is NOT a Numpy-matrix, rather, a Numpy-array.
|
| The dtype will be a lower-common-denominator dtype (implicit
| upcasting); that is to say if the dtypes (even of numeric types)
| are mixed, the one that accommodates all will be chosen. Use this
| with care if you are not dealing with the blocks.
|
| e.g. If the dtypes are float16 and float32, dtype will be upcast to
| float32. If dtypes are int32 and uint8, dtype will be upcase to
| int32.
|
| This method is provided for backwards compatibility. Generally,
| it is recommended to use &#39;.values&#39;.
|
| 【参见】
| --------| pandas.DataFrame.values
|
| asfreq(self, freq, method=None, how=None, normalize=False)
| Convert all TimeSeries inside to specified frequency using DateOffset
| objects. Optionally provide fill method to pad/backfill missing values.
|
779
| 【参数】
| ----------| freq : DateOffset object, or string
| method : {&#39;backfill&#39;, &#39;bfill&#39;, &#39;pad&#39;, &#39;ffill&#39;, None}
| Method to use for filling holes in reindexed Series
| pad / ffill: propagate last valid observation forward to next valid
| backfill / bfill: use NEXT valid observation to fill method
| how : {&#39;start&#39;, &#39;end&#39;}, default end
| For PeriodIndex only, see PeriodIndex.asfreq
| normalize : bool, default False
| Whether to reset output index to midnight
|
| 【返回值】
| -------| converted : type of caller
|
| astype(self, dtype, copy=True, raise_on_error=True, **kwargs)
| Cast object to input numpy.dtype
| Return a copy when copy = True (be really careful with this!)
|
| 【参数】
| ----------| dtype : numpy.dtype or Python type
| raise_on_error : raise on invalid input
| kwargs : keyword arguments to pass on to the constructor
|
| 【返回值】
| -------| casted : type of caller
|
| at_time(self, time, asof=False)
| Select values at particular time of day (e.g. 9:30AM)
|
| 【参数】
| ----------| time : datetime.time or string
|
| 【返回值】
| -------| values_at_time : type of caller
|
| between_time(self, start_time, end_time, include_start=True, include_end=True)
| Select values between particular times of the day (e.g., 9:00-9:30 AM)
|
| 【参数】
| ----------| start_time : datetime.time or string
| end_time : datetime.time or string
| include_start : boolean, default True
| include_end : boolean, default True
|
| 【返回值】
| -------| values_between_time : type of caller
|
| bfill(self, axis=None, inplace=False, limit=None, downcast=None)
780
| Synonym for NDFrame.fillna(method=&#39;bfill&#39;)
|
| bool(self)
| Return the bool of a single element PandasObject
| This must be a boolean scalar value, either True or False
|
| Raise a ValueError if the PandasObject does not have exactly
| 1 element, or that element is not boolean
|
| clip(self, lower=None, upper=None, out=None, axis=None)
| Trim values at input threshold(s)
|
| 【参数】
| ----------| lower : float or array_like, default None
| upper : float or array_like, default None
| axis : int or string axis name, optional
| Align object with lower and upper along the given axis.
|
| 【返回值】
| -------| clipped : Series
|
| 【示例】
| --------| &gt;&gt;&gt; df
| 0 1
| 0 0.335232 -1.256177
| 1 -1.367855 0.746646
| 2 0.027753 -1.176076
| 3 0.230930 -0.679613
| 4 1.261967 0.570967
| &gt;&gt;&gt; df.clip(-1.0, 0.5)
| 0 1
| 0 0.335232 -1.000000
| 1 -1.000000 0.500000
| 2 0.027753 -1.000000
| 3 0.230930 -0.679613
| 4 0.500000 0.500000
| &gt;&gt;&gt; t
| 0 -0.3
| 1 -0.2
| 2 -0.1
| 3 0.0
| 4 0.1
| dtype: float64
| &gt;&gt;&gt; df.clip(t, t + 1, axis=0)
| 0 1
| 0 0.335232 -0.300000
| 1 -0.200000 0.746646
| 2 0.027753 -0.100000
| 3 0.230930 0.000000
| 4 1.100000 0.570967
|
| clip_lower(self, threshold, axis=None)
| Return copy of the input with values below given value(s) truncated
|
781
| 【参数】
| ----------| threshold : float or array_like
| axis : int or string axis name, optional
| Align object with threshold along the given axis.
|
| 【参见】
| --------| clip
|
| 【返回值】
| -------| clipped : same type as input
|
| clip_upper(self, threshold, axis=None)
| Return copy of input with values above given value(s) truncated
|
| 【参数】
| ----------| threshold : float or array_like
| axis : int or string axis name, optional
| Align object with threshold along the given axis.
|
| 【参见】
| --------| clip
|
| 【返回值】
| -------| clipped : same type as input
|
| consolidate(self, inplace=False)
| Compute NDFrame with &quot;consolidated&quot; internals (data of each dtype
| grouped together in a single ndarray). Mainly an internal API function,
| but available here to the savvy user
|
| 【参数】
| ----------| inplace : boolean, default False
| If False return new object, otherwise modify existing object
|
| 【返回值】
| -------| consolidated : type of caller
|
| convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)
| Attempt to infer better dtype for object columns
|
| 【参数】
| ----------| convert_dates : boolean, default True
| If True, convert to date where possible. If &#39;coerce&#39;, force
| conversion, with unconvertible values becoming NaT.
| convert_numeric : boolean, default False
| If True, attempt to coerce to numbers (including strings), with
| unconvertible values becoming NaN.
782
| convert_timedeltas : boolean, default True
| If True, convert to timedelta where possible. If &#39;coerce&#39;, force
| conversion, with unconvertible values becoming NaT.
| copy : boolean, default True
| If True, return a copy even if no copy is necessary (e.g. no
| conversion was done). Note: This is meant for internal use, and
| should not be confused with inplace.
|
| 【返回值】
| -------| converted : same as input object
|
| describe(self, percentiles=None, include=None, exclude=None)
| Generate various summary statistics, excluding NaN values.
|
| 【参数】
| ----------| percentiles : array-like, optional
| The percentiles to include in the output. Should all
| be in the interval [0, 1]. By default</code>percentiles<code>is
| [.25, .5, .75], returning the 25th, 50th, and 75th percentiles.
| include, exclude : list-like, &#39;all&#39;, or None (default)
| Specify the form of the returned result. Either:
|
| - None to both (default). The result will include only numeric-typed
| columns or, if none are, only categorical columns.
| - A list of dtypes or strings to be included/excluded.
| To select all numeric types use numpy numpy.number. To select
| categorical objects use type object. 参见：the select_dtypes
| documentation. eg. df.describe(include=[&#39;O&#39;])
| - If include is the string &#39;all&#39;, the output column-set will
| match the input one.
|
| 【返回值】
| -------| summary: NDFrame of summary statistics
|
| 【注意】
| -----| The output DataFrame index depends on the requested dtypes:
|
| For numeric dtypes, it will include: count, mean, std, min,
| max, and lower, 50, and upper percentiles.
|
| For object dtypes (e.g. timestamps or strings), the index
| will include the count, unique, most common, and frequency of the
| most common. Timestamps also include the first and last items.
|
| For mixed dtypes, the index will be the union of the corresponding
| output types. Non-applicable entries will be filled with NaN.
| Note that mixed-dtype outputs can only be returned from mixed-dtype
| inputs and appropriate use of the include/exclude arguments.
|
| If multiple values have the highest count, then the
|</code>count<code>and</code>most common<code>pair will be arbitrarily chosen from
| among those with the highest count.
|
783
| The include, exclude arguments are ignored for Series.
|
| 【参见】
| --------| DataFrame.select_dtypes
|
| drop(self, labels, axis=0, level=None, inplace=False, errors=&#39;raise&#39;)
| Return new object with labels in requested axis removed
|
| 【参数】
| ----------| labels : single label or list-like
| axis : int or axis name
| level : int or level name, default None
| For MultiIndex
| inplace : bool, default False
| If True, do operation inplace and return None.
| errors : {&#39;ignore&#39;, &#39;raise&#39;}, default &#39;raise&#39;
| If &#39;ignore&#39;, suppress error and existing labels are dropped.
|
| .. versionadded:: 0.16.1
|
| 【返回值】
| -------| dropped : type of caller
|
| equals(self, other)
| Determines if two NDFrame objects contain the same elements. NaNs in the
| same location are considered equal.
|
| ffill(self, axis=None, inplace=False, limit=None, downcast=None)
| Synonym for NDFrame.fillna(method=&#39;ffill&#39;)
|
| filter(self, items=None, like=None, regex=None, axis=None)
| Restrict the info axis to set of items or wildcard
|
| 【参数】
| ----------| items : list-like
| List of info axis to restrict to (must not all be present)
| like : string
| Keep info axis where &quot;arg in col == True&quot;
| regex : string (regular expression)
| Keep info axis with re.search(regex, col) == True
| axis : int or None
| The axis to filter on. By default this is the info axis. The &quot;info
| axis&quot; is the axis that is used when indexing with ``[]``. For
| example, ``df = DataFrame({&#39;a&#39;: [1, 2, 3, 4]]}); df[&#39;a&#39;]``. So,
| the ``DataFrame`` columns are the info axis.
|
| 【注意】
| -----| Arguments are mutually exclusive, but this is not checked for
|
| first(self, offset)
| Convenience method for subsetting initial periods of time series data
| based on a date offset
784
|
| 【参数】
| ----------| offset : string, DateOffset, dateutil.relativedelta
|
| 【示例】
| --------| ts.last(&#39;10D&#39;) -&gt; First 10 days
|
| 【返回值】
| -------| subset : type of caller
|
| get_dtype_counts(self)
| Return the counts of dtypes in this object
|
| get_ftype_counts(self)
| Return the counts of ftypes in this object
|
| groupby(self, by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False)
| Group series using mapper (dict or key function, apply given function
| to group, return result as series) or by a series of columns
|
| 【参数】
| ----------| by : mapping function / list of functions, dict, Series, or tuple /
| list of column names.
| Called on each element of the object index to determine the groups.
| If a dict or Series is passed, the Series or dict VALUES will be
| used to determine the groups
| axis : int, default 0
| level : int, level name, or sequence of such, default None
| If the axis is a MultiIndex (hierarchical), group by a particular
| level or levels
| as_index : boolean, default True
| For aggregated output, return object with group labels as the
| index. Only relevant for DataFrame input. as_index=False is
| effectively &quot;SQL-style&quot; grouped output
| sort : boolean, default True
| Sort group keys. Get better performance by turning this off.
| Note this does not influence the order of observations within each group.
| groupby preserves the order of rows within each group.
| group_keys : boolean, default True
| When calling apply, add group keys to index to identify pieces
| squeeze : boolean, default False
| reduce the dimensionality of the return type if possible,
| otherwise return a consistent type
|
| 【示例】
| --------| DataFrame results
|
| &gt;&gt;&gt; data.groupby(func, axis=0).mean()
| &gt;&gt;&gt; data.groupby([&#39;col1&#39;, &#39;col2&#39;])[&#39;col3&#39;].mean()
|
| DataFrame with hierarchical index
|
785
| &gt;&gt;&gt; data.groupby([&#39;col1&#39;, &#39;col2&#39;]).mean()
|
| 【返回值】
| -------| GroupBy object
|
| head(self, n=5)
| Returns first n rows
|
| interpolate(self, method=&#39;linear&#39;, axis=0, limit=None, inplace=False, limit_direction=&#39;forward&#39;, downcast=None, **kwargs)
| Interpolate values according to different methods.
|
| Please note that only ``method=&#39;linear&#39;`` is supported for DataFrames/Series
| with a MultiIndex.
|
| 【参数】
| ----------| method : {&#39;linear&#39;, &#39;time&#39;, &#39;index&#39;, &#39;values&#39;, &#39;nearest&#39;, &#39;zero&#39;,
| &#39;slinear&#39;, &#39;quadratic&#39;, &#39;cubic&#39;, &#39;barycentric&#39;, &#39;krogh&#39;,
| &#39;polynomial&#39;, &#39;spline&#39; &#39;piecewise_polynomial&#39;, &#39;pchip&#39;}
|
| * &#39;linear&#39;: ignore the index and treat the values as equally
| spaced. This is the only method supported on MultiIndexes.
| default
| * &#39;time&#39;: interpolation works on daily and higher resolution
| data to interpolate given length of interval
| * &#39;index&#39;, &#39;values&#39;: use the actual numerical values of the index
| * &#39;nearest&#39;, &#39;zero&#39;, &#39;slinear&#39;, &#39;quadratic&#39;, &#39;cubic&#39;,
| &#39;barycentric&#39;, &#39;polynomial&#39; is passed to
| ``scipy.interpolate.interp1d``. Both &#39;polynomial&#39; and &#39;spline&#39;
| require that you also specify an</code>order<code>(int),
| e.g. df.interpolate(method=&#39;polynomial&#39;, order=4).
| These use the actual numerical values of the index.
| * &#39;krogh&#39;, &#39;piecewise_polynomial&#39;, &#39;spline&#39;, and &#39;pchip&#39; are all
| wrappers around the scipy interpolation methods of similar
| names. These use the actual numerical values of the index. See
| the scipy documentation for more on their behavior
|</code>here <a href="http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation" target="_blank" rel="external">http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation</a><code>__
|</code>and here <a href="http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html" target="_blank" rel="external">http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html</a><code>__
|
| axis : {0, 1}, default 0
| * 0: fill column-by-column
| * 1: fill row-by-row
| limit : int, default None.
| Maximum number of consecutive NaNs to fill.
| limit_direction : {&#39;forward&#39;, &#39;backward&#39;, &#39;both&#39;}, defaults to &#39;forward&#39;
| If limit is specified, consecutive NaNs will be filled in this
| direction.
|
| .. versionadded:: 0.17.0
|
| inplace : bool, default False
| Update the NDFrame in place if possible.
| downcast : optional, &#39;infer&#39; or None, defaults to None
| Downcast dtypes if possible.
| kwargs : keyword arguments to pass on to the interpolating function.
|
786
| 【返回值】
| -------| Series or DataFrame of same shape interpolated at the NaNs
|
| 【参见】
| --------| reindex, replace, fillna
|
| 【示例】
| --------|
| Filling in NaNs
|
| &gt;&gt;&gt; s = pd.Series([0, 1, np.nan, 3])
| &gt;&gt;&gt; s.interpolate()
| 0 0
| 1 1
| 2 2
| 3 3
| dtype: float64
|
| isnull(self)
| Return a boolean same-sized object indicating if the values are null
|
| 【参见】
| --------| notnull : boolean inverse of isnull
|
| iterkv(self, *args, **kwargs)
| iteritems alias used to get around 2to3. Deprecated
|
| last(self, offset)
| Convenience method for subsetting final periods of time series data
| based on a date offset
|
| 【参数】
| ----------| offset : string, DateOffset, dateutil.relativedelta
|
| 【示例】
| --------| ts.last(&#39;5M&#39;) -&gt; Last 5 months
|
| 【返回值】
| -------| subset : type of caller
|
| mask(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)
| Return an object of same shape as self and whose corresponding
| entries are from self where cond is False and otherwise are from other.
|
| 【参数】
| ----------| cond : boolean NDFrame or array
| other : scalar or NDFrame
| inplace : boolean, default False
787
| Whether to perform the operation in place on the data
| axis : alignment axis if needed, default None
| level : alignment level if needed, default None
| try_cast : boolean, default False
| try to cast the result back to the input type (if possible),
| raise_on_error : boolean, default True
| Whether to raise on invalid data types (e.g. trying to where on
| strings)
|
| 【返回值】
| -------| wh : same type as caller
|
| notnull(self)
| Return a boolean same-sized object indicating if the values are
| not null
|
| 【参见】
| --------| isnull : boolean inverse of notnull
|
| pct_change(self, periods=1, fill_method=&#39;pad&#39;, limit=None, freq=None, **kwargs)
| Percent change over given number of periods.
|
| 【参数】
| ----------| periods : int, default 1
| Periods to shift for forming percent change
| fill_method : str, default &#39;pad&#39;
| How to handle NAs before computing percent changes
| limit : int, default None
| The number of consecutive NAs to fill before stopping
| freq : DateOffset, timedelta, or offset alias string, optional
| Increment to use from time series API (e.g. &#39;M&#39; or BDay())
|
| 【返回值】
| -------| chg : NDFrame
|
| 【注意】
| -----|
| By default, the percentage change is calculated along the stat
| axis: 0, or ``Index``, for ``DataFrame`` and 1, or ``minor`` for
| ``Panel``. You can change this with the ``axis`` keyword argument.
|
| pipe(self, func, *args, **kwargs)
| Apply func(self, \*args, \*\*kwargs)
|
| .. versionadded:: 0.16.2
|
| 【参数】
| ----------| func : function
| function to apply to the NDFrame.
| ``args``, and ``kwargs`` are passed into ``func``.
| Alternatively a ``(callable, data_keyword)`` tuple where
788
| ``data_keyword`` is a string indicating the keyword of
| ``callable`` that expects the NDFrame.
| args : positional arguments passed into ``func``.
| kwargs : a dictionary of keyword arguments passed into ``func``.
|
| 【返回值】
| -------| object : the return type of ``func``.
|
| 【注意】
| -----|
| Use ``.pipe`` when chaining together functions that expect
| on Series or DataFrames. Instead of writing
|
| &gt;&gt;&gt; f(g(h(df), arg1=a), arg2=b, arg3=c)
|
| You can write
|
| &gt;&gt;&gt; (df.pipe(h)
| ... .pipe(g, arg1=a)
| ... .pipe(f, arg2=b, arg3=c)
| ... )
|
| If you have a function that takes the data as (say) the second
| argument, pass a tuple indicating which keyword expects the
| data. For example, suppose ``f`` takes its data as ``arg2``:
|
| &gt;&gt;&gt; (df.pipe(h)
| ... .pipe(g, arg1=a)
| ... .pipe((f, &#39;arg2&#39;), arg1=a, arg3=c)
| ... )
|
| 【参见】
| --------| pandas.DataFrame.apply
| pandas.DataFrame.applymap
| pandas.Series.map
|
| pop(self, item)
| Return item and drop from frame. Raise KeyError if not found.
|
| reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)
| return an object with matching indicies to myself
|
| 【参数】
| ----------| other : Object
| method : string or None
| copy : boolean, default True
| limit : int, default None
| Maximum number of consecutive labels to fill for inexact matches.
| tolerance : optional
| Maximum distance between labels of the other object and this
| object for inexact matches.
|
| .. versionadded:: 0.17.0
789
|
| 【注意】
| -----| Like calling s.reindex(index=other.index, columns=other.columns,
| method=...)
|
| 【返回值】
| -------| reindexed : same as input
|
| rename_axis(self, mapper, axis=0, copy=True, inplace=False)
| Alter index and / or columns using input function or functions.
| Function / dict values must be unique (1-to-1). Labels not contained in
| a dict / Series will be left as-is.
|
| 【参数】
| ----------| mapper : dict-like or function, optional
| axis : int or string, default 0
| copy : boolean, default True
| Also copy underlying data
| inplace : boolean, default False
|
| 【返回值】
| -------| renamed : type of caller
|
| replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method=&#39;pad&#39;, axis=None)
| Replace values given in &#39;to_replace&#39; with &#39;value&#39;.
|
| 【参数】
| ----------| to_replace : str, regex, list, dict, Series, numeric, or None
|
| * str or regex:
|
| - str: string exactly matching</code>to_replace<code>will be replaced
| with</code>value<code>| - regex: regexs matching</code>to_replace<code>will be replaced with
|</code>value<code>|
| * list of str, regex, or numeric:
|
| - First, if</code>to_replace<code>and</code>value<code>are both lists, they
| **must** be the same length.
| - Second, if ``regex=True`` then all of the strings in **both**
| lists will be interpreted as regexs otherwise they will match
| directly. This doesn&#39;t matter much for</code>value<code>since there
| are only a few possible substitution regexes you can use.
| - str and regex rules apply as above.
|
| * dict:
|
| - Nested dictionaries, e.g., {&#39;a&#39;: {&#39;b&#39;: nan}}, are read as
| follows: look in column &#39;a&#39; for the value &#39;b&#39; and replace it
| with nan. You can nest regular expressions as well. Note that
| column names (the top-level dictionary keys in a nested
790
| dictionary) **cannot** be regular expressions.
| - Keys map to column names and values map to substitution
| values. You can treat this as a special case of passing two
| lists except that you are specifying the column to search in.
|
| * None:
|
| - This means that the ``regex`` argument must be a string,
| compiled regular expression, or list, dict, ndarray or Series
| of such elements. If</code>value<code>is also ``None`` then this
| **must** be a nested dictionary or ``Series``.
|
| See the examples section for examples of each of these.
| value : scalar, dict, list, str, regex, default None
| Value to use to fill holes (e.g. 0), alternately a dict of values
| specifying which value to use for each column (columns not in the
| dict will not be filled). Regular expressions, strings and lists or
| dicts of such objects are also allowed.
| inplace : boolean, default False
| If True, in place. Note: this will modify any
| other views on this object (e.g. a column form a DataFrame).
| Returns the caller if this is True.
| limit : int, default None
| Maximum size gap to forward or backward fill
| regex : bool or same types as</code>to_replace<code>, default False
| Whether to interpret</code>to_replace<code>and/or</code>value<code>as regular
| expressions. If this is ``True`` then</code>to_replace<code>*must* be a
| string. Otherwise,</code>to_replace<code>must be ``None`` because this
| parameter will be interpreted as a regular expression or a list,
| dict, or array of regular expressions.
| method : string, optional, {&#39;pad&#39;, &#39;ffill&#39;, &#39;bfill&#39;}
| The method to use when for replacement, when ``to_replace`` is a
| ``list``.
|
| 【参见】
| --------| NDFrame.reindex
| NDFrame.asfreq
| NDFrame.fillna
|
| 【返回值】
| -------| filled : NDFrame
|
| 【Raises 引发错误】
| ------| AssertionError
| * If</code>regex<code>is not a ``bool`` and</code>to_replace<code>is not ``None``.
| TypeError
| * If</code>to_replace<code>is a ``dict`` and</code>value<code>is not a ``list``,
| ``dict``, ``ndarray``, or ``Series``
| * If</code>to_replace<code>is ``None`` and</code>regex<code>is not compilable into a
| regular expression or is a list, dict, ndarray, or Series.
| ValueError
| * If</code>to_replace<code>and</code>value<code>are ``list`` s or ``ndarray`` s, but
| they are not the same length.
|
791
| 【注意】
| -----| * Regex substitution is performed under the hood with ``re.sub``. The
| rules for substitution for ``re.sub`` are the same.
| * Regular expressions will only substitute on strings, meaning you
| cannot provide, for example, a regular expression matching floating
| point numbers and expect the columns in your frame that have a
| numeric dtype to be matched. However, if those floating point numbers
| *are* strings, then you can do this.
| * This method has *a lot* of options. You are encouraged to experiment
| and play with this method to gain intuition about how it works.
|
| resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention=&#39;start&#39;, kind=None,
loffset=None, limit=None, base=0)
| Convenience method for frequency conversion and resampling of regular
| time-series data.
|
| 【参数】
| ----------| rule : string
| the offset string or object representing target conversion
| how : string
| method for down- or re-sampling, default to &#39;mean&#39; for
| downsampling
| axis : int, optional, default 0
| fill_method : string, default None
| fill_method for upsampling
| closed : {&#39;right&#39;, &#39;left&#39;}
| Which side of bin interval is closed
| label : {&#39;right&#39;, &#39;left&#39;}
| Which bin edge label to label bucket with
| convention : {&#39;start&#39;, &#39;end&#39;, &#39;s&#39;, &#39;e&#39;}
| kind : &quot;period&quot;/&quot;timestamp&quot;
| loffset : timedelta
| Adjust the resampled time labels
| limit : int, default None
| Maximum size gap to when reindexing with fill_method
| base : int, default 0
| For frequencies that evenly subdivide 1 day, the &quot;origin&quot; of the
| aggregated intervals. For example, for &#39;5min&#39; frequency, base could
| range from 0 through 4. Defaults to 0
|
|
| 【示例】
| --------|
| Start by creating a series with 9 one minute timestamps.
|
| &gt;&gt;&gt; index = pd.date_range(&#39;1/1/2000&#39;, periods=9, freq=&#39;T&#39;)
| &gt;&gt;&gt; series = pd.Series(range(9), index=index)
| &gt;&gt;&gt; series
| 2000-01-01 00:00:00 0
| 2000-01-01 00:01:00 1
| 2000-01-01 00:02:00 2
| 2000-01-01 00:03:00 3
| 2000-01-01 00:04:00 4
| 2000-01-01 00:05:00 5
792
| 2000-01-01 00:06:00 6
| 2000-01-01 00:07:00 7
| 2000-01-01 00:08:00 8
| Freq: T, dtype: int64
|
| Downsample the series into 3 minute bins and sum the values
| of the timestamps falling into a bin.
|
| &gt;&gt;&gt; series.resample(&#39;3T&#39;, how=&#39;sum&#39;)
| 2000-01-01 00:00:00 3
| 2000-01-01 00:03:00 12
| 2000-01-01 00:06:00 21
| Freq: 3T, dtype: int64
|
| Downsample the series into 3 minute bins as above, but label each
| bin using the right edge instead of the left. Please note that the
| value in the bucket used as the label is not included in the bucket,
| which it labels. For example, in the original series the
| bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed
| value in the resampled bucket with the label``2000-01-01 00:03:00``
| does not include 3 (if it did, the summed value would be 6, not 3).
| To include this value close the right side of the bin interval as
| illustrated in the example below this one.
|
| &gt;&gt;&gt; series.resample(&#39;3T&#39;, how=&#39;sum&#39;, label=&#39;right&#39;)
| 2000-01-01 00:03:00 3
| 2000-01-01 00:06:00 12
| 2000-01-01 00:09:00 21
| Freq: 3T, dtype: int64
|
| Downsample the series into 3 minute bins as above, but close the right
| side of the bin interval.
|
| &gt;&gt;&gt; series.resample(&#39;3T&#39;, how=&#39;sum&#39;, label=&#39;right&#39;, closed=&#39;right&#39;)
| 2000-01-01 00:00:00 0
| 2000-01-01 00:03:00 6
| 2000-01-01 00:06:00 15
| 2000-01-01 00:09:00 15
| Freq: 3T, dtype: int64
|
| Upsample the series into 30 second bins.
|
| &gt;&gt;&gt; series.resample(&#39;30S&#39;)[0:5] #select first 5 rows
| 2000-01-01 00:00:00 0
| 2000-01-01 00:00:30 NaN
| 2000-01-01 00:01:00 1
| 2000-01-01 00:01:30 NaN
| 2000-01-01 00:02:00 2
| Freq: 30S, dtype: float64
|
| Upsample the series into 30 second bins and fill the ``NaN``
| values using the ``pad`` method.
|
| &gt;&gt;&gt; series.resample(&#39;30S&#39;, fill_method=&#39;pad&#39;)[0:5]
| 2000-01-01 00:00:00 0
| 2000-01-01 00:00:30 0
| 2000-01-01 00:01:00 1
793
| 2000-01-01 00:01:30 1
| 2000-01-01 00:02:00 2
| Freq: 30S, dtype: int64
|
| Upsample the series into 30 second bins and fill the
| ``NaN`` values using the ``bfill`` method.
|
| &gt;&gt;&gt; series.resample(&#39;30S&#39;, fill_method=&#39;bfill&#39;)[0:5]
| 2000-01-01 00:00:00 0
| 2000-01-01 00:00:30 1
| 2000-01-01 00:01:00 1
| 2000-01-01 00:01:30 2
| 2000-01-01 00:02:00 2
| Freq: 30S, dtype: int64
|
| Pass a custom function to ``how``.
|
| &gt;&gt;&gt; def custom_resampler(array_like):
| ... return np.sum(array_like)+5
|
| &gt;&gt;&gt; series.resample(&#39;3T&#39;, how=custom_resampler)
| 2000-01-01 00:00:00 8
| 2000-01-01 00:03:00 17
| 2000-01-01 00:06:00 26
| Freq: 3T, dtype: int64
|
| sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)
| Returns a random sample of items from an axis of object.
|
| .. versionadded:: 0.16.1
|
| 【参数】
| ----------| n : int, optional
| Number of items from axis to return. Cannot be used with</code>frac<code>.
| Default = 1 if</code>frac<code>= None.
| frac : float, optional
| Fraction of axis items to return. Cannot be used with</code>n<code>.
| replace : boolean, optional
| Sample with or without replacement. Default = False.
| weights : str or ndarray-like, optional
| Default &#39;None&#39; results in equal probability weighting.
| If passed a Series, will align with target object on index. Index
| values in weights not found in sampled object will be ignored and
| index values in sampled object not in weights will be assigned
| weights of zero.
| If called on a DataFrame, will accept the name of a column
| when axis = 0.
| Unless weights are a Series, weights must be same length as axis
| being sampled.
| If weights do not sum to 1, they will be normalized to sum to 1.
| Missing values in the weights column will be treated as zero.
| inf and -inf values not allowed.
| random_state : int or numpy.random.RandomState, optional
| Seed for the random number generator (if int), or numpy RandomState
| object.
| axis : int or string, optional
794
| Axis to sample. Accepts axis number or name. Default is stat axis
| for given data type (0 for Series and DataFrames, 1 for Panels).
|
| 【返回值】
| -------| A new object of same type as caller.
|
| select(self, crit, axis=0)
| Return data corresponding to axis labels matching criteria
|
| 【参数】
| ----------| crit : function
| To be called on each index (label). Should return True or False
| axis : int
|
| 【返回值】
| -------| selection : type of caller
|
| set_axis(self, axis, labels)
| public verson of axis assignment
|
| slice_shift(self, periods=1, axis=0)
| Equivalent to</code>shift<code>without copying data. The shifted data will
| not include the dropped periods and the shifted axis will be smaller
| than the original.
|
| 【参数】
| ----------| periods : int
| Number of periods to move, can be positive or negative
|
| 【注意】
| -----| While the</code>slice_shift<code>is faster than</code>shift<code>, you may pay for it
| later during alignment.
|
| 【返回值】
| -------| shifted : same type as caller
|
| squeeze(self)
| squeeze length 1 dimensions
|
| swapaxes(self, axis1, axis2, copy=True)
| Interchange axes and swap values axes appropriately
|
| 【返回值】
| -------| y : same as input
|
| tail(self, n=5)
| Returns last n rows
|
| to_clipboard(self, excel=None, sep=None, **kwargs)
| Attempt to write text representation of object to the system clipboard
795
| This can be pasted into Excel, for example.
|
| 【参数】
| ----------| excel : boolean, defaults to True
| if True, use the provided separator, writing in a csv
| format for allowing easy pasting into excel.
| if False, write a string representation of the object
| to the clipboard
| sep : optional, defaults to tab
| other keywords are passed to to_csv
|
| 【注意】
| -----| Requirements for your platform
| - Linux: xclip, or xsel (with gtk or PyQt4 modules)
| - Windows: none
| - OS X: none
|
| to_hdf(self, path_or_buf, key, **kwargs)
| activate the HDFStore
|
| 【参数】
| ----------| path_or_buf : the path (string) or HDFStore object
| key : string
| indentifier for the group in the store
| mode : optional, {&#39;a&#39;, &#39;w&#39;, &#39;r&#39;, &#39;r+&#39;}, default &#39;a&#39;
|
| ``&#39;r&#39;``
| Read-only; no data can be modified.
| ``&#39;w&#39;``
| Write; a new file is created (an existing file with the same
| name would be deleted).
| ``&#39;a&#39;``
| Append; an existing file is opened for reading and writing,
| and if the file does not exist it is created.
| ``&#39;r+&#39;``
| It is similar to ``&#39;a&#39;``, but the file must already exist.
| format : &#39;fixed(f)|table(t)&#39;, default is &#39;fixed&#39;
| fixed(f) : Fixed format
| Fast writing/reading. Not-appendable, nor searchable
| table(t) : Table format
| Write as a PyTables Table structure which may perform
| worse but allow more flexible operations like searching
| / selecting subsets of the data
| append : boolean, default False
| For Table formats, append the input data to the existing
| complevel : int, 1-9, default 0
| If a complib is specified compression will be applied
| where possible
| complib : {&#39;zlib&#39;, &#39;bzip2&#39;, &#39;lzo&#39;, &#39;blosc&#39;, None}, default None
| If complevel is &gt; 0 apply compression to objects written
| in the store wherever possible
| fletcher32 : bool, default False
| If applying compression use the fletcher32 checksum
| dropna : boolean, default False.
796
| If true, ALL nan rows will not be written to store.
|
| to_json(self, path_or_buf=None, orient=None, date_format=&#39;epoch&#39;, double_precision=10, force_ascii=True, date_unit=&#39;ms&#39;,
default_handler=None)
| Convert the object to a JSON string.
|
| Note NaN&#39;s and None will be converted to null and datetime objects
| will be converted to UNIX timestamps.
|
| 【参数】
| ----------| path_or_buf : the path or buffer to write the result string
| if this is None, return a StringIO of the converted string
| orient : string
|
| * Series
|
| - default is &#39;index&#39;
| - allowed values are: {&#39;split&#39;,&#39;records&#39;,&#39;index&#39;}
|
| * DataFrame
|
| - default is &#39;columns&#39;
| - allowed values are:
| {&#39;split&#39;,&#39;records&#39;,&#39;index&#39;,&#39;columns&#39;,&#39;values&#39;}
|
| * The format of the JSON string
|
| - split : dict like
| {index -&gt; [index], columns -&gt; [columns], data -&gt; [values]}
| - records : list like
| [{column -&gt; value}, ... , {column -&gt; value}]
| - index : dict like {index -&gt; {column -&gt; value}}
| - columns : dict like {column -&gt; {index -&gt; value}}
| - values : just the values array
|
| date_format : {&#39;epoch&#39;, &#39;iso&#39;}
| Type of date conversion.</code>epoch<code>= epoch milliseconds,
|</code>iso<code>= ISO8601, default is epoch.
| double_precision : The number of decimal places to use when encoding
| floating point values, default 10.
| force_ascii : force encoded string to be ASCII, default True.
| date_unit : string, default &#39;ms&#39; (milliseconds)
| The time unit to encode to, governs timestamp and ISO8601
| precision. One of &#39;s&#39;, &#39;ms&#39;, &#39;us&#39;, &#39;ns&#39; for second, millisecond,
| microsecond, and nanosecond respectively.
| default_handler : callable, default None
| Handler to call if object cannot otherwise be converted to a
| suitable format for JSON. Should receive a single argument which is
| the object to convert and return a serialisable object.
|
| 【返回值】
| -------| same type as input object with filtered info axis
|
| to_msgpack(self, path_or_buf=None, **kwargs)
| msgpack (serialize) object to input file path
797
|
| THIS IS AN EXPERIMENTAL LIBRARY and the storage format
| may not be stable until a future release.
|
| 【参数】
| ----------| path : string File path, buffer-like, or None
| if None, return generated string
| append : boolean whether to append to an existing msgpack
| (default is False)
| compress : type of compressor (zlib or blosc), default to None (no
| compression)
|
| to_pickle(self, path)
| Pickle (serialize) object to input file path
|
| 【参数】
| ----------| path : string
| File path
|
| to_sql(self, name, con, flavor=&#39;sqlite&#39;, schema=None, if_exists=&#39;fail&#39;, index=True, index_label=None, chunksize=None,
dtype=None)
| Write records stored in a DataFrame to a SQL database.
|
| 【参数】
| ----------| name : string
| Name of SQL table
| con : SQLAlchemy engine or DBAPI2 connection (legacy mode)
| Using SQLAlchemy makes it possible to use any DB supported by that
| library.
| If a DBAPI2 object, only sqlite3 is supported.
| flavor : {&#39;sqlite&#39;, &#39;mysql&#39;}, default &#39;sqlite&#39;
| The flavor of SQL to use. Ignored when using SQLAlchemy engine.
| &#39;mysql&#39; is deprecated and will be removed in future versions, but it
| will be further supported through SQLAlchemy engines.
| schema : string, default None
| Specify the schema (if database flavor supports this). If None, use
| default schema.
| if_exists : {&#39;fail&#39;, &#39;replace&#39;, &#39;append&#39;}, default &#39;fail&#39;
| - fail: If table exists, do nothing.
| - replace: If table exists, drop it, recreate it, and insert data.
| - append: If table exists, insert data. Create if does not exist.
| index : boolean, default True
| Write DataFrame index as a column.
| index_label : string or sequence, default None
| Column label for index column(s). If None is given (default) and
| `index` is True, then the index names are used.
| A sequence should be given if the DataFrame uses MultiIndex.
| chunksize : int, default None
| If not None, then rows will be written in batches of this size at a
| time. If None, all rows will be written at once.
| dtype : dict of column name to SQL type, default None
| Optional specifying the datatype for columns. The SQL type should
| be a SQLAlchemy type, or a string for sqlite3 fallback connection.
|
798
| truncate(self, before=None, after=None, axis=None, copy=True)
| Truncates a sorted NDFrame before and/or after some particular
| dates.
|
| 【参数】
| ----------| before : date
| Truncate before date
| after : date
| Truncate after date
| axis : the truncation axis, defaults to the stat axis
| copy : boolean, default is True,
| return a copy of the truncated section
|
| 【返回值】
| -------| truncated : type of caller
|
| tshift(self, periods=1, freq=None, axis=0)
| Shift the time index, using the index&#39;s frequency if available
|
| 【参数】
| ----------| periods : int
| Number of periods to move, can be positive or negative
| freq : DateOffset, timedelta, or time rule string, default None
| Increment to use from datetools module or time rule (e.g. &#39;EOM&#39;)
| axis : int or basestring
| Corresponds to the axis that contains the Index
|
| 【注意】
| -----| If freq is not specified then tries to use the freq or inferred_freq
| attributes of the index. If neither of those attributes exist, a
| ValueError is thrown
|
| 【返回值】
| -------| shifted : NDFrame
|
| tz_convert(self, tz, axis=0, level=None, copy=True)
| Convert tz-aware axis to target time zone.
|
| 【参数】
| ----------| tz : string or pytz.timezone object
| axis : the axis to convert
| level : int, str, default None
| If axis ia a MultiIndex, convert a specific level. Otherwise
| must be None
| copy : boolean, default True
| Also make a copy of the underlying data
|
| 【返回值】
| -------|
799
| 【Raises 引发错误】
| ------| TypeError
| If the axis is tz-naive.
|
| tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous=&#39;raise&#39;)
| Localize tz-naive TimeSeries to target time zone
|
| 【参数】
| ----------| tz : string or pytz.timezone object
| axis : the axis to localize
| level : int, str, default None
| If axis ia a MultiIndex, localize a specific level. Otherwise
| must be None
| copy : boolean, default True
| Also make a copy of the underlying data
| ambiguous : &#39;infer&#39;, bool-ndarray, &#39;NaT&#39;, default &#39;raise&#39;
| - &#39;infer&#39; will attempt to infer fall dst-transition hours based on order
| - bool-ndarray where True signifies a DST time, False designates
| a non-DST time (note that this flag is only applicable for ambiguous times)
| - &#39;NaT&#39; will return NaT where there are ambiguous times
| - &#39;raise&#39; will raise an AmbiguousTimeError if there are ambiguous times
| infer_dst : boolean, default False (DEPRECATED)
| Attempt to infer fall dst-transition hours based on order
|
| 【返回值】
| -------|
| 【Raises 引发错误】
| ------| TypeError
| If the TimeSeries is tz-aware and tz is not None.
|
| where(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)
| Return an object of same shape as self and whose corresponding
| entries are from self where cond is True and otherwise are from other.
|
| 【参数】
| ----------| cond : boolean NDFrame or array
| other : scalar or NDFrame
| inplace : boolean, default False
| Whether to perform the operation in place on the data
| axis : alignment axis if needed, default None
| level : alignment level if needed, default None
| try_cast : boolean, default False
| try to cast the result back to the input type (if possible),
| raise_on_error : boolean, default True
| Whether to raise on invalid data types (e.g. trying to where on
| strings)
|
| 【返回值】
| -------| wh : same type as caller
|
| xs(self, key, axis=0, level=None, copy=None, drop_level=True)
800
| Returns a cross-section (row(s) or column(s)) from the Series/DataFrame.
| Defaults to cross-section on the rows (axis=0).
|
| 【参数】
| ----------| key : object
| Some label contained in the index, or partially in a MultiIndex
| axis : int, default 0
| Axis to retrieve cross-section on
| level : object, defaults to first n levels (n=1 or len(key))
| In case of a key partially contained in a MultiIndex, indicate
| which levels are used. Levels can be referred by label or position.
| copy : boolean [deprecated]
| Whether to make a copy of the data
| drop_level : boolean, default True
| If False, returns object with same levels as self.
|
| 【示例】
| --------| &gt;&gt;&gt; df
| A B C
| a 4 5 2
| b 4 0 9
| c 9 7 3
| &gt;&gt;&gt; df.xs(&#39;a&#39;)
| A 4
| B 5
| C 2
| Name: a
| &gt;&gt;&gt; df.xs(&#39;C&#39;, axis=1)
| a 2
| b 9
| c 3
| Name: C
|
| &gt;&gt;&gt; df
| A B C D
| first second third
| bar one 1 4 1 8 9
| two 1 7 5 5 0
| baz one 1 6 6 8 0
| three 2 5 3 5 3
| &gt;&gt;&gt; df.xs((&#39;baz&#39;, &#39;three&#39;))
| A B C D
| third
| 2 5 3 5 3
| &gt;&gt;&gt; df.xs(&#39;one&#39;, level=1)
| A B C D
| first third
| bar 1 4 1 8 9
| baz 1 6 6 8 0
| &gt;&gt;&gt; df.xs((&#39;baz&#39;, 2), level=[0, &#39;third&#39;])
| A B C D
| second
| three 5 3 5 3
|
| 【返回值】
801
| -------| xs : Series or DataFrame
|
| 【注意】
| -----| xs is only for getting, not setting values.
|
| MultiIndex Slicers is a generic way to get/set values on any level or levels
| it is a superset of xs functionality, see :ref:`MultiIndex Slicers &lt;advanced.mi_slicers&gt;`
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.generic.NDFrame:
|
| at
| Fast label-based scalar accessor
|
| Similarly to</code>loc<code>,</code>at<code>provides **label** based scalar lookups.
| You can also set using these indexers.
|
| blocks
| Internal property, property synonym for as_blocks()
|
| empty
| True if NDFrame is entirely empty [no items]
|
| iat
| Fast integer location scalar accessor.
|
| Similarly to</code>iloc<code>,</code>iat<code>provides **integer** based lookups.
| You can also set using these indexers.
|
| iloc
| Purely integer-location based indexing for selection by position.
|
|</code>.iloc[]<code>is primarily integer position based (from</code>0<code>to
|</code>length-1<code>of the axis), but may also be used with a boolean
| array.
|
| Allowed inputs are:
|
| - An integer, e.g.</code>5<code>.
| - A list or array of integers, e.g.</code>[4, 3, 0]<code>.
| - A slice object with ints, e.g.</code>1:7<code>.
| - A boolean array.
|
|</code>.iloc<code>will raise</code>IndexError<code>if a requested indexer is
| out-of-bounds, except *slice* indexers which allow out-of-bounds
| indexing (this conforms with python/numpy *slice* semantics).
|
| See more at :ref:`Selection by Position &lt;indexing.integer&gt;`
|
| ix
| A primarily label-location based indexer, with integer position
| fallback.
|
|</code>.ix[]<code>supports mixed integer and label based access. It is
| primarily label based, but will fall back to integer positional
802
| access unless the corresponding axis is of integer type.
|
|</code>.ix<code>is the most general indexer and will support any of the
| inputs in</code>.loc<code>and</code>.iloc<code>.</code>.ix<code>also supports floating
| point label schemes.</code>.ix<code>is exceptionally useful when dealing
| with mixed positional and label based hierachical indexes.
|
| However, when an axis is integer based, ONLY label based access
| and not positional access is supported. Thus, in such cases, it&#39;s
| usually better to be explicit and use</code>.iloc<code>or</code>.loc<code>.
|
| See more at :ref:`Advanced Indexing &lt;advanced&gt;`.
|
| loc
| Purely label-location based indexer for selection by label.
|
|</code>.loc[]<code>is primarily label based, but may also be used with a
| boolean array.
|
| Allowed inputs are:
|
| - A single label, e.g.</code>5<code>or</code>‘a’<code>, (note that</code>5<code>is
| interpreted as a *label* of the index, and **never** as an
| integer position along the index).
| - A list or array of labels, e.g.</code>[‘a’, ‘b’, ‘c’]<code>.
| - A slice object with labels, e.g.</code>‘a’:’f’<code>(note that contrary
| to usual python slices, **both** the start and the stop are included!).
| - A boolean array.
|
|</code>.loc<code>will raise a</code>KeyError<code>when the items are not found.
|
| See more at :ref:`Selection by Label &lt;indexing.label&gt;`
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.generic.NDFrame:
|
| is_copy = None
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.PandasObject:
|
| __dir__(self)
| Provide method name lookup and completion
| Only provide &#39;public&#39; methods
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
| Return a string representation for a particular object.
|
| Invoked by bytes(obj) in py3 only.
| Yields a bytestring in both py2/py3.
|
| __repr__(self)
| Return a string representation for a particular object.
|
803
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
Term
Expr 模块所属：pandas.computation.pytables:
类定义：Expr(pandas.computation.expr.Expr)
| hold a pytables like expression, comprised of possibly multiple &#39;terms&#39;
|
| 【参数】
| ----------| where : string term expression, Expr, or list-like of Exprs
| queryables : a &quot;kinds&quot; map (dict of column name -&gt; kind), or None if column
| is non-indexable
| encoding : an encoding that will encode the query terms
|
| Returns
| -------| an Expr object
|
| 【示例】
| --------|
| &#39;index&gt;=date&#39;
| &quot;columns=[&#39;A&#39;, &#39;D&#39;]&quot;
| &#39;columns=A&#39;
| &#39;columns==A&#39;
| &quot;~(columns=[&#39;A&#39;,&#39;B&#39;])&quot;
| &#39;index&gt;df.index[3] &amp; string=&quot;bar&quot;&#39;
| &#39;(index&gt;df.index[3] &amp; index&lt;=df.index[6]) | string=&quot;bar&quot;&#39;
| &quot;ts&gt;=Timestamp(&#39;2012-02-01&#39;)&quot;
| &quot;major_axis&gt;=20130101&quot;
|
| 【方法排序】
| Expr
| pandas.computation.expr.Expr
| pandas.core.base.StringMixin
| 【内置对象】
|
| 【方法定义】
|
| __init__(self, where, op=None, value=None, queryables=None, encoding=None, scope_level=0)
| Initialize self. See help(type(self)) for accurate signature.
|
804
| __unicode__(self)
|
| evaluate(self)
| create and return the numexpr condition and filter
|
| parse_back_compat(self, w, op=None, value=None)
| allow backward compatibility for passed arguments
|
| ----------------------------------------------------------------------| Methods inherited from pandas.computation.expr.Expr:
|
| __call__(self)
| Call self as a function.
|
| __len__(self)
|
| parse(self)
| Parse an expression
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.computation.expr.Expr:
|
| assigner
|
| names
| Get the names in an expression
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
| Return a string representation for a particular object.
|
| Invoked by bytes(obj) in py3 only.
| Yields a bytestring in both py2/py3.
|
| __repr__(self)
| Return a string representation for a particular object.
|
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.base.StringMixin:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
805
TimeGrouper
TimeGrouper 模块所属：pandas.tseries.resample:
类定义：TimeGrouper(pandas.core.groupby.Grouper)
| Custom groupby class for time-interval grouping
|
| 【参数】
| ----------| freq : pandas date offset or offset alias for identifying bin edges
| closed : closed end of interval; left or right
| label : interval boundary to use for labeling; left or right
| nperiods : optional, integer
| convention : {&#39;start&#39;, &#39;end&#39;, &#39;e&#39;, &#39;s&#39;}
| If axis is PeriodIndex
|
|【注意】
| -----| Use begin, end, nperiods to generate intervals that cannot be derived
| directly from the associated object
|
| 【方法排序】
| TimeGrouper
| pandas.core.groupby.Grouper
| 【内置对象】
|
| 【方法定义】
|
| __init__(self, freq=&#39;Min&#39;, closed=None, label=None, how=&#39;mean&#39;, nperiods=None, axis=0, fill_method=None, limit=None,
loffset=None, kind=None, convention=None, base=0, **kwargs)
| Initialize self. See help(type(self)) for accurate signature.
|
| resample(self, obj)
|
| ----------------------------------------------------------------------| Static methods inherited from pandas.core.groupby.Grouper:
|
| __new__(cls, *args, **kwargs)
| Create and return a new object. See help(type) for accurate signature.
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.groupby.Grouper:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
|
| ax
|
806
| groups
TimeSeries
TimeSeries 模块所属：pandas.core.series:
类定义：TimeSeries(Series)
| One-dimensional ndarray with axis labels (including time series).
|
| Labels need not be unique but must be any hashable type. The object
| supports both integer- and label-based indexing and provides a host of
| methods for performing operations involving the index. Statistical
| methods from ndarray have been overridden to automatically exclude
| missing data (currently represented as NaN)
|
| Operations between Series (+, -, /, *, **) align values based on their
| associated index values-- they need not be the same length. The result
| index will be the sorted union of the two indexes.
|
| 【参数】
| ----------| data : array-like, dict, or scalar value
| Contains data stored in Series
| index : array-like or Index (1d)
| Values must be unique and hashable, same length as data. Index
| object (or other iterable of same length as data) Will default to
| np.arange(len(data)) if not provided. If both a dict and index
| sequence are used, the index will override the keys found in the
| dict.
| dtype : numpy.dtype or None
| If None, dtype will be inferred
| copy : boolean, default False
| Copy input data
|
| 【方法排序】
| TimeSeries
| Series
| pandas.core.base.IndexOpsMixin
| pandas.core.strings.StringAccessorMixin
| pandas.core.generic.NDFrame
| pandas.core.base.PandasObject
| pandas.core.base.StringMixin
| 【内置对象】
|
| 【方法定义】
|
| __init__(self, *args, **kwargs)
| Initialize self. See help(type(self)) for accurate signature.
|
| ----------------------------------------------------------------------
807
| Methods inherited from Series:
|
| __add__ = wrapper(left, right, name=&#39;__add__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004EC20D0&gt;)
|
| __and__ = wrapper(self, other)
|
| __array__(self, result=None)
| the array interface, return my values
|
| __array_prepare__(self, result, context=None)
| Gets called prior to a ufunc
|
| __array_wrap__(self, result, context=None)
| Gets called after a ufunc
|
| __div__ = wrapper(left, right, name=&#39;__truediv__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004EC2510&gt;)
|
| __eq__ = wrapper(self, other, axis=None)
|
| __float__ = wrapper(self)
|
| __floordiv__ = wrapper(left, right, name=&#39;__floordiv__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004EC2620&gt;)
|
| __ge__ = wrapper(self, other, axis=None)
|
| __getitem__(self, key)
|
| __gt__ = wrapper(self, other, axis=None)
|
| __iadd__ = f(self, other)
|
| __imul__ = f(self, other)
|
| __int__ = wrapper(self)
|
| __ipow__ = f(self, other)
|
| __isub__ = f(self, other)
|
| __iter__(self)
| provide iteration over the values of the Series
| box values if necessary
|
| __itruediv__ = f(self, other)
|
| __le__ = wrapper(self, other, axis=None)
|
| __len__(self)
| return the length of the Series
|
| __long__ = wrapper(self)
|
| __lt__ = wrapper(self, other, axis=None)
|
808
| __mod__ = wrapper(left, right, name=&#39;__mod__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004EC2730&gt;)
|
| __mul__ = wrapper(left, right, name=&#39;__mul__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004EC2400&gt;)
|
| __ne__ = wrapper(self, other, axis=None)
|
| __or__ = wrapper(self, other)
|
| __pow__ = wrapper(left, right, name=&#39;__pow__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004EC2840&gt;)
|
| __radd__ = wrapper(left, right, name=&#39;__radd__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004EC21E0&gt;)
|
| __rand__ = wrapper(self, other)
|
| __rdiv__ = wrapper(left, right, name=&#39;__rtruediv__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004EC2C80&gt;)
|
| __rfloordiv__ = wrapper(left, right, name=&#39;__rfloordiv__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004EC2E18&gt;)
|
| __rmod__ = wrapper(left, right, name=&#39;__rmod__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004EC41E0&gt;)
|
| __rmul__ = wrapper(left, right, name=&#39;__rmul__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004EC2950&gt;)
|
| __ror__ = wrapper(self, other)
|
| __rpow__ = wrapper(left, right, name=&#39;__rpow__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004EC4048&gt;)
|
| __rsub__ = wrapper(left, right, name=&#39;__rsub__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004EC2AE8&gt;)
|
| __rtruediv__ = wrapper(left, right, name=&#39;__rtruediv__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004EC2C80&gt;)
|
| __rxor__ = wrapper(self, other)
|
| __setitem__(self, key, value)
|
| __sub__ = wrapper(left, right, name=&#39;__sub__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004EC22F0&gt;)
|
| __truediv__ = wrapper(left, right, name=&#39;__truediv__&#39;, na_op=&lt;function _arith_method_SERIES.&lt;locals&gt;.na_op at
0x0000000004EC2510&gt;)
|
| __unicode__(self)
| Return a string representation for a particular DataFrame
|
| Invoked by unicode(df) in py2 only. Yields a Unicode String in both
| py2/py3.
|
809
| __xor__ = wrapper(self, other)
|
| add(self, other, level=None, fill_value=None, axis=0)
| Addition of series and other, element-wise (binary operator `add`).
|
| Equivalent to</code>series + other<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.radd
|
| align(self, other, join=&#39;outer&#39;, axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0,
broadcast_axis=None)
| Align two object on their axes with the
| specified join method for each axis Index
|
| 【参数】
| ----------| other : DataFrame or Series
| join : {&#39;outer&#39;, &#39;inner&#39;, &#39;left&#39;, &#39;right&#39;}, default &#39;outer&#39;
| axis : allowed axis of the other object, default None
| Align on index (0), columns (1), or both (None)
| level : int or level name, default None
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
| copy : boolean, default True
| Always returns new objects. If copy=False and no reindexing is
| required then original objects are returned.
| fill_value : scalar, default np.NaN
| Value to use for missing values. Defaults to NaN, but can be any
| &quot;compatible&quot; value
| method : str, default None
| limit : int, default None
| fill_axis : {0, &#39;index&#39;}, default 0
| Filling axis, method and limit
| broadcast_axis : {0, &#39;index&#39;}, default None
| Broadcast values along this axis, if aligning two objects of
| different dimensions
|
| .. versionadded:: 0.17.0
|
| 【返回值】
810
| -------| (left, right) : (Series, type of other)
| Aligned objects
|
| all(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)
| Return whether all elements are True over requested axis
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| bool_only : boolean, default None
| Include only boolean data. If None, will attempt to use everything,
| then use only boolean data
|
| 【返回值】
| -------| all : scalar or Series (if level specified)
|
| any(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)
| Return whether any element is True over requested axis
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| bool_only : boolean, default None
| Include only boolean data. If None, will attempt to use everything,
| then use only boolean data
|
| 【返回值】
| -------| any : scalar or Series (if level specified)
|
| append(self, to_append, verify_integrity=False)
| Concatenate two or more Series.
|
| 【参数】
| ----------| to_append : Series or list/tuple of Series
| verify_integrity : boolean, default False
| If True, raise Exception on creating index with duplicates
|
| 【返回值】
| -------| appended : Series
|
811
| apply(self, func, convert_dtype=True, args=(), **kwds)
| Invoke function on values of Series. Can be ufunc (a NumPy function
| that applies to the entire Series) or a Python function that only works
| on single values
|
| 【参数】
| ----------| func : function
| convert_dtype : boolean, default True
| Try to find better dtype for elementwise function results. If
| False, leave as dtype=object
| args : tuple
| Positional arguments to pass to function in addition to the value
| Additional keyword arguments will be passed as keywords to the function
|
| 【返回值】
| -------| y : Series or DataFrame if func returns a Series
|
| 【参见】
| --------| Series.map: For element-wise operations
|
| 【示例】
| --------|
| Create a series with typical summer temperatures for each city.
|
| &gt;&gt;&gt; import pandas as pd
| &gt;&gt;&gt; import numpy as np
| &gt;&gt;&gt; series = pd.Series([20, 21, 12], index=[&#39;London&#39;,
| ... &#39;New York&#39;,&#39;Helsinki&#39;])
| London 20
| New York 21
| Helsinki 12
| dtype: int64
|
| Square the values by defining a function and passing it as an
| argument to</code>apply()<code>.
|
| &gt;&gt;&gt; def square(x):
| ... return x**2
| &gt;&gt;&gt; series.apply(square)
| London 400
| New York 441
| Helsinki 144
| dtype: int64
|
| Square the values by passing an anonymous function as an
| argument to</code>apply()<code>.
|
| &gt;&gt;&gt; series.apply(lambda x: x**2)
| London 400
| New York 441
| Helsinki 144
| dtype: int64
|
812
| Define a custom function that needs additional positional
| arguments and pass these additional arguments using the
|</code>args<code>keyword.
|
| &gt;&gt;&gt; def subtract_custom_value(x, custom_value):
| ... return x-custom_value
|
| &gt;&gt;&gt; series.apply(subtract_custom_value, args=(5,))
| London 15
| New York 16
| Helsinki 7
| dtype: int64
|
| Define a custom function that takes keyword arguments
| and pass these arguments to</code>apply<code>.
|
| &gt;&gt;&gt; def add_custom_values(x, **kwargs):
| ... for month in kwargs:
| ... x+=kwargs[month]
| ... return x
|
| &gt;&gt;&gt; series.apply(add_custom_values, june=30, july=20, august=25)
| London 95
| New York 96
| Helsinki 87
| dtype: int64
|
| Use a function from the Numpy library.
|
| &gt;&gt;&gt; series.apply(np.log)
| London 2.995732
| New York 3.044522
| Helsinki 2.484907
| dtype: float64
|
| argmax = idxmax(self, axis=None, out=None, skipna=True)
| Index of first occurrence of maximum of values.
|
| 【参数】
| ----------| skipna : boolean, default True
| Exclude NA/null values
|
| 【返回值】
| -------| idxmax : Index of maximum of values
|
| 【注意】
| -----| This method is the Series version of</code>ndarray.argmax<code>.
|
| 【参见】
| --------| DataFrame.idxmax
| numpy.ndarray.argmax
|
| argmin = idxmin(self, axis=None, out=None, skipna=True)
813
| Index of first occurrence of minimum of values.
|
| 【参数】
| ----------| skipna : boolean, default True
| Exclude NA/null values
|
| 【返回值】
| -------| idxmin : Index of minimum of values
|
| 【注意】
| -----| This method is the Series version of</code>ndarray.argmin<code>.
|
| 【参见】
| --------| DataFrame.idxmin
| numpy.ndarray.argmin
|
| argsort(self, axis=0, kind=&#39;quicksort&#39;, order=None)
| Overrides ndarray.argsort. Argsorts the value, omitting NA/null values,
| and places the result in the same locations as the non-NA values
|
| 【参数】
| ----------| axis : int (can only be zero)
| kind : {&#39;mergesort&#39;, &#39;quicksort&#39;, &#39;heapsort&#39;}, default &#39;quicksort&#39;
| Choice of sorting algorithm. See np.sort for more
| information. &#39;mergesort&#39; is the only stable algorithm
| order : ignored
|
| 【返回值】
| -------| argsorted : Series, with -1 indicated where nan values are present
|
| 【参见】
| --------| numpy.ndarray.argsort
|
| asof(self, where)
| Return last good (non-NaN) value in Series if value is NaN for
| requested date.
|
| If there is no good value, NaN is returned.
|
| 【参数】
| ----------| where : date or array of dates
|
| 【注意】
| -----| Dates are assumed to be sorted
|
| 【返回值】
| -------
814
| value or NaN
|
| autocorr(self, lag=1)
| Lag-N autocorrelation
|
| 【参数】
| ----------| lag : int, default 1
| Number of lags to apply before performing autocorrelation.
|
| 【返回值】
| -------| autocorr : float
|
| between(self, left, right, inclusive=True)
| Return boolean Series equivalent to left &lt;= series &lt;= right. NA values
| will be treated as False
|
| 【参数】
| ----------| left : scalar
| Left boundary
| right : scalar
| Right boundary
|
| 【返回值】
| -------| is_between : Series
|
| combine(self, other, func, fill_value=nan)
| Perform elementwise binary operation on two Series using given function
| with optional fill value when an index is missing from one Series or
| the other
|
| 【参数】
| ----------| other : Series or scalar value
| func : function
| fill_value : scalar value
|
| 【返回值】
| -------| result : Series
|
| combine_first(self, other)
| Combine Series values, choosing the calling Series&#39;s values
| first. Result index will be the union of the two indexes
|
| 【参数】
| ----------| other : Series
|
| 【返回值】
| -------| y : Series
|
815
| compound(self, axis=None, skipna=None, level=None)
| Return the compound percentage of the values for the requested axis
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| compounded : scalar or Series (if level specified)
|
| compress(self, condition, axis=0, out=None, **kwargs)
| Return selected slices of an array along given axis as a Series
|
| 【参见】
| --------| numpy.ndarray.compress
|
| corr(self, other, method=&#39;pearson&#39;, min_periods=None)
| Compute correlation with `other` Series, excluding missing values
|
| 【参数】
| ----------| other : Series
| method : {&#39;pearson&#39;, &#39;kendall&#39;, &#39;spearman&#39;}
| * pearson : standard correlation coefficient
| * kendall : Kendall Tau correlation coefficient
| * spearman : Spearman rank correlation
| min_periods : int, optional
| Minimum number of observations needed to have a valid result
|
|
| 【返回值】
| -------| correlation : float
|
| count(self, level=None)
| Return number of non-NA/null observations in the Series
|
| 【参数】
| ----------| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a smaller Series
|
| 【返回值】
| -------| nobs : int or Series (if level specified)
816
|
| cov(self, other, min_periods=None)
| Compute covariance with Series, excluding missing values
|
| 【参数】
| ----------| other : Series
| min_periods : int, optional
| Minimum number of observations needed to have a valid result
|
| 【返回值】
| -------| covariance : float
|
| Normalized by N-1 (unbiased estimator).
|
| cummax = max(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative max over requested axis.
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| max : scalar
|
| cummin = min(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative min over requested axis.
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| min : scalar
|
| cumprod = prod(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative prod over requested axis.
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------
817
| prod : scalar
|
| cumsum = sum(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative sum over requested axis.
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| sum : scalar
|
| diff(self, periods=1)
| 1st discrete difference of object
|
| 【参数】
| ----------| periods : int, default 1
| Periods to shift for forming difference
|
| 【返回值】
| -------| diffed : Series
|
| div = truediv(self, other, level=None, fill_value=None, axis=0)
| Floating division of series and other, element-wise (binary operator `truediv`).
|
| Equivalent to</code>series / other<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rtruediv
|
| divide = truediv(self, other, level=None, fill_value=None, axis=0)
| Floating division of series and other, element-wise (binary operator `truediv`).
|
| Equivalent to</code>series / other<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
818
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rtruediv
|
| dot(self, other)
| Matrix multiplication with DataFrame or inner-product with Series
| objects
|
| 【参数】
| ----------| other : Series or DataFrame
|
| 【返回值】
| -------| dot_product : scalar or Series
|
| drop_duplicates(self, keep=&#39;first&#39;, inplace=False)
| Return Series with duplicate values removed
|
| 【参数】
| ----------|
| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| -</code>first<code>: Drop duplicates except for the first occurrence.
| -</code>last<code>: Drop duplicates except for the last occurrence.
| - False : Drop all duplicates.
| take_last : deprecated
| inplace : boolean, default False
| If True, performs operation inplace and returns None.
|
| 【返回值】
| -------| deduplicated : Series
|
| dropna(self, axis=0, inplace=False, **kwargs)
| Return Series without null values
|
| 【返回值】
| -------| valid : Series
| inplace : boolean, default False
819
| Do operation in place.
|
| duplicated(self, keep=&#39;first&#39;)
| Return boolean Series denoting duplicate values
|
| 【参数】
| ----------| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| -</code>first<code>: Mark duplicates as</code>True<code>except for the first occurrence.
| -</code>last<code>: Mark duplicates as</code>True<code>except for the last occurrence.
| - False : Mark all duplicates as</code>True<code>.
| take_last : deprecated
|
| 【返回值】
| -------| duplicated : Series
|
| eq = wrapper(self, other, axis=None)
|
| fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)
| Fill NA/NaN values using the specified method
|
| 【参数】
| ----------| value : scalar, dict, Series, or DataFrame
| Value to use to fill holes (e.g. 0), alternately a dict/Series/DataFrame of
| values specifying which value to use for each index (for a Series) or
| column (for a DataFrame). (values not in the dict/Series/DataFrame will not be
| filled). This value cannot be a list.
| method : {&#39;backfill&#39;, &#39;bfill&#39;, &#39;pad&#39;, &#39;ffill&#39;, None}, default None
| Method to use for filling holes in reindexed Series
| pad / ffill: propagate last valid observation forward to next valid
| backfill / bfill: use NEXT valid observation to fill gap
| axis : {0, &#39;index&#39;}
| inplace : boolean, default False
| If True, fill in place. Note: this will modify any
| other views on this object, (e.g. a no-copy slice for a column in a
| DataFrame).
| limit : int, default None
| If method is specified, this is the maximum number of consecutive
| NaN values to forward/backward fill. In other words, if there is
| a gap with more than this number of consecutive NaNs, it will only
| be partially filled. If method is not specified, this is the
| maximum number of entries along the entire axis where NaNs will be
| filled.
| downcast : dict, default is None
| a dict of item-&gt;dtype of what to downcast if possible,
| or the string &#39;infer&#39; which will try to downcast to an appropriate
| equal type (e.g. float64 to int64 if possible)
|
| 【参见】
| --------| reindex, asfreq
|
| 【返回值】
| -------| filled : Series
820
|
| first_valid_index(self)
| Return label for first non-NA/null value
|
| floordiv(self, other, level=None, fill_value=None, axis=0)
| Integer division of series and other, element-wise (binary operator `floordiv`).
|
| Equivalent to</code>series // other<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rfloordiv
|
| ge = wrapper(self, other, axis=None)
|
| get_value(self, label, takeable=False)
| Quickly retrieve single value at passed index label
|
| 【参数】
| ----------| index : label
| takeable : interpret the index as indexers, default False
|
| 【返回值】
| -------| value : scalar value
|
| get_values(self)
| same as values (but handles sparseness conversions); is a view
|
| gt = wrapper(self, other, axis=None)
|
| hist = hist_series(self, by=None, ax=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None,
figsize=None, bins=10, **kwds)
| Draw histogram of the input series using matplotlib
|
| 【参数】
| ----------| by : object, optional
| If passed, then used to form histograms for separate groups
| ax : matplotlib axis object
| If not passed, uses gca()
821
| grid : boolean, default True
| Whether to show axis grid lines
| xlabelsize : int, default None
| If specified changes the x-axis label size
| xrot : float, default None
| rotation of x axis labels
| ylabelsize : int, default None
| If specified changes the y-axis label size
| yrot : float, default None
| rotation of y axis labels
| figsize : tuple, default None
| figure size in inches by default
| bins: integer, default 10
| Number of histogram bins to be used
| kwds : keywords
| To be passed to the actual plotting function
|
| 【注意】
| -----| See matplotlib documentation online for more on this
|
| idxmax(self, axis=None, out=None, skipna=True)
| Index of first occurrence of maximum of values.
|
| 【参数】
| ----------| skipna : boolean, default True
| Exclude NA/null values
|
| 【返回值】
| -------| idxmax : Index of maximum of values
|
| 【注意】
| -----| This method is the Series version of</code>ndarray.argmax<code>.
|
| 【参见】
| --------| DataFrame.idxmax
| numpy.ndarray.argmax
|
| idxmin(self, axis=None, out=None, skipna=True)
| Index of first occurrence of minimum of values.
|
| 【参数】
| ----------| skipna : boolean, default True
| Exclude NA/null values
|
| 【返回值】
| -------| idxmin : Index of minimum of values
|
| 【注意】
| -----
822
| This method is the Series version of</code>ndarray.argmin<code>.
|
| 【参见】
| --------| DataFrame.idxmin
| numpy.ndarray.argmin
|
| iget(self, i, axis=0)
| DEPRECATED. Use</code>.iloc[i]<code>or</code>.iat[i]<code>instead
|
| iget_value(self, i, axis=0)
| DEPRECATED. Use</code>.iloc[i]<code>or</code>.iat[i]<code>instead
|
| irow(self, i, axis=0)
| DEPRECATED. Use</code>.iloc[i]<code>or</code>.iat[i]<code>instead
|
| isin(self, values)
| Return a boolean :class:`~pandas.Series` showing whether each element
| in the :class:`~pandas.Series` is exactly contained in the passed
| sequence of</code>values<code>.
|
| 【参数】
| ----------| values : list-like
| The sequence of values to test. Passing in a single string will
| raise a</code>TypeError<code>. Instead, turn a single string into a
|</code>list<code>of one element.
|
| 【返回值】
| -------| isin : Series (bool dtype)
|
| 【Raises 引发错误】
| ------| TypeError
| * If</code>values<code>is a string
|
| 【参见】
| --------| pandas.DataFrame.isin
|
| 【示例】
| --------|
| &gt;&gt;&gt; s = pd.Series(list(&#39;abc&#39;))
| &gt;&gt;&gt; s.isin([&#39;a&#39;, &#39;c&#39;, &#39;e&#39;])
| 0 True
| 1 False
| 2 True
| dtype: bool
|
| Passing a single string as</code>s.isin(‘a’)<code>will raise an error. Use
| a list of one element instead:
|
| &gt;&gt;&gt; s.isin([&#39;a&#39;])
| 0 True
| 1 False
823
| 2 False
| dtype: bool
|
| items = iteritems(self)
| Lazily iterate over (index, value) tuples
|
| iteritems(self)
| Lazily iterate over (index, value) tuples
|
| keys(self)
| Alias for index
|
| kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return unbiased kurtosis over requested axis using Fishers definition of
| kurtosis (kurtosis of normal == 0.0). Normalized by N-1
|
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| kurt : scalar or Series (if level specified)
|
| kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return unbiased kurtosis over requested axis using Fishers definition of
| kurtosis (kurtosis of normal == 0.0). Normalized by N-1
|
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| kurt : scalar or Series (if level specified)
|
| last_valid_index(self)
824
| Return label for last non-NA/null value
|
| le = wrapper(self, other, axis=None)
|
| lt = wrapper(self, other, axis=None)
|
| mad(self, axis=None, skipna=None, level=None)
| Return the mean absolute deviation of the values for the requested axis
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| mad : scalar or Series (if level specified)
|
| map(self, arg, na_action=None)
| Map values of Series using input correspondence (which can be
| a dict, Series, or function)
|
| 【参数】
| ----------| arg : function, dict, or Series
| na_action : {None, &#39;ignore&#39;}
| If &#39;ignore&#39;, propagate NA values
|
| 【示例】
| --------| &gt;&gt;&gt; x
| one 1
| two 2
| three 3
|
| &gt;&gt;&gt; y
| 1 foo
| 2 bar
| 3 baz
|
| &gt;&gt;&gt; x.map(y)
| one foo
| two bar
| three baz
|
| 【返回值】
| -------| y : Series
| same index as caller
825
|
| max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| This method returns the maximum of the values in the object. If you
| want the *index* of the maximum, use</code>idxmax<code>. This is the
| equivalent of the</code>numpy.ndarray<code>method</code>argmax<code>.
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| max : scalar or Series (if level specified)
|
| mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the mean of the values for the requested axis
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| mean : scalar or Series (if level specified)
|
| median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the median of the values for the requested axis
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
826
| everything, then use only numeric data
|
| 【返回值】
| -------| median : scalar or Series (if level specified)
|
| memory_usage(self, index=False, deep=False)
| Memory usage of the Series
|
| 【参数】
| ----------| index : bool
| Specifies whether to include memory usage of Series index
| deep : bool
| Introspect the data deeply, interrogate
| `object` dtypes for system-level memory consumption
|
| 【返回值】
| -------| scalar bytes of memory consumed
|
| 【注意】
| -----| Memory usage does not include memory consumed by elements that
| are not components of the array if deep=False
|
| 【参见】
| --------| numpy.ndarray.nbytes
|
| min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| This method returns the minimum of the values in the object. If you
| want the *index* of the minimum, use</code>idxmin<code>. This is the
| equivalent of the</code>numpy.ndarray<code>method</code>argmin<code>.
|
| 【参数】
| ----------| axis : {index (0)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a scalar
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| min : scalar or Series (if level specified)
|
| mod(self, other, level=None, fill_value=None, axis=0)
| Modulo of series and other, element-wise (binary operator `mod`).
|
| Equivalent to</code>series % other<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
827
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rmod
|
| mode(self)
| Returns the mode(s) of the dataset.
|
| Empty if nothing occurs at least 2 times. Always returns Series even
| if only one value.
|
| 【参数】
| ----------| sort : bool, default True
| If True, will lexicographically sort values, if False skips
| sorting. Result ordering when</code>sort=False<code>is not defined.
|
| 【返回值】
| -------| modes : Series (sorted)
|
| mul(self, other, level=None, fill_value=None, axis=0)
| Multiplication of series and other, element-wise (binary operator `mul`).
|
| Equivalent to</code>series <em> other<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
828
| --------| Series.rmul
|
| multiply = mul(self, other, level=None, fill_value=None, axis=0)
| Multiplication of series and other, element-wise (binary operator `mul`).
|
| Equivalent to</code>series </em> other<code>, but with support to substitute a fill_value for
| missing data in one of the inputs.
|
| 【参数】
| ----------| other: Series or scalar value
| fill_value : None or float value, default None (NaN)
| Fill missing (NaN) values with this value. If both Series are
| missing, the result will be missing
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
|
| 【返回值】
| -------| result : Series
|
| 【参见】
| --------| Series.rmul
|
| ne = wrapper(self, other, axis=None)
|
| nlargest(self, n=5, keep=&#39;first&#39;)
| Return the largest `n` elements.
|
| 【参数】
| ----------| n : int
| Return this many descending sorted values
| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| Where there are duplicate values:
| -</code>first<code>: take the first occurrence.
| -</code>last<code>: take the last occurrence.
| take_last : deprecated
|
| 【返回值】
| -------| top_n : Series
| The n largest values in the Series, in sorted order
|
| 【注意】
| -----| Faster than</code>.sort_values(ascending=False).head(n)<code>for small `n` relative
| to the size of the</code>Series<code>object.
|
| 【参见】
| --------| Series.nsmallest
|
829
| 【示例】
| --------| &gt;&gt;&gt; import pandas as pd
| &gt;&gt;&gt; import numpy as np
| &gt;&gt;&gt; s = pd.Series(np.random.randn(1e6))
| &gt;&gt;&gt; s.nlargest(10) # only sorts up to the N requested
|
| nonzero(self)
| Return the indices of the elements that are non-zero
|
| This method is equivalent to calling `numpy.nonzero` on the
| series data. For compatability with NumPy, the return value is
| the same (a tuple with an array of indices for each dimension),
| but it will always be a one-item tuple because series only have
| one dimension.
|
| 【示例】
| --------| &gt;&gt;&gt; s = pd.Series([0, 3, 0, 4])
| &gt;&gt;&gt; s.nonzero()
| (array([1, 3]),)
| &gt;&gt;&gt; s.iloc[s.nonzero()[0]]
| 1 3
| 3 4
| dtype: int64
|
| 【参见】
| --------| numpy.nonzero
|
| nsmallest(self, n=5, keep=&#39;first&#39;)
| Return the smallest `n` elements.
|
| 【参数】
| ----------| n : int
| Return this many ascending sorted values
| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| Where there are duplicate values:
| -</code>first<code>: take the first occurrence.
| -</code>last<code>: take the last occurrence.
| take_last : deprecated
|
| 【返回值】
| -------| bottom_n : Series
| The n smallest values in the Series, in sorted order
|
| 【注意】
| -----| Faster than</code>.sort_values().head(n)<code>for small `n` relative to
| the size of the</code>Series<code>object.
|
| 【参见】
| --------| Series.nlargest
|
830
| 【示例】
| --------| &gt;&gt;&gt; import pandas as pd
| &gt;&gt;&gt; import numpy as np
| &gt;&gt;&gt; s = pd.Series(np.random.randn(1e6))
| &gt;&gt;&gt; s.nsmallest(10) # only sorts up to the N requested
|
| order(self, na_last=None, ascending=True, kind=&#39;quicksort&#39;, na_position=&#39;last&#39;, inplace=False)
| DEPRECATED: use :meth:`Series.sort_values`
|
| Sorts Series object, by value, maintaining index-value link.
| This will return a new Series by default. Series.sort is the equivalent but as an inplace method.
|
| 【参数】
| ----------| na_last : boolean (optional, default=True) (DEPRECATED; use na_position)
| Put NaN&#39;s at beginning or end
| ascending : boolean, default True
| Sort ascending. Passing False sorts descending
| kind : {&#39;mergesort&#39;, &#39;quicksort&#39;, &#39;heapsort&#39;}, default &#39;quicksort&#39;
| Choice of sorting algorithm. See np.sort for more
| information. &#39;mergesort&#39; is the only stable algorithm
| na_position : {&#39;first&#39;, &#39;last&#39;} (optional, default=&#39;last&#39;)
| &#39;first&#39; puts NaNs at the beginning
| &#39;last&#39; puts NaNs at the end
| inplace : boolean, default False
| Do operation in place.
|
| 【返回值】
| -------| y : Series
|
| 【参见】
| --------| Series.sort_values
|
| pow(self, other, level=None, fill_value=None, axis=0)
| Exponential power of series and other, element-wise (binary operator `pow`).
|
| Equivalent to</code>series <strong> other``, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other: Series or scalar value<br>| fill_value : None or float value, default None (NaN)<br>| Fill missing (NaN) values with this value. If both Series are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【返回值】<br>| ——-| result : Series<br>|<br>| 【参见】<br>831<br>| ——–| Series.rpow<br>|<br>| prod(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| Return the product of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| prod : scalar or Series (if level specified)<br>|<br>| product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, <strong>kwargs)<br>| Return the product of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| prod : scalar or Series (if level specified)<br>|<br>| ptp(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| Returns the difference between the maximum value and the minimum<br>| value in the object. This is the equivalent of the <code>numpy.ndarray</code><br>| method <code>ptp</code>.<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>832<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| ptp : scalar or Series (if level specified)<br>|<br>| put(self, <em>args, **kwargs)<br>| return a ndarray with the values put<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.put<br>|<br>| quantile(self, q=0.5)<br>| Return value at the given quantile, a la numpy.percentile.<br>|<br>| 【参数】<br>| ———-| q : float or array-like, default 0.5 (50% quantile)<br>| 0 &lt;= q &lt;= 1, the quantile(s) to compute<br>|<br>| 【返回值】<br>| ——-| quantile : float or Series<br>| if <code>q</code> is an array, a Series will be returned where the<br>| index is <code>q</code> and the values are the quantiles.<br>|<br>| 【示例】<br>| ——–|<br>| &gt;&gt;&gt; s = Series([1, 2, 3, 4])<br>| &gt;&gt;&gt; s.quantile(.5)<br>| 2.5<br>| &gt;&gt;&gt; s.quantile([.25, .5, .75])<br>| 0.25 1.75<br>| 0.50 2.50<br>| 0.75 3.25<br>| dtype: float64<br>|<br>| radd(self, other, level=None, fill_value=None, axis=0)<br>| Addition of series and other, element-wise (binary operator <code>radd</code>).<br>|<br>| Equivalent to <code>other + series</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other: Series or scalar value<br>| fill_value : None or float value, default None (NaN)<br>| Fill missing (NaN) values with this value. If both Series are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>833<br>| 【返回值】<br>| ——-| result : Series<br>|<br>| 【参见】<br>| ——–| Series.add<br>|<br>| rank(self, method=’average’, na_option=’keep’, ascending=True, pct=False)<br>| Compute data ranks (1 through n). Equal values are assigned a rank that<br>| is the average of the ranks of those values<br>|<br>| 【参数】<br>| ———-| method : {‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}<br>| </em> average: average rank of group<br>| <em> min: lowest rank in group<br>| </em> max: highest rank in group<br>| <em> first: ranks assigned in order they appear in the array<br>| </em> dense: like ‘min’, but rank always increases by 1 between groups<br>| na_option : {‘keep’}<br>| keep: leave NA values where they are<br>| ascending : boolean, default True<br>| False for ranks by high (1) to low (N)<br>| pct : boolean, default False<br>| Computes percentage rank of data<br>|<br>| 【返回值】<br>| ——-| ranks : Series<br>|<br>| ravel(self, order=’C’)<br>| Return the flattened underlying data as an ndarray<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.ravel<br>|<br>| rdiv = rtruediv(self, other, level=None, fill_value=None, axis=0)<br>| Floating division of series and other, element-wise (binary operator <code>rtruediv</code>).<br>|<br>| Equivalent to <code>other / series</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other: Series or scalar value<br>| fill_value : None or float value, default None (NaN)<br>| Fill missing (NaN) values with this value. If both Series are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【返回值】<br>| ——-| result : Series<br>834<br>|<br>| 【参见】<br>| ——–| Series.truediv<br>|<br>| reindex(self, index=None, <strong>kwargs)<br>| Conform Series to new index with optional filling logic, placing<br>| NA/NaN in locations having no value in the previous index. A new object<br>| is produced unless the new index is equivalent to the current one and<br>| copy=False<br>|<br>| 【参数】<br>| ———-| index : array-like, optional (can be specified in order, or as<br>| keywords)<br>| New labels / index to conform to. Preferably an Index object to<br>| avoid duplicating data<br>| method : {None, ‘backfill’/‘bfill’, ‘pad’/‘ffill’, ‘nearest’}, optional<br>| method to use for filling holes in reindexed DataFrame.<br>| Please note: this is only applicable to DataFrames/Series with a<br>| monotonically increasing/decreasing index.<br>| <em> default: don’t fill gaps<br>| </em> pad / ffill: propagate last valid observation forward to next valid<br>| <em> backfill / bfill: use next valid observation to fill gap<br>| </em> nearest: use nearest valid observations to fill gap<br>| copy : boolean, default True<br>| Return a new object, even if the passed indexes are the same<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>| fill_value : scalar, default np.NaN<br>| Value to use for missing values. Defaults to NaN, but can be any<br>| “compatible” value<br>| limit : int, default None<br>| Maximum number of consecutive elements to forward or backward fill<br>| tolerance : optional<br>| Maximum distance between original and new labels for inexact<br>| matches. The values of the index at the matching locations most<br>| satisfy the equation <code>abs(index[indexer] - target) &lt;= tolerance</code>.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【示例】<br>| ——–|<br>| Create a dataframe with some fictional data.<br>|<br>| &gt;&gt;&gt; index = [‘Firefox’, ‘Chrome’, ‘Safari’, ‘IE10’, ‘Konqueror’]<br>| &gt;&gt;&gt; df = pd.DataFrame({<br>| … ‘http_status’: [200,200,404,404,301],<br>| … ‘response_time’: [0.04, 0.02, 0.07, 0.08, 1.0]},<br>| … index=index)<br>| &gt;&gt;&gt; df<br>| http_status response_time<br>| Firefox 200 0.04<br>| Chrome 200 0.02<br>| Safari 404 0.07<br>835<br>| IE10 404 0.08<br>| Konqueror 301 1.00<br>|<br>| Create a new index and reindex the dataframe. By default<br>| values in the new index that do not have corresponding<br>| records in the dataframe are assigned <code>NaN</code>.<br>|<br>| &gt;&gt;&gt; new_index= [‘Safari’, ‘Iceweasel’, ‘Comodo Dragon’, ‘IE10’,<br>| … ‘Chrome’]<br>| &gt;&gt;&gt; df.reindex(new_index)<br>| http_status response_time<br>| Safari 404 0.07<br>| Iceweasel NaN NaN<br>| Comodo Dragon NaN NaN<br>| IE10 404 0.08<br>| Chrome 200 0.02<br>|<br>| We can fill in the missing values by passing a value to<br>| the keyword <code>fill_value</code>. Because the index is not monotonically<br>| increasing or decreasing, we cannot use arguments to the keyword<br>| <code>method</code> to fill the <code>NaN</code> values.<br>|<br>| &gt;&gt;&gt; df.reindex(new_index, fill_value=0)<br>| http_status response_time<br>| Safari 404 0.07<br>| Iceweasel 0 0.00<br>| Comodo Dragon 0 0.00<br>| IE10 404 0.08<br>| Chrome 200 0.02<br>|<br>| &gt;&gt;&gt; df.reindex(new_index, fill_value=’missing’)<br>| http_status response_time<br>| Safari 404 0.07<br>| Iceweasel missing missing<br>| Comodo Dragon missing missing<br>| IE10 404 0.08<br>| Chrome 200 0.02<br>|<br>| To further illustrate the filling functionality in<br>| <code>reindex</code>, we will create a dataframe with a<br>| monotonically increasing index (for example, a sequence<br>| of dates).<br>|<br>| &gt;&gt;&gt; date_index = pd.date_range(‘1/1/2010’, periods=6, freq=’D’)<br>| &gt;&gt;&gt; df2 = pd.DataFrame({“prices”: [100, 101, np.nan, 100, 89, 88]},<br>| index=date_index)<br>| &gt;&gt;&gt; df2<br>| prices<br>| 2010-01-01 100<br>| 2010-01-02 101<br>| 2010-01-03 NaN<br>| 2010-01-04 100<br>| 2010-01-05 89<br>| 2010-01-06 88<br>|<br>| Suppose we decide to expand the dataframe to cover a wider<br>| date range.<br>836<br>|<br>| &gt;&gt;&gt; date_index2 = pd.date_range(‘12/29/2009’, periods=10, freq=’D’)<br>| &gt;&gt;&gt; df2.reindex(date_index2)<br>| prices<br>| 2009-12-29 NaN<br>| 2009-12-30 NaN<br>| 2009-12-31 NaN<br>| 2010-01-01 100<br>| 2010-01-02 101<br>| 2010-01-03 NaN<br>| 2010-01-04 100<br>| 2010-01-05 89<br>| 2010-01-06 88<br>| 2010-01-07 NaN<br>|<br>| The index entries that did not have a value in the original data frame<br>| (for example, ‘2009-12-29’) are by default filled with <code>NaN</code>.<br>| If desired, we can fill in the missing values using one of several<br>| options.<br>|<br>| For example, to backpropagate the last valid value to fill the <code>NaN</code><br>| values, pass <code>bfill</code> as an argument to the <code>method</code> keyword.<br>|<br>| &gt;&gt;&gt; df2.reindex(date_index2, method=’bfill’)<br>| prices<br>| 2009-12-29 100<br>| 2009-12-30 100<br>| 2009-12-31 100<br>| 2010-01-01 100<br>| 2010-01-02 101<br>| 2010-01-03 NaN<br>| 2010-01-04 100<br>| 2010-01-05 89<br>| 2010-01-06 88<br>| 2010-01-07 NaN<br>|<br>| Please note that the <code>NaN</code> value present in the original dataframe<br>| (at index value 2010-01-03) will not be filled by any of the<br>| value propagation schemes. This is because filling while reindexing<br>| does not look at dataframe values, but only compares the original and<br>| desired indexes. If you do want to fill in the <code>NaN</code> values present<br>| in the original dataframe, use the <code>fillna()</code> method.<br>|<br>| 【返回值】<br>| ——-| reindexed : Series<br>|<br>| reindex_axis(self, labels, axis=0, </strong>kwargs)<br>| for compatibility with higher dims<br>|<br>| rename(self, index=None, <strong>kwargs)<br>| Alter axes input function or functions. Function / dict values must be<br>| unique (1-to-1). Labels not contained in a dict / Series will be left<br>| as-is.<br>|<br>| 【参数】<br>| ———-<br>837<br>| index : dict-like or function, optional<br>| Transformation to apply to that axis values<br>|<br>| copy : boolean, default True<br>| Also copy underlying data<br>| inplace : boolean, default False<br>| Whether to return a new Series. If True then value of copy is<br>| ignored.<br>|<br>| 【返回值】<br>| ——-| renamed : Series (new object)<br>|<br>| reorder_levels(self, order)<br>| Rearrange index levels using input order. May not drop or duplicate<br>| levels<br>|<br>| 【参数】<br>| ———-| order: list of int representing new level order.<br>| (reference level by number or key)<br>| axis: where to reorder levels<br>|<br>| 【返回值】<br>| ——-| type of caller (new object)<br>|<br>| repeat(self, reps)<br>| return a new Series with the values repeated reps times<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.repeat<br>|<br>| reset_index(self, level=None, drop=False, name=None, inplace=False)<br>| Analogous to the :meth:<code>pandas.DataFrame.reset_index</code> function, see<br>| docstring there.<br>|<br>| 【参数】<br>| ———-| level : int, str, tuple, or list, default None<br>| Only remove the given levels from the index. Removes all levels by<br>| default<br>| drop : boolean, default False<br>| Do not try to insert index into dataframe columns<br>| name : object, default None<br>| The name of the column corresponding to the Series values<br>| inplace : boolean, default False<br>| Modify the Series in place (do not create a new object)<br>|<br>| 【返回值】<br>| ———-| resetted : DataFrame, or Series if drop == True<br>|<br>| reshape(self, *args, </strong>kwargs)<br>| return an ndarray with the values shape<br>| if the specified shape matches exactly the current shape, then<br>838<br>| return self (for compat)<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.take<br>|<br>| rfloordiv(self, other, level=None, fill_value=None, axis=0)<br>| Integer division of series and other, element-wise (binary operator <code>rfloordiv</code>).<br>|<br>| Equivalent to <code>other // series</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other: Series or scalar value<br>| fill_value : None or float value, default None (NaN)<br>| Fill missing (NaN) values with this value. If both Series are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【返回值】<br>| ——-| result : Series<br>|<br>| 【参见】<br>| ——–| Series.floordiv<br>|<br>| rmod(self, other, level=None, fill_value=None, axis=0)<br>| Modulo of series and other, element-wise (binary operator <code>rmod</code>).<br>|<br>| Equivalent to <code>other % series</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other: Series or scalar value<br>| fill_value : None or float value, default None (NaN)<br>| Fill missing (NaN) values with this value. If both Series are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【返回值】<br>| ——-| result : Series<br>|<br>| 【参见】<br>| ——–| Series.mod<br>|<br>| rmul(self, other, level=None, fill_value=None, axis=0)<br>| Multiplication of series and other, element-wise (binary operator <code>rmul</code>).<br>|<br>839<br>| Equivalent to <code>other * series</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other: Series or scalar value<br>| fill_value : None or float value, default None (NaN)<br>| Fill missing (NaN) values with this value. If both Series are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【返回值】<br>| ——-| result : Series<br>|<br>| 【参见】<br>| ——–| Series.mul<br>|<br>| round(self, decimals=0, out=None)<br>| a.round(decimals=0, out=None)<br>|<br>| Return <code>a</code> with each element rounded to the given number of decimals.<br>|<br>| Refer to <code>numpy.around</code> for full documentation.<br>|<br>| 【参见】<br>| ——–| numpy.around : equivalent function<br>|<br>| rpow(self, other, level=None, fill_value=None, axis=0)<br>| Exponential power of series and other, element-wise (binary operator <code>rpow</code>).<br>|<br>| Equivalent to <code>other ** series</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other: Series or scalar value<br>| fill_value : None or float value, default None (NaN)<br>| Fill missing (NaN) values with this value. If both Series are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【返回值】<br>| ——-| result : Series<br>|<br>| 【参见】<br>| ——–| Series.pow<br>|<br>| rsub(self, other, level=None, fill_value=None, axis=0)<br>840<br>| Subtraction of series and other, element-wise (binary operator <code>rsub</code>).<br>|<br>| Equivalent to <code>other - series</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other: Series or scalar value<br>| fill_value : None or float value, default None (NaN)<br>| Fill missing (NaN) values with this value. If both Series are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【返回值】<br>| ——-| result : Series<br>|<br>| 【参见】<br>| ——–| Series.sub<br>|<br>| rtruediv(self, other, level=None, fill_value=None, axis=0)<br>| Floating division of series and other, element-wise (binary operator <code>rtruediv</code>).<br>|<br>| Equivalent to <code>other / series</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other: Series or scalar value<br>| fill_value : None or float value, default None (NaN)<br>| Fill missing (NaN) values with this value. If both Series are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【返回值】<br>| ——-| result : Series<br>|<br>| 【参见】<br>| ——–| Series.truediv<br>|<br>| searchsorted(self, v, side=’left’, sorter=None)<br>| Find indices where elements should be inserted to maintain order.<br>|<br>| Find the indices into a sorted Series <code>self</code> such that, if the<br>| corresponding elements in <code>v</code> were inserted before the indices, the<br>| order of <code>self</code> would be preserved.<br>|<br>| 【参数】<br>| ———-| v : array_like<br>841<br>| Values to insert into <code>a</code>.<br>| side : {‘left’, ‘right’}, optional<br>| If ‘left’, the index of the first suitable location found is given.<br>| If ‘right’, return the last such index. If there is no suitable<br>| index, return either 0 or N (where N is the length of <code>a</code>).<br>| sorter : 1-D array_like, optional<br>| Optional array of integer indices that sort <code>self</code> into ascending<br>| order. They are typically the result of <code>np.argsort</code>.<br>|<br>| 【返回值】<br>| ——-| indices : array of ints<br>| Array of insertion points with the same shape as <code>v</code>.<br>|<br>| 【参见】<br>| ——–| Series.sort_values<br>| numpy.searchsorted<br>|<br>| 【注意】<br>| —–| Binary search is used to find the required insertion points.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; x = pd.Series([1, 2, 3])<br>| &gt;&gt;&gt; x<br>| 0 1<br>| 1 2<br>| 2 3<br>| dtype: int64<br>| &gt;&gt;&gt; x.searchsorted(4)<br>| array([3])<br>| &gt;&gt;&gt; x.searchsorted([0, 4])<br>| array([0, 3])<br>| &gt;&gt;&gt; x.searchsorted([1, 3], side=’left’)<br>| array([0, 2])<br>| &gt;&gt;&gt; x.searchsorted([1, 3], side=’right’)<br>| array([1, 3])<br>| &gt;&gt;&gt; x.searchsorted([1, 2], side=’right’, sorter=[0, 2, 1])<br>| array([1, 3])<br>|<br>| sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, <strong>kwargs)<br>| Return unbiased standard error of the mean over requested axis.<br>|<br>| Normalized by N-1 by default. This can be changed using the ddof argument<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| ddof : int, default 1<br>842<br>| degrees of freedom<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| sem : scalar or Series (if level specified)<br>|<br>| set_value(self, label, value, takeable=False)<br>| Quickly set single value at passed label. If label is not contained, a<br>| new object is created with the label placed at the end of the result<br>| index<br>|<br>| 【参数】<br>| ———-| label : object<br>| Partial indexing with MultiIndex not allowed<br>| value : object<br>| Scalar value<br>| takeable : interpret the index as indexers, default False<br>|<br>| 【返回值】<br>| ——-| series : Series<br>| If label is contained, will be reference to calling Series,<br>| otherwise a new object<br>|<br>| shift(self, periods=1, freq=None, axis=0)<br>| Shift index by desired number of periods with an optional time freq<br>|<br>| 【参数】<br>| ———-| periods : int<br>| Number of periods to move, can be positive or negative<br>| freq : DateOffset, timedelta, or time rule string, optional<br>| Increment to use from datetools module or time rule (e.g. ‘EOM’).<br>| See Notes.<br>| axis : {0, ‘index’}<br>|<br>| 【注意】<br>| —–| If freq is specified then the index values are shifted but the data<br>| is not realigned. That is, use freq if you would like to extend the<br>| index when shifting and preserve the original data.<br>|<br>| 【返回值】<br>| ——-| shifted : Series<br>|<br>| skew(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| Return unbiased skew over requested axis<br>| Normalized by N-1<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>843<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| skew : scalar or Series (if level specified)<br>|<br>| sort(self, axis=0, ascending=True, kind=’quicksort’, na_position=’last’, inplace=True)<br>| DEPRECATED: use :meth:<code>Series.sort_values(inplace=True)</code> for INPLACE sorting<br>|<br>| Sort values and index labels by value. This is an inplace sort by default.<br>| Series.order is the equivalent but returns a new Series.<br>|<br>| 【参数】<br>| ———-| axis : int (can only be zero)<br>| ascending : boolean, default True<br>| Sort ascending. Passing False sorts descending<br>| kind : {‘mergesort’, ‘quicksort’, ‘heapsort’}, default ‘quicksort’<br>| Choice of sorting algorithm. See np.sort for more<br>| information. ‘mergesort’ is the only stable algorithm<br>| na_position : {‘first’, ‘last’} (optional, default=’last’)<br>| ‘first’ puts NaNs at the beginning<br>| ‘last’ puts NaNs at the end<br>| inplace : boolean, default True<br>| Do operation in place.<br>|<br>| 【参见】<br>| ——–| Series.sort_values<br>|<br>| sort_index(self, axis=0, level=None, ascending=True, inplace=False, sort_remaining=True)<br>| Sort object by labels (along an axis)<br>|<br>| 【参数】<br>| ———-| axis : index to direct sorting<br>| level : int or level name or list of ints or list of level names<br>| if not None, sort on values in specified index level(s)<br>| ascending : boolean, default True<br>| Sort ascending vs. descending<br>| inplace : bool<br>| if True, perform operation in-place<br>| kind : {<code>quicksort</code>, <code>mergesort</code>, <code>heapsort</code>}<br>| Choice of sorting algorithm. 参见：ndarray.np.sort for more information.<br>| <code>mergesort</code> is the only stable algorithm. For DataFrames, this option is<br>| only applied when sorting on a single column or label.<br>| na_position : {‘first’, ‘last’}<br>| <code>first</code> puts NaNs at the beginning, <code>last</code> puts NaNs at the end<br>| sort_remaining : bool<br>844<br>| if true and sorting by level and index is multilevel, sort by other levels<br>| too (in order) after sorting by specified level<br>|<br>| 【返回值】<br>| ——-| sorted_obj : Series<br>|<br>| sort_values(self, axis=0, ascending=True, inplace=False, kind=’quicksort’, na_position=’last’)<br>| Sort by the values along either axis<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| by : string name or list of names which refer to the axis items<br>| axis : index to direct sorting<br>| ascending : bool or list of bool<br>| Sort ascending vs. descending. Specify list for multiple sort orders.<br>| If this is a list of bools, must match the length of the by<br>| inplace : bool<br>| if True, perform operation in-place<br>| kind : {<code>quicksort</code>, <code>mergesort</code>, <code>heapsort</code>}<br>| Choice of sorting algorithm. 参见：ndarray.np.sort for more information.<br>| <code>mergesort</code> is the only stable algorithm. For DataFrames, this option is<br>| only applied when sorting on a single column or label.<br>| na_position : {‘first’, ‘last’}<br>| <code>first</code> puts NaNs at the beginning, <code>last</code> puts NaNs at the end<br>|<br>| 【返回值】<br>| ——-| sorted_obj : Series<br>|<br>| sortlevel(self, level=0, ascending=True, sort_remaining=True)<br>| Sort Series with MultiIndex by chosen level. Data will be<br>| lexicographically sorted by the chosen level followed by the other<br>| levels (in order)<br>|<br>| 【参数】<br>| ———-| level : int or level name, default None<br>| ascending : bool, default True<br>|<br>| 【返回值】<br>| ——-| sorted : Series<br>|<br>| 【参见】<br>| ——–| Series.sort_index(level=…)<br>|<br>| std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, <strong>kwargs)<br>| Return unbiased standard deviation over requested axis.<br>|<br>| Normalized by N-1 by default. This can be changed using the ddof argument<br>|<br>| 【参数】<br>845<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| ddof : int, default 1<br>| degrees of freedom<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| std : scalar or Series (if level specified)<br>|<br>| sub(self, other, level=None, fill_value=None, axis=0)<br>| Subtraction of series and other, element-wise (binary operator <code>sub</code>).<br>|<br>| Equivalent to <code>series - other</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other: Series or scalar value<br>| fill_value : None or float value, default None (NaN)<br>| Fill missing (NaN) values with this value. If both Series are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【返回值】<br>| ——-| result : Series<br>|<br>| 【参见】<br>| ——–| Series.rsub<br>|<br>| subtract = sub(self, other, level=None, fill_value=None, axis=0)<br>| Subtraction of series and other, element-wise (binary operator <code>sub</code>).<br>|<br>| Equivalent to <code>series - other</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other: Series or scalar value<br>| fill_value : None or float value, default None (NaN)<br>| Fill missing (NaN) values with this value. If both Series are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>846<br>|<br>| 【返回值】<br>| ——-| result : Series<br>|<br>| 【参见】<br>| ——–| Series.rsub<br>|<br>| sum(self, axis=None, skipna=None, level=None, numeric_only=None, </strong>kwargs)<br>| Return the sum of the values for the requested axis<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| sum : scalar or Series (if level specified)<br>|<br>| swaplevel(self, i, j, copy=True)<br>| Swap levels i and j in a MultiIndex<br>|<br>| 【参数】<br>| ———-| i, j : int, string (can be mixed)<br>| Level of index to be swapped. Can pass level name as string.<br>|<br>| 【返回值】<br>| ——-| swapped : Series<br>|<br>| take(self, indices, axis=0, convert=True, is_copy=False)<br>| return Series corresponding to requested indices<br>|<br>| 【参数】<br>| ———-| indices : list / array of ints<br>| convert : translate negative to positive indices (default)<br>|<br>| 【返回值】<br>| ——-| taken : Series<br>|<br>| 【参见】<br>| ——–| numpy.ndarray.take<br>847<br>|<br>| to_csv(self, path, index=True, sep=’,’, na_rep=’’, float_format=None, header=False, index_label=None, mode=’w’,<br>nanRep=None, encoding=None, date_format=None, decimal=’.’)<br>| Write Series to a comma-separated values (csv) file<br>|<br>| 【参数】<br>| ———-| path : string file path or file handle / StringIO. If None is provided<br>| the result is returned as a string.<br>| na_rep : string, default ‘’<br>| Missing data representation<br>| float_format : string, default None<br>| Format string for floating point numbers<br>| header : boolean, default False<br>| Write out series name<br>| index : boolean, default True<br>| Write row names (index)<br>| index_label : string or sequence, default None<br>| Column label for index column(s) if desired. If None is given, and<br>| <code>header</code> and <code>index</code> are True, then the index names are used. A<br>| sequence should be given if the DataFrame uses MultiIndex.<br>| mode : Python write mode, default ‘w’<br>| sep : character, default “,”<br>| Field delimiter for the output file.<br>| encoding : string, optional<br>| a string representing the encoding to use if the contents are<br>| non-ascii, for python versions prior to 3<br>| date_format: string, default None<br>| Format string for datetime objects.<br>| decimal: string, default ‘.’<br>| Character recognized as decimal separator. E.g. use ‘,’ for European data<br>|<br>| to_dict(self)<br>| Convert Series to {label -&gt; value} dict<br>|<br>| 【返回值】<br>| ——-| value_dict : dict<br>|<br>| to_frame(self, name=None)<br>| Convert Series to DataFrame<br>|<br>| 【参数】<br>| ———-| name : object, default None<br>| The passed name should substitute for the series name (if it has<br>| one).<br>|<br>| 【返回值】<br>| ——-| data_frame : DataFrame<br>|<br>| to_period(self, freq=None, copy=True)<br>| Convert Series from DatetimeIndex to PeriodIndex with desired<br>| frequency (inferred from index if not passed)<br>|<br>| 【参数】<br>848<br>| ———-| freq : string, default<br>|<br>| 【返回值】<br>| ——-| ts : Series with PeriodIndex<br>|<br>| to_sparse(self, kind=’block’, fill_value=None)<br>| Convert Series to SparseSeries<br>|<br>| 【参数】<br>| ———-| kind : {‘block’, ‘integer’}<br>| fill_value : float, defaults to NaN (missing)<br>|<br>| 【返回值】<br>| ——-| sp : SparseSeries<br>|<br>| to_string(self, buf=None, na_rep=’NaN’, float_format=None, header=True, length=False, dtype=False, name=False,<br>max_rows=None)<br>| Render a string representation of the Series<br>|<br>| 【参数】<br>| ———-| buf : StringIO-like, optional<br>| buffer to write to<br>| na_rep : string, optional<br>| string representation of NAN to use, default ‘NaN’<br>| float_format : one-parameter function, optional<br>| formatter function to apply to columns’ elements if they are floats<br>| default None<br>| header: boolean, default True<br>| Add the Series header (index name)<br>| length : boolean, default False<br>| Add the Series length<br>| dtype : boolean, default False<br>| Add the Series dtype<br>| name : boolean, default False<br>| Add the Series name if not None<br>| max_rows : int, optional<br>| Maximum number of rows to show before truncating. If None, show<br>| all.<br>|<br>| 【返回值】<br>| ——-| formatted : string (if not buffer passed)<br>|<br>| to_timestamp(self, freq=None, how=’start’, copy=True)<br>| Cast to datetimeindex of timestamps, at <em>beginning</em> of period<br>|<br>| 【参数】<br>| ———-| freq : string, default frequency of PeriodIndex<br>| Desired frequency<br>| how : {‘s’, ‘e’, ‘start’, ‘end’}<br>| Convention for converting period to timestamp; start of period<br>849<br>| vs. end<br>|<br>| 【返回值】<br>| ——-| ts : Series with DatetimeIndex<br>|<br>| tolist(self)<br>| Convert Series to a nested list<br>|<br>| truediv(self, other, level=None, fill_value=None, axis=0)<br>| Floating division of series and other, element-wise (binary operator <code>truediv</code>).<br>|<br>| Equivalent to <code>series / other</code>, but with support to substitute a fill_value for<br>| missing data in one of the inputs.<br>|<br>| 【参数】<br>| ———-| other: Series or scalar value<br>| fill_value : None or float value, default None (NaN)<br>| Fill missing (NaN) values with this value. If both Series are<br>| missing, the result will be missing<br>| level : int or name<br>| Broadcast across a level, matching Index values on the<br>| passed MultiIndex level<br>|<br>| 【返回值】<br>| ——-| result : Series<br>|<br>| 【参见】<br>| ——–| Series.rtruediv<br>|<br>| unstack(self, level=-1)<br>| Unstack, a.k.a. pivot, Series with MultiIndex to produce DataFrame.<br>| The level involved will automatically get sorted.<br>|<br>| 【参数】<br>| ———-| level : int, string, or list of these, default last level<br>| Level(s) to unstack, can pass level name<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; s<br>| one a 1.<br>| one b 2.<br>| two a 3.<br>| two b 4.<br>|<br>| &gt;&gt;&gt; s.unstack(level=-1)<br>| a b<br>| one 1. 2.<br>| two 3. 4.<br>|<br>| &gt;&gt;&gt; s.unstack(level=0)<br>| one two<br>850<br>| a 1. 2.<br>| b 3. 4.<br>|<br>| 【返回值】<br>| ——-| unstacked : DataFrame<br>|<br>| update(self, other)<br>| Modify Series in place using non-NA values from passed<br>| Series. Aligns on index<br>|<br>| 【参数】<br>| ———-| other : Series<br>|<br>| valid lambda self, inplace=False, <strong>kwargs<br>|<br>| var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, </strong>kwargs)<br>| Return unbiased variance over requested axis.<br>|<br>| Normalized by N-1 by default. This can be changed using the ddof argument<br>|<br>| 【参数】<br>| ———-| axis : {index (0)}<br>| skipna : boolean, default True<br>| Exclude NA/null values. If an entire row/column is NA, the result<br>| will be NA<br>| level : int or level name, default None<br>| If the axis is a MultiIndex (hierarchical), count along a<br>| particular level, collapsing into a scalar<br>| ddof : int, default 1<br>| degrees of freedom<br>| numeric_only : boolean, default None<br>| Include only float, int, boolean data. If None, will attempt to use<br>| everything, then use only numeric data<br>|<br>| 【返回值】<br>| ——-| var : scalar or Series (if level specified)<br>|<br>| view(self, dtype=None)<br>|<br>| ———————————————————————-| Class methods inherited from Series:<br>|<br>| from_array(arr, index=None, name=None, dtype=None, copy=False, fastpath=False) from builtins.type<br>|<br>| from_csv(path, sep=’,’, parse_dates=True, header=None, index_col=0, encoding=None, infer_datetime_format=False) from<br>builtins.type<br>| Read CSV file (DISCOURAGED, please use :func:<code>pandas.read_csv</code> instead).<br>|<br>| It is preferable to use the more powerful :func:<code>pandas.read_csv</code><br>| for most general purposes, but <code>from_csv</code> makes for an easy<br>| roundtrip to and from a file (the exact counterpart of<br>| <code>to_csv</code>), especially with a time Series.<br>|<br>851<br>| This method only differs from :func:<code>pandas.read_csv</code> in some defaults:<br>|<br>| - <code>index_col</code> is <code>0</code> instead of <code>None</code> (take first column as index<br>| by default)<br>| - <code>header</code> is <code>None</code> instead of <code>0</code> (the first row is not used as<br>| the column names)<br>| - <code>parse_dates</code> is <code>True</code> instead of <code>False</code> (try parsing the index<br>| as datetime by default)<br>|<br>| With :func:<code>pandas.read_csv</code>, the option <code>squeeze=True</code> can be used<br>| to return a Series like <code>from_csv</code>.<br>|<br>| 【参数】<br>| ———-| path : string file path or file handle / StringIO<br>| sep : string, default ‘,’<br>| Field delimiter<br>| parse_dates : boolean, default True<br>| Parse dates. Different default from read_table<br>| header : int, default None<br>| Row to use as header (skip prior rows)<br>| index_col : int or sequence, default 0<br>| Column to use for index. If a sequence is given, a MultiIndex<br>| is used. Different default from read_table<br>| encoding : string, optional<br>| a string representing the encoding to use if the contents are<br>| non-ascii, for python versions prior to 3<br>| infer_datetime_format: boolean, default False<br>| If True and <code>parse_dates</code> is True for a column, try to infer the<br>| datetime format based on the first datetime string. If the format<br>| can be inferred, there often will be a large parsing speed-up.<br>|<br>| 【参见】<br>| ——–| pandas.read_csv<br>|<br>| 【返回值】<br>| ——-| y : Series<br>|<br>| ———————————————————————-| Data descriptors inherited from Series:<br>|<br>| axes<br>| Return a list of the row axis labels<br>|<br>| dtype<br>| return the dtype object of the underlying data<br>|<br>| dtypes<br>| return the dtype object of the underlying data<br>|<br>| ftype<br>| return if the data is sparse|dense<br>|<br>| ftypes<br>| return if the data is sparse|dense<br>852<br>|<br>| imag<br>|<br>| index<br>|<br>| is_time_series<br>|<br>| real<br>|<br>| values<br>| Return Series as ndarray or ndarray-like<br>| depending on the dtype<br>|<br>| 【返回值】<br>| ——-| arr : numpy.ndarray or ndarray-like<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; pd.Series([1, 2, 3]).values<br>| array([1, 2, 3])<br>|<br>| &gt;&gt;&gt; pd.Series(list(‘aabc’)).values<br>| array([‘a’, ‘a’, ‘b’, ‘c’], dtype=object)<br>|<br>| &gt;&gt;&gt; pd.Series(list(‘aabc’)).astype(‘category’).values<br>| [a, a, b, c]<br>| Categories (3, object): [a, b, c]<br>|<br>| Timezone aware datetime data is converted to UTC:<br>|<br>| &gt;&gt;&gt; pd.Series(pd.date_range(‘20130101’,periods=3,tz=’US/Eastern’)).values<br>| array([‘2013-01-01T00:00:00.000000000-0500’,<br>| ‘2013-01-02T00:00:00.000000000-0500’,<br>| ‘2013-01-03T00:00:00.000000000-0500’], dtype=’datetime64[ns]’)<br>|<br>| ———————————————————————-| Data and other attributes inherited from Series:<br>|<br>| cat = <class 'pandas.core.categorical.categoricalaccessor'=""><br>| Accessor object for categorical properties of the Series values.<br>|<br>| Be aware that assigning to <code>categories</code> is a inplace operation, while all methods return<br>| new categorical data per default (but can be called with <code>inplace=True</code>).<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; s.cat.categories<br>| &gt;&gt;&gt; s.cat.categories = list(‘abc’)<br>| &gt;&gt;&gt; s.cat.rename_categories(list(‘cab’))<br>| &gt;&gt;&gt; s.cat.reorder_categories(list(‘cab’))<br>| &gt;&gt;&gt; s.cat.add_categories([‘d’,’e’])<br>| &gt;&gt;&gt; s.cat.remove_categories([‘d’])<br>| &gt;&gt;&gt; s.cat.remove_unused_categories()<br>| &gt;&gt;&gt; s.cat.set_categories(list(‘abcde’))<br>| &gt;&gt;&gt; s.cat.as_ordered()<br>| &gt;&gt;&gt; s.cat.as_unordered()<br>853<br>|<br>| dt = <class 'pandas.tseries.common.combineddatetimelikeproperties'=""><br>| Accessor object for datetimelike properties of the Series values.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; s.dt.hour<br>| &gt;&gt;&gt; s.dt.second<br>| &gt;&gt;&gt; s.dt.quarter<br>|<br>| Returns a Series indexed like the original Series.<br>| Raises TypeError if the Series does not contain datetimelike values.<br>|<br>| plot = <class 'pandas.tools.plotting.seriesplotmethods'=""><br>| Series plotting accessor and method<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; s.plot.line()<br>| &gt;&gt;&gt; s.plot.bar()<br>| &gt;&gt;&gt; s.plot.hist()<br>|<br>| Plotting methods can also be accessed by calling the accessor as a method<br>| with the <code>kind</code> argument:<br>| <code>s.plot(kind=&#39;line&#39;)</code> is equivalent to <code>s.plot.line()</code><br>|<br>| ———————————————————————-| Methods inherited from pandas.core.base.IndexOpsMixin:<br>|<br>| factorize(self, sort=False, na_sentinel=-1)<br>| Encode the object as an enumerated type or categorical variable<br>|<br>| 【参数】<br>| ———-| sort : boolean, default False<br>| Sort by values<br>| na_sentinel: int, default -1<br>| Value to mark “not found”<br>|<br>| 【返回值】<br>| ——-| labels : the indexer to the original array<br>| uniques : the unique Index<br>|<br>| item(self)<br>| return the first element of the underlying data as a python scalar<br>|<br>| nunique(self, dropna=True)<br>| Return number of unique elements in the object.<br>|<br>| Excludes NA values by default.<br>|<br>| 【参数】<br>| ———-| dropna : boolean, default True<br>| Don’t include NaN in the count.<br>|<br>854<br>| 【返回值】<br>| ——-| nunique : int<br>|<br>| transpose(self)<br>| return the transpose, which is by definition self<br>|<br>| unique(self)<br>| Return array of unique values in the object. Significantly faster than<br>| numpy.unique. Includes NA values.<br>|<br>| 【返回值】<br>| ——-| uniques : ndarray<br>|<br>| value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)<br>| Returns object containing counts of unique values.<br>|<br>| The resulting object will be in descending order so that the<br>| first element is the most frequently-occurring element.<br>| Excludes NA values by default.<br>|<br>| 【参数】<br>| ———-| normalize : boolean, default False<br>| If True then the object returned will contain the relative<br>| frequencies of the unique values.<br>| sort : boolean, default True<br>| Sort by values<br>| ascending : boolean, default False<br>| Sort in ascending order<br>| bins : integer, optional<br>| Rather than count values, group them into half-open bins,<br>| a convenience for pd.cut, only works with numeric data<br>| dropna : boolean, default True<br>| Don’t include counts of NaN.<br>|<br>| 【返回值】<br>| ——-| counts : Series<br>|<br>| ———————————————————————-| Data descriptors inherited from pandas.core.base.IndexOpsMixin:<br>|<br>| T<br>| return the transpose, which is by definition self<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| base<br>| return the base object if the memory of the underlying data is shared<br>|<br>| data<br>855<br>| return the data pointer of the underlying data<br>|<br>| flags<br>| return the ndarray.flags for the underlying data<br>|<br>| hasnans<br>|<br>| itemsize<br>| return the size of the dtype of the item of the underlying data<br>|<br>| nbytes<br>| return the number of bytes in the underlying data<br>|<br>| ndim<br>| return the number of dimensions of the underlying data, by definition 1<br>|<br>| shape<br>| return a tuple of the shape of the underlying data<br>|<br>| size<br>| return the number of elements in the underlying data<br>|<br>| strides<br>| return the strides of the underlying data<br>|<br>| ———————————————————————-| Data and other attributes inherited from pandas.core.base.IndexOpsMixin:<br>|<br>| <strong>array_priority</strong> = 1000<br>|<br>| ———————————————————————-| Data and other attributes inherited from pandas.core.strings.StringAccessorMixin:<br>|<br>| str = <class 'pandas.core.strings.stringmethods'=""><br>| Vectorized string functions for Series and Index. NAs stay NA unless<br>| handled otherwise by a particular method. Patterned after Python’s string<br>| methods, with some inspiration from R’s stringr package.<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; s.str.split(‘<em>‘)<br>| &gt;&gt;&gt; s.str.replace(‘</em>‘, ‘’)<br>|<br>| ———————————————————————-| Methods inherited from pandas.core.generic.NDFrame:<br>|<br>| <strong>abs</strong>(self)<br>|<br>| <strong>bool</strong> = <strong>nonzero</strong>(self)<br>|<br>| <strong>contains</strong>(self, key)<br>| True if the key is in the info axis<br>|<br>| <strong>delitem</strong>(self, key)<br>| Delete item<br>|<br>| <strong>finalize</strong>(self, other, method=None, <strong>kwargs)<br>856<br>| propagate metadata from other to self<br>|<br>| 【参数】<br>| ———-| other : the object from which to get the attributes that we are going<br>| to propagate<br>| method : optional, a passed method name ; possibly to take different<br>| types of propagation actions based on this<br>|<br>| <strong>getattr</strong>(self, name)<br>| After regular attribute access, try looking up the name<br>| This allows simpler access to columns for interactive use.<br>|<br>| <strong>getstate</strong>(self)<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>invert</strong>(self)<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>nonzero</strong>(self)<br>|<br>| <strong>setattr</strong>(self, name, value)<br>| After regular attribute access, try setting the name<br>| This allows simpler access to columns for interactive use.<br>|<br>| <strong>setstate</strong>(self, state)<br>|<br>| abs(self)<br>| Return an object with absolute value taken. Only applicable to objects<br>| that are all numeric<br>|<br>| 【返回值】<br>| ——-| abs: type of caller<br>|<br>| add_prefix(self, prefix)<br>| Concatenate prefix string with panel items names.<br>|<br>| 【参数】<br>| ———-| prefix : string<br>|<br>| 【返回值】<br>| ——-| with_prefix : type of caller<br>|<br>| add_suffix(self, suffix)<br>| Concatenate suffix string with panel items names<br>|<br>| 【参数】<br>| ———-| suffix : string<br>|<br>| 【返回值】<br>857<br>| ——-| with_suffix : type of caller<br>|<br>| as_blocks(self, copy=True)<br>| Convert the frame to a dict of dtype -&gt; Constructor Types that each has<br>| a homogeneous dtype.<br>|<br>| NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in<br>| as_matrix)<br>|<br>| 【参数】<br>| ———-| copy : boolean, default True<br>|<br>| .. versionadded: 0.16.1<br>|<br>| 【返回值】<br>| ——-| values : a dict of dtype -&gt; Constructor Types<br>|<br>| as_matrix(self, columns=None)<br>| Convert the frame to its Numpy-array representation.<br>|<br>| 【参数】<br>| ———-| columns: list, optional, default:None<br>| If None, return all columns, otherwise, returns specified columns.<br>|<br>| 【返回值】<br>| ——-| values : ndarray<br>| If the caller is heterogeneous and contains booleans or objects,<br>| the result will be of dtype=object. See Notes.<br>|<br>|<br>| 【注意】<br>| —–| Return is NOT a Numpy-matrix, rather, a Numpy-array.<br>|<br>| The dtype will be a lower-common-denominator dtype (implicit<br>| upcasting); that is to say if the dtypes (even of numeric types)<br>| are mixed, the one that accommodates all will be chosen. Use this<br>| with care if you are not dealing with the blocks.<br>|<br>| e.g. If the dtypes are float16 and float32, dtype will be upcast to<br>| float32. If dtypes are int32 and uint8, dtype will be upcase to<br>| int32.<br>|<br>| This method is provided for backwards compatibility. Generally,<br>| it is recommended to use ‘.values’.<br>|<br>| 【参见】<br>| ——–| pandas.DataFrame.values<br>|<br>| asfreq(self, freq, method=None, how=None, normalize=False)<br>| Convert all TimeSeries inside to specified frequency using DateOffset<br>858<br>| objects. Optionally provide fill method to pad/backfill missing values.<br>|<br>| 【参数】<br>| ———-| freq : DateOffset object, or string<br>| method : {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}<br>| Method to use for filling holes in reindexed Series<br>| pad / ffill: propagate last valid observation forward to next valid<br>| backfill / bfill: use NEXT valid observation to fill method<br>| how : {‘start’, ‘end’}, default end<br>| For PeriodIndex only, see PeriodIndex.asfreq<br>| normalize : bool, default False<br>| Whether to reset output index to midnight<br>|<br>| 【返回值】<br>| ——-| converted : type of caller<br>|<br>| astype(self, dtype, copy=True, raise_on_error=True, </strong>kwargs)<br>| Cast object to input numpy.dtype<br>| Return a copy when copy = True (be really careful with this!)<br>|<br>| 【参数】<br>| ———-| dtype : numpy.dtype or Python type<br>| raise_on_error : raise on invalid input<br>| kwargs : keyword arguments to pass on to the constructor<br>|<br>| 【返回值】<br>| ——-| casted : type of caller<br>|<br>| at_time(self, time, asof=False)<br>| Select values at particular time of day (e.g. 9:30AM)<br>|<br>| 【参数】<br>| ———-| time : datetime.time or string<br>|<br>| 【返回值】<br>| ——-| values_at_time : type of caller<br>|<br>| between_time(self, start_time, end_time, include_start=True, include_end=True)<br>| Select values between particular times of the day (e.g., 9:00-9:30 AM)<br>|<br>| 【参数】<br>| ———-| start_time : datetime.time or string<br>| end_time : datetime.time or string<br>| include_start : boolean, default True<br>| include_end : boolean, default True<br>|<br>| 【返回值】<br>| ——-| values_between_time : type of caller<br>859<br>|<br>| bfill(self, axis=None, inplace=False, limit=None, downcast=None)<br>| Synonym for NDFrame.fillna(method=’bfill’)<br>|<br>| bool(self)<br>| Return the bool of a single element PandasObject<br>| This must be a boolean scalar value, either True or False<br>|<br>| Raise a ValueError if the PandasObject does not have exactly<br>| 1 element, or that element is not boolean<br>|<br>| clip(self, lower=None, upper=None, out=None, axis=None)<br>| Trim values at input threshold(s)<br>|<br>| 【参数】<br>| ———-| lower : float or array_like, default None<br>| upper : float or array_like, default None<br>| axis : int or string axis name, optional<br>| Align object with lower and upper along the given axis.<br>|<br>| 【返回值】<br>| ——-| clipped : Series<br>|<br>| 【示例】<br>| ——–| &gt;&gt;&gt; df<br>| 0 1<br>| 0 0.335232 -1.256177<br>| 1 -1.367855 0.746646<br>| 2 0.027753 -1.176076<br>| 3 0.230930 -0.679613<br>| 4 1.261967 0.570967<br>| &gt;&gt;&gt; df.clip(-1.0, 0.5)<br>| 0 1<br>| 0 0.335232 -1.000000<br>| 1 -1.000000 0.500000<br>| 2 0.027753 -1.000000<br>| 3 0.230930 -0.679613<br>| 4 0.500000 0.500000<br>| &gt;&gt;&gt; t<br>| 0 -0.3<br>| 1 -0.2<br>| 2 -0.1<br>| 3 0.0<br>| 4 0.1<br>| dtype: float64<br>| &gt;&gt;&gt; df.clip(t, t + 1, axis=0)<br>| 0 1<br>| 0 0.335232 -0.300000<br>| 1 -0.200000 0.746646<br>| 2 0.027753 -0.100000<br>| 3 0.230930 0.000000<br>| 4 1.100000 0.570967<br>|<br>| clip_lower(self, threshold, axis=None)<br>860<br>| Return copy of the input with values below given value(s) truncated<br>|<br>| 【参数】<br>| ———-| threshold : float or array_like<br>| axis : int or string axis name, optional<br>| Align object with threshold along the given axis.<br>|<br>| 【参见】<br>| ——–| clip<br>|<br>| 【返回值】<br>| ——-| clipped : same type as input<br>|<br>| clip_upper(self, threshold, axis=None)<br>| Return copy of input with values above given value(s) truncated<br>|<br>| 【参数】<br>| ———-| threshold : float or array_like<br>| axis : int or string axis name, optional<br>| Align object with threshold along the given axis.<br>|<br>| 【参见】<br>| ——–| clip<br>|<br>| 【返回值】<br>| ——-| clipped : same type as input<br>|<br>| consolidate(self, inplace=False)<br>| Compute NDFrame with “consolidated” internals (data of each dtype<br>| grouped together in a single ndarray). Mainly an internal API function,<br>| but available here to the savvy user<br>|<br>| 【参数】<br>| ———-| inplace : boolean, default False<br>| If False return new object, otherwise modify existing object<br>|<br>| 【返回值】<br>| ——-| consolidated : type of caller<br>|<br>| convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)<br>| Attempt to infer better dtype for object columns<br>|<br>| 【参数】<br>| ———-| convert_dates : boolean, default True<br>| If True, convert to date where possible. If ‘coerce’, force<br>| conversion, with unconvertible values becoming NaT.<br>| convert_numeric : boolean, default False<br>861<br>| If True, attempt to coerce to numbers (including strings), with<br>| unconvertible values becoming NaN.<br>| convert_timedeltas : boolean, default True<br>| If True, convert to timedelta where possible. If ‘coerce’, force<br>| conversion, with unconvertible values becoming NaT.<br>| copy : boolean, default True<br>| If True, return a copy even if no copy is necessary (e.g. no<br>| conversion was done). Note: This is meant for internal use, and<br>| should not be confused with inplace.<br>|<br>| 【返回值】<br>| ——-| converted : same as input object<br>|<br>| copy(self, deep=True)<br>| Make a copy of this object<br>|<br>| 【参数】<br>| ———-| deep : boolean or string, default True<br>| Make a deep copy, i.e. also copy data<br>|<br>| 【返回值】<br>| ——-| copy : type of caller<br>|<br>| describe(self, percentiles=None, include=None, exclude=None)<br>| Generate various summary statistics, excluding NaN values.<br>|<br>| 【参数】<br>| ———-| percentiles : array-like, optional<br>| The percentiles to include in the output. Should all<br>| be in the interval [0, 1]. By default <code>percentiles</code> is<br>| [.25, .5, .75], returning the 25th, 50th, and 75th percentiles.<br>| include, exclude : list-like, ‘all’, or None (default)<br>| Specify the form of the returned result. Either:<br>|<br>| - None to both (default). The result will include only numeric-typed<br>| columns or, if none are, only categorical columns.<br>| - A list of dtypes or strings to be included/excluded.<br>| To select all numeric types use numpy numpy.number. To select<br>| categorical objects use type object. 参见：the select_dtypes<br>| documentation. eg. df.describe(include=[‘O’])<br>| - If include is the string ‘all’, the output column-set will<br>| match the input one.<br>|<br>| 【返回值】<br>| ——-| summary: NDFrame of summary statistics<br>|<br>| 【注意】<br>| —–| The output DataFrame index depends on the requested dtypes:<br>|<br>| For numeric dtypes, it will include: count, mean, std, min,<br>| max, and lower, 50, and upper percentiles.<br>862<br>|<br>| For object dtypes (e.g. timestamps or strings), the index<br>| will include the count, unique, most common, and frequency of the<br>| most common. Timestamps also include the first and last items.<br>|<br>| For mixed dtypes, the index will be the union of the corresponding<br>| output types. Non-applicable entries will be filled with NaN.<br>| Note that mixed-dtype outputs can only be returned from mixed-dtype<br>| inputs and appropriate use of the include/exclude arguments.<br>|<br>| If multiple values have the highest count, then the<br>| <code>count</code> and <code>most common</code> pair will be arbitrarily chosen from<br>| among those with the highest count.<br>|<br>| The include, exclude arguments are ignored for Series.<br>|<br>| 【参见】<br>| ——–| DataFrame.select_dtypes<br>|<br>| drop(self, labels, axis=0, level=None, inplace=False, errors=’raise’)<br>| Return new object with labels in requested axis removed<br>|<br>| 【参数】<br>| ———-| labels : single label or list-like<br>| axis : int or axis name<br>| level : int or level name, default None<br>| For MultiIndex<br>| inplace : bool, default False<br>| If True, do operation inplace and return None.<br>| errors : {‘ignore’, ‘raise’}, default ‘raise’<br>| If ‘ignore’, suppress error and existing labels are dropped.<br>|<br>| .. versionadded:: 0.16.1<br>|<br>| 【返回值】<br>| ——-| dropped : type of caller<br>|<br>| equals(self, other)<br>| Determines if two NDFrame objects contain the same elements. NaNs in the<br>| same location are considered equal.<br>|<br>| ffill(self, axis=None, inplace=False, limit=None, downcast=None)<br>| Synonym for NDFrame.fillna(method=’ffill’)<br>|<br>| filter(self, items=None, like=None, regex=None, axis=None)<br>| Restrict the info axis to set of items or wildcard<br>|<br>| 【参数】<br>| ———-| items : list-like<br>| List of info axis to restrict to (must not all be present)<br>| like : string<br>| Keep info axis where “arg in col == True”<br>| regex : string (regular expression)<br>863<br>| Keep info axis with re.search(regex, col) == True<br>| axis : int or None<br>| The axis to filter on. By default this is the info axis. The “info<br>| axis” is the axis that is used when indexing with <code>[]</code>. For<br>| example, <code>df = DataFrame({&#39;a&#39;: [1, 2, 3, 4]]}); df[&#39;a&#39;]</code>. So,<br>| the <code>DataFrame</code> columns are the info axis.<br>|<br>| 【注意】<br>| —–| Arguments are mutually exclusive, but this is not checked for<br>|<br>| first(self, offset)<br>| Convenience method for subsetting initial periods of time series data<br>| based on a date offset<br>|<br>| 【参数】<br>| ———-| offset : string, DateOffset, dateutil.relativedelta<br>|<br>| 【示例】<br>| ——–| ts.last(‘10D’) -&gt; First 10 days<br>|<br>| 【返回值】<br>| ——-| subset : type of caller<br>|<br>| get(self, key, default=None)<br>| Get item from object for given key (DataFrame column, Panel slice,<br>| etc.). Returns default value if not found<br>|<br>| 【参数】<br>| ———-| key : object<br>|<br>| 【返回值】<br>| ——-| value : type of items contained in object<br>|<br>| get_dtype_counts(self)<br>| Return the counts of dtypes in this object<br>|<br>| get_ftype_counts(self)<br>| Return the counts of ftypes in this object<br>|<br>| groupby(self, by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False)<br>| Group series using mapper (dict or key function, apply given function<br>| to group, return result as series) or by a series of columns<br>|<br>| 【参数】<br>| ———-| by : mapping function / list of functions, dict, Series, or tuple /<br>| list of column names.<br>| Called on each element of the object index to determine the groups.<br>| If a dict or Series is passed, the Series or dict VALUES will be<br>| used to determine the groups<br>| axis : int, default 0<br>864<br>| level : int, level name, or sequence of such, default None<br>| If the axis is a MultiIndex (hierarchical), group by a particular<br>| level or levels<br>| as_index : boolean, default True<br>| For aggregated output, return object with group labels as the<br>| index. Only relevant for DataFrame input. as_index=False is<br>| effectively “SQL-style” grouped output<br>| sort : boolean, default True<br>| Sort group keys. Get better performance by turning this off.<br>| Note this does not influence the order of observations within each group.<br>| groupby preserves the order of rows within each group.<br>| group_keys : boolean, default True<br>| When calling apply, add group keys to index to identify pieces<br>| squeeze : boolean, default False<br>| reduce the dimensionality of the return type if possible,<br>| otherwise return a consistent type<br>|<br>| 【示例】<br>| ——–| DataFrame results<br>|<br>| &gt;&gt;&gt; data.groupby(func, axis=0).mean()<br>| &gt;&gt;&gt; data.groupby([‘col1’, ‘col2’])[‘col3’].mean()<br>|<br>| DataFrame with hierarchical index<br>|<br>| &gt;&gt;&gt; data.groupby([‘col1’, ‘col2’]).mean()<br>|<br>| 【返回值】<br>| ——-| GroupBy object<br>|<br>| head(self, n=5)<br>| Returns first n rows<br>|<br>| interpolate(self, method=’linear’, axis=0, limit=None, inplace=False, limit_direction=’forward’, downcast=None, <strong>kwargs)<br>| Interpolate values according to different methods.<br>|<br>| Please note that only <code>method=&#39;linear&#39;</code> is supported for DataFrames/Series<br>| with a MultiIndex.<br>|<br>| 【参数】<br>| ———-| method : {‘linear’, ‘time’, ‘index’, ‘values’, ‘nearest’, ‘zero’,<br>| ‘slinear’, ‘quadratic’, ‘cubic’, ‘barycentric’, ‘krogh’,<br>| ‘polynomial’, ‘spline’ ‘piecewise_polynomial’, ‘pchip’}<br>|<br>| <em> ‘linear’: ignore the index and treat the values as equally<br>| spaced. This is the only method supported on MultiIndexes.<br>| default<br>| </em> ‘time’: interpolation works on daily and higher resolution<br>| data to interpolate given length of interval<br>| <em> ‘index’, ‘values’: use the actual numerical values of the index<br>| </em> ‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’,<br>| ‘barycentric’, ‘polynomial’ is passed to<br>| <code>scipy.interpolate.interp1d</code>. Both ‘polynomial’ and ‘spline’<br>| require that you also specify an <code>order</code> (int),<br>865<br>| e.g. df.interpolate(method=’polynomial’, order=4).<br>| These use the actual numerical values of the index.<br>| <em> ‘krogh’, ‘piecewise_polynomial’, ‘spline’, and ‘pchip’ are all<br>| wrappers around the scipy interpolation methods of similar<br>| names. These use the actual numerical values of the index. See<br>| the scipy documentation for more on their behavior<br>| <code>here &lt;http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation&gt;</code><strong><br>| <code>and here &lt;http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html&gt;</code></strong><br>|<br>| axis : {0, 1}, default 0<br>| </em> 0: fill column-by-column<br>| <em> 1: fill row-by-row<br>| limit : int, default None.<br>| Maximum number of consecutive NaNs to fill.<br>| limit_direction : {‘forward’, ‘backward’, ‘both’}, defaults to ‘forward’<br>| If limit is specified, consecutive NaNs will be filled in this<br>| direction.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| inplace : bool, default False<br>| Update the NDFrame in place if possible.<br>| downcast : optional, ‘infer’ or None, defaults to None<br>| Downcast dtypes if possible.<br>| kwargs : keyword arguments to pass on to the interpolating function.<br>|<br>| 【返回值】<br>| ——-| Series or DataFrame of same shape interpolated at the NaNs<br>|<br>| 【参见】<br>| ——–| reindex, replace, fillna<br>|<br>| 【示例】<br>| ——–|<br>| Filling in NaNs<br>|<br>| &gt;&gt;&gt; s = pd.Series([0, 1, np.nan, 3])<br>| &gt;&gt;&gt; s.interpolate()<br>| 0 0<br>| 1 1<br>| 2 2<br>| 3 3<br>| dtype: float64<br>|<br>| isnull(self)<br>| Return a boolean same-sized object indicating if the values are null<br>|<br>| 【参见】<br>| ——–| notnull : boolean inverse of isnull<br>|<br>| iterkv(self, </em>args, </strong>kwargs)<br>| iteritems alias used to get around 2to3. Deprecated<br>|<br>866<br>| last(self, offset)<br>| Convenience method for subsetting final periods of time series data<br>| based on a date offset<br>|<br>| 【参数】<br>| ———-| offset : string, DateOffset, dateutil.relativedelta<br>|<br>| 【示例】<br>| ——–| ts.last(‘5M’) -&gt; Last 5 months<br>|<br>| 【返回值】<br>| ——-| subset : type of caller<br>|<br>| mask(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)<br>| Return an object of same shape as self and whose corresponding<br>| entries are from self where cond is False and otherwise are from other.<br>|<br>| 【参数】<br>| ———-| cond : boolean NDFrame or array<br>| other : scalar or NDFrame<br>| inplace : boolean, default False<br>| Whether to perform the operation in place on the data<br>| axis : alignment axis if needed, default None<br>| level : alignment level if needed, default None<br>| try_cast : boolean, default False<br>| try to cast the result back to the input type (if possible),<br>| raise_on_error : boolean, default True<br>| Whether to raise on invalid data types (e.g. trying to where on<br>| strings)<br>|<br>| 【返回值】<br>| ——-| wh : same type as caller<br>|<br>| notnull(self)<br>| Return a boolean same-sized object indicating if the values are<br>| not null<br>|<br>| 【参见】<br>| ——–| isnull : boolean inverse of notnull<br>|<br>| pct_change(self, periods=1, fill_method=’pad’, limit=None, freq=None, <strong>kwargs)<br>| Percent change over given number of periods.<br>|<br>| 【参数】<br>| ———-| periods : int, default 1<br>| Periods to shift for forming percent change<br>| fill_method : str, default ‘pad’<br>| How to handle NAs before computing percent changes<br>| limit : int, default None<br>| The number of consecutive NAs to fill before stopping<br>867<br>| freq : DateOffset, timedelta, or offset alias string, optional<br>| Increment to use from time series API (e.g. ‘M’ or BDay())<br>|<br>| 【返回值】<br>| ——-| chg : NDFrame<br>|<br>| 【注意】<br>| —–|<br>| By default, the percentage change is calculated along the stat<br>| axis: 0, or <code>Index</code>, for <code>DataFrame</code> and 1, or <code>minor</code> for<br>| <code>Panel</code>. You can change this with the <code>axis</code> keyword argument.<br>|<br>| pipe(self, func, *args, </strong>kwargs)<br>| Apply func(self, *args, **kwargs)<br>|<br>| .. versionadded:: 0.16.2<br>|<br>| 【参数】<br>| ———-| func : function<br>| function to apply to the NDFrame.<br>| <code>args</code>, and <code>kwargs</code> are passed into <code>func</code>.<br>| Alternatively a <code>(callable, data_keyword)</code> tuple where<br>| <code>data_keyword</code> is a string indicating the keyword of<br>| <code>callable</code> that expects the NDFrame.<br>| args : positional arguments passed into <code>func</code>.<br>| kwargs : a dictionary of keyword arguments passed into <code>func</code>.<br>|<br>| 【返回值】<br>| ——-| object : the return type of <code>func</code>.<br>|<br>| 【注意】<br>| —–|<br>| Use <code>.pipe</code> when chaining together functions that expect<br>| on Series or DataFrames. Instead of writing<br>|<br>| &gt;&gt;&gt; f(g(h(df), arg1=a), arg2=b, arg3=c)<br>|<br>| You can write<br>|<br>| &gt;&gt;&gt; (df.pipe(h)<br>| … .pipe(g, arg1=a)<br>| … .pipe(f, arg2=b, arg3=c)<br>| … )<br>|<br>| If you have a function that takes the data as (say) the second<br>| argument, pass a tuple indicating which keyword expects the<br>| data. For example, suppose <code>f</code> takes its data as <code>arg2</code>:<br>|<br>| &gt;&gt;&gt; (df.pipe(h)<br>| … .pipe(g, arg1=a)<br>| … .pipe((f, ‘arg2’), arg1=a, arg3=c)<br>| … )<br>868<br>|<br>| 【参见】<br>| ——–| pandas.DataFrame.apply<br>| pandas.DataFrame.applymap<br>| pandas.Series.map<br>|<br>| pop(self, item)<br>| Return item and drop from frame. Raise KeyError if not found.<br>|<br>| reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)<br>| return an object with matching indicies to myself<br>|<br>| 【参数】<br>| ———-| other : Object<br>| method : string or None<br>| copy : boolean, default True<br>| limit : int, default None<br>| Maximum number of consecutive labels to fill for inexact matches.<br>| tolerance : optional<br>| Maximum distance between labels of the other object and this<br>| object for inexact matches.<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【注意】<br>| —–| Like calling s.reindex(index=other.index, columns=other.columns,<br>| method=…)<br>|<br>| 【返回值】<br>| ——-| reindexed : same as input<br>|<br>| rename_axis(self, mapper, axis=0, copy=True, inplace=False)<br>| Alter index and / or columns using input function or functions.<br>| Function / dict values must be unique (1-to-1). Labels not contained in<br>| a dict / Series will be left as-is.<br>|<br>| 【参数】<br>| ———-| mapper : dict-like or function, optional<br>| axis : int or string, default 0<br>| copy : boolean, default True<br>| Also copy underlying data<br>| inplace : boolean, default False<br>|<br>| 【返回值】<br>| ——-| renamed : type of caller<br>|<br>| replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method=’pad’, axis=None)<br>| Replace values given in ‘to_replace’ with ‘value’.<br>|<br>| 【参数】<br>| ———-<br>869<br>| to_replace : str, regex, list, dict, Series, numeric, or None<br>|<br>| <em> str or regex:<br>|<br>| - str: string exactly matching <code>to_replace</code> will be replaced<br>| with <code>value</code><br>| - regex: regexs matching <code>to_replace</code> will be replaced with<br>| <code>value</code><br>|<br>| </em> list of str, regex, or numeric:<br>|<br>| - First, if <code>to_replace</code> and <code>value</code> are both lists, they<br>| <strong>must</strong> be the same length.<br>| - Second, if <code>regex=True</code> then all of the strings in <strong>both</strong><br>| lists will be interpreted as regexs otherwise they will match<br>| directly. This doesn’t matter much for <code>value</code> since there<br>| are only a few possible substitution regexes you can use.<br>| - str and regex rules apply as above.<br>|<br>| <em> dict:<br>|<br>| - Nested dictionaries, e.g., {‘a’: {‘b’: nan}}, are read as<br>| follows: look in column ‘a’ for the value ‘b’ and replace it<br>| with nan. You can nest regular expressions as well. Note that<br>| column names (the top-level dictionary keys in a nested<br>| dictionary) <strong>cannot</strong> be regular expressions.<br>| - Keys map to column names and values map to substitution<br>| values. You can treat this as a special case of passing two<br>| lists except that you are specifying the column to search in.<br>|<br>| </em> None:<br>|<br>| - This means that the <code>regex</code> argument must be a string,<br>| compiled regular expression, or list, dict, ndarray or Series<br>| of such elements. If <code>value</code> is also <code>None</code> then this<br>| <strong>must</strong> be a nested dictionary or <code>Series</code>.<br>|<br>| See the examples section for examples of each of these.<br>| value : scalar, dict, list, str, regex, default None<br>| Value to use to fill holes (e.g. 0), alternately a dict of values<br>| specifying which value to use for each column (columns not in the<br>| dict will not be filled). Regular expressions, strings and lists or<br>| dicts of such objects are also allowed.<br>| inplace : boolean, default False<br>| If True, in place. Note: this will modify any<br>| other views on this object (e.g. a column form a DataFrame).<br>| Returns the caller if this is True.<br>| limit : int, default None<br>| Maximum size gap to forward or backward fill<br>| regex : bool or same types as <code>to_replace</code>, default False<br>| Whether to interpret <code>to_replace</code> and/or <code>value</code> as regular<br>| expressions. If this is <code>True</code> then <code>to_replace</code> <em>must</em> be a<br>| string. Otherwise, <code>to_replace</code> must be <code>None</code> because this<br>| parameter will be interpreted as a regular expression or a list,<br>| dict, or array of regular expressions.<br>| method : string, optional, {‘pad’, ‘ffill’, ‘bfill’}<br>| The method to use when for replacement, when <code>to_replace</code> is a<br>870<br>| <code>list</code>.<br>|<br>| 【参见】<br>| ——–| NDFrame.reindex<br>| NDFrame.asfreq<br>| NDFrame.fillna<br>|<br>| 【返回值】<br>| ——-| filled : NDFrame<br>|<br>| 【Raises 引发错误】<br>| ——| AssertionError<br>| <em> If <code>regex</code> is not a <code>bool</code> and <code>to_replace</code> is not <code>None</code>.<br>| TypeError<br>| </em> If <code>to_replace</code> is a <code>dict</code> and <code>value</code> is not a <code>list</code>,<br>| <code>dict</code>, <code>ndarray</code>, or <code>Series</code><br>| <em> If <code>to_replace</code> is <code>None</code> and <code>regex</code> is not compilable into a<br>| regular expression or is a list, dict, ndarray, or Series.<br>| ValueError<br>| </em> If <code>to_replace</code> and <code>value</code> are <code>list</code> s or <code>ndarray</code> s, but<br>| they are not the same length.<br>|<br>| 【注意】<br>| —–| <em> Regex substitution is performed under the hood with <code>re.sub</code>. The<br>| rules for substitution for <code>re.sub</code> are the same.<br>| </em> Regular expressions will only substitute on strings, meaning you<br>| cannot provide, for example, a regular expression matching floating<br>| point numbers and expect the columns in your frame that have a<br>| numeric dtype to be matched. However, if those floating point numbers<br>| <em>are</em> strings, then you can do this.<br>| <em> This method has </em>a lot<em> of options. You are encouraged to experiment<br>| and play with this method to gain intuition about how it works.<br>|<br>| resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention=’start’, kind=None,<br>loffset=None, limit=None, base=0)<br>| Convenience method for frequency conversion and resampling of regular<br>| time-series data.<br>|<br>| 【参数】<br>| ———-| rule : string<br>| the offset string or object representing target conversion<br>| how : string<br>| method for down- or re-sampling, default to ‘mean’ for<br>| downsampling<br>| axis : int, optional, default 0<br>| fill_method : string, default None<br>| fill_method for upsampling<br>| closed : {‘right’, ‘left’}<br>| Which side of bin interval is closed<br>| label : {‘right’, ‘left’}<br>| Which bin edge label to label bucket with<br>| convention : {‘start’, ‘end’, ‘s’, ‘e’}<br>871<br>| kind : “period”/“timestamp”<br>| loffset : timedelta<br>| Adjust the resampled time labels<br>| limit : int, default None<br>| Maximum size gap to when reindexing with fill_method<br>| base : int, default 0<br>| For frequencies that evenly subdivide 1 day, the “origin” of the<br>| aggregated intervals. For example, for ‘5min’ frequency, base could<br>| range from 0 through 4. Defaults to 0<br>|<br>|<br>| 【示例】<br>| ——–|<br>| Start by creating a series with 9 one minute timestamps.<br>|<br>| &gt;&gt;&gt; index = pd.date_range(‘1/1/2000’, periods=9, freq=’T’)<br>| &gt;&gt;&gt; series = pd.Series(range(9), index=index)<br>| &gt;&gt;&gt; series<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:01:00 1<br>| 2000-01-01 00:02:00 2<br>| 2000-01-01 00:03:00 3<br>| 2000-01-01 00:04:00 4<br>| 2000-01-01 00:05:00 5<br>| 2000-01-01 00:06:00 6<br>| 2000-01-01 00:07:00 7<br>| 2000-01-01 00:08:00 8<br>| Freq: T, dtype: int64<br>|<br>| Downsample the series into 3 minute bins and sum the values<br>| of the timestamps falling into a bin.<br>|<br>| &gt;&gt;&gt; series.resample(‘3T’, how=’sum’)<br>| 2000-01-01 00:00:00 3<br>| 2000-01-01 00:03:00 12<br>| 2000-01-01 00:06:00 21<br>| Freq: 3T, dtype: int64<br>|<br>| Downsample the series into 3 minute bins as above, but label each<br>| bin using the right edge instead of the left. Please note that the<br>| value in the bucket used as the label is not included in the bucket,<br>| which it labels. For example, in the original series the<br>| bucket <code>2000-01-01 00:03:00</code> contains the value 3, but the summed<br>| value in the resampled bucket with the label<code>2000-01-01 00:03:00</code><br>| does not include 3 (if it did, the summed value would be 6, not 3).<br>| To include this value close the right side of the bin interval as<br>| illustrated in the example below this one.<br>|<br>| &gt;&gt;&gt; series.resample(‘3T’, how=’sum’, label=’right’)<br>| 2000-01-01 00:03:00 3<br>| 2000-01-01 00:06:00 12<br>| 2000-01-01 00:09:00 21<br>| Freq: 3T, dtype: int64<br>|<br>| Downsample the series into 3 minute bins as above, but close the right<br>| side of the bin interval.<br>872<br>|<br>| &gt;&gt;&gt; series.resample(‘3T’, how=’sum’, label=’right’, closed=’right’)<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:03:00 6<br>| 2000-01-01 00:06:00 15<br>| 2000-01-01 00:09:00 15<br>| Freq: 3T, dtype: int64<br>|<br>| Upsample the series into 30 second bins.<br>|<br>| &gt;&gt;&gt; series.resample(‘30S’)[0:5] #select first 5 rows<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:00:30 NaN<br>| 2000-01-01 00:01:00 1<br>| 2000-01-01 00:01:30 NaN<br>| 2000-01-01 00:02:00 2<br>| Freq: 30S, dtype: float64<br>|<br>| Upsample the series into 30 second bins and fill the <code>NaN</code><br>| values using the <code>pad</code> method.<br>|<br>| &gt;&gt;&gt; series.resample(‘30S’, fill_method=’pad’)[0:5]<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:00:30 0<br>| 2000-01-01 00:01:00 1<br>| 2000-01-01 00:01:30 1<br>| 2000-01-01 00:02:00 2<br>| Freq: 30S, dtype: int64<br>|<br>| Upsample the series into 30 second bins and fill the<br>| <code>NaN</code> values using the <code>bfill</code> method.<br>|<br>| &gt;&gt;&gt; series.resample(‘30S’, fill_method=’bfill’)[0:5]<br>| 2000-01-01 00:00:00 0<br>| 2000-01-01 00:00:30 1<br>| 2000-01-01 00:01:00 1<br>| 2000-01-01 00:01:30 2<br>| 2000-01-01 00:02:00 2<br>| Freq: 30S, dtype: int64<br>|<br>| Pass a custom function to <code>how</code>.<br>|<br>| &gt;&gt;&gt; def custom_resampler(array_like):<br>| … return np.sum(array_like)+5<br>|<br>| &gt;&gt;&gt; series.resample(‘3T’, how=custom_resampler)<br>| 2000-01-01 00:00:00 8<br>| 2000-01-01 00:03:00 17<br>| 2000-01-01 00:06:00 26<br>| Freq: 3T, dtype: int64<br>|<br>| sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)<br>| Returns a random sample of items from an axis of object.<br>|<br>| .. versionadded:: 0.16.1<br>|<br>| 【参数】<br>873<br>| ———-| n : int, optional<br>| Number of items from axis to return. Cannot be used with <code>frac</code>.<br>| Default = 1 if <code>frac</code> = None.<br>| frac : float, optional<br>| Fraction of axis items to return. Cannot be used with <code>n</code>.<br>| replace : boolean, optional<br>| Sample with or without replacement. Default = False.<br>| weights : str or ndarray-like, optional<br>| Default ‘None’ results in equal probability weighting.<br>| If passed a Series, will align with target object on index. Index<br>| values in weights not found in sampled object will be ignored and<br>| index values in sampled object not in weights will be assigned<br>| weights of zero.<br>| If called on a DataFrame, will accept the name of a column<br>| when axis = 0.<br>| Unless weights are a Series, weights must be same length as axis<br>| being sampled.<br>| If weights do not sum to 1, they will be normalized to sum to 1.<br>| Missing values in the weights column will be treated as zero.<br>| inf and -inf values not allowed.<br>| random_state : int or numpy.random.RandomState, optional<br>| Seed for the random number generator (if int), or numpy RandomState<br>| object.<br>| axis : int or string, optional<br>| Axis to sample. Accepts axis number or name. Default is stat axis<br>| for given data type (0 for Series and DataFrames, 1 for Panels).<br>|<br>| 【返回值】<br>| ——-| A new object of same type as caller.<br>|<br>| select(self, crit, axis=0)<br>| Return data corresponding to axis labels matching criteria<br>|<br>| 【参数】<br>| ———-| crit : function<br>| To be called on each index (label). Should return True or False<br>| axis : int<br>|<br>| 【返回值】<br>| ——-| selection : type of caller<br>|<br>| set_axis(self, axis, labels)<br>| public verson of axis assignment<br>|<br>| slice_shift(self, periods=1, axis=0)<br>| Equivalent to <code>shift</code> without copying data. The shifted data will<br>| not include the dropped periods and the shifted axis will be smaller<br>| than the original.<br>|<br>| 【参数】<br>| ———-| periods : int<br>| Number of periods to move, can be positive or negative<br>874<br>|<br>| 【注意】<br>| —–| While the <code>slice_shift</code> is faster than <code>shift</code>, you may pay for it<br>| later during alignment.<br>|<br>| 【返回值】<br>| ——-| shifted : same type as caller<br>|<br>| squeeze(self)<br>| squeeze length 1 dimensions<br>|<br>| swapaxes(self, axis1, axis2, copy=True)<br>| Interchange axes and swap values axes appropriately<br>|<br>| 【返回值】<br>| ——-| y : same as input<br>|<br>| tail(self, n=5)<br>| Returns last n rows<br>|<br>| to_clipboard(self, excel=None, sep=None, <strong>kwargs)<br>| Attempt to write text representation of object to the system clipboard<br>| This can be pasted into Excel, for example.<br>|<br>| 【参数】<br>| ———-| excel : boolean, defaults to True<br>| if True, use the provided separator, writing in a csv<br>| format for allowing easy pasting into excel.<br>| if False, write a string representation of the object<br>| to the clipboard<br>| sep : optional, defaults to tab<br>| other keywords are passed to to_csv<br>|<br>| 【注意】<br>| —–| Requirements for your platform<br>| - Linux: xclip, or xsel (with gtk or PyQt4 modules)<br>| - Windows: none<br>| - OS X: none<br>|<br>| to_dense(self)<br>| Return dense representation of NDFrame (as opposed to sparse)<br>|<br>| to_hdf(self, path_or_buf, key, </strong>kwargs)<br>| activate the HDFStore<br>|<br>| 【参数】<br>| ———-| path_or_buf : the path (string) or HDFStore object<br>| key : string<br>| indentifier for the group in the store<br>| mode : optional, {‘a’, ‘w’, ‘r’, ‘r+’}, default ‘a’<br>|<br>875<br>| <code>&#39;r&#39;</code><br>| Read-only; no data can be modified.<br>| <code>&#39;w&#39;</code><br>| Write; a new file is created (an existing file with the same<br>| name would be deleted).<br>| <code>&#39;a&#39;</code><br>| Append; an existing file is opened for reading and writing,<br>| and if the file does not exist it is created.<br>| <code>&#39;r+&#39;</code><br>| It is similar to <code>&#39;a&#39;</code>, but the file must already exist.<br>| format : ‘fixed(f)|table(t)’, default is ‘fixed’<br>| fixed(f) : Fixed format<br>| Fast writing/reading. Not-appendable, nor searchable<br>| table(t) : Table format<br>| Write as a PyTables Table structure which may perform<br>| worse but allow more flexible operations like searching<br>| / selecting subsets of the data<br>| append : boolean, default False<br>| For Table formats, append the input data to the existing<br>| complevel : int, 1-9, default 0<br>| If a complib is specified compression will be applied<br>| where possible<br>| complib : {‘zlib’, ‘bzip2’, ‘lzo’, ‘blosc’, None}, default None<br>| If complevel is &gt; 0 apply compression to objects written<br>| in the store wherever possible<br>| fletcher32 : bool, default False<br>| If applying compression use the fletcher32 checksum<br>| dropna : boolean, default False.<br>| If true, ALL nan rows will not be written to store.<br>|<br>| to_json(self, path_or_buf=None, orient=None, date_format=’epoch’, double_precision=10, force_ascii=True, date_unit=’ms’,<br>default_handler=None)<br>| Convert the object to a JSON string.<br>|<br>| Note NaN’s and None will be converted to null and datetime objects<br>| will be converted to UNIX timestamps.<br>|<br>| 【参数】<br>| ———-| path_or_buf : the path or buffer to write the result string<br>| if this is None, return a StringIO of the converted string<br>| orient : string<br>|<br>| </em> Series<br>|<br>| - default is ‘index’<br>| - allowed values are: {‘split’,’records’,’index’}<br>|<br>| <em> DataFrame<br>|<br>| - default is ‘columns’<br>| - allowed values are:<br>| {‘split’,’records’,’index’,’columns’,’values’}<br>|<br>| </em> The format of the JSON string<br>|<br>| - split : dict like<br>876<br>| {index -&gt; [index], columns -&gt; [columns], data -&gt; [values]}<br>| - records : list like<br>| [{column -&gt; value}, … , {column -&gt; value}]<br>| - index : dict like {index -&gt; {column -&gt; value}}<br>| - columns : dict like {column -&gt; {index -&gt; value}}<br>| - values : just the values array<br>|<br>| date_format : {‘epoch’, ‘iso’}<br>| Type of date conversion. <code>epoch</code> = epoch milliseconds,<br>| <code>iso`` = ISO8601, default is epoch.
| double_precision : The number of decimal places to use when encoding
| floating point values, default 10.
| force_ascii : force encoded string to be ASCII, default True.
| date_unit : string, default &#39;ms&#39; (milliseconds)
| The time unit to encode to, governs timestamp and ISO8601
| precision. One of &#39;s&#39;, &#39;ms&#39;, &#39;us&#39;, &#39;ns&#39; for second, millisecond,
| microsecond, and nanosecond respectively.
| default_handler : callable, default None
| Handler to call if object cannot otherwise be converted to a
| suitable format for JSON. Should receive a single argument which is
| the object to convert and return a serialisable object.
|
| 【返回值】
| -------| same type as input object with filtered info axis
|
| to_msgpack(self, path_or_buf=None, **kwargs)
| msgpack (serialize) object to input file path
|
| THIS IS AN EXPERIMENTAL LIBRARY and the storage format
| may not be stable until a future release.
|
| 【参数】
| ----------| path : string File path, buffer-like, or None
| if None, return generated string
| append : boolean whether to append to an existing msgpack
| (default is False)
| compress : type of compressor (zlib or blosc), default to None (no
| compression)
|
| to_pickle(self, path)
| Pickle (serialize) object to input file path
|
| 【参数】
| ----------| path : string
| File path
|
| to_sql(self, name, con, flavor=&#39;sqlite&#39;, schema=None, if_exists=&#39;fail&#39;, index=True, index_label=None, chunksize=None,
dtype=None)
| Write records stored in a DataFrame to a SQL database.
|
| 【参数】
| ----------| name : string
| Name of SQL table
877
| con : SQLAlchemy engine or DBAPI2 connection (legacy mode)
| Using SQLAlchemy makes it possible to use any DB supported by that
| library.
| If a DBAPI2 object, only sqlite3 is supported.
| flavor : {&#39;sqlite&#39;, &#39;mysql&#39;}, default &#39;sqlite&#39;
| The flavor of SQL to use. Ignored when using SQLAlchemy engine.
| &#39;mysql&#39; is deprecated and will be removed in future versions, but it
| will be further supported through SQLAlchemy engines.
| schema : string, default None
| Specify the schema (if database flavor supports this). If None, use
| default schema.
| if_exists : {&#39;fail&#39;, &#39;replace&#39;, &#39;append&#39;}, default &#39;fail&#39;
| - fail: If table exists, do nothing.
| - replace: If table exists, drop it, recreate it, and insert data.
| - append: If table exists, insert data. Create if does not exist.
| index : boolean, default True
| Write DataFrame index as a column.
| index_label : string or sequence, default None
| Column label for index column(s). If None is given (default) and
|</code>index<code>is True, then the index names are used.
| A sequence should be given if the DataFrame uses MultiIndex.
| chunksize : int, default None
| If not None, then rows will be written in batches of this size at a
| time. If None, all rows will be written at once.
| dtype : dict of column name to SQL type, default None
| Optional specifying the datatype for columns. The SQL type should
| be a SQLAlchemy type, or a string for sqlite3 fallback connection.
|
| truncate(self, before=None, after=None, axis=None, copy=True)
| Truncates a sorted NDFrame before and/or after some particular
| dates.
|
| 【参数】
| ----------| before : date
| Truncate before date
| after : date
| Truncate after date
| axis : the truncation axis, defaults to the stat axis
| copy : boolean, default is True,
| return a copy of the truncated section
|
| 【返回值】
| -------| truncated : type of caller
|
| tshift(self, periods=1, freq=None, axis=0)
| Shift the time index, using the index&#39;s frequency if available
|
| 【参数】
| ----------| periods : int
| Number of periods to move, can be positive or negative
| freq : DateOffset, timedelta, or time rule string, default None
| Increment to use from datetools module or time rule (e.g. &#39;EOM&#39;)
| axis : int or basestring
| Corresponds to the axis that contains the Index
878
|
| 【注意】
| -----| If freq is not specified then tries to use the freq or inferred_freq
| attributes of the index. If neither of those attributes exist, a
| ValueError is thrown
|
| 【返回值】
| -------| shifted : NDFrame
|
| tz_convert(self, tz, axis=0, level=None, copy=True)
| Convert tz-aware axis to target time zone.
|
| 【参数】
| ----------| tz : string or pytz.timezone object
| axis : the axis to convert
| level : int, str, default None
| If axis ia a MultiIndex, convert a specific level. Otherwise
| must be None
| copy : boolean, default True
| Also make a copy of the underlying data
|
| 【返回值】
| -------|
| 【Raises 引发错误】
| ------| TypeError
| If the axis is tz-naive.
|
| tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous=&#39;raise&#39;)
| Localize tz-naive TimeSeries to target time zone
|
| 【参数】
| ----------| tz : string or pytz.timezone object
| axis : the axis to localize
| level : int, str, default None
| If axis ia a MultiIndex, localize a specific level. Otherwise
| must be None
| copy : boolean, default True
| Also make a copy of the underlying data
| ambiguous : &#39;infer&#39;, bool-ndarray, &#39;NaT&#39;, default &#39;raise&#39;
| - &#39;infer&#39; will attempt to infer fall dst-transition hours based on order
| - bool-ndarray where True signifies a DST time, False designates
| a non-DST time (note that this flag is only applicable for ambiguous times)
| - &#39;NaT&#39; will return NaT where there are ambiguous times
| - &#39;raise&#39; will raise an AmbiguousTimeError if there are ambiguous times
| infer_dst : boolean, default False (DEPRECATED)
| Attempt to infer fall dst-transition hours based on order
|
| 【返回值】
| -------|
879
| 【Raises 引发错误】
| ------| TypeError
| If the TimeSeries is tz-aware and tz is not None.
|
| where(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)
| Return an object of same shape as self and whose corresponding
| entries are from self where cond is True and otherwise are from other.
|
| 【参数】
| ----------| cond : boolean NDFrame or array
| other : scalar or NDFrame
| inplace : boolean, default False
| Whether to perform the operation in place on the data
| axis : alignment axis if needed, default None
| level : alignment level if needed, default None
| try_cast : boolean, default False
| try to cast the result back to the input type (if possible),
| raise_on_error : boolean, default True
| Whether to raise on invalid data types (e.g. trying to where on
| strings)
|
| 【返回值】
| -------| wh : same type as caller
|
| xs(self, key, axis=0, level=None, copy=None, drop_level=True)
| Returns a cross-section (row(s) or column(s)) from the Series/DataFrame.
| Defaults to cross-section on the rows (axis=0).
|
| 【参数】
| ----------| key : object
| Some label contained in the index, or partially in a MultiIndex
| axis : int, default 0
| Axis to retrieve cross-section on
| level : object, defaults to first n levels (n=1 or len(key))
| In case of a key partially contained in a MultiIndex, indicate
| which levels are used. Levels can be referred by label or position.
| copy : boolean [deprecated]
| Whether to make a copy of the data
| drop_level : boolean, default True
| If False, returns object with same levels as self.
|
| 【示例】
| --------| &gt;&gt;&gt; df
| A B C
| a 4 5 2
| b 4 0 9
| c 9 7 3
| &gt;&gt;&gt; df.xs(&#39;a&#39;)
| A 4
| B 5
| C 2
| Name: a
880
| &gt;&gt;&gt; df.xs(&#39;C&#39;, axis=1)
| a 2
| b 9
| c 3
| Name: C
|
| &gt;&gt;&gt; df
| A B C D
| first second third
| bar one 1 4 1 8 9
| two 1 7 5 5 0
| baz one 1 6 6 8 0
| three 2 5 3 5 3
| &gt;&gt;&gt; df.xs((&#39;baz&#39;, &#39;three&#39;))
| A B C D
| third
| 2 5 3 5 3
| &gt;&gt;&gt; df.xs(&#39;one&#39;, level=1)
| A B C D
| first third
| bar 1 4 1 8 9
| baz 1 6 6 8 0
| &gt;&gt;&gt; df.xs((&#39;baz&#39;, 2), level=[0, &#39;third&#39;])
| A B C D
| second
| three 5 3 5 3
|
| 【返回值】
| -------| xs : Series or DataFrame
|
| 【注意】
| -----| xs is only for getting, not setting values.
|
| MultiIndex Slicers is a generic way to get/set values on any level or levels
| it is a superset of xs functionality, see :ref:</code>MultiIndex Slicers <advanced.mi_slicers><code>|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.generic.NDFrame:
|
| at
| Fast label-based scalar accessor
|
| Similarly to ``loc``, ``at`` provides **label** based scalar lookups.
| You can also set using these indexers.
|
| blocks
| Internal property, property synonym for as_blocks()
|
| empty
| True if NDFrame is entirely empty [no items]
|
| iat
| Fast integer location scalar accessor.
|
| Similarly to ``iloc``, ``iat`` provides **integer** based lookups.
881
| You can also set using these indexers.
|
| iloc
| Purely integer-location based indexing for selection by position.
|
| ``.iloc[]`` is primarily integer position based (from ``0`` to
| ``length-1`` of the axis), but may also be used with a boolean
| array.
|
| Allowed inputs are:
|
| - An integer, e.g. ``5``.
| - A list or array of integers, e.g. ``[4, 3, 0]``.
| - A slice object with ints, e.g. ``1:7``.
| - A boolean array.
|
| ``.iloc`` will raise ``IndexError`` if a requested indexer is
| out-of-bounds, except *slice* indexers which allow out-of-bounds
| indexing (this conforms with python/numpy *slice* semantics).
|
| See more at :ref:</code>Selection by Position <indexing.integer><code>|
| ix
| A primarily label-location based indexer, with integer position
| fallback.
|
| ``.ix[]`` supports mixed integer and label based access. It is
| primarily label based, but will fall back to integer positional
| access unless the corresponding axis is of integer type.
|
| ``.ix`` is the most general indexer and will support any of the
| inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating
| point label schemes. ``.ix`` is exceptionally useful when dealing
| with mixed positional and label based hierachical indexes.
|
| However, when an axis is integer based, ONLY label based access
| and not positional access is supported. Thus, in such cases, it&#39;s
| usually better to be explicit and use ``.iloc`` or ``.loc``.
|
| See more at :ref:</code>Advanced Indexing <advanced><code>.
|
| loc
| Purely label-location based indexer for selection by label.
|
| ``.loc[]`` is primarily label based, but may also be used with a
| boolean array.
|
| Allowed inputs are:
|
| - A single label, e.g. ``5`` or ``&#39;a&#39;``, (note that ``5`` is
| interpreted as a *label* of the index, and **never** as an
| integer position along the index).
| - A list or array of labels, e.g. ``[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]``.
| - A slice object with labels, e.g. ``&#39;a&#39;:&#39;f&#39;`` (note that contrary
| to usual python slices, **both** the start and the stop are included!).
| - A boolean array.
|
882
| ``.loc`` will raise a ``KeyError`` when the items are not found.
|
| See more at :ref:</code>Selection by Label <indexing.label><code>|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.generic.NDFrame:
|
| is_copy = None
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.PandasObject:
|
| __dir__(self)
| Provide method name lookup and completion
| Only provide &#39;public&#39; methods
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
| Return a string representation for a particular object.
|
| Invoked by bytes(obj) in py3 only.
| Yields a bytestring in both py2/py3.
|
| __repr__(self)
| Return a string representation for a particular object.
|
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
Timedelta
Timedelta 模块所属：pandas.tslib:
类定义：Timedelta(_Timedelta)
| Represents a duration, the difference between two dates or times.
|
| Timedelta is the pandas equivalent of python&#39;s ``datetime.timedelta``
| and is interchangable with it in most cases.
|
| 【参数】
| ----------| value : Timedelta, timedelta, np.timedelta64, string, or integer
| unit : string, [D,h,m,s,ms,us,ns]
883
| Denote the unit of the input, if input is an integer. Default &#39;ns&#39;.
| days, seconds, microseconds, milliseconds, minutes, hours, weeks : numeric, optional
| Values for construction in compat with datetime.timedelta.
| np ints and floats will be coereced to python ints and floats.
|
|【注意】
| -----| The ``.value`` attribute is always in ns.
|
| 【方法排序】
| Timedelta
| _Timedelta
| datetime.timedelta
| 【内置对象】
|
| 【方法定义】
|
| __abs__(self)
|
| __add__(self, other)
|
| __floordiv__ = _not_implemented(self, *args, **kwargs)
|
| __inv__(self)
|
| __mul__(self, other)
|
| __neg__(self)
|
| __new__(cls, value=None, unit=None, **kwargs)
|
| __pos__(self)
|
| __radd__(self, other)
|
| __reduce__(self)
|
| __repr__(self)
|
| __rfloordiv__ = _not_implemented(self, *args, **kwargs)
|
| __rmul__ = __mul__(self, other)
|
| __rsub__(self, other)
|
| __rtruediv__(self, other)
|
| __setstate__(self, state)
|
| __str__(self)
|
| __sub__(self, other)
|
| __truediv__(self, other)
|
| round(self, reso)
| return a new Timedelta rounded to this resolution
884
|
| 【参数】
| ----------| reso : a string indicating the rouding resolution, accepting values
| d,h,m,s,ms,us
|
| to_timedelta64(self)
| Returns a numpy.timedelta64 object with &#39;ns&#39; precision
|
| total_seconds(self)
| Total duration of timedelta in seconds (to ns precision)
|
| view(self, dtype)
| array view compat
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
|
| asm8
| return a numpy timedelta64 array view of myself
|
| components
| Return a Components NamedTuple-like
|
| days
| Number of Days
|
| .components will return the shown components
|
| delta
| return out delta in ns (for internal compat)
|
| microseconds
| Number of microseconds (&gt;= 0 and less than 1 second).
|
| .components will return the shown components
|
| nanoseconds
| Number of nanoseconds (&gt;= 0 and less than 1 microsecond).
|
| .components will return the shown components
|
| resolution
| return a string representing the lowest resolution that we have
|
| seconds
| Number of seconds (&gt;= 0 and less than 1 day).
|
| .components will return the shown components
|
| ----------------------------------------------------------------------
885
| 其他数据、属性定义：
|
| __array_priority__ = 100
|
| ----------------------------------------------------------------------| Methods inherited from _Timedelta:
|
| __eq__(self, value, /)
| Return self==value.
|
| __ge__(self, value, /)
| Return self&gt;=value.
|
| __gt__(self, value, /)
| Return self&gt;value.
|
| __hash__(self, /)
| Return hash(self).
|
| __le__(self, value, /)
| Return self&lt;=value.
|
| __lt__(self, value, /)
| Return self&lt;value.
|
| __ne__(self, value, /)
| Return self!=value.
|
| to_pytimedelta(...)
| return an actual datetime.timedelta object
| note: we lose nanosecond resolution if any
|
| ----------------------------------------------------------------------| Data descriptors inherited from _Timedelta:
|
| freq
|
| is_populated
|
| value
|
| ----------------------------------------------------------------------| Data and other attributes inherited from _Timedelta:
|
| __pyx_vtable__ = &lt;capsule object NULL&gt;
|
| ----------------------------------------------------------------------| Methods inherited from datetime.timedelta:
|
| __bool__(self, /)
| self != 0
|
| __divmod__(self, value, /)
| Return divmod(self, value).
|
| __getattribute__(self, name, /)
| Return getattr(self, name).
886
|
| __mod__(self, value, /)
| Return self%value.
|
| __rdivmod__(self, value, /)
| Return divmod(value, self).
|
| __rmod__(self, value, /)
| Return value%self.
|
| ----------------------------------------------------------------------| Data and other attributes inherited from datetime.timedelta:
|
| max = datetime.timedelta(999999999, 86399, 999999)
|
| min = datetime.timedelta(-999999999)
TimedeltaIndex
TimedeltaIndex 模块所属：pandas.tseries.tdi:
类定义：TimedeltaIndex(pandas.tseries.base.DatetimeIndexOpsMixin, pandas.core.index.Int64Index)
| Immutable ndarray of timedelta64 data, represented internally as int64, and
| which can be boxed to timedelta objects
|
| 【参数】
| ----------| data : array-like (1-dimensional), optional
| Optional timedelta-like data to construct index with
| unit: unit of the arg (D,h,m,s,ms,us,ns) denote the unit, optional
| which is an integer/float number
| freq: a frequency for the index, optional
| copy : bool
| Make a copy of input ndarray
| start : starting value, timedelta-like, optional
| If data is None, start is used as the start point in generating regular
| timedelta data.
| periods : int, optional, &gt; 0
| Number of periods to generate, if generating index. Takes precedence
| over end argument
| end : end time, timedelta-like, optional
| If periods is none, generated index will extend to first conforming
| time on or just past end argument
| closed : string or None, default None
| Make the interval closed with respect to the given frequency to
| the &#39;left&#39;, &#39;right&#39;, or both sides (None)
| name : object
| Name to be stored in the index
|
| 【方法排序】
887
| TimedeltaIndex
| pandas.tseries.base.DatetimeIndexOpsMixin
| pandas.core.index.Int64Index
| pandas.core.index.NumericIndex
| pandas.core.index.Index
| pandas.core.base.IndexOpsMixin
| pandas.core.strings.StringAccessorMixin
| pandas.core.base.PandasObject
| pandas.core.base.StringMixin
| 【内置对象】
|
| 【方法定义】
|
| __abs__ = _evaluate_numeric_unary(self)
|
| __add__(self, other)
|
| __eq__ = wrapper(self, other)
|
| __floordiv__ = _evaluate_numeric_binop(self, other)
|
| __ge__ = wrapper(self, other)
|
| __gt__ = wrapper(self, other)
|
| __iadd__ = __add__(self, other)
|
| __inv__ = _evaluate_numeric_unary(self)
|
| __isub__ = __sub__(self, other)
|
| __le__ = wrapper(self, other)
|
| __lt__ = wrapper(self, other)
|
| __mul__ = _evaluate_numeric_binop(self, other)
|
| __ne__ = wrapper(self, other)
|
| __neg__ = _evaluate_numeric_unary(self)
|
| __pos__ = _evaluate_numeric_unary(self)
|
| __radd__ = __add__(self, other)
|
| __rfloordiv__ = _evaluate_numeric_binop(self, other)
|
| __rmul__ = _evaluate_numeric_binop(self, other)
|
| __rsub__(self, other)
|
| __rtruediv__ = _evaluate_numeric_binop(self, other)
|
| __setstate__(self, state)
| Necessary for making this object picklable
|
| __sub__(self, other)
888
|
| __truediv__ = _evaluate_numeric_binop(self, other)
|
| all(self, other=None)
|
| any(self, other=None)
|
| append(self, other)
| Append a collection of Index options together
|
| 【参数】
| ----------| other : Index or list/tuple of indices
|
| 【返回值】
| -------| appended : Index
|
| astype(self, dtype)
|
| delete(self, loc)
| Make a new DatetimeIndex with passed location(s) deleted.
|
| 【参数】
| ----------| loc: int, slice or array of ints
| Indicate which sub-arrays to remove.
|
| 【返回值】
| -------| new_index : TimedeltaIndex
|
| equals(self, other)
| Determines if two Index objects contain the same elements.
|
| get_loc(self, key, method=None, tolerance=None)
| Get integer location for requested label
|
| 【返回值】
| -------| loc : int
|
| get_value(self, series, key)
| Fast lookup of value from 1-dimensional ndarray. Only use this if you
| know what you&#39;re doing
|
| get_value_maybe_box(self, series, key)
|
| insert(self, loc, item)
| Make new Index inserting new item at location
|
| 【参数】
| ----------| loc : int
| item : object
| if not either a Python datetime or a numpy integer-like, returned
| Index dtype will be object rather than datetime.
889
|
| 【返回值】
| -------| new_index : Index
|
| intersection(self, other)
| Specialized intersection for TimedeltaIndex objects. May be much faster
| than Index.intersection
|
| 【参数】
| ----------| other : TimedeltaIndex or array-like
|
| 【返回值】
| -------| y : Index or TimedeltaIndex
|
| is_type_compatible(self, typ)
|
| join(self, other, how=&#39;left&#39;, level=None, return_indexers=False)
| See Index.join
|
| searchsorted(self, key, side=&#39;left&#39;)
| np.ndarray searchsorted compat
|
| to_pytimedelta(self)
| Return TimedeltaIndex as object ndarray of datetime.timedelta objects
|
| 【返回值】
| -------| datetimes : ndarray
|
| total_seconds(self)
| Total duration of each element expressed in seconds.
|
| .. versionadded:: 0.17.0
|
| union(self, other)
| Specialized union for TimedeltaIndex objects. If combine
| overlapping ranges with the same DateOffset, will be much
| faster than Index.union
|
| 【参数】
| ----------| other : TimedeltaIndex or array-like
|
| 【返回值】
| -------| y : Index or TimedeltaIndex
|
| ----------------------------------------------------------------------| Static methods defined here:
|
| __new__(cls, data=None, unit=None, freq=None, start=None, end=None, periods=None, copy=False, name=None,
closed=None, verify_integrity=True, **kwargs)
| Create and return a new object. See help(type) for accurate signature.
|
890
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| components
| Return a dataframe of the components (days, hours, minutes,
| seconds, milliseconds, microseconds, nanoseconds) of the Timedeltas.
|
| 【返回值】
| -------| a DataFrame
|
| days
| Number of days for each element.
|
| dtype
|
| inferred_type
|
| is_all_dates
| Checks that all the labels are datetime objects
|
| microseconds
| Number of microseconds (&gt;= 0 and less than 1 second) for each element.
|
| nanoseconds
| Number of nanoseconds (&gt;= 0 and less than 1 microsecond) for each element.
|
| seconds
| Number of seconds (&gt;= 0 and less than 1 day) for each element.
|
| ----------------------------------------------------------------------| 其他数据、属性定义：
|
| __hash__ = None
|
| freq = None
|
| ----------------------------------------------------------------------| Methods inherited from pandas.tseries.base.DatetimeIndexOpsMixin:
|
| __contains__(self, key)
|
| __getitem__(self, key)
|
| __iter__(self)
|
| argmax(self, axis=None)
| return a ndarray of the maximum argument indexer
|
| 【参见】
| --------| numpy.ndarray.argmax
|
| argmin(self, axis=None)
| return a ndarray of the minimum argument indexer
|
| 【参见】
891
| --------| numpy.ndarray.argmin
|
| get_duplicates(self)
|
| groupby(self, f)
|
| isin(self, values)
| Compute boolean array of whether each index value is found in the
| passed set of values
|
| 【参数】
| ----------| values : set or sequence of values
|
| 【返回值】
| -------| is_contained : ndarray (boolean dtype)
|
| map(self, f)
| # Try to run function on index first, and then on elements of index
| # Especially important for group-by functionality
|
| max(self, axis=None)
| return the maximum value of the Index
|
| 【参见】
| --------| numpy.ndarray.max
|
| min(self, axis=None)
| return the minimum value of the Index
|
| 【参见】
| --------| numpy.ndarray.min
|
| repeat(self, repeats, axis=None)
| Analogous to ndarray.repeat
|
| shift(self, n, freq=None)
| Specialized shift which produces a DatetimeIndex
|
| 【参数】
| ----------| n : int
| Periods to shift by
| freq : DateOffset or timedelta-like, optional
|
| 【返回值】
| -------| shifted : DatetimeIndex
|
| sort_values(self, return_indexer=False, ascending=True)
| Return sorted copy of Index
|
| summary(self, name=None)
892
| return a summarized representation
|
| take(self, indices, axis=0, allow_fill=True, fill_value=None)
| Analogous to ndarray.take
|
| tolist(self)
| return a list of the underlying data
|
| unique(self)
| Index.unique with handling for DatetimeIndex/PeriodIndex metadata
|
| 【返回值】
| -------| result : DatetimeIndex or PeriodIndex
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.tseries.base.DatetimeIndexOpsMixin:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
|
| asobject
|
| freqstr
| return the frequency object as a string if its set, otherwise None
|
| hasnans
|
| inferred_freq
|
| resolution
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.index.Int64Index:
|
| asi8
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.index.Index:
|
| __and__(self, other)
|
| __array__(self, dtype=None)
| the array interface, return my values
|
| __array_wrap__(self, result, context=None)
| Gets called after a ufunc
|
| __bool__ = __nonzero__(self)
|
| __copy__ = copy(self, names=None, name=None, dtype=None, deep=False)
| Make a copy of this object. Name and dtype sets those attributes on
| the new object.
|
893
| 【参数】
| ----------| name : string, optional
| dtype : numpy dtype or pandas type
|
| 【返回值】
| -------| copy : Index
|
| 【注意】
| -----| In most cases, there should be no functional difference from using
| ``deep``, but if ``deep`` is passed it will attempt to deepcopy.
|
| __deepcopy__(self, memo={})
|
| __len__(self)
| return the length of the Index
|
| __nonzero__(self)
|
| __or__(self, other)
|
| __reduce__(self)
| helper for pickle
|
| __setitem__(self, key, value)
|
| __unicode__(self)
| Return a string representation for this object.
|
| Invoked by unicode(df) in py2 only. Yields a Unicode String in both
| py2/py3.
|
| __xor__(self, other)
|
| argsort(self, *args, **kwargs)
| return an ndarray indexer of the underlying data
|
| 【参见】
| --------| numpy.ndarray.argsort
|
| asof(self, label)
| For a sorted index, return the most recent label up to and including
| the passed label. Return NaN if not found.
|
| 【参见】
| --------| get_loc : asof is a thin wrapper around get_loc with method=&#39;pad&#39;
|
| asof_locs(self, where, mask)
| where : array of timestamps
| mask : array of booleans where data is not NA
|
| copy(self, names=None, name=None, dtype=None, deep=False)
| Make a copy of this object. Name and dtype sets those attributes on
894
| the new object.
|
| 【参数】
| ----------| name : string, optional
| dtype : numpy dtype or pandas type
|
| 【返回值】
| -------| copy : Index
|
| 【注意】
| -----| In most cases, there should be no functional difference from using
| ``deep``, but if ``deep`` is passed it will attempt to deepcopy.
|
| diff = wrapper(*args, **kwargs)
|
| difference(self, other)
| Return a new Index with elements from the index that are not in</code>other<code>.
|
| This is the sorted set difference of two Index objects.
|
| 【参数】
| ----------| other : Index or array-like
|
| 【返回值】
| -------| difference : Index
|
| 【示例】
| --------|
| &gt;&gt;&gt; idx1 = pd.Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = pd.Index([3, 4, 5, 6])
| &gt;&gt;&gt; idx1.difference(idx2)
| Int64Index([1, 2], dtype=&#39;int64&#39;)
|
| drop(self, labels, errors=&#39;raise&#39;)
| Make new Index with passed list of labels deleted
|
| 【参数】
| ----------| labels : array-like
| errors : {&#39;ignore&#39;, &#39;raise&#39;}, default &#39;raise&#39;
| If &#39;ignore&#39;, suppress error and existing labels are dropped.
|
| 【返回值】
| -------| dropped : Index
|
| drop_duplicates(self, keep=&#39;first&#39;)
| Return Index with duplicate values removed
|
| 【参数】
895
| ----------|
| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| - ``first`` : Drop duplicates except for the first occurrence.
| - ``last`` : Drop duplicates except for the last occurrence.
| - False : Drop all duplicates.
| take_last : deprecated
|
|
| 【返回值】
| -------| deduplicated : Index
|
| duplicated(self, keep=&#39;first&#39;)
| Return boolean np.array denoting duplicate values
|
| 【参数】
| ----------| keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
| - ``first`` : Mark duplicates as ``True`` except for the first occurrence.
| - ``last`` : Mark duplicates as ``True`` except for the last occurrence.
| - False : Mark all duplicates as ``True``.
| take_last : deprecated
|
| 【返回值】
| -------| duplicated : np.array
|
| fillna(self, value=None, downcast=None)
| Fill NA/NaN values with the specified value
|
| 【参数】
| ----------| value : scalar
| Scalar value to use to fill holes (e.g. 0).
| This value cannot be a list-likes.
| downcast : dict, default is None
| a dict of item-&gt;dtype of what to downcast if possible,
| or the string &#39;infer&#39; which will try to downcast to an appropriate
| equal type (e.g. float64 to int64 if possible)
|
| 【返回值】
| -------| filled : Index
|
| format(self, name=False, formatter=None, **kwargs)
| Render a string representation of the Index
|
| get_indexer(self, target, method=None, limit=None, tolerance=None)
| Compute indexer and mask for new index given the current index. The
| indexer should be then used as an input to ndarray.take to align the
| current data to the new index.
|
| 【参数】
| ----------| target : Index
| method : {None, &#39;pad&#39;/&#39;ffill&#39;, &#39;backfill&#39;/&#39;bfill&#39;, &#39;nearest&#39;}, optional
896
| * default: exact matches only.
| * pad / ffill: find the PREVIOUS index value if no exact match.
| * backfill / bfill: use NEXT index value if no exact match
| * nearest: use the NEAREST index value if no exact match. Tied
| distances are broken by preferring the larger index value.
| limit : int, optional
| Maximum number of consecutive labels in ``target`` to match for
| inexact matches.
| tolerance : optional
| Maximum distance between original and new labels for inexact
| matches. The values of the index at the matching locations most
| satisfy the equation ``abs(index[indexer] - target) &lt;= tolerance``.
|
| .. versionadded:: 0.17.0
|
| 【示例】
| --------| &gt;&gt;&gt; indexer = index.get_indexer(new_index)
| &gt;&gt;&gt; new_values = cur_values.take(indexer)
|
| 【返回值】
| -------| indexer : ndarray of int
| Integers from 0 to n - 1 indicating that the index at these
| positions matches the corresponding target values. Missing values
| in the target are marked by -1.
|
| get_indexer_for(self, target, **kwargs)
| guaranteed return of an indexer even when non-unique
|
| get_indexer_non_unique(self, target)
| return an indexer suitable for taking from a non unique index
| return the labels in the same order as the target, and
| return a missing indexer into the target (missing are marked as -1
| in the indexer); target must be an iterable
|
| get_level_values(self, level)
| Return vector of label values for requested level, equal to the length
| of the index
|
| 【参数】
| ----------| level : int
|
| 【返回值】
| -------| values : ndarray
|
| get_slice_bound(self, label, side, kind)
| Calculate slice bound that corresponds to given label.
|
| Returns leftmost (one-past-the-rightmost if ``side==&#39;right&#39;``) position
| of given label.
|
| 【参数】
| ----------| label : object
897
| side : {&#39;left&#39;, &#39;right&#39;}
| kind : string / None, the type of indexer
|
| get_values(self)
| return the underlying data as an ndarray
|
| holds_integer(self)
|
| identical(self, other)
| Similar to equals, but check that other comparable attributes are
| also equal
|
| is_(self, other)
| More flexible, faster check like ``is`` but that works through views
|
| Note: this is *not* the same as ``Index.identical()``, which checks
| that metadata is also the same.
|
| 【参数】
| ----------| other : object
| other object to compare against.
|
| 【返回值】
| -------| True if both have same underlying data, False otherwise : bool
|
| is_boolean(self)
|
| is_categorical(self)
|
| is_floating(self)
|
| is_integer(self)
|
| is_lexsorted_for_tuple(self, tup)
|
| is_mixed(self)
|
| is_numeric(self)
|
| is_object(self)
|
| order(self, return_indexer=False, ascending=True)
| Return sorted copy of Index
|
| DEPRECATED: use :meth:</code>Index.sort_values<code>|
| putmask(self, mask, value)
| return a new Index of the values set with the mask
|
| 【参见】
| --------| numpy.ndarray.putmask
|
| ravel(self, order=&#39;C&#39;)
| return an ndarray of the flattened values of the underlying data
898
|
| 【参见】
| --------| numpy.ndarray.ravel
|
| reindex(self, target, method=None, level=None, limit=None, tolerance=None)
| Create index with target&#39;s values (move/add/delete values as necessary)
|
| 【参数】
| ----------| target : an iterable
|
| 【返回值】
| -------| new_index : pd.Index
| Resulting index
| indexer : np.ndarray or None
| Indices of output values in original index
|
| rename(self, name, inplace=False)
| Set new names on index. Defaults to returning new index.
|
| 【参数】
| ----------| name : str or list
| name to set
| inplace : bool
| if True, mutates in place
|
| 【返回值】
| -------| new index (of same type and class...etc) [if inplace, returns None]
|
| set_names(self, names, level=None, inplace=False)
| Set new names on index. Defaults to returning new index.
|
| 【参数】
| ----------| names : str or sequence
| name(s) to set
| level : int or level name, or sequence of int / level names (default None)
| If the index is a MultiIndex (hierarchical), level(s) to set (None for all levels)
| Otherwise level must be None
| inplace : bool
| if True, mutates in place
|
| 【返回值】
| -------| new index (of same type and class...etc) [if inplace, returns None]
|
| 【示例】
| --------| &gt;&gt;&gt; Index([1, 2, 3, 4]).set_names(&#39;foo&#39;)
| Int64Index([1, 2, 3, 4], dtype=&#39;int64&#39;)
| &gt;&gt;&gt; Index([1, 2, 3, 4]).set_names([&#39;foo&#39;])
| Int64Index([1, 2, 3, 4], dtype=&#39;int64&#39;)
899
| &gt;&gt;&gt; idx = MultiIndex.from_tuples([(1, u&#39;one&#39;), (1, u&#39;two&#39;),
| (2, u&#39;one&#39;), (2, u&#39;two&#39;)],
| names=[&#39;foo&#39;, &#39;bar&#39;])
| &gt;&gt;&gt; idx.set_names([&#39;baz&#39;, &#39;quz&#39;])
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
| names=[u&#39;baz&#39;, u&#39;quz&#39;])
| &gt;&gt;&gt; idx.set_names(&#39;baz&#39;, level=0)
| MultiIndex(levels=[[1, 2], [u&#39;one&#39;, u&#39;two&#39;]],
| labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
| names=[u&#39;baz&#39;, u&#39;bar&#39;])
|
| set_value(self, arr, key, value)
| Fast lookup of value from 1-dimensional ndarray. Only use this if you
| know what you&#39;re doing
|
| slice_indexer(self, start=None, end=None, step=None, kind=None)
| For an ordered Index, compute the slice indexer for input labels and
| step
|
| 【参数】
| ----------| start : label, default None
| If None, defaults to the beginning
| end : label, default None
| If None, defaults to the end
| step : int, default None
| kind : string, default None
|
| 【返回值】
| -------| indexer : ndarray or slice
|
| 【注意】
| -----| This function assumes that the data is sorted, so use at your own peril
|
| slice_locs(self, start=None, end=None, step=None, kind=None)
| Compute slice locations for input labels.
|
| 【参数】
| ----------| start : label, default None
| If None, defaults to the beginning
| end : label, default None
| If None, defaults to the end
| step : int, defaults None
| If None, defaults to 1
| kind : string, defaults None
|
| 【返回值】
| -------| start, end : int
|
| sort(self, *args, **kwargs)
|
| sortlevel(self, level=None, ascending=True, sort_remaining=None)
900
| For internal compatibility with with the Index API
|
| Sort the Index. This is for compat with MultiIndex
|
| 【参数】
| ----------| ascending : boolean, default True
| False to sort in descending order
|
| level, sort_remaining are compat paramaters
|
| 【返回值】
| -------| sorted_index : Index
|
| sym_diff(self, other, result_name=None)
| Compute the sorted symmetric difference of two Index objects.
|
| 【参数】
| ----------| other : Index or array-like
| result_name : str
|
| 【返回值】
| -------| sym_diff : Index
|
| 【注意】
| -----| ``sym_diff`` contains elements that appear in either ``idx1`` or
| ``idx2`` but not both. Equivalent to the Index created by
| ``(idx1 - idx2) + (idx2 - idx1)`` with duplicates dropped.
|
| The sorting of a result containing ``NaN`` values is not guaranteed
| across Python versions. See GitHub issue #6444.
|
| 【示例】
| --------| &gt;&gt;&gt; idx1 = Index([1, 2, 3, 4])
| &gt;&gt;&gt; idx2 = Index([2, 3, 4, 5])
| &gt;&gt;&gt; idx1.sym_diff(idx2)
| Int64Index([1, 5], dtype=&#39;int64&#39;)
|
| You can also use the ``^`` operator:
|
| &gt;&gt;&gt; idx1 ^ idx2
| Int64Index([1, 5], dtype=&#39;int64&#39;)
|
| to_datetime(self, dayfirst=False)
| For an Index containing strings or datetime.datetime objects, attempt
| conversion to DatetimeIndex
|
| to_native_types(self, slicer=None, **kwargs)
| slice and dice then format
|
| to_series(self, **kwargs)
| Create a Series with both index and values equal to the index keys
901
| useful with map for returning an indexer based on an index
|
| 【返回值】
| -------| Series : dtype will be based on the type of the Index values.
|
| view(self, cls=None)
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.index.Index:
|
| dtype_str
|
| has_duplicates
|
| is_monotonic
| alias for is_monotonic_increasing (deprecated)
|
| is_monotonic_decreasing
| return if the index is monotonic decreasing (only equal or
| decreasing) values.
|
| is_monotonic_increasing
| return if the index is monotonic increasing (only equal or
| increasing) values.
|
| is_unique
|
| names
|
| nlevels
|
| values
| return the underlying data as an ndarray
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.index.Index:
|
| name = None
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.IndexOpsMixin:
|
| factorize(self, sort=False, na_sentinel=-1)
| Encode the object as an enumerated type or categorical variable
|
| 【参数】
| ----------| sort : boolean, default False
| Sort by values
| na_sentinel: int, default -1
| Value to mark &quot;not found&quot;
|
| 【返回值】
| -------| labels : the indexer to the original array
| uniques : the unique Index
902
|
| item(self)
| return the first element of the underlying data as a python scalar
|
| memory_usage(self, deep=False)
| Memory usage of my values
|
| 【参数】
| ----------| deep : bool
| Introspect the data deeply, interrogate
|</code>object<code>dtypes for system-level memory consumption
|
| 【返回值】
| -------| bytes used
|
| 【注意】
| -----| Memory usage does not include memory consumed by elements that
| are not components of the array if deep=False
|
| 【参见】
| --------| numpy.ndarray.nbytes
|
| nunique(self, dropna=True)
| Return number of unique elements in the object.
|
| Excludes NA values by default.
|
| 【参数】
| ----------| dropna : boolean, default True
| Don&#39;t include NaN in the count.
|
| 【返回值】
| -------| nunique : int
|
| transpose(self)
| return the transpose, which is by definition self
|
| value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)
| Returns object containing counts of unique values.
|
| The resulting object will be in descending order so that the
| first element is the most frequently-occurring element.
| Excludes NA values by default.
|
| 【参数】
| ----------| normalize : boolean, default False
| If True then the object returned will contain the relative
| frequencies of the unique values.
| sort : boolean, default True
| Sort by values
903
| ascending : boolean, default False
| Sort in ascending order
| bins : integer, optional
| Rather than count values, group them into half-open bins,
| a convenience for pd.cut, only works with numeric data
| dropna : boolean, default True
| Don&#39;t include counts of NaN.
|
| 【返回值】
| -------| counts : Series
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.base.IndexOpsMixin:
|
| T
| return the transpose, which is by definition self
|
| base
| return the base object if the memory of the underlying data is shared
|
| data
| return the data pointer of the underlying data
|
| flags
| return the ndarray.flags for the underlying data
|
| itemsize
| return the size of the dtype of the item of the underlying data
|
| nbytes
| return the number of bytes in the underlying data
|
| ndim
| return the number of dimensions of the underlying data, by definition 1
|
| shape
| return a tuple of the shape of the underlying data
|
| size
| return the number of elements in the underlying data
|
| strides
| return the strides of the underlying data
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.base.IndexOpsMixin:
|
| __array_priority__ = 1000
|
| ----------------------------------------------------------------------| Data and other attributes inherited from pandas.core.strings.StringAccessorMixin:
|
| str = &lt;class &#39;pandas.core.strings.StringMethods&#39;&gt;
| Vectorized string functions for Series and Index. NAs stay NA unless
| handled otherwise by a particular method. Patterned after Python&#39;s string
| methods, with some inspiration from R&#39;s stringr package.
904
|
| 【示例】
| --------| &gt;&gt;&gt; s.str.split(&#39;_&#39;)
| &gt;&gt;&gt; s.str.replace(&#39;_&#39;, &#39;&#39;)
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.PandasObject:
|
| __dir__(self)
| Provide method name lookup and completion
| Only provide &#39;public&#39; methods
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.base.StringMixin:
|
| __bytes__(self)
| Return a string representation for a particular object.
|
| Invoked by bytes(obj) in py3 only.
| Yields a bytestring in both py2/py3.
|
| __repr__(self)
| Return a string representation for a particular object.
|
| Yields Bytestring in Py2, Unicode String in py3.
|
| __str__(self)
| Return a string representation for a particular Object
|
| Invoked by str(df) in both py2/py3.
| Yields Bytestring in Py2, Unicode String in py3.
Timestamp
Timestamp 模块所属：pandas.tslib:
类定义：Timestamp(_Timestamp)
| TimeStamp is the pandas equivalent of python&#39;s Datetime
| and is interchangable with it in most cases. It&#39;s the type used
| for the entries that make up a DatetimeIndex, and other timeseries
| oriented data structures in pandas.
|
| 【参数】
| ----------| ts_input : datetime-like, str, int, float
| Value to be converted to Timestamp
| offset : str, DateOffset
| Offset which Timestamp will have
| tz : string, pytz.timezone, dateutil.tz.tzfile or None
905
| Time zone for time which Timestamp will have.
| unit : string
| numpy unit used for conversion, if ts_input is int or float
|
| 【方法排序】
| Timestamp
| _Timestamp
| datetime.datetime
| datetime.date
| 【内置对象】
|
| 【方法定义】
|
| __new__(cls, ts_input, offset=None, tz=None, unit=None)
|
| __radd__(self, other)
|
| __reduce__(self)
|
| __repr__(self)
|
| __setstate__(self, state)
|
| astimezone = tz_convert(self, tz)
| Convert tz-aware Timestamp to another time zone.
|
| 【参数】
| ----------| tz : string, pytz.timezone, dateutil.tz.tzfile or None
| Time zone for time which Timestamp will be converted to.
| None will remove timezone holding UTC time.
|
| 【返回值】
| -------| converted : Timestamp
|
| 【Raises 引发错误】
| ------| TypeError
| If Timestamp is tz-naive.
|
| isoformat(self, sep=&#39;T&#39;)
|
| normalize(self)
| Normalize Timestamp to midnight, preserving
| tz information.
|
| replace(self, **kwds)
|
| to_julian_date(self)
| Convert TimeStamp to a Julian Date.
| 0 Julian date is noon January 1, 4713 BC.
|
| to_period(self, freq=None)
| Return an period of which this timestamp is an observation.
|
| to_pydatetime(self, warn=True)
906
| If warn=True, issue warning if nanoseconds is nonzero
|
| tz_convert(self, tz)
| Convert tz-aware Timestamp to another time zone.
|
| 【参数】
| ----------| tz : string, pytz.timezone, dateutil.tz.tzfile or None
| Time zone for time which Timestamp will be converted to.
| None will remove timezone holding UTC time.
|
| 【返回值】
| -------| converted : Timestamp
|
| 【Raises 引发错误】
| ------| TypeError
| If Timestamp is tz-naive.
|
| tz_localize(self, tz, ambiguous=&#39;raise&#39;)
| Convert naive Timestamp to local time zone, or remove
| timezone from tz-aware Timestamp.
|
| 【参数】
| ----------| tz : string, pytz.timezone, dateutil.tz.tzfile or None
| Time zone for time which Timestamp will be converted to.
| None will remove timezone holding local time.
| ambiguous : bool, &#39;NaT&#39;, default &#39;raise&#39;
| - bool contains flags to determine if time is dst or not (note
| that this flag is only applicable for ambiguous fall dst dates)
| - &#39;NaT&#39; will return NaT for an ambiguous time
| - &#39;raise&#39; will raise an AmbiguousTimeError for an ambiguous time
|
| 【返回值】
| -------| localized : Timestamp
|
| 【Raises 引发错误】
| ------| TypeError
| If the Timestamp is tz-aware and tz is not None.
|
| ----------------------------------------------------------------------| Class methods defined here:
|
| combine(date, time) from builtins.type
| date, time -&gt; datetime with same date and time fields
|
| fromordinal(ordinal, offset=None, tz=None) from builtins.type
| passed an ordinal, translate and convert to a ts
| note: by definition there cannot be any tz info on the ordinal itself
|
| fromtimestamp(ts) from builtins.type
| timestamp[, tz] -&gt; tz&#39;s local time from POSIX timestamp.
|
907
| now(tz=None) from builtins.type
| Return the current time in the local timezone. Equivalent
| to datetime.now([tz])
|
| 【参数】
| ----------| tz : string / timezone object, default None
| Timezone to localize to
|
| today(tz=None) from builtins.type
| Return the current time in the local timezone. This differs
| from datetime.today() in that it can be localized to a
| passed timezone.
|
| 【参数】
| ----------| tz : string / timezone object, default None
| Timezone to localize to
|
| utcfromtimestamp(ts) from builtins.type
| Construct a naive UTC datetime from a POSIX timestamp.
|
| utcnow() from builtins.type
| Return a new datetime representing UTC day and time.
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
|
| asm8
|
| dayofweek
|
| dayofyear
|
| days_in_month
|
| daysinmonth
|
| freq
|
| freqstr
|
| is_month_end
|
| is_month_start
|
| is_quarter_end
|
| is_quarter_start
|
| is_year_end
908
|
| is_year_start
|
| microsecond
|
| quarter
|
| tz
| Alias for tzinfo
|
| week
|
| weekofyear
|
| ----------------------------------------------------------------------| 其他数据、属性定义：
|
| max = Timestamp(&#39;2262-04-11 23:47:16.854775807&#39;)
|
| min = Timestamp(&#39;1677-09-22 00:12:43.145225&#39;)
|
| ----------------------------------------------------------------------| Methods inherited from _Timestamp:
|
| __add__(self, value, /)
| Return self+value.
|
| __eq__(self, value, /)
| Return self==value.
|
| __ge__(self, value, /)
| Return self&gt;=value.
|
| __gt__(self, value, /)
| Return self&gt;value.
|
| __hash__(self, /)
| Return hash(self).
|
| __le__(self, value, /)
| Return self&lt;=value.
|
| __lt__(self, value, /)
| Return self&lt;value.
|
| __ne__(self, value, /)
| Return self!=value.
|
| __rsub__(self, value, /)
| Return value-self.
|
| __sub__(self, value, /)
| Return self-value.
|
| to_datetime(...)
|
| to_datetime64(...)
909
| Returns a numpy.datetime64 object with &#39;ns&#39; precision
|
| ----------------------------------------------------------------------| Data descriptors inherited from _Timestamp:
|
| nanosecond
|
| offset
|
| value
|
| ----------------------------------------------------------------------| Data and other attributes inherited from _Timestamp:
|
| __pyx_vtable__ = &lt;capsule object NULL&gt;
|
| ----------------------------------------------------------------------| Methods inherited from datetime.datetime:
|
| __getattribute__(self, name, /)
| Return getattr(self, name).
|
| __str__(self, /)
| Return str(self).
|
| ctime(...)
| Return ctime() style string.
|
| date(...)
| Return date object with same year, month and day.
|
| dst(...)
| Return self.tzinfo.dst(self).
|
| strptime(...) from builtins.type
| string, format -&gt; new datetime parsed from a string (like time.strptime()).
|
| time(...)
| Return time object with same time but with tzinfo=None.
|
| timestamp(...)
| Return POSIX timestamp as float.
|
| timetuple(...)
| Return time tuple, compatible with time.localtime().
|
| timetz(...)
| Return time object with same time and tzinfo.
|
| tzname(...)
| Return self.tzinfo.tzname(self).
|
| utcoffset(...)
| Return self.tzinfo.utcoffset(self).
|
| utctimetuple(...)
| Return UTC time tuple, compatible with time.localtime().
910
|
| ----------------------------------------------------------------------| Data descriptors inherited from datetime.datetime:
|
| hour
|
| minute
|
| second
|
| tzinfo
|
| ----------------------------------------------------------------------| Data and other attributes inherited from datetime.datetime:
|
| resolution = datetime.timedelta(0, 0, 1)
|
| ----------------------------------------------------------------------| Methods inherited from datetime.date:
|
| __format__(...)
| Formats self with strftime.
|
| isocalendar(...)
| Return a 3-tuple containing ISO year, week number, and weekday.
|
| isoweekday(...)
| Return the day of the week represented by the date.
| Monday == 1 ... Sunday == 7
|
| strftime(...)
| format -&gt; strftime() style string.
|
| toordinal(...)
| Return proleptic Gregorian ordinal. January 1 of year 1 is day 1.
|
| weekday(...)
| Return the day of the week represented by the date.
| Monday == 0 ... Sunday == 6
|
| ----------------------------------------------------------------------| Data descriptors inherited from datetime.date:
|
| day
|
| month
|
| year
WidePanel
911
WidePanel 模块所属：pandas.core.panel:
类定义：WidePanel(Panel)
| Represents wide format panel data, stored as 3-dimensional array
|
| 【参数】
| ----------| data : ndarray (items x major x minor), or dict of DataFrames
| items : Index or array-like
| axis=0
| major_axis : Index or array-like
| axis=1
| minor_axis : Index or array-like
| axis=2
| dtype : dtype, default None
| Data type to force, otherwise infer
| copy : boolean, default False
| Copy data from inputs. Only affects DataFrame / 2d ndarray input
|
| 【方法排序】
| WidePanel
| Panel
| pandas.core.generic.NDFrame
| pandas.core.base.PandasObject
| pandas.core.base.StringMixin
| 【内置对象】
|
| 【方法定义】
|
| __init__(self, *args, **kwargs)
| Initialize self. See help(type(self)) for accurate signature.
|
| ----------------------------------------------------------------------| Methods inherited from Panel:
|
| __add__(self, other)
| # work only for scalars
|
| __and__(self, other)
| # work only for scalars
|
| __div__ = __truediv__(self, other)
| # work only for scalars
|
| __eq__(self, other)
| Wrapper for comparison method __eq__
|
| __floordiv__(self, other)
| # work only for scalars
|
| __ge__(self, other)
| Wrapper for comparison method __ge__
|
| __getitem__(self, key)
|
| __gt__(self, other)
| Wrapper for comparison method __gt__
912
|
| __iadd__ = f(self, other)
|
| __imul__ = f(self, other)
|
| __ipow__ = f(self, other)
|
| __isub__ = f(self, other)
|
| __itruediv__ = f(self, other)
|
| __le__(self, other)
| Wrapper for comparison method __le__
|
| __lt__(self, other)
| Wrapper for comparison method __lt__
|
| __mod__(self, other)
| # work only for scalars
|
| __mul__(self, other)
| # work only for scalars
|
| __ne__(self, other)
| Wrapper for comparison method __ne__
|
| __or__(self, other)
| # work only for scalars
|
| __pow__(self, other)
| # work only for scalars
|
| __radd__(self, other)
| # work only for scalars
|
| __rand__(self, other)
| # work only for scalars
|
| __rdiv__ = __rtruediv__(self, other)
| # work only for scalars
|
| __rfloordiv__(self, other)
| # work only for scalars
|
| __rmod__(self, other)
| # work only for scalars
|
| __rmul__(self, other)
| # work only for scalars
|
| __ror__(self, other)
| # work only for scalars
|
| __rpow__(self, other)
| # work only for scalars
|
| __rsub__(self, other)
913
| # work only for scalars
|
| __rtruediv__(self, other)
| # work only for scalars
|
| __rxor__(self, other)
| # work only for scalars
|
| __setitem__(self, key, value)
|
| __sub__(self, other)
| # work only for scalars
|
| __truediv__(self, other)
| # work only for scalars
|
| __unicode__(self)
| Return a string representation for a particular Panel
|
| Invoked by unicode(df) in py2 only.
| Yields a Unicode String in both py2/py3.
|
| __xor__(self, other)
| # work only for scalars
|
| add(self, other, axis=0)
| Addition of series and other, element-wise (binary operator</code>add<code>).
| Equivalent to ``panel + other``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.radd
|
| align(self, other, **kwargs)
| Align two object on their axes with the
| specified join method for each axis Index
|
| 【参数】
| ----------| other : DataFrame or Series
| join : {&#39;outer&#39;, &#39;inner&#39;, &#39;left&#39;, &#39;right&#39;}, default &#39;outer&#39;
| axis : allowed axis of the other object, default None
| Align on index (0), columns (1), or both (None)
| level : int or level name, default None
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
| copy : boolean, default True
914
| Always returns new objects. If copy=False and no reindexing is
| required then original objects are returned.
| fill_value : scalar, default np.NaN
| Value to use for missing values. Defaults to NaN, but can be any
| &quot;compatible&quot; value
| method : str, default None
| limit : int, default None
| fill_axis : int or labels for object, default 0
| Filling axis, method and limit
| broadcast_axis : int or labels for object, default None
| Broadcast values along this axis, if aligning two objects of
| different dimensions
|
| .. versionadded:: 0.17.0
|
| 【返回值】
| -------| (left, right) : (NDFrame, type of other)
| Aligned objects
|
| all(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)
| Return whether all elements are True over requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| bool_only : boolean, default None
| Include only boolean data. If None, will attempt to use everything,
| then use only boolean data
|
| 【返回值】
| -------| all : DataFrame or Panel (if level specified)
|
| any(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)
| Return whether any element is True over requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| bool_only : boolean, default None
| Include only boolean data. If None, will attempt to use everything,
| then use only boolean data
|
| 【返回值】
915
| -------| any : DataFrame or Panel (if level specified)
|
| apply(self, func, axis=&#39;major&#39;, **kwargs)
| Applies function along axis (or axes) of the Panel
|
| 【参数】
| ----------| func : function
| Function to apply to each combination of &#39;other&#39; axes
| e.g. if axis = &#39;items&#39;, the combination of major_axis/minor_axis
| will each be passed as a Series; if axis = (&#39;items&#39;, &#39;major&#39;), DataFrames
| of items &amp; major axis will be passed
| axis : {&#39;items&#39;, &#39;minor&#39;, &#39;major&#39;}, or {0, 1, 2}, or a tuple with two axes
| Additional keyword arguments will be passed as keywords to the function
|
| 【示例】
| --------|
| Returns a Panel with the square root of each element
|
| &gt;&gt;&gt; p = pd.Panel(np.random.rand(4,3,2))
| &gt;&gt;&gt; p.apply(np.sqrt)
|
| Equivalent to p.sum(1), returning a DataFrame
|
| &gt;&gt;&gt; p.apply(lambda x: x.sum(), axis=1)
|
| Equivalent to previous:
|
| &gt;&gt;&gt; p.apply(lambda x: x.sum(), axis=&#39;minor&#39;)
|
| Return the shapes of each DataFrame over axis 2 (i.e the shapes of items x major), as a Series
|
| &gt;&gt;&gt; p.apply(lambda x: x.shape, axis=(0,1))
|
| 【返回值】
| -------| result : Panel, DataFrame, or Series
|
| as_matrix(self)
| Convert the frame to its Numpy-array representation.
|
| 【参数】
| ----------| columns: list, optional, default:None
| If None, return all columns, otherwise, returns specified columns.
|
| 【返回值】
| -------| values : ndarray
| If the caller is heterogeneous and contains booleans or objects,
| the result will be of dtype=object. See Notes.
|
|
| 【注意】
| -----
916
| Return is NOT a Numpy-matrix, rather, a Numpy-array.
|
| The dtype will be a lower-common-denominator dtype (implicit
| upcasting); that is to say if the dtypes (even of numeric types)
| are mixed, the one that accommodates all will be chosen. Use this
| with care if you are not dealing with the blocks.
|
| e.g. If the dtypes are float16 and float32, dtype will be upcast to
| float32. If dtypes are int32 and uint8, dtype will be upcase to
| int32.
|
| This method is provided for backwards compatibility. Generally,
| it is recommended to use &#39;.values&#39;.
|
| 【参见】
| --------| pandas.DataFrame.values
|
| compound(self, axis=None, skipna=None, level=None)
| Return the compound percentage of the values for the requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| compounded : DataFrame or Panel (if level specified)
|
| conform(self, frame, axis=&#39;items&#39;)
| Conform input DataFrame to align with chosen axis pair.
|
| 【参数】
| ----------| frame : DataFrame
| axis : {&#39;items&#39;, &#39;major&#39;, &#39;minor&#39;}
|
| Axis the input corresponds to. E.g., if axis=&#39;major&#39;, then
| the frame&#39;s columns would be items, and the index would be
| values of the minor axis
|
| 【返回值】
| -------| DataFrame
|
| count(self, axis=&#39;major&#39;)
| Return number of observations over requested axis.
|
917
| 【参数】
| ----------| axis : {&#39;items&#39;, &#39;major&#39;, &#39;minor&#39;} or {0, 1, 2}
|
| 【返回值】
| -------| count : DataFrame
|
| cummax = max(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative max over requested axis.
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| max : DataFrame
|
| cummin = min(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative min over requested axis.
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| min : DataFrame
|
| cumprod = prod(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative prod over requested axis.
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| prod : DataFrame
|
| cumsum = sum(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)
| Return cumulative sum over requested axis.
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
918
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
|
| 【返回值】
| -------| sum : DataFrame
|
| div = truediv(self, other, axis=0)
| Floating division of series and other, element-wise (binary operator</code>truediv<code>).
| Equivalent to ``panel / other``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.rtruediv
|
| divide = truediv(self, other, axis=0)
| Floating division of series and other, element-wise (binary operator</code>truediv<code>).
| Equivalent to ``panel / other``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.rtruediv
|
| dropna(self, axis=0, how=&#39;any&#39;, inplace=False)
| Drop 2D from panel, holding passed axis constant
|
| 【参数】
| ----------| axis : int, default 0
| Axis to hold constant. E.g. axis=1 will drop major_axis entries
| having a certain amount of NA data
| how : {&#39;all&#39;, &#39;any&#39;}, default &#39;any&#39;
| &#39;any&#39;: one or more values are NA in the DataFrame along the
| axis. For &#39;all&#39; they all must be.
| inplace : bool, default False
919
| If True, do operation inplace and return None.
|
| 【返回值】
| -------| dropped : Panel
|
| eq(self, other)
| Wrapper for comparison method eq
|
| fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)
| Fill NA/NaN values using the specified method
|
| 【参数】
| ----------| value : scalar, dict, Series, or DataFrame
| Value to use to fill holes (e.g. 0), alternately a dict/Series/DataFrame of
| values specifying which value to use for each index (for a Series) or
| column (for a DataFrame). (values not in the dict/Series/DataFrame will not be
| filled). This value cannot be a list.
| method : {&#39;backfill&#39;, &#39;bfill&#39;, &#39;pad&#39;, &#39;ffill&#39;, None}, default None
| Method to use for filling holes in reindexed Series
| pad / ffill: propagate last valid observation forward to next valid
| backfill / bfill: use NEXT valid observation to fill gap
| axis : {0, 1, 2, &#39;items&#39;, &#39;major_axis&#39;, &#39;minor_axis&#39;}
| inplace : boolean, default False
| If True, fill in place. Note: this will modify any
| other views on this object, (e.g. a no-copy slice for a column in a
| DataFrame).
| limit : int, default None
| If method is specified, this is the maximum number of consecutive
| NaN values to forward/backward fill. In other words, if there is
| a gap with more than this number of consecutive NaNs, it will only
| be partially filled. If method is not specified, this is the
| maximum number of entries along the entire axis where NaNs will be
| filled.
| downcast : dict, default is None
| a dict of item-&gt;dtype of what to downcast if possible,
| or the string &#39;infer&#39; which will try to downcast to an appropriate
| equal type (e.g. float64 to int64 if possible)
|
| 【参见】
| --------| reindex, asfreq
|
| 【返回值】
| -------| filled : Panel
|
| floordiv(self, other, axis=0)
| Integer division of series and other, element-wise (binary operator</code>floordiv<code>).
| Equivalent to ``panel // other``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
920
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.rfloordiv
|
| ge(self, other)
| Wrapper for comparison method ge
|
| get_value(self, *args, **kwargs)
| Quickly retrieve single value at (item, major, minor) location
|
| 【参数】
| ----------| item : item label (panel item)
| major : major axis label (panel item row)
| minor : minor axis label (panel item column)
| takeable : interpret the passed labels as indexers, default False
|
| 【返回值】
| -------| value : scalar value
|
| groupby(self, function, axis=&#39;major&#39;)
| Group data on given axis, returning GroupBy object
|
| 【参数】
| ----------| function : callable
| Mapping function for chosen access
| axis : {&#39;major&#39;, &#39;minor&#39;, &#39;items&#39;}, default &#39;major&#39;
|
| 【返回值】
| -------| grouped : PanelGroupBy
|
| gt(self, other)
| Wrapper for comparison method gt
|
| head(self, n=5)
| Returns first n rows
|
| join(self, other, how=&#39;left&#39;, lsuffix=&#39;&#39;, rsuffix=&#39;&#39;)
| Join items with other Panel either on major and minor axes column
|
| 【参数】
| ----------| other : Panel or list of Panels
| Index should be similar to one of the columns in this one
| how : {&#39;left&#39;, &#39;right&#39;, &#39;outer&#39;, &#39;inner&#39;}
| How to handle indexes of the two objects. Default: &#39;left&#39;
| for joining on index, None otherwise
| * left: use calling frame&#39;s index
| * right: use input frame&#39;s index
921
| * outer: form union of indexes
| * inner: use intersection of indexes
| lsuffix : string
| Suffix to use from left frame&#39;s overlapping columns
| rsuffix : string
| Suffix to use from right frame&#39;s overlapping columns
|
| 【返回值】
| -------| joined : Panel
|
| kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return unbiased kurtosis over requested axis using Fishers definition of
| kurtosis (kurtosis of normal == 0.0). Normalized by N-1
|
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| kurt : DataFrame or Panel (if level specified)
|
| kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return unbiased kurtosis over requested axis using Fishers definition of
| kurtosis (kurtosis of normal == 0.0). Normalized by N-1
|
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| kurt : DataFrame or Panel (if level specified)
|
| le(self, other)
| Wrapper for comparison method le
922
|
| lt(self, other)
| Wrapper for comparison method lt
|
| mad(self, axis=None, skipna=None, level=None)
| Return the mean absolute deviation of the values for the requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| mad : DataFrame or Panel (if level specified)
|
| major_xs(self, key, copy=None)
| Return slice of panel along major axis
|
| 【参数】
| ----------| key : object
| Major axis label
| copy : boolean [deprecated]
| Whether to make a copy of the data
|
| 【返回值】
| -------| y : DataFrame
| index -&gt; minor axis, columns -&gt; items
|
| 【注意】
| -----| major_xs is only for getting, not setting values.
|
| MultiIndex Slicers is a generic way to get/set values on any level or levels
| it is a superset of major_xs functionality, see :ref:</code>MultiIndex Slicers <advanced.mi_slicers><code>|
| max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| This method returns the maximum of the values in the object. If you
| want the *index* of the maximum, use ``idxmax``. This is the
| equivalent of the ``numpy.ndarray`` method ``argmax``.
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
923
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| max : DataFrame or Panel (if level specified)
|
| mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the mean of the values for the requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| mean : DataFrame or Panel (if level specified)
|
| median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the median of the values for the requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| median : DataFrame or Panel (if level specified)
|
| min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| This method returns the minimum of the values in the object. If you
| want the *index* of the minimum, use ``idxmin``. This is the
| equivalent of the ``numpy.ndarray`` method ``argmin``.
|
| 【参数】
924
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| min : DataFrame or Panel (if level specified)
|
| minor_xs(self, key, copy=None)
| Return slice of panel along minor axis
|
| 【参数】
| ----------| key : object
| Minor axis label
| copy : boolean [deprecated]
| Whether to make a copy of the data
|
| 【返回值】
| -------| y : DataFrame
| index -&gt; major axis, columns -&gt; items
|
| 【注意】
| -----| minor_xs is only for getting, not setting values.
|
| MultiIndex Slicers is a generic way to get/set values on any level or levels
| it is a superset of minor_xs functionality, see :ref:</code>MultiIndex Slicers <advanced.mi_slicers><code>|
| mod(self, other, axis=0)
| Modulo of series and other, element-wise (binary operator</code>mod<code>).
| Equivalent to ``panel % other``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.rmod
|
| mul(self, other, axis=0)
925
| Multiplication of series and other, element-wise (binary operator</code>mul<code>).
| Equivalent to ``panel * other``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.rmul
|
| multiply = mul(self, other, axis=0)
| Multiplication of series and other, element-wise (binary operator</code>mul<code>).
| Equivalent to ``panel * other``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.rmul
|
| ne(self, other)
| Wrapper for comparison method ne
|
| pow(self, other, axis=0)
| Exponential power of series and other, element-wise (binary operator</code>pow<code>).
| Equivalent to ``panel ** other``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.rpow
|
926
| prod(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the product of the values for the requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| prod : DataFrame or Panel (if level specified)
|
| product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the product of the values for the requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| prod : DataFrame or Panel (if level specified)
|
| radd(self, other, axis=0)
| Addition of series and other, element-wise (binary operator</code>radd<code>).
| Equivalent to ``other + panel``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.add
927
|
| rdiv = rtruediv(self, other, axis=0)
| Floating division of series and other, element-wise (binary operator</code>rtruediv<code>).
| Equivalent to ``other / panel``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.truediv
|
| reindex(self, items=None, major_axis=None, minor_axis=None, **kwargs)
| Conform Panel to new index with optional filling logic, placing
| NA/NaN in locations having no value in the previous index. A new object
| is produced unless the new index is equivalent to the current one and
| copy=False
|
| 【参数】
| ----------| items, major_axis, minor_axis : array-like, optional (can be specified in order, or as
| keywords)
| New labels / index to conform to. Preferably an Index object to
| avoid duplicating data
| method : {None, &#39;backfill&#39;/&#39;bfill&#39;, &#39;pad&#39;/&#39;ffill&#39;, &#39;nearest&#39;}, optional
| method to use for filling holes in reindexed DataFrame.
| Please note: this is only applicable to DataFrames/Series with a
| monotonically increasing/decreasing index.
| * default: don&#39;t fill gaps
| * pad / ffill: propagate last valid observation forward to next valid
| * backfill / bfill: use next valid observation to fill gap
| * nearest: use nearest valid observations to fill gap
| copy : boolean, default True
| Return a new object, even if the passed indexes are the same
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
| fill_value : scalar, default np.NaN
| Value to use for missing values. Defaults to NaN, but can be any
| &quot;compatible&quot; value
| limit : int, default None
| Maximum number of consecutive elements to forward or backward fill
| tolerance : optional
| Maximum distance between original and new labels for inexact
| matches. The values of the index at the matching locations most
| satisfy the equation ``abs(index[indexer] - target) &lt;= tolerance``.
|
| .. versionadded:: 0.17.0
|
| 【示例】
928
| --------|
| Create a dataframe with some fictional data.
|
| &gt;&gt;&gt; index = [&#39;Firefox&#39;, &#39;Chrome&#39;, &#39;Safari&#39;, &#39;IE10&#39;, &#39;Konqueror&#39;]
| &gt;&gt;&gt; df = pd.DataFrame({
| ... &#39;http_status&#39;: [200,200,404,404,301],
| ... &#39;response_time&#39;: [0.04, 0.02, 0.07, 0.08, 1.0]},
| ... index=index)
| &gt;&gt;&gt; df
| http_status response_time
| Firefox 200 0.04
| Chrome 200 0.02
| Safari 404 0.07
| IE10 404 0.08
| Konqueror 301 1.00
|
| Create a new index and reindex the dataframe. By default
| values in the new index that do not have corresponding
| records in the dataframe are assigned ``NaN``.
|
| &gt;&gt;&gt; new_index= [&#39;Safari&#39;, &#39;Iceweasel&#39;, &#39;Comodo Dragon&#39;, &#39;IE10&#39;,
| ... &#39;Chrome&#39;]
| &gt;&gt;&gt; df.reindex(new_index)
| http_status response_time
| Safari 404 0.07
| Iceweasel NaN NaN
| Comodo Dragon NaN NaN
| IE10 404 0.08
| Chrome 200 0.02
|
| We can fill in the missing values by passing a value to
| the keyword ``fill_value``. Because the index is not monotonically
| increasing or decreasing, we cannot use arguments to the keyword
| ``method`` to fill the ``NaN`` values.
|
| &gt;&gt;&gt; df.reindex(new_index, fill_value=0)
| http_status response_time
| Safari 404 0.07
| Iceweasel 0 0.00
| Comodo Dragon 0 0.00
| IE10 404 0.08
| Chrome 200 0.02
|
| &gt;&gt;&gt; df.reindex(new_index, fill_value=&#39;missing&#39;)
| http_status response_time
| Safari 404 0.07
| Iceweasel missing missing
| Comodo Dragon missing missing
| IE10 404 0.08
| Chrome 200 0.02
|
| To further illustrate the filling functionality in
| ``reindex``, we will create a dataframe with a
| monotonically increasing index (for example, a sequence
| of dates).
|
929
| &gt;&gt;&gt; date_index = pd.date_range(&#39;1/1/2010&#39;, periods=6, freq=&#39;D&#39;)
| &gt;&gt;&gt; df2 = pd.DataFrame({&quot;prices&quot;: [100, 101, np.nan, 100, 89, 88]},
| index=date_index)
| &gt;&gt;&gt; df2
| prices
| 2010-01-01 100
| 2010-01-02 101
| 2010-01-03 NaN
| 2010-01-04 100
| 2010-01-05 89
| 2010-01-06 88
|
| Suppose we decide to expand the dataframe to cover a wider
| date range.
|
| &gt;&gt;&gt; date_index2 = pd.date_range(&#39;12/29/2009&#39;, periods=10, freq=&#39;D&#39;)
| &gt;&gt;&gt; df2.reindex(date_index2)
| prices
| 2009-12-29 NaN
| 2009-12-30 NaN
| 2009-12-31 NaN
| 2010-01-01 100
| 2010-01-02 101
| 2010-01-03 NaN
| 2010-01-04 100
| 2010-01-05 89
| 2010-01-06 88
| 2010-01-07 NaN
|
| The index entries that did not have a value in the original data frame
| (for example, &#39;2009-12-29&#39;) are by default filled with ``NaN``.
| If desired, we can fill in the missing values using one of several
| options.
|
| For example, to backpropagate the last valid value to fill the ``NaN``
| values, pass ``bfill`` as an argument to the ``method`` keyword.
|
| &gt;&gt;&gt; df2.reindex(date_index2, method=&#39;bfill&#39;)
| prices
| 2009-12-29 100
| 2009-12-30 100
| 2009-12-31 100
| 2010-01-01 100
| 2010-01-02 101
| 2010-01-03 NaN
| 2010-01-04 100
| 2010-01-05 89
| 2010-01-06 88
| 2010-01-07 NaN
|
| Please note that the ``NaN`` value present in the original dataframe
| (at index value 2010-01-03) will not be filled by any of the
| value propagation schemes. This is because filling while reindexing
| does not look at dataframe values, but only compares the original and
| desired indexes. If you do want to fill in the ``NaN`` values present
| in the original dataframe, use the ``fillna()`` method.
|
930
| 【返回值】
| -------| reindexed : Panel
|
| reindex_axis(self, labels, axis=0, method=None, level=None, copy=True, limit=None, fill_value=nan)
| Conform input object to new index with optional filling logic,
| placing NA/NaN in locations having no value in the previous index. A
| new object is produced unless the new index is equivalent to the
| current one and copy=False
|
| 【参数】
| ----------| labels : array-like
| New labels / index to conform to. Preferably an Index object to
| avoid duplicating data
| axis : {0, 1, 2, &#39;items&#39;, &#39;major_axis&#39;, &#39;minor_axis&#39;}
| method : {None, &#39;backfill&#39;/&#39;bfill&#39;, &#39;pad&#39;/&#39;ffill&#39;, &#39;nearest&#39;}, optional
| Method to use for filling holes in reindexed DataFrame:
| * default: don&#39;t fill gaps
| * pad / ffill: propagate last valid observation forward to next valid
| * backfill / bfill: use next valid observation to fill gap
| * nearest: use nearest valid observations to fill gap
| copy : boolean, default True
| Return a new object, even if the passed indexes are the same
| level : int or name
| Broadcast across a level, matching Index values on the
| passed MultiIndex level
| limit : int, default None
| Maximum number of consecutive elements to forward or backward fill
| tolerance : optional
| Maximum distance between original and new labels for inexact
| matches. The values of the index at the matching locations most
| satisfy the equation ``abs(index[indexer] - target) &lt;= tolerance``.
|
| .. versionadded:: 0.17.0
|
| 【示例】
| --------| &gt;&gt;&gt; df.reindex_axis([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;], axis=1)
|
| 【参见】
| --------| reindex, reindex_like
|
| 【返回值】
| -------| reindexed : Panel
|
| rename(self, items=None, major_axis=None, minor_axis=None, **kwargs)
| Alter axes input function or functions. Function / dict values must be
| unique (1-to-1). Labels not contained in a dict / Series will be left
| as-is.
|
| 【参数】
| ----------| items, major_axis, minor_axis : dict-like or function, optional
| Transformation to apply to that axis values
931
|
| copy : boolean, default True
| Also copy underlying data
| inplace : boolean, default False
| Whether to return a new Panel. If True then value of copy is
| ignored.
|
| 【返回值】
| -------| renamed : Panel (new object)
|
| rfloordiv(self, other, axis=0)
| Integer division of series and other, element-wise (binary operator</code>rfloordiv<code>).
| Equivalent to ``other // panel``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.floordiv
|
| rmod(self, other, axis=0)
| Modulo of series and other, element-wise (binary operator</code>rmod<code>).
| Equivalent to ``other % panel``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.mod
|
| rmul(self, other, axis=0)
| Multiplication of series and other, element-wise (binary operator</code>rmul<code>).
| Equivalent to ``other * panel``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
932
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.mul
|
| rpow(self, other, axis=0)
| Exponential power of series and other, element-wise (binary operator</code>rpow<code>).
| Equivalent to ``other ** panel``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.pow
|
| rsub(self, other, axis=0)
| Subtraction of series and other, element-wise (binary operator</code>rsub<code>).
| Equivalent to ``other - panel``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.sub
|
| rtruediv(self, other, axis=0)
| Floating division of series and other, element-wise (binary operator</code>rtruediv<code>).
| Equivalent to ``other / panel``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
933
| -------| Panel
|
| 【参见】
| --------| Panel.truediv
|
| sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)
| Return unbiased standard error of the mean over requested axis.
|
| Normalized by N-1 by default. This can be changed using the ddof argument
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| ddof : int, default 1
| degrees of freedom
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| sem : DataFrame or Panel (if level specified)
|
| set_value(self, *args, **kwargs)
| Quickly set single value at (item, major, minor) location
|
| 【参数】
| ----------| item : item label (panel item)
| major : major axis label (panel item row)
| minor : minor axis label (panel item column)
| value : scalar
| takeable : interpret the passed labels as indexers, default False
|
| 【返回值】
| -------| panel : Panel
| If label combo is contained, will be reference to calling Panel,
| otherwise a new object
|
| shift(self, periods=1, freq=None, axis=&#39;major&#39;)
| Shift index by desired number of periods with an optional time freq.
| The shifted data will not include the dropped periods and the
| shifted axis will be smaller than the original. This is different
| from the behavior of DataFrame.shift()
|
| 【参数】
| ----------| periods : int
934
| Number of periods to move, can be positive or negative
| freq : DateOffset, timedelta, or time rule string, optional
| axis : {&#39;items&#39;, &#39;major&#39;, &#39;minor&#39;} or {0, 1, 2}
|
| 【返回值】
| -------| shifted : Panel
|
| skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return unbiased skew over requested axis
| Normalized by N-1
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| skew : DataFrame or Panel (if level specified)
|
| std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)
| Return unbiased standard deviation over requested axis.
|
| Normalized by N-1 by default. This can be changed using the ddof argument
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| ddof : int, default 1
| degrees of freedom
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| std : DataFrame or Panel (if level specified)
|
| sub(self, other, axis=0)
| Subtraction of series and other, element-wise (binary operator</code>sub<code>).
| Equivalent to ``panel - other``.
|
935
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.rsub
|
| subtract = sub(self, other, axis=0)
| Subtraction of series and other, element-wise (binary operator</code>sub<code>).
| Equivalent to ``panel - other``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.rsub
|
| sum(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
| Return the sum of the values for the requested axis
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| sum : DataFrame or Panel (if level specified)
|
| tail(self, n=5)
| Returns last n rows
|
| toLong = wrapper(*args, **kwargs)
936
|
| to_excel(self, path, na_rep=&#39;&#39;, engine=None, **kwargs)
| Write each DataFrame in Panel to a separate excel sheet
|
| 【参数】
| ----------| path : string or ExcelWriter object
| File path or existing ExcelWriter
| na_rep : string, default &#39;&#39;
| Missing data representation
| engine : string, default None
| write engine to use - you can also set this via the options
| ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and
| ``io.excel.xlsm.writer``.
|
| Other【参数】
| ----------------| float_format : string, default None
| Format string for floating point numbers
| cols : sequence, optional
| Columns to write
| header : boolean or list of string, default True
| Write out column names. If a list of string is given it is
| assumed to be aliases for the column names
| index : boolean, default True
| Write row names (index)
| index_label : string or sequence, default None
| Column label for index column(s) if desired. If None is given, and
|</code>header<code>and</code>index<code>are True, then the index names are used. A
| sequence should be given if the DataFrame uses MultiIndex.
| startrow : upper left cell row to dump data frame
| startcol : upper left cell column to dump data frame
|
| 【注意】
| -----| Keyword arguments (and na_rep) are passed to the ``to_excel`` method
| for each DataFrame written.
|
| to_frame(self, filter_observations=True)
| Transform wide format into long (stacked) format as DataFrame whose
| columns are the Panel&#39;s items and whose index is a MultiIndex formed
| of the Panel&#39;s major and minor axes.
|
| 【参数】
| ----------| filter_observations : boolean, default True
| Drop (major, minor) pairs without a complete set of observations
| across all the items
|
| 【返回值】
| -------| y : DataFrame
|
| to_long = wrapper(*args, **kwargs)
|
| to_sparse(self, fill_value=None, kind=&#39;block&#39;)
| Convert to SparsePanel
937
|
| 【参数】
| ----------| fill_value : float, default NaN
| kind : {&#39;block&#39;, &#39;integer&#39;}
|
| 【返回值】
| -------| y : SparseDataFrame
|
| transpose(self, *args, **kwargs)
| Permute the dimensions of the Panel
|
| 【参数】
| ----------| args : three positional arguments: each oneof
| {0, 1, 2, &#39;items&#39;, &#39;major_axis&#39;, &#39;minor_axis&#39;}
| copy : boolean, default False
| Make a copy of the underlying data. Mixed-dtype data will
| always result in a copy
|
| 【示例】
| --------| &gt;&gt;&gt; p.transpose(2, 0, 1)
| &gt;&gt;&gt; p.transpose(2, 0, 1, copy=True)
|
| 【返回值】
| -------| y : same as input
|
| truediv(self, other, axis=0)
| Floating division of series and other, element-wise (binary operator</code>truediv<code>).
| Equivalent to ``panel / other``.
|
| 【参数】
| ----------| other : DataFrame or Panel
| axis : {items, major_axis, minor_axis}
| Axis to broadcast over
|
| 【返回值】
| -------| Panel
|
| 【参见】
| --------| Panel.rtruediv
|
| tshift(self, periods=1, freq=None, axis=&#39;major&#39;)
| Shift the time index, using the index&#39;s frequency if available
|
| 【参数】
| ----------| periods : int
| Number of periods to move, can be positive or negative
| freq : DateOffset, timedelta, or time rule string, default None
938
| Increment to use from datetools module or time rule (e.g. &#39;EOM&#39;)
| axis : int or basestring
| Corresponds to the axis that contains the Index
|
| 【注意】
| -----| If freq is not specified then tries to use the freq or inferred_freq
| attributes of the index. If neither of those attributes exist, a
| ValueError is thrown
|
| 【返回值】
| -------| shifted : NDFrame
|
| update(self, other, join=&#39;left&#39;, overwrite=True, filter_func=None, raise_conflict=False)
| Modify Panel in place using non-NA values from passed
| Panel, or object coercible to Panel. Aligns on items
|
| 【参数】
| ----------| other : Panel, or object coercible to Panel
| join : How to join individual DataFrames
| {&#39;left&#39;, &#39;right&#39;, &#39;outer&#39;, &#39;inner&#39;}, default &#39;left&#39;
| overwrite : boolean, default True
| If True then overwrite values for common keys in the calling panel
| filter_func : callable(1d-array) -&gt; 1d-array&lt;boolean&gt;, default None
| Can choose to replace values other than NA. Return True for values
| that should be updated
| raise_conflict : bool
| If True, will raise an error if a DataFrame and other both
| contain data in the same place.
|
| var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)
| Return unbiased variance over requested axis.
|
| Normalized by N-1 by default. This can be changed using the ddof argument
|
| 【参数】
| ----------| axis : {items (0), major_axis (1), minor_axis (2)}
| skipna : boolean, default True
| Exclude NA/null values. If an entire row/column is NA, the result
| will be NA
| level : int or level name, default None
| If the axis is a MultiIndex (hierarchical), count along a
| particular level, collapsing into a DataFrame
| ddof : int, default 1
| degrees of freedom
| numeric_only : boolean, default None
| Include only float, int, boolean data. If None, will attempt to use
| everything, then use only numeric data
|
| 【返回值】
| -------| var : DataFrame or Panel (if level specified)
|
| xs(self, key, axis=1, copy=None)
939
| Return slice of panel along selected axis
|
| 【参数】
| ----------| key : object
| Label
| axis : {&#39;items&#39;, &#39;major&#39;, &#39;minor}, default 1/&#39;major&#39;
| copy : boolean [deprecated]
| Whether to make a copy of the data
|
| 【返回值】
| -------| y : ndim(self)-1
|
| 【注意】
| -----| xs is only for getting, not setting values.
|
| MultiIndex Slicers is a generic way to get/set values on any level or levels
| it is a superset of xs functionality, see :ref:</code>MultiIndex Slicers <advanced.mi_slicers><code>|
| ----------------------------------------------------------------------| Class methods inherited from Panel:
|
| fromDict = from_dict(data, intersect=False, orient=&#39;items&#39;, dtype=None) from builtins.type
| Construct Panel from dict of DataFrame objects
|
| 【参数】
| ----------| data : dict
| {field : DataFrame}
| intersect : boolean
| Intersect indexes of input DataFrames
| orient : {&#39;items&#39;, &#39;minor&#39;}, default &#39;items&#39;
| The &quot;orientation&quot; of the data. If the keys of the passed dict
| should be the items of the result panel, pass &#39;items&#39;
| (default). Otherwise if the columns of the values of the passed
| DataFrame objects should be the items (which in the case of
| mixed-dtype data you should do), instead pass &#39;minor&#39;
| dtype : dtype, default None
| Data type to force, otherwise infer
|
| 【返回值】
| -------| Panel
|
| from_dict(data, intersect=False, orient=&#39;items&#39;, dtype=None) from builtins.type
| Construct Panel from dict of DataFrame objects
|
| 【参数】
| ----------| data : dict
| {field : DataFrame}
| intersect : boolean
| Intersect indexes of input DataFrames
| orient : {&#39;items&#39;, &#39;minor&#39;}, default &#39;items&#39;
| The &quot;orientation&quot; of the data. If the keys of the passed dict
940
| should be the items of the result panel, pass &#39;items&#39;
| (default). Otherwise if the columns of the values of the passed
| DataFrame objects should be the items (which in the case of
| mixed-dtype data you should do), instead pass &#39;minor&#39;
| dtype : dtype, default None
| Data type to force, otherwise infer
|
| 【返回值】
| -------| Panel
|
| ----------------------------------------------------------------------| Data descriptors inherited from Panel:
|
| items
|
| major_axis
|
| minor_axis
|
| ----------------------------------------------------------------------| Methods inherited from pandas.core.generic.NDFrame:
|
| __abs__(self)
|
| __array__(self, dtype=None)
|
| __array_wrap__(self, result, context=None)
|
| __bool__ = __nonzero__(self)
|
| __contains__(self, key)
| True if the key is in the info axis
|
| __delitem__(self, key)
| Delete item
|
| __finalize__(self, other, method=None, **kwargs)
| propagate metadata from other to self
|
| 【参数】
| ----------| other : the object from which to get the attributes that we are going
| to propagate
| method : optional, a passed method name ; possibly to take different
| types of propagation actions based on this
|
| __getattr__(self, name)
| After regular attribute access, try looking up the name
| This allows simpler access to columns for interactive use.
|
| __getstate__(self)
|
| __hash__(self)
| Return hash(self).
|
| __invert__(self)
941
|
| __iter__(self)
| Iterate over infor axis
|
| __len__(self)
| Returns length of info axis
|
| __neg__(self)
|
| __nonzero__(self)
|
| __setattr__(self, name, value)
| After regular attribute access, try setting the name
| This allows simpler access to columns for interactive use.
|
| __setstate__(self, state)
|
| abs(self)
| Return an object with absolute value taken. Only applicable to objects
| that are all numeric
|
| 【返回值】
| -------| abs: type of caller
|
| add_prefix(self, prefix)
| Concatenate prefix string with panel items names.
|
| 【参数】
| ----------| prefix : string
|
| 【返回值】
| -------| with_prefix : type of caller
|
| add_suffix(self, suffix)
| Concatenate suffix string with panel items names
|
| 【参数】
| ----------| suffix : string
|
| 【返回值】
| -------| with_suffix : type of caller
|
| as_blocks(self, copy=True)
| Convert the frame to a dict of dtype -&gt; Constructor Types that each has
| a homogeneous dtype.
|
| NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in
| as_matrix)
|
| 【参数】
| ----------| copy : boolean, default True
942
|
| .. versionadded: 0.16.1
|
| 【返回值】
| -------| values : a dict of dtype -&gt; Constructor Types
|
| asfreq(self, freq, method=None, how=None, normalize=False)
| Convert all TimeSeries inside to specified frequency using DateOffset
| objects. Optionally provide fill method to pad/backfill missing values.
|
| 【参数】
| ----------| freq : DateOffset object, or string
| method : {&#39;backfill&#39;, &#39;bfill&#39;, &#39;pad&#39;, &#39;ffill&#39;, None}
| Method to use for filling holes in reindexed Series
| pad / ffill: propagate last valid observation forward to next valid
| backfill / bfill: use NEXT valid observation to fill method
| how : {&#39;start&#39;, &#39;end&#39;}, default end
| For PeriodIndex only, see PeriodIndex.asfreq
| normalize : bool, default False
| Whether to reset output index to midnight
|
| 【返回值】
| -------| converted : type of caller
|
| astype(self, dtype, copy=True, raise_on_error=True, **kwargs)
| Cast object to input numpy.dtype
| Return a copy when copy = True (be really careful with this!)
|
| 【参数】
| ----------| dtype : numpy.dtype or Python type
| raise_on_error : raise on invalid input
| kwargs : keyword arguments to pass on to the constructor
|
| 【返回值】
| -------| casted : type of caller
|
| at_time(self, time, asof=False)
| Select values at particular time of day (e.g. 9:30AM)
|
| 【参数】
| ----------| time : datetime.time or string
|
| 【返回值】
| -------| values_at_time : type of caller
|
| between_time(self, start_time, end_time, include_start=True, include_end=True)
| Select values between particular times of the day (e.g., 9:00-9:30 AM)
|
| 【参数】
943
| ----------| start_time : datetime.time or string
| end_time : datetime.time or string
| include_start : boolean, default True
| include_end : boolean, default True
|
| 【返回值】
| -------| values_between_time : type of caller
|
| bfill(self, axis=None, inplace=False, limit=None, downcast=None)
| Synonym for NDFrame.fillna(method=&#39;bfill&#39;)
|
| bool(self)
| Return the bool of a single element PandasObject
| This must be a boolean scalar value, either True or False
|
| Raise a ValueError if the PandasObject does not have exactly
| 1 element, or that element is not boolean
|
| clip(self, lower=None, upper=None, out=None, axis=None)
| Trim values at input threshold(s)
|
| 【参数】
| ----------| lower : float or array_like, default None
| upper : float or array_like, default None
| axis : int or string axis name, optional
| Align object with lower and upper along the given axis.
|
| 【返回值】
| -------| clipped : Series
|
| 【示例】
| --------| &gt;&gt;&gt; df
| 0 1
| 0 0.335232 -1.256177
| 1 -1.367855 0.746646
| 2 0.027753 -1.176076
| 3 0.230930 -0.679613
| 4 1.261967 0.570967
| &gt;&gt;&gt; df.clip(-1.0, 0.5)
| 0 1
| 0 0.335232 -1.000000
| 1 -1.000000 0.500000
| 2 0.027753 -1.000000
| 3 0.230930 -0.679613
| 4 0.500000 0.500000
| &gt;&gt;&gt; t
| 0 -0.3
| 1 -0.2
| 2 -0.1
| 3 0.0
| 4 0.1
| dtype: float64
944
| &gt;&gt;&gt; df.clip(t, t + 1, axis=0)
| 0 1
| 0 0.335232 -0.300000
| 1 -0.200000 0.746646
| 2 0.027753 -0.100000
| 3 0.230930 0.000000
| 4 1.100000 0.570967
|
| clip_lower(self, threshold, axis=None)
| Return copy of the input with values below given value(s) truncated
|
| 【参数】
| ----------| threshold : float or array_like
| axis : int or string axis name, optional
| Align object with threshold along the given axis.
|
| 【参见】
| --------| clip
|
| 【返回值】
| -------| clipped : same type as input
|
| clip_upper(self, threshold, axis=None)
| Return copy of input with values above given value(s) truncated
|
| 【参数】
| ----------| threshold : float or array_like
| axis : int or string axis name, optional
| Align object with threshold along the given axis.
|
| 【参见】
| --------| clip
|
| 【返回值】
| -------| clipped : same type as input
|
| consolidate(self, inplace=False)
| Compute NDFrame with &quot;consolidated&quot; internals (data of each dtype
| grouped together in a single ndarray). Mainly an internal API function,
| but available here to the savvy user
|
| 【参数】
| ----------| inplace : boolean, default False
| If False return new object, otherwise modify existing object
|
| 【返回值】
| -------| consolidated : type of caller
|
945
| convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)
| Attempt to infer better dtype for object columns
|
| 【参数】
| ----------| convert_dates : boolean, default True
| If True, convert to date where possible. If &#39;coerce&#39;, force
| conversion, with unconvertible values becoming NaT.
| convert_numeric : boolean, default False
| If True, attempt to coerce to numbers (including strings), with
| unconvertible values becoming NaN.
| convert_timedeltas : boolean, default True
| If True, convert to timedelta where possible. If &#39;coerce&#39;, force
| conversion, with unconvertible values becoming NaT.
| copy : boolean, default True
| If True, return a copy even if no copy is necessary (e.g. no
| conversion was done). Note: This is meant for internal use, and
| should not be confused with inplace.
|
| 【返回值】
| -------| converted : same as input object
|
| copy(self, deep=True)
| Make a copy of this object
|
| 【参数】
| ----------| deep : boolean or string, default True
| Make a deep copy, i.e. also copy data
|
| 【返回值】
| -------| copy : type of caller
|
| describe(self, percentiles=None, include=None, exclude=None)
| Generate various summary statistics, excluding NaN values.
|
| 【参数】
| ----------| percentiles : array-like, optional
| The percentiles to include in the output. Should all
| be in the interval [0, 1]. By default</code>percentiles<code>is
| [.25, .5, .75], returning the 25th, 50th, and 75th percentiles.
| include, exclude : list-like, &#39;all&#39;, or None (default)
| Specify the form of the returned result. Either:
|
| - None to both (default). The result will include only numeric-typed
| columns or, if none are, only categorical columns.
| - A list of dtypes or strings to be included/excluded.
| To select all numeric types use numpy numpy.number. To select
| categorical objects use type object. 参见：the select_dtypes
| documentation. eg. df.describe(include=[&#39;O&#39;])
| - If include is the string &#39;all&#39;, the output column-set will
| match the input one.
|
| 【返回值】
946
| -------| summary: NDFrame of summary statistics
|
| 【注意】
| -----| The output DataFrame index depends on the requested dtypes:
|
| For numeric dtypes, it will include: count, mean, std, min,
| max, and lower, 50, and upper percentiles.
|
| For object dtypes (e.g. timestamps or strings), the index
| will include the count, unique, most common, and frequency of the
| most common. Timestamps also include the first and last items.
|
| For mixed dtypes, the index will be the union of the corresponding
| output types. Non-applicable entries will be filled with NaN.
| Note that mixed-dtype outputs can only be returned from mixed-dtype
| inputs and appropriate use of the include/exclude arguments.
|
| If multiple values have the highest count, then the
|</code>count<code>and</code>most common<code>pair will be arbitrarily chosen from
| among those with the highest count.
|
| The include, exclude arguments are ignored for Series.
|
| 【参见】
| --------| DataFrame.select_dtypes
|
| drop(self, labels, axis=0, level=None, inplace=False, errors=&#39;raise&#39;)
| Return new object with labels in requested axis removed
|
| 【参数】
| ----------| labels : single label or list-like
| axis : int or axis name
| level : int or level name, default None
| For MultiIndex
| inplace : bool, default False
| If True, do operation inplace and return None.
| errors : {&#39;ignore&#39;, &#39;raise&#39;}, default &#39;raise&#39;
| If &#39;ignore&#39;, suppress error and existing labels are dropped.
|
| .. versionadded:: 0.16.1
|
| 【返回值】
| -------| dropped : type of caller
|
| equals(self, other)
| Determines if two NDFrame objects contain the same elements. NaNs in the
| same location are considered equal.
|
| ffill(self, axis=None, inplace=False, limit=None, downcast=None)
| Synonym for NDFrame.fillna(method=&#39;ffill&#39;)
|
| filter(self, items=None, like=None, regex=None, axis=None)
947
| Restrict the info axis to set of items or wildcard
|
| 【参数】
| ----------| items : list-like
| List of info axis to restrict to (must not all be present)
| like : string
| Keep info axis where &quot;arg in col == True&quot;
| regex : string (regular expression)
| Keep info axis with re.search(regex, col) == True
| axis : int or None
| The axis to filter on. By default this is the info axis. The &quot;info
| axis&quot; is the axis that is used when indexing with ``[]``. For
| example, ``df = DataFrame({&#39;a&#39;: [1, 2, 3, 4]]}); df[&#39;a&#39;]``. So,
| the ``DataFrame`` columns are the info axis.
|
| 【注意】
| -----| Arguments are mutually exclusive, but this is not checked for
|
| first(self, offset)
| Convenience method for subsetting initial periods of time series data
| based on a date offset
|
| 【参数】
| ----------| offset : string, DateOffset, dateutil.relativedelta
|
| 【示例】
| --------| ts.last(&#39;10D&#39;) -&gt; First 10 days
|
| 【返回值】
| -------| subset : type of caller
|
| get(self, key, default=None)
| Get item from object for given key (DataFrame column, Panel slice,
| etc.). Returns default value if not found
|
| 【参数】
| ----------| key : object
|
| 【返回值】
| -------| value : type of items contained in object
|
| get_dtype_counts(self)
| Return the counts of dtypes in this object
|
| get_ftype_counts(self)
| Return the counts of ftypes in this object
|
| get_values(self)
| same as values (but handles sparseness conversions)
|
948
| interpolate(self, method=&#39;linear&#39;, axis=0, limit=None, inplace=False, limit_direction=&#39;forward&#39;, downcast=None, **kwargs)
| Interpolate values according to different methods.
|
| Please note that only ``method=&#39;linear&#39;`` is supported for DataFrames/Series
| with a MultiIndex.
|
| 【参数】
| ----------| method : {&#39;linear&#39;, &#39;time&#39;, &#39;index&#39;, &#39;values&#39;, &#39;nearest&#39;, &#39;zero&#39;,
| &#39;slinear&#39;, &#39;quadratic&#39;, &#39;cubic&#39;, &#39;barycentric&#39;, &#39;krogh&#39;,
| &#39;polynomial&#39;, &#39;spline&#39; &#39;piecewise_polynomial&#39;, &#39;pchip&#39;}
|
| * &#39;linear&#39;: ignore the index and treat the values as equally
| spaced. This is the only method supported on MultiIndexes.
| default
| * &#39;time&#39;: interpolation works on daily and higher resolution
| data to interpolate given length of interval
| * &#39;index&#39;, &#39;values&#39;: use the actual numerical values of the index
| * &#39;nearest&#39;, &#39;zero&#39;, &#39;slinear&#39;, &#39;quadratic&#39;, &#39;cubic&#39;,
| &#39;barycentric&#39;, &#39;polynomial&#39; is passed to
| ``scipy.interpolate.interp1d``. Both &#39;polynomial&#39; and &#39;spline&#39;
| require that you also specify an</code>order<code>(int),
| e.g. df.interpolate(method=&#39;polynomial&#39;, order=4).
| These use the actual numerical values of the index.
| * &#39;krogh&#39;, &#39;piecewise_polynomial&#39;, &#39;spline&#39;, and &#39;pchip&#39; are all
| wrappers around the scipy interpolation methods of similar
| names. These use the actual numerical values of the index. See
| the scipy documentation for more on their behavior
|</code>here <a href="http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation" target="_blank" rel="external">http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation</a><code>__
|</code>and here <a href="http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html" target="_blank" rel="external">http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html</a><code>__
|
| axis : {0, 1}, default 0
| * 0: fill column-by-column
| * 1: fill row-by-row
| limit : int, default None.
| Maximum number of consecutive NaNs to fill.
| limit_direction : {&#39;forward&#39;, &#39;backward&#39;, &#39;both&#39;}, defaults to &#39;forward&#39;
| If limit is specified, consecutive NaNs will be filled in this
| direction.
|
| .. versionadded:: 0.17.0
|
| inplace : bool, default False
| Update the NDFrame in place if possible.
| downcast : optional, &#39;infer&#39; or None, defaults to None
| Downcast dtypes if possible.
| kwargs : keyword arguments to pass on to the interpolating function.
|
| 【返回值】
| -------| Series or DataFrame of same shape interpolated at the NaNs
|
| 【参见】
| --------| reindex, replace, fillna
|
| 【示例】
949
| --------|
| Filling in NaNs
|
| &gt;&gt;&gt; s = pd.Series([0, 1, np.nan, 3])
| &gt;&gt;&gt; s.interpolate()
| 0 0
| 1 1
| 2 2
| 3 3
| dtype: float64
|
| isnull(self)
| Return a boolean same-sized object indicating if the values are null
|
| 【参见】
| --------| notnull : boolean inverse of isnull
|
| iteritems(self)
| Iterate over (label, values) on info axis
|
| This is index for Series, columns for DataFrame, major_axis for Panel,
| and so on.
|
| iterkv(self, *args, **kwargs)
| iteritems alias used to get around 2to3. Deprecated
|
| keys(self)
| Get the &#39;info axis&#39; (see Indexing for more)
|
| This is index for Series, columns for DataFrame and major_axis for
| Panel.
|
| last(self, offset)
| Convenience method for subsetting final periods of time series data
| based on a date offset
|
| 【参数】
| ----------| offset : string, DateOffset, dateutil.relativedelta
|
| 【示例】
| --------| ts.last(&#39;5M&#39;) -&gt; Last 5 months
|
| 【返回值】
| -------| subset : type of caller
|
| mask(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)
| Return an object of same shape as self and whose corresponding
| entries are from self where cond is False and otherwise are from other.
|
| 【参数】
| ----------| cond : boolean NDFrame or array
950
| other : scalar or NDFrame
| inplace : boolean, default False
| Whether to perform the operation in place on the data
| axis : alignment axis if needed, default None
| level : alignment level if needed, default None
| try_cast : boolean, default False
| try to cast the result back to the input type (if possible),
| raise_on_error : boolean, default True
| Whether to raise on invalid data types (e.g. trying to where on
| strings)
|
| 【返回值】
| -------| wh : same type as caller
|
| notnull(self)
| Return a boolean same-sized object indicating if the values are
| not null
|
| 【参见】
| --------| isnull : boolean inverse of notnull
|
| pct_change(self, periods=1, fill_method=&#39;pad&#39;, limit=None, freq=None, **kwargs)
| Percent change over given number of periods.
|
| 【参数】
| ----------| periods : int, default 1
| Periods to shift for forming percent change
| fill_method : str, default &#39;pad&#39;
| How to handle NAs before computing percent changes
| limit : int, default None
| The number of consecutive NAs to fill before stopping
| freq : DateOffset, timedelta, or offset alias string, optional
| Increment to use from time series API (e.g. &#39;M&#39; or BDay())
|
| 【返回值】
| -------| chg : NDFrame
|
| 【注意】
| -----|
| By default, the percentage change is calculated along the stat
| axis: 0, or ``Index``, for ``DataFrame`` and 1, or ``minor`` for
| ``Panel``. You can change this with the ``axis`` keyword argument.
|
| pipe(self, func, *args, **kwargs)
| Apply func(self, \*args, \*\*kwargs)
|
| .. versionadded:: 0.16.2
|
| 【参数】
| ----------| func : function
| function to apply to the NDFrame.
951
| ``args``, and ``kwargs`` are passed into ``func``.
| Alternatively a ``(callable, data_keyword)`` tuple where
| ``data_keyword`` is a string indicating the keyword of
| ``callable`` that expects the NDFrame.
| args : positional arguments passed into ``func``.
| kwargs : a dictionary of keyword arguments passed into ``func``.
|
| 【返回值】
| -------| object : the return type of ``func``.
|
| 【注意】
| -----|
| Use ``.pipe`` when chaining together functions that expect
| on Series or DataFrames. Instead of writing
|
| &gt;&gt;&gt; f(g(h(df), arg1=a), arg2=b, arg3=c)
|
| You can write
|
| &gt;&gt;&gt; (df.pipe(h)
| ... .pipe(g, arg1=a)
| ... .pipe(f, arg2=b, arg3=c)
| ... )
|
| If you have a function that takes the data as (say) the second
| argument, pass a tuple indicating which keyword expects the
| data. For example, suppose ``f`` takes its data as ``arg2``:
|
| &gt;&gt;&gt; (df.pipe(h)
| ... .pipe(g, arg1=a)
| ... .pipe((f, &#39;arg2&#39;), arg1=a, arg3=c)
| ... )
|
| 【参见】
| --------| pandas.DataFrame.apply
| pandas.DataFrame.applymap
| pandas.Series.map
|
| pop(self, item)
| Return item and drop from frame. Raise KeyError if not found.
|
| reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)
| return an object with matching indicies to myself
|
| 【参数】
| ----------| other : Object
| method : string or None
| copy : boolean, default True
| limit : int, default None
| Maximum number of consecutive labels to fill for inexact matches.
| tolerance : optional
| Maximum distance between labels of the other object and this
| object for inexact matches.
952
|
| .. versionadded:: 0.17.0
|
| 【注意】
| -----| Like calling s.reindex(index=other.index, columns=other.columns,
| method=...)
|
| 【返回值】
| -------| reindexed : same as input
|
| rename_axis(self, mapper, axis=0, copy=True, inplace=False)
| Alter index and / or columns using input function or functions.
| Function / dict values must be unique (1-to-1). Labels not contained in
| a dict / Series will be left as-is.
|
| 【参数】
| ----------| mapper : dict-like or function, optional
| axis : int or string, default 0
| copy : boolean, default True
| Also copy underlying data
| inplace : boolean, default False
|
| 【返回值】
| -------| renamed : type of caller
|
| replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method=&#39;pad&#39;, axis=None)
| Replace values given in &#39;to_replace&#39; with &#39;value&#39;.
|
| 【参数】
| ----------| to_replace : str, regex, list, dict, Series, numeric, or None
|
| * str or regex:
|
| - str: string exactly matching</code>to_replace<code>will be replaced
| with</code>value<code>| - regex: regexs matching</code>to_replace<code>will be replaced with
|</code>value<code>|
| * list of str, regex, or numeric:
|
| - First, if</code>to_replace<code>and</code>value<code>are both lists, they
| **must** be the same length.
| - Second, if ``regex=True`` then all of the strings in **both**
| lists will be interpreted as regexs otherwise they will match
| directly. This doesn&#39;t matter much for</code>value<code>since there
| are only a few possible substitution regexes you can use.
| - str and regex rules apply as above.
|
| * dict:
|
| - Nested dictionaries, e.g., {&#39;a&#39;: {&#39;b&#39;: nan}}, are read as
| follows: look in column &#39;a&#39; for the value &#39;b&#39; and replace it
953
| with nan. You can nest regular expressions as well. Note that
| column names (the top-level dictionary keys in a nested
| dictionary) **cannot** be regular expressions.
| - Keys map to column names and values map to substitution
| values. You can treat this as a special case of passing two
| lists except that you are specifying the column to search in.
|
| * None:
|
| - This means that the ``regex`` argument must be a string,
| compiled regular expression, or list, dict, ndarray or Series
| of such elements. If</code>value<code>is also ``None`` then this
| **must** be a nested dictionary or ``Series``.
|
| See the examples section for examples of each of these.
| value : scalar, dict, list, str, regex, default None
| Value to use to fill holes (e.g. 0), alternately a dict of values
| specifying which value to use for each column (columns not in the
| dict will not be filled). Regular expressions, strings and lists or
| dicts of such objects are also allowed.
| inplace : boolean, default False
| If True, in place. Note: this will modify any
| other views on this object (e.g. a column form a DataFrame).
| Returns the caller if this is True.
| limit : int, default None
| Maximum size gap to forward or backward fill
| regex : bool or same types as</code>to_replace<code>, default False
| Whether to interpret</code>to_replace<code>and/or</code>value<code>as regular
| expressions. If this is ``True`` then</code>to_replace<code>*must* be a
| string. Otherwise,</code>to_replace<code>must be ``None`` because this
| parameter will be interpreted as a regular expression or a list,
| dict, or array of regular expressions.
| method : string, optional, {&#39;pad&#39;, &#39;ffill&#39;, &#39;bfill&#39;}
| The method to use when for replacement, when ``to_replace`` is a
| ``list``.
|
| 【参见】
| --------| NDFrame.reindex
| NDFrame.asfreq
| NDFrame.fillna
|
| 【返回值】
| -------| filled : NDFrame
|
| 【Raises 引发错误】
| ------| AssertionError
| * If</code>regex<code>is not a ``bool`` and</code>to_replace<code>is not ``None``.
| TypeError
| * If</code>to_replace<code>is a ``dict`` and</code>value<code>is not a ``list``,
| ``dict``, ``ndarray``, or ``Series``
| * If</code>to_replace<code>is ``None`` and</code>regex<code>is not compilable into a
| regular expression or is a list, dict, ndarray, or Series.
| ValueError
| * If</code>to_replace<code>and</code>value<code>are ``list`` s or ``ndarray`` s, but
954
| they are not the same length.
|
| 【注意】
| -----| * Regex substitution is performed under the hood with ``re.sub``. The
| rules for substitution for ``re.sub`` are the same.
| * Regular expressions will only substitute on strings, meaning you
| cannot provide, for example, a regular expression matching floating
| point numbers and expect the columns in your frame that have a
| numeric dtype to be matched. However, if those floating point numbers
| *are* strings, then you can do this.
| * This method has *a lot* of options. You are encouraged to experiment
| and play with this method to gain intuition about how it works.
|
| resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention=&#39;start&#39;, kind=None,
loffset=None, limit=None, base=0)
| Convenience method for frequency conversion and resampling of regular
| time-series data.
|
| 【参数】
| ----------| rule : string
| the offset string or object representing target conversion
| how : string
| method for down- or re-sampling, default to &#39;mean&#39; for
| downsampling
| axis : int, optional, default 0
| fill_method : string, default None
| fill_method for upsampling
| closed : {&#39;right&#39;, &#39;left&#39;}
| Which side of bin interval is closed
| label : {&#39;right&#39;, &#39;left&#39;}
| Which bin edge label to label bucket with
| convention : {&#39;start&#39;, &#39;end&#39;, &#39;s&#39;, &#39;e&#39;}
| kind : &quot;period&quot;/&quot;timestamp&quot;
| loffset : timedelta
| Adjust the resampled time labels
| limit : int, default None
| Maximum size gap to when reindexing with fill_method
| base : int, default 0
| For frequencies that evenly subdivide 1 day, the &quot;origin&quot; of the
| aggregated intervals. For example, for &#39;5min&#39; frequency, base could
| range from 0 through 4. Defaults to 0
|
|
| 【示例】
| --------|
| Start by creating a series with 9 one minute timestamps.
|
| &gt;&gt;&gt; index = pd.date_range(&#39;1/1/2000&#39;, periods=9, freq=&#39;T&#39;)
| &gt;&gt;&gt; series = pd.Series(range(9), index=index)
| &gt;&gt;&gt; series
| 2000-01-01 00:00:00 0
| 2000-01-01 00:01:00 1
| 2000-01-01 00:02:00 2
| 2000-01-01 00:03:00 3
955
| 2000-01-01 00:04:00 4
| 2000-01-01 00:05:00 5
| 2000-01-01 00:06:00 6
| 2000-01-01 00:07:00 7
| 2000-01-01 00:08:00 8
| Freq: T, dtype: int64
|
| Downsample the series into 3 minute bins and sum the values
| of the timestamps falling into a bin.
|
| &gt;&gt;&gt; series.resample(&#39;3T&#39;, how=&#39;sum&#39;)
| 2000-01-01 00:00:00 3
| 2000-01-01 00:03:00 12
| 2000-01-01 00:06:00 21
| Freq: 3T, dtype: int64
|
| Downsample the series into 3 minute bins as above, but label each
| bin using the right edge instead of the left. Please note that the
| value in the bucket used as the label is not included in the bucket,
| which it labels. For example, in the original series the
| bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed
| value in the resampled bucket with the label``2000-01-01 00:03:00``
| does not include 3 (if it did, the summed value would be 6, not 3).
| To include this value close the right side of the bin interval as
| illustrated in the example below this one.
|
| &gt;&gt;&gt; series.resample(&#39;3T&#39;, how=&#39;sum&#39;, label=&#39;right&#39;)
| 2000-01-01 00:03:00 3
| 2000-01-01 00:06:00 12
| 2000-01-01 00:09:00 21
| Freq: 3T, dtype: int64
|
| Downsample the series into 3 minute bins as above, but close the right
| side of the bin interval.
|
| &gt;&gt;&gt; series.resample(&#39;3T&#39;, how=&#39;sum&#39;, label=&#39;right&#39;, closed=&#39;right&#39;)
| 2000-01-01 00:00:00 0
| 2000-01-01 00:03:00 6
| 2000-01-01 00:06:00 15
| 2000-01-01 00:09:00 15
| Freq: 3T, dtype: int64
|
| Upsample the series into 30 second bins.
|
| &gt;&gt;&gt; series.resample(&#39;30S&#39;)[0:5] #select first 5 rows
| 2000-01-01 00:00:00 0
| 2000-01-01 00:00:30 NaN
| 2000-01-01 00:01:00 1
| 2000-01-01 00:01:30 NaN
| 2000-01-01 00:02:00 2
| Freq: 30S, dtype: float64
|
| Upsample the series into 30 second bins and fill the ``NaN``
| values using the ``pad`` method.
|
| &gt;&gt;&gt; series.resample(&#39;30S&#39;, fill_method=&#39;pad&#39;)[0:5]
| 2000-01-01 00:00:00 0
956
| 2000-01-01 00:00:30 0
| 2000-01-01 00:01:00 1
| 2000-01-01 00:01:30 1
| 2000-01-01 00:02:00 2
| Freq: 30S, dtype: int64
|
| Upsample the series into 30 second bins and fill the
| ``NaN`` values using the ``bfill`` method.
|
| &gt;&gt;&gt; series.resample(&#39;30S&#39;, fill_method=&#39;bfill&#39;)[0:5]
| 2000-01-01 00:00:00 0
| 2000-01-01 00:00:30 1
| 2000-01-01 00:01:00 1
| 2000-01-01 00:01:30 2
| 2000-01-01 00:02:00 2
| Freq: 30S, dtype: int64
|
| Pass a custom function to ``how``.
|
| &gt;&gt;&gt; def custom_resampler(array_like):
| ... return np.sum(array_like)+5
|
| &gt;&gt;&gt; series.resample(&#39;3T&#39;, how=custom_resampler)
| 2000-01-01 00:00:00 8
| 2000-01-01 00:03:00 17
| 2000-01-01 00:06:00 26
| Freq: 3T, dtype: int64
|
| sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)
| Returns a random sample of items from an axis of object.
|
| .. versionadded:: 0.16.1
|
| 【参数】
| ----------| n : int, optional
| Number of items from axis to return. Cannot be used with</code>frac<code>.
| Default = 1 if</code>frac<code>= None.
| frac : float, optional
| Fraction of axis items to return. Cannot be used with</code>n<code>.
| replace : boolean, optional
| Sample with or without replacement. Default = False.
| weights : str or ndarray-like, optional
| Default &#39;None&#39; results in equal probability weighting.
| If passed a Series, will align with target object on index. Index
| values in weights not found in sampled object will be ignored and
| index values in sampled object not in weights will be assigned
| weights of zero.
| If called on a DataFrame, will accept the name of a column
| when axis = 0.
| Unless weights are a Series, weights must be same length as axis
| being sampled.
| If weights do not sum to 1, they will be normalized to sum to 1.
| Missing values in the weights column will be treated as zero.
| inf and -inf values not allowed.
| random_state : int or numpy.random.RandomState, optional
| Seed for the random number generator (if int), or numpy RandomState
957
| object.
| axis : int or string, optional
| Axis to sample. Accepts axis number or name. Default is stat axis
| for given data type (0 for Series and DataFrames, 1 for Panels).
|
| 【返回值】
| -------| A new object of same type as caller.
|
| select(self, crit, axis=0)
| Return data corresponding to axis labels matching criteria
|
| 【参数】
| ----------| crit : function
| To be called on each index (label). Should return True or False
| axis : int
|
| 【返回值】
| -------| selection : type of caller
|
| set_axis(self, axis, labels)
| public verson of axis assignment
|
| slice_shift(self, periods=1, axis=0)
| Equivalent to</code>shift<code>without copying data. The shifted data will
| not include the dropped periods and the shifted axis will be smaller
| than the original.
|
| 【参数】
| ----------| periods : int
| Number of periods to move, can be positive or negative
|
| 【注意】
| -----| While the</code>slice_shift<code>is faster than</code>shift<code>, you may pay for it
| later during alignment.
|
| 【返回值】
| -------| shifted : same type as caller
|
| sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind=&#39;quicksort&#39;, na_position=&#39;last&#39;,
sort_remaining=True)
| Sort object by labels (along an axis)
|
| 【参数】
| ----------| axis : axes to direct sorting
| level : int or level name or list of ints or list of level names
| if not None, sort on values in specified index level(s)
| ascending : boolean, default True
| Sort ascending vs. descending
| inplace : bool
| if True, perform operation in-place
958
| kind : {</code>quicksort<code>,</code>mergesort<code>,</code>heapsort<code>}
| Choice of sorting algorithm. 参见：ndarray.np.sort for more information.
|</code>mergesort<code>is the only stable algorithm. For DataFrames, this option is
| only applied when sorting on a single column or label.
| na_position : {&#39;first&#39;, &#39;last&#39;}
|</code>first<code>puts NaNs at the beginning,</code>last<code>puts NaNs at the end
| sort_remaining : bool
| if true and sorting by level and index is multilevel, sort by other levels
| too (in order) after sorting by specified level
|
| 【返回值】
| -------| sorted_obj : NDFrame
|
| sort_values(self, by, axis=0, ascending=True, inplace=False, kind=&#39;quicksort&#39;, na_position=&#39;last&#39;)
|
| squeeze(self)
| squeeze length 1 dimensions
|
| swapaxes(self, axis1, axis2, copy=True)
| Interchange axes and swap values axes appropriately
|
| 【返回值】
| -------| y : same as input
|
| swaplevel(self, i, j, axis=0)
| Swap levels i and j in a MultiIndex on a particular axis
|
| 【参数】
| ----------| i, j : int, string (can be mixed)
| Level of index to be swapped. Can pass level name as string.
|
| 【返回值】
| -------| swapped : type of caller (new object)
|
| take(self, indices, axis=0, convert=True, is_copy=True)
| Analogous to ndarray.take
|
| 【参数】
| ----------| indices : list / array of ints
| axis : int, default 0
| convert : translate neg to pos indices (default)
| is_copy : mark the returned frame as a copy
|
| 【返回值】
| -------| taken : type of caller
|
| to_clipboard(self, excel=None, sep=None, **kwargs)
| Attempt to write text representation of object to the system clipboard
| This can be pasted into Excel, for example.
|
959
| 【参数】
| ----------| excel : boolean, defaults to True
| if True, use the provided separator, writing in a csv
| format for allowing easy pasting into excel.
| if False, write a string representation of the object
| to the clipboard
| sep : optional, defaults to tab
| other keywords are passed to to_csv
|
| 【注意】
| -----| Requirements for your platform
| - Linux: xclip, or xsel (with gtk or PyQt4 modules)
| - Windows: none
| - OS X: none
|
| to_dense(self)
| Return dense representation of NDFrame (as opposed to sparse)
|
| to_hdf(self, path_or_buf, key, **kwargs)
| activate the HDFStore
|
| 【参数】
| ----------| path_or_buf : the path (string) or HDFStore object
| key : string
| indentifier for the group in the store
| mode : optional, {&#39;a&#39;, &#39;w&#39;, &#39;r&#39;, &#39;r+&#39;}, default &#39;a&#39;
|
| ``&#39;r&#39;``
| Read-only; no data can be modified.
| ``&#39;w&#39;``
| Write; a new file is created (an existing file with the same
| name would be deleted).
| ``&#39;a&#39;``
| Append; an existing file is opened for reading and writing,
| and if the file does not exist it is created.
| ``&#39;r+&#39;``
| It is similar to ``&#39;a&#39;``, but the file must already exist.
| format : &#39;fixed(f)|table(t)&#39;, default is &#39;fixed&#39;
| fixed(f) : Fixed format
| Fast writing/reading. Not-appendable, nor searchable
| table(t) : Table format
| Write as a PyTables Table structure which may perform
| worse but allow more flexible operations like searching
| / selecting subsets of the data
| append : boolean, default False
| For Table formats, append the input data to the existing
| complevel : int, 1-9, default 0
| If a complib is specified compression will be applied
| where possible
| complib : {&#39;zlib&#39;, &#39;bzip2&#39;, &#39;lzo&#39;, &#39;blosc&#39;, None}, default None
| If complevel is &gt; 0 apply compression to objects written
| in the store wherever possible
| fletcher32 : bool, default False
| If applying compression use the fletcher32 checksum
960
| dropna : boolean, default False.
| If true, ALL nan rows will not be written to store.
|
| to_json(self, path_or_buf=None, orient=None, date_format=&#39;epoch&#39;, double_precision=10, force_ascii=True, date_unit=&#39;ms&#39;,
default_handler=None)
| Convert the object to a JSON string.
|
| Note NaN&#39;s and None will be converted to null and datetime objects
| will be converted to UNIX timestamps.
|
| 【参数】
| ----------| path_or_buf : the path or buffer to write the result string
| if this is None, return a StringIO of the converted string
| orient : string
|
| * Series
|
| - default is &#39;index&#39;
| - allowed values are: {&#39;split&#39;,&#39;records&#39;,&#39;index&#39;}
|
| * DataFrame
|
| - default is &#39;columns&#39;
| - allowed values are:
| {&#39;split&#39;,&#39;records&#39;,&#39;index&#39;,&#39;columns&#39;,&#39;values&#39;}
|
| * The format of the JSON string
|
| - split : dict like
| {index -&gt; [index], columns -&gt; [columns], data -&gt; [values]}
| - records : list like
| [{column -&gt; value}, ... , {column -&gt; value}]
| - index : dict like {index -&gt; {column -&gt; value}}
| - columns : dict like {column -&gt; {index -&gt; value}}
| - values : just the values array
|
| date_format : {&#39;epoch&#39;, &#39;iso&#39;}
| Type of date conversion.</code>epoch<code>= epoch milliseconds,
|</code>iso<code>= ISO8601, default is epoch.
| double_precision : The number of decimal places to use when encoding
| floating point values, default 10.
| force_ascii : force encoded string to be ASCII, default True.
| date_unit : string, default &#39;ms&#39; (milliseconds)
| The time unit to encode to, governs timestamp and ISO8601
| precision. One of &#39;s&#39;, &#39;ms&#39;, &#39;us&#39;, &#39;ns&#39; for second, millisecond,
| microsecond, and nanosecond respectively.
| default_handler : callable, default None
| Handler to call if object cannot otherwise be converted to a
| suitable format for JSON. Should receive a single argument which is
| the object to convert and return a serialisable object.
|
| 【返回值】
| -------| same type as input object with filtered info axis
|
| to_msgpack(self, path_or_buf=None, **kwargs)
961
| msgpack (serialize) object to input file path
|
| THIS IS AN EXPERIMENTAL LIBRARY and the storage format
| may not be stable until a future release.
|
| 【参数】
| ----------| path : string File path, buffer-like, or None
| if None, return generated string
| append : boolean whether to append to an existing msgpack
| (default is False)
| compress : type of compressor (zlib or blosc), default to None (no
| compression)
|
| to_pickle(self, path)
| Pickle (serialize) object to input file path
|
| 【参数】
| ----------| path : string
| File path
|
| to_sql(self, name, con, flavor=&#39;sqlite&#39;, schema=None, if_exists=&#39;fail&#39;, index=True, index_label=None, chunksize=None,
dtype=None)
| Write records stored in a DataFrame to a SQL database.
|
| 【参数】
| ----------| name : string
| Name of SQL table
| con : SQLAlchemy engine or DBAPI2 connection (legacy mode)
| Using SQLAlchemy makes it possible to use any DB supported by that
| library.
| If a DBAPI2 object, only sqlite3 is supported.
| flavor : {&#39;sqlite&#39;, &#39;mysql&#39;}, default &#39;sqlite&#39;
| The flavor of SQL to use. Ignored when using SQLAlchemy engine.
| &#39;mysql&#39; is deprecated and will be removed in future versions, but it
| will be further supported through SQLAlchemy engines.
| schema : string, default None
| Specify the schema (if database flavor supports this). If None, use
| default schema.
| if_exists : {&#39;fail&#39;, &#39;replace&#39;, &#39;append&#39;}, default &#39;fail&#39;
| - fail: If table exists, do nothing.
| - replace: If table exists, drop it, recreate it, and insert data.
| - append: If table exists, insert data. Create if does not exist.
| index : boolean, default True
| Write DataFrame index as a column.
| index_label : string or sequence, default None
| Column label for index column(s). If None is given (default) and
| `index` is True, then the index names are used.
| A sequence should be given if the DataFrame uses MultiIndex.
| chunksize : int, default None
| If not None, then rows will be written in batches of this size at a
| time. If None, all rows will be written at once.
| dtype : dict of column name to SQL type, default None
| Optional specifying the datatype for columns. The SQL type should
| be a SQLAlchemy type, or a string for sqlite3 fallback connection.
962
|
| truncate(self, before=None, after=None, axis=None, copy=True)
| Truncates a sorted NDFrame before and/or after some particular
| dates.
|
| 【参数】
| ----------| before : date
| Truncate before date
| after : date
| Truncate after date
| axis : the truncation axis, defaults to the stat axis
| copy : boolean, default is True,
| return a copy of the truncated section
|
| 【返回值】
| -------| truncated : type of caller
|
| tz_convert(self, tz, axis=0, level=None, copy=True)
| Convert tz-aware axis to target time zone.
|
| 【参数】
| ----------| tz : string or pytz.timezone object
| axis : the axis to convert
| level : int, str, default None
| If axis ia a MultiIndex, convert a specific level. Otherwise
| must be None
| copy : boolean, default True
| Also make a copy of the underlying data
|
| 【返回值】
| -------|
| 【Raises 引发错误】
| ------| TypeError
| If the axis is tz-naive.
|
| tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous=&#39;raise&#39;)
| Localize tz-naive TimeSeries to target time zone
|
| 【参数】
| ----------| tz : string or pytz.timezone object
| axis : the axis to localize
| level : int, str, default None
| If axis ia a MultiIndex, localize a specific level. Otherwise
| must be None
| copy : boolean, default True
| Also make a copy of the underlying data
| ambiguous : &#39;infer&#39;, bool-ndarray, &#39;NaT&#39;, default &#39;raise&#39;
| - &#39;infer&#39; will attempt to infer fall dst-transition hours based on order
| - bool-ndarray where True signifies a DST time, False designates
| a non-DST time (note that this flag is only applicable for ambiguous times)
| - &#39;NaT&#39; will return NaT where there are ambiguous times
963
| - &#39;raise&#39; will raise an AmbiguousTimeError if there are ambiguous times
| infer_dst : boolean, default False (DEPRECATED)
| Attempt to infer fall dst-transition hours based on order
|
| 【返回值】
| -------|
| 【Raises 引发错误】
| ------| TypeError
| If the TimeSeries is tz-aware and tz is not None.
|
| where(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)
| Return an object of same shape as self and whose corresponding
| entries are from self where cond is True and otherwise are from other.
|
| 【参数】
| ----------| cond : boolean NDFrame or array
| other : scalar or NDFrame
| inplace : boolean, default False
| Whether to perform the operation in place on the data
| axis : alignment axis if needed, default None
| level : alignment level if needed, default None
| try_cast : boolean, default False
| try to cast the result back to the input type (if possible),
| raise_on_error : boolean, default True
| Whether to raise on invalid data types (e.g. trying to where on
| strings)
|
| 【返回值】
| -------| wh : same type as caller
|
| ----------------------------------------------------------------------| Data descriptors inherited from pandas.core.generic.NDFrame:
|
| at
| Fast label-based scalar accessor
|
| Similarly to</code>loc<code>,</code>at<code>provides **label** based scalar lookups.
| You can also set using these indexers.
|
| axes
| Return index label(s) of the internal NDFrame
|
| blocks
| Internal property, property synonym for as_blocks()
|
| dtypes
| Return the dtypes in this object
|
| empty
| True if NDFrame is entirely empty [no items]
|
| ftypes
| Return the ftypes (indication of sparse/dense and dtype)
964
| in this object.
|
| iat
| Fast integer location scalar accessor.
|
| Similarly to</code>iloc<code>,</code>iat<code>provides **integer** based lookups.
| You can also set using these indexers.
|
| iloc
| Purely integer-location based indexing for selection by position.
|
|</code>.iloc[]<code>is primarily integer position based (from</code>0<code>to
|</code>length-1<code>of the axis), but may also be used with a boolean
| array.
|
| Allowed inputs are:
|
| - An integer, e.g.</code>5<code>.
| - A list or array of integers, e.g.</code>[4, 3, 0]<code>.
| - A slice object with ints, e.g.</code>1:7<code>.
| - A boolean array.
|
|</code>.iloc<code>will raise</code>IndexError<code>if a requested indexer is
| out-of-bounds, except *slice* indexers which allow out-of-bounds
| indexing (this conforms with python/numpy *slice* semantics).
|
| See more at :ref:`Selection by Position &lt;indexing.integer&gt;`
|
| ix
| A primarily label-location based indexer, with integer position
| fallback.
|
|</code>.ix[]<code>supports mixed integer and label based access. It is
| primarily label based, but will fall back to integer positional
| access unless the corresponding axis is of integer type.
|
|</code>.ix<code>is the most general indexer and will support any of the
| inputs in</code>.loc<code>and</code>.iloc<code>.</code>.ix<code>also supports floating
| point label schemes.</code>.ix<code>is exceptionally useful when dealing
| with mixed positional and label based hierachical indexes.
|
| However, when an axis is integer based, ONLY label based access
| and not positional access is supported. Thus, in such cases, it&#39;s
| usually better to be explicit and use</code>.iloc<code>or</code>.loc<code>.
|
| See more at :ref:`Advanced Indexing &lt;advanced&gt;`.
|
| loc
| Purely label-location based indexer for selection by label.
|
|</code>.loc[]<code>is primarily label based, but may also be used with a
| boolean array.
|
| Allowed inputs are:
|
| - A single label, e.g.</code>5<code>or</code>‘a’<code>, (note that</code>5<code>is
| interpreted as a *label* of the index, and **never** as an
965
| integer position along the index).
| - A list or array of labels, e.g.</code>[‘a’, ‘b’, ‘c’]<code>.
| - A slice object with labels, e.g.</code>‘a’:’f’<code>(note that contrary
| to usual python slices, **both** the start and the stop are included!).
| - A boolean array.
|
|</code>.loc<code>will raise a</code>KeyError<code>` when the items are not found.
|
| See more at :ref:</code>Selection by Label <indexing.label>`<br>|<br>| ndim<br>| Number of axes / array dimensions<br>|<br>| shape<br>| Return a tuple of axis dimensions<br>|<br>| size<br>| number of elements in the NDFrame<br>|<br>| values<br>| Numpy representation of NDFrame<br>|<br>| 【注意】<br>| —–| The dtype will be a lower-common-denominator dtype (implicit<br>| upcasting); that is to say if the dtypes (even of numeric types)<br>| are mixed, the one that accommodates all will be chosen. Use this<br>| with care if you are not dealing with the blocks.<br>|<br>| e.g. If the dtypes are float16 and float32, dtype will be upcast to<br>| float32. If dtypes are int32 and uint8, dtype will be upcase to<br>| int32.<br>|<br>| ———————————————————————-| Data and other attributes inherited from pandas.core.generic.NDFrame:<br>|<br>| is_copy = None<br>|<br>| ———————————————————————-| Methods inherited from pandas.core.base.PandasObject:<br>|<br>| <strong>dir</strong>(self)<br>| Provide method name lookup and completion<br>| Only provide ‘public’ methods<br>|<br>| ———————————————————————-| Methods inherited from pandas.core.base.StringMixin:<br>|<br>| <strong>bytes</strong>(self)<br>| Return a string representation for a particular object.<br>|<br>| Invoked by bytes(obj) in py3 only.<br>| Yields a bytestring in both py2/py3.<br>|<br>| <strong>repr</strong>(self)<br>| Return a string representation for a particular object.<br>|<br>966<br>| Yields Bytestring in Py2, Unicode String in py3.<br>|<br>| <strong>str</strong>(self)<br>| Return a string representation for a particular Object<br>|<br>| Invoked by str(df) in both py2/py3.<br>| Yields Bytestring in Py2, Unicode String in py3.<br>|<br>| ———————————————————————-| Data descriptors inherited from pandas.core.base.StringMixin:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br><strong>builtins</strong><br>dict object:<br>类定义：dict(object)<br>| dict() -&gt; new empty dictionary<br>| dict(mapping) -&gt; new dictionary initialized from a mapping object’s<br>| (key, value) pairs<br>| dict(iterable) -&gt; new dictionary initialized as if via:<br>| d = {}<br>| for k, v in iterable:<br>| d[k] = v<br>| dict(<strong>kwargs) -&gt; new dictionary initialized with the name=value pairs<br>| in the keyword argument list. For example: dict(one=1, two=2)<br>|<br>| 【方法定义】<br>|<br>| <strong>contains</strong>(self, key, /)<br>| True if D has a key k, else False.<br>|<br>| <strong>delitem</strong>(self, key, /)<br>| Delete self[key].<br>|<br>| <strong>eq</strong>(self, value, /)<br>| Return self==value.<br>|<br>| <strong>ge</strong>(self, value, /)<br>| Return self&gt;=value.<br>|<br>| <strong>getattribute</strong>(self, name, /)<br>| Return getattr(self, name).<br>|<br>| <strong>getitem</strong>(…)<br>967<br>| x.<strong>getitem</strong>(y) &lt;==&gt; x[y]<br>|<br>| <strong>gt</strong>(self, value, /)<br>| Return self&gt;value.<br>|<br>| <strong>init</strong>(self, /, *args, </strong>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>iter</strong>(self, /)<br>| Implement iter(self).<br>|<br>| <strong>le</strong>(self, value, /)<br>| Return self&lt;=value.<br>|<br>| <strong>len</strong>(self, /)<br>| Return len(self).<br>|<br>| <strong>lt</strong>(self, value, /)<br>| Return self<value. |="" __ne__(self,="" value,="" )="" return="" self!="value." __new__(*args,="" **kwargs)="" from="" builtins.type="" create="" and="" a="" new="" object.="" see="" help(type)="" for="" accurate="" signature.="" __repr__(self,="" repr(self).="" __setitem__(self,="" key,="" set="" self[key]="" to="" value.="" __sizeof__(...)="" d.__sizeof__()="" -=""> size of D in memory, in bytes<br>|<br>| clear(…)<br>| D.clear() -&gt; None. Remove all items from D.<br>|<br>| copy(…)<br>| D.copy() -&gt; a shallow copy of D<br>|<br>| fromkeys(iterable, value=None, /) from builtins.type<br>| Returns a new dict with keys from iterable and values equal to value.<br>|<br>| get(…)<br>| D.get(k[,d]) -&gt; D[k] if k in D, else d. d defaults to None.<br>|<br>| items(…)<br>| D.items() -&gt; a set-like object providing a view on D’s items<br>|<br>| keys(…)<br>| D.keys() -&gt; a set-like object providing a view on D’s keys<br>|<br>| pop(…)<br>| D.pop(k[,d]) -&gt; v, remove specified key and return the corresponding value.<br>| If key is not found, d is returned if given, otherwise KeyError is raised<br>|<br>968<br>| popitem(…)<br>| D.popitem() -&gt; (k, v), remove and return some (key, value) pair as a<br>| 2-tuple; but raise KeyError if D is empty.<br>|<br>| setdefault(…)<br>| D.setdefault(k[,d]) -&gt; D.get(k,d), also set D[k]=d if k not in D<br>|<br>| update(…)<br>| D.update([E, ]<strong>F) -&gt; None. Update D from dict/iterable E and F.<br>| If E is present and has a .keys() method, then does: for k in E: D[k] = E[k]<br>| If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v<br>| In either case, this is followed by: for k in F: D[k] = F[k]<br>|<br>| values(…)<br>| D.values() -&gt; an object providing a view on D’s values<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| <strong>hash</strong> = None<br><strong>cached</strong><br>没有找到说明文档： \pandas__pycache<strong>\</strong>init<strong>.cpython-35.pyc’.
</strong>doc<strong><br>没有找到说明文档：
</strong>docformat<strong><br>没有找到说明文档： ‘restructuredtext’.<br>969
</strong>file<strong><br>没有找到说明文档： \pandas\</strong>init<strong>.py’.
</strong>loader<strong><br>SourceFileLoader in module importlib._bootstrap_external object:<br>类定义：SourceFileLoader(FileLoader, SourceLoader)<br>| Concrete implementation of SourceLoader using the file system.<br>|<br>| 【方法排序】<br>| SourceFileLoader<br>| FileLoader<br>| SourceLoader<br>| _LoaderBasics<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| path_stats(self, path)<br>| Return the metadata for the path.<br>|<br>| set_data(self, path, data, *, _mode=438)<br>| Write bytes data to a file.<br>|<br>| ———————————————————————-| Methods inherited from FileLoader:<br>|<br>| </strong>eq<strong>(self, other)<br>| Return self==value.<br>|<br>| </strong>hash<strong>(self)<br>| Return hash(self).<br>|<br>| </strong>init__(self, fullname, path)<br>| Cache the module name and the path to the file found by the<br>| finder.<br>|<br>| get_data(self, path)<br>| Return the data from path as raw bytes.<br>|<br>| get_filename(self, name=None, *args, </strong>kwargs)<br>| Return the path to the source file as found by the finder.<br>|<br>970<br>| load_module(self, name=None, <em>args, **kwargs)<br>| Load a module from a file.<br>|<br>| This method is deprecated. Use exec_module() instead.<br>|<br>| ———————————————————————-| Data descriptors inherited from FileLoader:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| ———————————————————————-| Methods inherited from SourceLoader:<br>|<br>| get_code(self, fullname)<br>| Concrete implementation of InspectLoader.get_code.<br>|<br>| Reading of bytecode requires path_stats to be implemented. To write<br>| bytecode, set_data must also be implemented.<br>|<br>| get_source(self, fullname)<br>| Concrete implementation of InspectLoader.get_source.<br>|<br>| path_mtime(self, path)<br>| Optional method that returns the modification time (an int) for the<br>| specified path, where path is a str.<br>|<br>| Raises IOError when the path cannot be handled.<br>|<br>| source_to_code(self, data, path, </em>, _optimize=-1)<br>| Return the code object compiled from source.<br>|<br>| The ‘data’ argument can be any object type that compile() supports.<br>|<br>| ———————————————————————-| Methods inherited from _LoaderBasics:<br>|<br>| create_module(self, spec)<br>| Use default semantics for module creation.<br>|<br>| exec_module(self, module)<br>| Execute the module.<br>|<br>| is_package(self, fullname)<br>| Concrete implementation of InspectLoader.is_package by checking if<br>| the path returned by get_filename has a filename of ‘<strong>init</strong>.py’.<br><strong>name</strong><br>971<br>package pandas:<br>【名称】<br>pandas<br>【说明】</value.></indexing.label></advanced.mi_slicers></advanced.mi_slicers></advanced.mi_slicers></indexing.label></advanced></indexing.integer></advanced.mi_slicers></class></class></class></class></indexing.label></advanced></indexing.integer></advanced.mi_slicers></advanced.mi_slicers></indexing.label></advanced></indexing.integer></boolean></module></stdin></indexing.label></advanced></indexing.integer></boolean></advanced.mi_slicers></advanced.mi_slicers></advanced.mi_slicers></indexing.label></advanced></indexing.integer></advanced.mi_slicers></boolean></p>
<h1 id="pandas-a-powerful-data-analysis-and-manipulation-library-for-Python"><a href="#pandas-a-powerful-data-analysis-and-manipulation-library-for-Python" class="headerlink" title="pandas - a powerful data analysis and manipulation library for Python"></a>pandas - a powerful data analysis and manipulation library for Python</h1><p>See <a href="http://pandas.pydata.org/" target="_blank" rel="external">http://pandas.pydata.org/</a> for full documentation. Otherwise, see the<br>docstrings of the various objects in the pandas namespace:<br>Series<br>DataFrame<br>Panel<br>Index<br>DatetimeIndex<br>HDFStore<br>bdate_range<br>date_range<br>read_csv<br>read_fwf<br>read_table<br>ols<br>【模块包·内容】<br>_period<br>_sparse<br>_testing<br>_version<br>algos<br>compat (package)<br>computation (package)<br>core (package)<br>hashtable<br>index<br>info<br>io (package)<br>json<br>lib<br>msgpack (package)<br>parser<br>rpy (package)<br>sandbox (package)<br>sparse (package)<br>stats (package)<br>tests (package)<br>tools (package)<br>tseries (package)<br>tslib<br>util (package)<br>【子模块】<br>datetools<br>offsets<br>972<br>【数据】<br>IndexSlice = <pandas.core.indexing._indexslice object=""><br>NaT = NaT<br><strong>docformat</strong> = ‘restructuredtext’<br><strong>warningregistry</strong> = {‘version’: 7, (r’bad escape \s’, &lt;class ‘Deprec…<br>describe_option = <pandas.core.config.callabledynamicdoc object=""><br>get_option = <pandas.core.config.callabledynamicdoc object=""><br>options = <pandas.core.config.dictwrapper object=""><br>plot_params = {‘xaxis.compat’: False}<br>reset_option = <pandas.core.config.callabledynamicdoc object=""><br>set_option = <pandas.core.config.callabledynamicdoc object=""><br>【版本】<br>0.17.1<br>【文件】 ： \pandas__init<strong>.py
</strong>package__<br>package pandas:<br>【名称】<br>pandas<br>【说明】</pandas.core.config.callabledynamicdoc></pandas.core.config.callabledynamicdoc></pandas.core.config.dictwrapper></pandas.core.config.callabledynamicdoc></pandas.core.config.callabledynamicdoc></pandas.core.indexing._indexslice></p>
<h1 id="pandas-a-powerful-data-analysis-and-manipulation-library-for-Python-1"><a href="#pandas-a-powerful-data-analysis-and-manipulation-library-for-Python-1" class="headerlink" title="pandas - a powerful data analysis and manipulation library for Python"></a>pandas - a powerful data analysis and manipulation library for Python</h1><p>See <a href="http://pandas.pydata.org/" target="_blank" rel="external">http://pandas.pydata.org/</a> for full documentation. Otherwise, see the<br>docstrings of the various objects in the pandas namespace:<br>Series<br>DataFrame<br>Panel<br>Index<br>DatetimeIndex<br>HDFStore<br>bdate_range<br>date_range<br>read_csv<br>read_fwf<br>read_table<br>ols<br>【模块包·内容】<br>_period<br>_sparse<br>_testing<br>_version<br>973<br>algos<br>compat (package)<br>computation (package)<br>core (package)<br>hashtable<br>index<br>info<br>io (package)<br>json<br>lib<br>msgpack (package)<br>parser<br>rpy (package)<br>sandbox (package)<br>sparse (package)<br>stats (package)<br>tests (package)<br>tools (package)<br>tseries (package)<br>tslib<br>util (package)<br>【子模块】<br>datetools<br>offsets<br>【数据】<br>IndexSlice = <pandas.core.indexing._indexslice object=""><br>NaT = NaT<br><strong>docformat</strong> = ‘restructuredtext’<br><strong>warningregistry</strong> = {(r’bad escape \s’, <class 'deprecationwarning'="">…<br>describe_option = <pandas.core.config.callabledynamicdoc object=""><br>get_option = <pandas.core.config.callabledynamicdoc object=""><br>options = <pandas.core.config.dictwrapper object=""><br>plot_params = {‘xaxis.compat’: False}<br>reset_option = <pandas.core.config.callabledynamicdoc object=""><br>set_option = <pandas.core.config.callabledynamicdoc object=""><br>【版本】<br>0.17.1<br>【文件】 ： \pandas__init<strong>.py
</strong>path<strong><br>list object:<br>类定义：list(object)<br>| list() -&gt; new empty list<br>974<br>| list(iterable) -&gt; new list initialized from iterable’s items<br>|<br>| 【方法定义】<br>|<br>| </strong>add<strong>(self, value, /)<br>| Return self+value.<br>|<br>| </strong>contains<strong>(self, key, /)<br>| Return key in self.<br>|<br>| </strong>delitem<strong>(self, key, /)<br>| Delete self[key].<br>|<br>| </strong>eq<strong>(self, value, /)<br>| Return self==value.<br>|<br>| </strong>ge<strong>(self, value, /)<br>| Return self&gt;=value.<br>|<br>| </strong>getattribute<strong>(self, name, /)<br>| Return getattr(self, name).<br>|<br>| </strong>getitem<strong>(…)<br>| x.</strong>getitem<strong>(y) &lt;==&gt; x[y]<br>|<br>| </strong>gt<strong>(self, value, /)<br>| Return self&gt;value.<br>|<br>| </strong>iadd<strong>(self, value, /)<br>| Implement self+=value.<br>|<br>| </strong>imul<strong>(self, value, /)<br>| Implement self*=value.<br>|<br>| </strong>init<strong>(self, /, <em>args, *</em>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| </strong>iter<strong>(self, /)<br>| Implement iter(self).<br>|<br>| </strong>le<strong>(self, value, /)<br>| Return self&lt;=value.<br>|<br>| </strong>len<strong>(self, /)<br>| Return len(self).<br>|<br>| </strong>lt<strong>(self, value, /)<br>| Return self&lt;value.<br>|<br>| </strong>mul<strong>(self, value, /)<br>| Return self*value.n<br>|<br>| </strong>ne<strong>(self, value, /)<br>| Return self!=value.<br>|<br>| </strong>new<strong>(<em>args, *</em>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>975<br>|<br>| </strong>repr<strong>(self, /)<br>| Return repr(self).<br>|<br>| </strong>reversed<strong>(…)<br>| L.</strong>reversed<strong>() – return a reverse iterator over the list<br>|<br>| </strong>rmul<strong>(self, value, /)<br>| Return self*value.<br>|<br>| </strong>setitem<strong>(self, key, value, /)<br>| Set self[key] to value.<br>|<br>| </strong>sizeof<strong>(…)<br>| L.</strong>sizeof<strong>() – size of L in memory, in bytes<br>|<br>| append(…)<br>| L.append(object) -&gt; None – append object to end<br>|<br>| clear(…)<br>| L.clear() -&gt; None – remove all items from L<br>|<br>| copy(…)<br>| L.copy() -&gt; list – a shallow copy of L<br>|<br>| count(…)<br>| L.count(value) -&gt; integer – return number of occurrences of value<br>|<br>| extend(…)<br>| L.extend(iterable) -&gt; None – extend list by appending elements from the iterable<br>|<br>| index(…)<br>| L.index(value, [start, [stop]]) -&gt; integer – return first index of value.<br>| Raises ValueError if the value is not present.<br>|<br>| insert(…)<br>| L.insert(index, object) – insert object before index<br>|<br>| pop(…)<br>| L.pop([index]) -&gt; item – remove and return item at index (default last).<br>| Raises IndexError if list is empty or index is out of range.<br>|<br>| remove(…)<br>| L.remove(value) -&gt; None – remove first occurrence of value.<br>| Raises ValueError if the value is not present.<br>|<br>| reverse(…)<br>| L.reverse() – reverse <em>IN PLACE</em><br>|<br>| sort(…)<br>| L.sort(key=None, reverse=False) -&gt; None – stable sort <em>IN PLACE</em><br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| </strong>hash<strong> = None<br>976
</strong>spec<strong><br>ModuleSpec in module importlib._bootstrap object:<br>类定义：ModuleSpec(builtins.object)<br>| The specification for a module, used for loading.<br>|<br>| A module’s spec is the source for information about the module. For<br>| data associated with the module, including source, use the spec’s<br>| loader.<br>|<br>| <code>name</code> is the absolute name of the module. <code>loader</code> is the loader<br>| to use when loading the module. <code>parent</code> is the name of the<br>| package the module is in. The parent is derived from the name.<br>|<br>| <code>is_package</code> determines if the module is considered a package or<br>| not. On modules this is reflected by the `</strong>path<strong><code>attribute.
|
|</code>origin<code>is the specific location used by the loader from which to
| load the module, if that information is available. When filename is
| set, origin will match.
|
|</code>has_location<code>indicates that a spec&#39;s &quot;origin&quot; reflects a location.
| When this is True,</code></strong>file<strong><code>attribute of the module is set.
|
|</code>cached<code>is the location of the cached bytecode file, if any. It
| corresponds to the</code></strong>cached<strong><code>attribute.
|
|</code>submodule_search_locations<code>is the sequence of path entries to
| search when importing submodules. If set, is_package should be
| True--and False otherwise.
|
| Packages are simply modules that (may) have submodules. If a spec
| has a non-None value in</code>submodule_search_locations`, the import<br>| system will consider modules loaded from the spec as packages.<br>|<br>| Only finders (see importlib.abc.MetaPathFinder and<br>| importlib.abc.PathEntryFinder) should modify ModuleSpec instances.<br>|<br>| 【方法定义】<br>|<br>| </strong>eq<strong>(self, other)<br>| Return self==value.<br>|<br>| </strong>init<strong>(self, name, loader, *, origin=None, loader_state=None, is_package=None)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| </strong>repr<strong>(self)<br>| Return repr(self).<br>|<br>977<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| </strong>dict<strong><br>| dictionary for instance variables (if defined)<br>|<br>| </strong>weakref<strong><br>| list of weak references to the object (if defined)<br>|<br>| cached<br>|<br>| has_location<br>|<br>| parent<br>| The name of the module’s parent.<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| </strong>hash<strong> = None
</strong>version<strong><br>没有找到说明文档： ‘0.17.1’.
</strong>warningregistry<strong><br>dict object:<br>类定义：dict(object)<br>| dict() -&gt; new empty dictionary<br>| dict(mapping) -&gt; new dictionary initialized from a mapping object’s<br>| (key, value) pairs<br>| dict(iterable) -&gt; new dictionary initialized as if via:<br>| d = {}<br>| for k, v in iterable:<br>| d[k] = v<br>| dict(**kwargs) -&gt; new dictionary initialized with the name=value pairs<br>| in the keyword argument list. For example: dict(one=1, two=2)<br>|<br>| 【方法定义】<br>|<br>978<br>| </strong>contains<strong>(self, key, /)<br>| True if D has a key k, else False.<br>|<br>| </strong>delitem<strong>(self, key, /)<br>| Delete self[key].<br>|<br>| </strong>eq<strong>(self, value, /)<br>| Return self==value.<br>|<br>| </strong>ge<strong>(self, value, /)<br>| Return self&gt;=value.<br>|<br>| </strong>getattribute<strong>(self, name, /)<br>| Return getattr(self, name).<br>|<br>| </strong>getitem<strong>(…)<br>| x.</strong>getitem<strong>(y) &lt;==&gt; x[y]<br>|<br>| </strong>gt<strong>(self, value, /)<br>| Return self&gt;value.<br>|<br>| </strong>init<strong>(self, /, <em>args, *</em>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| </strong>iter<strong>(self, /)<br>| Implement iter(self).<br>|<br>| </strong>le<strong>(self, value, /)<br>| Return self&lt;=value.<br>|<br>| </strong>len<strong>(self, /)<br>| Return len(self).<br>|<br>| </strong>lt<strong>(self, value, /)<br>| Return self&lt;value.<br>|<br>| </strong>ne<strong>(self, value, /)<br>| Return self!=value.<br>|<br>| </strong>new<strong>(<em>args, *</em>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| </strong>repr<strong>(self, /)<br>| Return repr(self).<br>|<br>| </strong>setitem<strong>(self, key, value, /)<br>| Set self[key] to value.<br>|<br>| </strong>sizeof<strong>(…)<br>| D.</strong>sizeof<strong>() -&gt; size of D in memory, in bytes<br>|<br>| clear(…)<br>| D.clear() -&gt; None. Remove all items from D.<br>|<br>| copy(…)<br>| D.copy() -&gt; a shallow copy of D<br>|<br>979<br>| fromkeys(iterable, value=None, /) from builtins.type<br>| Returns a new dict with keys from iterable and values equal to value.<br>|<br>| get(…)<br>| D.get(k[,d]) -&gt; D[k] if k in D, else d. d defaults to None.<br>|<br>| items(…)<br>| D.items() -&gt; a set-like object providing a view on D’s items<br>|<br>| keys(…)<br>| D.keys() -&gt; a set-like object providing a view on D’s keys<br>|<br>| pop(…)<br>| D.pop(k[,d]) -&gt; v, remove specified key and return the corresponding value.<br>| If key is not found, d is returned if given, otherwise KeyError is raised<br>|<br>| popitem(…)<br>| D.popitem() -&gt; (k, v), remove and return some (key, value) pair as a<br>| 2-tuple; but raise KeyError if D is empty.<br>|<br>| setdefault(…)<br>| D.setdefault(k[,d]) -&gt; D.get(k,d), also set D[k]=d if k not in D<br>|<br>| update(…)<br>| D.update([E, ]**F) -&gt; None. Update D from dict/iterable E and F.<br>| If E is present and has a .keys() method, then does: for k in E: D[k] = E[k]<br>| If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v<br>| In either case, this is followed by: for k in F: D[k] = F[k]<br>|<br>| values(…)<br>| D.values() -&gt; an object providing a view on D’s values<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| </strong>hash<strong> = None<br>_np_version<br>没有找到说明文档： ‘1.9.3’.<br>_np_version_under1p8<br>980<br>bool object:<br>类定义：bool(int)<br>| bool(x) -&gt; bool<br>|<br>| Returns True when the argument x is true, False otherwise.<br>| The builtins True and False are the only two instances of the class bool.<br>| The class bool is a subclass of the class int, and cannot be subclassed.<br>|<br>| 【方法排序】<br>| bool<br>| int<br>| object<br>|<br>| 【方法定义】<br>|<br>| </strong>and<strong>(self, value, /)<br>| Return self&amp;value.<br>|<br>| </strong>new<strong>(<em>args, *</em>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| </strong>or<strong>(self, value, /)<br>| Return self|value.<br>|<br>| </strong>rand<strong>(self, value, /)<br>| Return value&amp;self.<br>|<br>| </strong>repr<strong>(self, /)<br>| Return repr(self).<br>|<br>| </strong>ror<strong>(self, value, /)<br>| Return value|self.<br>|<br>| </strong>rxor<strong>(self, value, /)<br>| Return value^self.<br>|<br>| </strong>str<strong>(self, /)<br>| Return str(self).<br>|<br>| </strong>xor<strong>(self, value, /)<br>| Return self^value.<br>|<br>| ———————————————————————-| Methods inherited from int:<br>|<br>| </strong>abs<strong>(self, /)<br>| abs(self)<br>|<br>| </strong>add<strong>(self, value, /)<br>| Return self+value.<br>|<br>| </strong>bool<strong>(self, /)<br>| self != 0<br>|<br>| </strong>ceil<strong>(…)<br>| Ceiling of an Integral returns itself.<br>981<br>|<br>| </strong>divmod<strong>(self, value, /)<br>| Return divmod(self, value).<br>|<br>| </strong>eq<strong>(self, value, /)<br>| Return self==value.<br>|<br>| </strong>float<strong>(self, /)<br>| float(self)<br>|<br>| </strong>floor<strong>(…)<br>| Flooring an Integral returns itself.<br>|<br>| </strong>floordiv<strong>(self, value, /)<br>| Return self//value.<br>|<br>| </strong>format<strong>(…)<br>| default object formatter<br>|<br>| </strong>ge<strong>(self, value, /)<br>| Return self&gt;=value.<br>|<br>| </strong>getattribute<strong>(self, name, /)<br>| Return getattr(self, name).<br>|<br>| </strong>getnewargs<strong>(…)<br>|<br>| </strong>gt<strong>(self, value, /)<br>| Return self&gt;value.<br>|<br>| </strong>hash<strong>(self, /)<br>| Return hash(self).<br>|<br>| </strong>index<strong>(self, /)<br>| Return self converted to an integer, if self is suitable for use as an index into a list.<br>|<br>| </strong>int<strong>(self, /)<br>| int(self)<br>|<br>| </strong>invert<strong>(self, /)<br>| ~self<br>|<br>| </strong>le<strong>(self, value, /)<br>| Return self&lt;=value.<br>|<br>| </strong>lshift<strong>(self, value, /)<br>| Return self&lt;&lt;value.<br>|<br>| </strong>lt<strong>(self, value, /)<br>| Return self&lt;value.<br>|<br>| </strong>mod<strong>(self, value, /)<br>| Return self%value.<br>|<br>| </strong>mul<strong>(self, value, /)<br>| Return self*value.<br>|<br>982<br>| </strong>ne<strong>(self, value, /)<br>| Return self!=value.<br>|<br>| </strong>neg<strong>(self, /)<br>| -self<br>|<br>| </strong>pos<strong>(self, /)<br>| +self<br>|<br>| </strong>pow<strong>(self, value, mod=None, /)<br>| Return pow(self, value, mod).<br>|<br>| </strong>radd<strong>(self, value, /)<br>| Return value+self.<br>|<br>| </strong>rdivmod<strong>(self, value, /)<br>| Return divmod(value, self).<br>|<br>| </strong>rfloordiv<strong>(self, value, /)<br>| Return value//self.<br>|<br>| </strong>rlshift<strong>(self, value, /)<br>| Return value&lt;&lt;self.<br>|<br>| </strong>rmod<strong>(self, value, /)<br>| Return value%self.<br>|<br>| </strong>rmul<strong>(self, value, /)<br>| Return value*self.<br>|<br>| </strong>round<strong>(…)<br>| Rounding an Integral returns itself.<br>| Rounding with an ndigits argument also returns an integer.<br>|<br>| </strong>rpow<strong>(self, value, mod=None, /)<br>| Return pow(value, self, mod).<br>|<br>| </strong>rrshift<strong>(self, value, /)<br>| Return value&gt;&gt;self.<br>|<br>| </strong>rshift<strong>(self, value, /)<br>| Return self&gt;&gt;value.<br>|<br>| </strong>rsub<strong>(self, value, /)<br>| Return value-self.<br>|<br>| </strong>rtruediv<strong>(self, value, /)<br>| Return value/self.<br>|<br>| </strong>sizeof<strong>(…)<br>| Returns size in memory, in bytes<br>|<br>| </strong>sub<strong>(self, value, /)<br>| Return self-value.<br>|<br>| </strong>truediv<strong>(self, value, /)<br>| Return self/value.<br>983<br>|<br>| </strong>trunc<strong>(…)<br>| Truncating an Integral returns itself.<br>|<br>| bit_length(…)<br>| int.bit_length() -&gt; int<br>|<br>| Number of bits necessary to represent self in binary.<br>| &gt;&gt;&gt; bin(37)<br>| ‘0b100101’<br>| &gt;&gt;&gt; (37).bit_length()<br>| 6<br>|<br>| conjugate(…)<br>| Returns self, the complex conjugate of any int.<br>|<br>| from_bytes(…) from builtins.type<br>| int.from_bytes(bytes, byteorder, <em>, signed=False) -&gt; int<br>|<br>| Return the integer represented by the given array of bytes.<br>|<br>| The bytes argument must be a bytes-like object (e.g. bytes or bytearray).<br>|<br>| The byteorder argument determines the byte order used to represent the<br>| integer. If byteorder is ‘big’, the most significant byte is at the<br>| beginning of the byte array. If byteorder is ‘little’, the most<br>| significant byte is at the end of the byte array. To request the native<br>| byte order of the host system, use `sys.byteorder’ as the byte order value.<br>|<br>| The signed keyword-only argument indicates whether two’s complement is<br>| used to represent the integer.<br>|<br>| to_bytes(…)<br>| int.to_bytes(length, byteorder, </em>, signed=False) -&gt; bytes<br>|<br>| Return an array of bytes representing an integer.<br>|<br>| The integer is represented using length bytes. An OverflowError is<br>| raised if the integer is not representable with the given number of<br>| bytes.<br>|<br>| The byteorder argument determines the byte order used to represent the<br>| integer. If byteorder is ‘big’, the most significant byte is at the<br>| beginning of the byte array. If byteorder is ‘little’, the most<br>| significant byte is at the end of the byte array. To request the native<br>| byte order of the host system, use `sys.byteorder’ as the byte order value.<br>|<br>| The signed keyword-only argument determines whether two’s complement is<br>| used to represent the integer. If signed is False and a negative integer<br>| is given, an OverflowError is raised.<br>|<br>| ———————————————————————-| Data descriptors inherited from int:<br>|<br>| denominator<br>| the denominator of a rational number in lowest terms<br>|<br>984<br>| imag<br>| the imaginary part of a complex number<br>|<br>| numerator<br>| the numerator of a rational number in lowest terms<br>|<br>| real<br>| the real part of a complex number<br>_np_version_under1p9<br>bool object:<br>类定义：bool(int)<br>| bool(x) -&gt; bool<br>|<br>| Returns True when the argument x is true, False otherwise.<br>| The builtins True and False are the only two instances of the class bool.<br>| The class bool is a subclass of the class int, and cannot be subclassed.<br>|<br>| 【方法排序】<br>| bool<br>| int<br>| object<br>|<br>| 【方法定义】<br>|<br>| </strong>and<strong>(self, value, /)<br>| Return self&amp;value.<br>|<br>| </strong>new<strong>(<em>args, *</em>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| </strong>or<strong>(self, value, /)<br>| Return self|value.<br>|<br>| </strong>rand<strong>(self, value, /)<br>| Return value&amp;self.<br>|<br>| </strong>repr<strong>(self, /)<br>| Return repr(self).<br>|<br>| </strong>ror<strong>(self, value, /)<br>| Return value|self.<br>|<br>| </strong>rxor<strong>(self, value, /)<br>| Return value^self.<br>|<br>| </strong>str<strong>(self, /)<br>| Return str(self).<br>985<br>|<br>| </strong>xor<strong>(self, value, /)<br>| Return self^value.<br>|<br>| ———————————————————————-| Methods inherited from int:<br>|<br>| </strong>abs<strong>(self, /)<br>| abs(self)<br>|<br>| </strong>add<strong>(self, value, /)<br>| Return self+value.<br>|<br>| </strong>bool<strong>(self, /)<br>| self != 0<br>|<br>| </strong>ceil<strong>(…)<br>| Ceiling of an Integral returns itself.<br>|<br>| </strong>divmod<strong>(self, value, /)<br>| Return divmod(self, value).<br>|<br>| </strong>eq<strong>(self, value, /)<br>| Return self==value.<br>|<br>| </strong>float<strong>(self, /)<br>| float(self)<br>|<br>| </strong>floor<strong>(…)<br>| Flooring an Integral returns itself.<br>|<br>| </strong>floordiv<strong>(self, value, /)<br>| Return self//value.<br>|<br>| </strong>format<strong>(…)<br>| default object formatter<br>|<br>| </strong>ge<strong>(self, value, /)<br>| Return self&gt;=value.<br>|<br>| </strong>getattribute<strong>(self, name, /)<br>| Return getattr(self, name).<br>|<br>| </strong>getnewargs<strong>(…)<br>|<br>| </strong>gt<strong>(self, value, /)<br>| Return self&gt;value.<br>|<br>| </strong>hash<strong>(self, /)<br>| Return hash(self).<br>|<br>| </strong>index<strong>(self, /)<br>| Return self converted to an integer, if self is suitable for use as an index into a list.<br>|<br>| </strong>int<strong>(self, /)<br>| int(self)<br>|<br>986<br>| </strong>invert<strong>(self, /)<br>| ~self<br>|<br>| </strong>le<strong>(self, value, /)<br>| Return self&lt;=value.<br>|<br>| </strong>lshift<strong>(self, value, /)<br>| Return self&lt;&lt;value.<br>|<br>| </strong>lt<strong>(self, value, /)<br>| Return self&lt;value.<br>|<br>| </strong>mod<strong>(self, value, /)<br>| Return self%value.<br>|<br>| </strong>mul<strong>(self, value, /)<br>| Return self*value.<br>|<br>| </strong>ne<strong>(self, value, /)<br>| Return self!=value.<br>|<br>| </strong>neg<strong>(self, /)<br>| -self<br>|<br>| </strong>pos<strong>(self, /)<br>| +self<br>|<br>| </strong>pow<strong>(self, value, mod=None, /)<br>| Return pow(self, value, mod).<br>|<br>| </strong>radd<strong>(self, value, /)<br>| Return value+self.<br>|<br>| </strong>rdivmod<strong>(self, value, /)<br>| Return divmod(value, self).<br>|<br>| </strong>rfloordiv<strong>(self, value, /)<br>| Return value//self.<br>|<br>| </strong>rlshift<strong>(self, value, /)<br>| Return value&lt;&lt;self.<br>|<br>| </strong>rmod<strong>(self, value, /)<br>| Return value%self.<br>|<br>| </strong>rmul<strong>(self, value, /)<br>| Return value*self.<br>|<br>| </strong>round<strong>(…)<br>| Rounding an Integral returns itself.<br>| Rounding with an ndigits argument also returns an integer.<br>|<br>| </strong>rpow<strong>(self, value, mod=None, /)<br>| Return pow(value, self, mod).<br>|<br>| </strong>rrshift<strong>(self, value, /)<br>| Return value&gt;&gt;self.<br>987<br>|<br>| </strong>rshift<strong>(self, value, /)<br>| Return self&gt;&gt;value.<br>|<br>| </strong>rsub<strong>(self, value, /)<br>| Return value-self.<br>|<br>| </strong>rtruediv<strong>(self, value, /)<br>| Return value/self.<br>|<br>| </strong>sizeof<strong>(…)<br>| Returns size in memory, in bytes<br>|<br>| </strong>sub<strong>(self, value, /)<br>| Return self-value.<br>|<br>| </strong>truediv<strong>(self, value, /)<br>| Return self/value.<br>|<br>| </strong>trunc<strong>(…)<br>| Truncating an Integral returns itself.<br>|<br>| bit_length(…)<br>| int.bit_length() -&gt; int<br>|<br>| Number of bits necessary to represent self in binary.<br>| &gt;&gt;&gt; bin(37)<br>| ‘0b100101’<br>| &gt;&gt;&gt; (37).bit_length()<br>| 6<br>|<br>| conjugate(…)<br>| Returns self, the complex conjugate of any int.<br>|<br>| from_bytes(…) from builtins.type<br>| int.from_bytes(bytes, byteorder, <em>, signed=False) -&gt; int<br>|<br>| Return the integer represented by the given array of bytes.<br>|<br>| The bytes argument must be a bytes-like object (e.g. bytes or bytearray).<br>|<br>| The byteorder argument determines the byte order used to represent the<br>| integer. If byteorder is ‘big’, the most significant byte is at the<br>| beginning of the byte array. If byteorder is ‘little’, the most<br>| significant byte is at the end of the byte array. To request the native<br>| byte order of the host system, use `sys.byteorder’ as the byte order value.<br>|<br>| The signed keyword-only argument indicates whether two’s complement is<br>| used to represent the integer.<br>|<br>| to_bytes(…)<br>| int.to_bytes(length, byteorder, </em>, signed=False) -&gt; bytes<br>|<br>| Return an array of bytes representing an integer.<br>|<br>| The integer is represented using length bytes. An OverflowError is<br>| raised if the integer is not representable with the given number of<br>988<br>| bytes.<br>|<br>| The byteorder argument determines the byte order used to represent the<br>| integer. If byteorder is ‘big’, the most significant byte is at the<br>| beginning of the byte array. If byteorder is ‘little’, the most<br>| significant byte is at the end of the byte array. To request the native<br>| byte order of the host system, use `sys.byteorder’ as the byte order value.<br>|<br>| The signed keyword-only argument determines whether two’s complement is<br>| used to represent the integer. If signed is False and a negative integer<br>| is given, an OverflowError is raised.<br>|<br>| ———————————————————————-| Data descriptors inherited from int:<br>|<br>| denominator<br>| the denominator of a rational number in lowest terms<br>|<br>| imag<br>| the imaginary part of a complex number<br>|<br>| numerator<br>| the numerator of a rational number in lowest terms<br>|<br>| real<br>| the real part of a complex number<br>_period<br>所属模块：pandas._period in pandas:<br>【名称】<br>pandas._period<br>【类型】<br>【内置对象】<br>Period<br>class Period(builtins.object)<br>| Represents an period of time<br>|<br>| 【参数】<br>| ———-| value : Period or compat.string_types, default None<br>| The time period represented (e.g., ‘4Q2005’)<br>| freq : str, default None<br>| One of pandas period strings or corresponding objects<br>| year : int, default None<br>| month : int, default 1<br>| quarter : int, default None<br>989<br>| day : int, default 1<br>| hour : int, default 0<br>| minute : int, default 0<br>| second : int, default 0<br>|<br>| 【方法定义】<br>|<br>| </strong>add<strong>(self, value, /)<br>| Return self+value.<br>|<br>| </strong>eq<strong>(self, value, /)<br>| Return self==value.<br>|<br>| </strong>ge<strong>(self, value, /)<br>| Return self&gt;=value.<br>|<br>| </strong>gt<strong>(self, value, /)<br>| Return self&gt;value.<br>|<br>| </strong>hash<strong>(self, /)<br>| Return hash(self).<br>|<br>| </strong>init<strong>(self, /, <em>args, *</em>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| </strong>le<strong>(self, value, /)<br>| Return self&lt;=value.<br>|<br>| </strong>lt<strong>(self, value, /)<br>| Return self&lt;value.<br>|<br>| </strong>ne<strong>(self, value, /)<br>| Return self!=value.<br>|<br>| </strong>new<strong>(<em>args, *</em>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| </strong>radd<strong>(self, value, /)<br>| Return value+self.<br>|<br>| </strong>reduce<strong>(…)<br>| helper for pickle<br>|<br>| </strong>repr<strong>(self, /)<br>| Return repr(self).<br>|<br>| </strong>rsub<strong>(self, value, /)<br>| Return value-self.<br>|<br>| </strong>setstate<strong>(…)<br>|<br>| </strong>str<strong>(self, /)<br>| Return str(self).<br>|<br>| </strong>sub<strong>(self, value, /)<br>| Return self-value.<br>|<br>990<br>| </strong>unicode<strong>(…)<br>| Return a string representation for a particular DataFrame<br>|<br>| Invoked by unicode(df) in py2 only. Yields a Unicode String in both<br>| py2/py3.<br>|<br>| asfreq(…)<br>| Convert Period to desired frequency, either at the start or end of the<br>| interval<br>|<br>| 【参数】<br>| ———-| freq : string<br>| how : {‘E’, ‘S’, ‘end’, ‘start’}, default ‘end’<br>| Start or end of the timespan<br>|<br>| 【返回值】<br>| ——-| resampled : Period<br>|<br>| now(…) from builtins.type<br>|<br>| strftime(…)<br>| Returns the string representation of the :class:<code>Period</code>, depending<br>| on the selected :keyword:<code>format</code>. :keyword:<code>format</code> must be a string<br>| containing one or several directives. The method recognizes the same<br>| directives as the :func:<code>time.strftime</code> function of the standard Python<br>| distribution, as well as the specific additional directives <code>%f</code>,<br>| <code>%F</code>, <code>%q</code>. (formatting &amp; docs originally from scikits.timeries)<br>|<br>| +———–+——————————–+——-+<br>| | Directive | Meaning | Notes |<br>| +===========+================================+=======+<br>| | <code>%a</code> | Locale’s abbreviated weekday | |<br>| | | name. | |<br>| +———–+——————————–+——-+<br>| | <code>%A</code> | Locale’s full weekday name. | |<br>| +———–+——————————–+——-+<br>| | <code>%b</code> | Locale’s abbreviated month | |<br>| | | name. | |<br>| +———–+——————————–+——-+<br>| | <code>%B</code> | Locale’s full month name. | |<br>| +———–+——————————–+——-+<br>| | <code>%c</code> | Locale’s appropriate date and | |<br>| | | time representation. | |<br>| +———–+——————————–+——-+<br>| | <code>%d</code> | Day of the month as a decimal | |<br>| | | number [01,31]. | |<br>| +———–+——————————–+——-+<br>| | <code>%f</code> | ‘Fiscal’ year without a | (1) |<br>| | | century as a decimal number | |<br>| | | [00,99] | |<br>| +———–+——————————–+——-+<br>| | <code>%F</code> | ‘Fiscal’ year with a century | (2) |<br>| | | as a decimal number | |<br>| +———–+——————————–+——-+<br>| | <code>%H</code> | Hour (24-hour clock) as a | |<br>991<br>| | | decimal number [00,23]. | |<br>| +———–+——————————–+——-+<br>| | <code>%I</code> | Hour (12-hour clock) as a | |<br>| | | decimal number [01,12]. | |<br>| +———–+——————————–+——-+<br>| | <code>%j</code> | Day of the year as a decimal | |<br>| | | number [001,366]. | |<br>| +———–+——————————–+——-+<br>| | <code>%m</code> | Month as a decimal number | |<br>| | | [01,12]. | |<br>| +———–+——————————–+——-+<br>| | <code>%M</code> | Minute as a decimal number | |<br>| | | [00,59]. | |<br>| +———–+——————————–+——-+<br>| | <code>%p</code> | Locale’s equivalent of either | (3) |<br>| | | AM or PM. | |<br>| +———–+——————————–+——-+<br>| | <code>%q</code> | Quarter as a decimal number | |<br>| | | [01,04] | |<br>| +———–+——————————–+——-+<br>| | <code>%S</code> | Second as a decimal number | (4) |<br>| | | [00,61]. | |<br>| +———–+——————————–+——-+<br>| | <code>%U</code> | Week number of the year | (5) |<br>| | | (Sunday as the first day of | |<br>| | | the week) as a decimal number | |<br>| | | [00,53]. All days in a new | |<br>| | | year preceding the first | |<br>| | | Sunday are considered to be in | |<br>| | | week 0. | |<br>| +———–+——————————–+——-+<br>| | <code>%w</code> | Weekday as a decimal number | |<br>| | | [0(Sunday),6]. | |<br>| +———–+——————————–+——-+<br>| | <code>%W</code> | Week number of the year | (5) |<br>| | | (Monday as the first day of | |<br>| | | the week) as a decimal number | |<br>| | | [00,53]. All days in a new | |<br>| | | year preceding the first | |<br>| | | Monday are considered to be in | |<br>| | | week 0. | |<br>| +———–+——————————–+——-+<br>| | <code>%x</code> | Locale’s appropriate date | |<br>| | | representation. | |<br>| +———–+——————————–+——-+<br>| | <code>%X</code> | Locale’s appropriate time | |<br>| | | representation. | |<br>| +———–+——————————–+——-+<br>| | <code>%y</code> | Year without century as a | |<br>| | | decimal number [00,99]. | |<br>| +———–+——————————–+——-+<br>| | <code>%Y</code> | Year with century as a decimal | |<br>| | | number. | |<br>| +———–+——————————–+——-+<br>| | <code>%Z</code> | Time zone name (no characters | |<br>| | | if no time zone exists). | |<br>| +———–+——————————–+——-+<br>992<br>| | <code>%%</code> | A literal <code>&#39;%&#39;</code> character. | |<br>| +———–+——————————–+——-+<br>|<br>| .. note::<br>|<br>| (1)<br>| The <code>%f</code> directive is the same as <code>%y</code> if the frequency is<br>| not quarterly.<br>| Otherwise, it corresponds to the ‘fiscal’ year, as defined by<br>| the :attr:<code>qyear</code> attribute.<br>|<br>| (2)<br>| The <code>%F</code> directive is the same as <code>%Y</code> if the frequency is<br>| not quarterly.<br>| Otherwise, it corresponds to the ‘fiscal’ year, as defined by<br>| the :attr:<code>qyear</code> attribute.<br>|<br>| (3)<br>| The <code>%p</code> directive only affects the output hour field<br>| if the <code>%I</code> directive is used to parse the hour.<br>|<br>| (4)<br>| The range really is <code>0</code> to <code>61</code>; this accounts for leap<br>| seconds and the (very rare) double leap seconds.<br>|<br>| (5)<br>| The <code>%U</code> and <code>%W</code> directives are only used in calculations<br>| when the day of the week and the year are specified.<br>|<br>| .. rubric:: 【示例】<br>|<br>| &gt;&gt;&gt; a = Period(freq=’Q@JUL’, year=2006, quarter=1)<br>| &gt;&gt;&gt; a.strftime(‘%F-Q%q’)<br>| ‘2006-Q1’<br>| &gt;&gt;&gt; # Output the last month in the quarter of this date<br>| &gt;&gt;&gt; a.strftime(‘%b-%Y’)<br>| ‘Oct-2005’<br>| &gt;&gt;&gt;<br>| &gt;&gt;&gt; a = Period(freq=’D’, year=2001, month=1, day=1)<br>| &gt;&gt;&gt; a.strftime(‘%d-%b-%Y’)<br>| ‘01-Jan-2006’<br>| &gt;&gt;&gt; a.strftime(‘%b. %d, %Y was a %A’)<br>| ‘Jan. 01, 2001 was a Monday’<br>|<br>| to_timestamp(…)<br>| Return the Timestamp representation of the Period at the target<br>| frequency at the specified end (how) of the Period<br>|<br>| 【参数】<br>| ———-| freq : string or DateOffset, default is ‘D’ if self.freq is week or<br>| longer and ‘S’ otherwise<br>| Target frequency<br>| how: str, default ‘S’ (start)<br>| ‘S’, ‘E’. Can be aliased as case insensitive<br>| ‘Start’, ‘Finish’, ‘Begin’, ‘End’<br>|<br>993<br>| 【返回值】<br>| ——-| Timestamp<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| day<br>|<br>| dayofweek<br>|<br>| dayofyear<br>|<br>| days_in_month<br>|<br>| daysinmonth<br>|<br>| end_time<br>|<br>| freq<br>|<br>| freqstr<br>|<br>| hour<br>|<br>| minute<br>|<br>| month<br>|<br>| ordinal<br>|<br>| quarter<br>|<br>| qyear<br>|<br>| second<br>|<br>| start_time<br>|<br>| week<br>|<br>| weekday<br>|<br>| weekofyear<br>|<br>| year<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| </strong>pyx_vtable<strong> = <capsule object="" null=""><br>【函数】<br>dt64arr_to_periodarr(…)<br>Convert array of datetime64 values (passed in as ‘i8’ dtype) to a set of<br>periods corresponding to desired frequency, per period convention.<br>994<br>extract_ordinals(…)<br>get_period_field(…)<br>get_period_field_arr(…)<br>period_asfreq(…)<br>Convert period ordinal from one frequency to another, and if upsampling,<br>choose to use start (‘S’) or end (‘E’) of period.<br>period_asfreq_arr(…)<br>Convert int64-array of period ordinals from one frequency to another, and<br>if upsampling, choose to use start (‘S’) or end (‘E’) of period.<br>period_format(…)<br>period_ordinal(…)<br>period_ordinal_to_dt64(…)<br>periodarr_to_dt64arr(…)<br>Convert array to datetime64 values from a set of ordinals corresponding to<br>periods per period convention.<br>resolution(…)<br>【数据】<br>D_RESO = 5<br>H_RESO = 4<br>MS_RESO = 1<br>NaT = NaT<br>S_RESO = 2<br>T_RESO = 3<br>US_RESO = 0
</capsule></strong>test<strong> = {‘Period.strftime (line 1017)’: “\n Returns the stri…<br>have_pytz = True<br>iNaT = -9223372036854775808<br>version_info = sys.version_info(major=3, minor=5, micro=1, releaseleve…<br>【文件】 ： \pandas_period.cp35-win_amd64.pyd<br>_sparse<br>所属模块：pandas._sparse in pandas:<br>【名称】<br>pandas._sparse<br>【类型】<br>995<br>【内置对象】<br>BlockMerge<br>BlockIntersection<br>BlockUnion<br>SparseIndex<br>BlockIndex<br>IntIndex<br>class BlockIndex(SparseIndex)<br>| Object for holding block-based sparse indexing information<br>|<br>| 【参数】<br>| ———-|<br>| 【方法排序】<br>| BlockIndex<br>| SparseIndex<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| </strong>init<strong>(self, /, <em>args, *</em>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| </strong>new<strong>(<em>args, *</em>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| </strong>reduce<strong>(…)<br>| helper for pickle<br>|<br>| </strong>repr<strong>(self, /)<br>| Return repr(self).<br>|<br>| check_integrity(…)<br>| Check:<br>| - Locations are in ascending order<br>| - No overlapping blocks<br>| - Blocks to not start after end of index, nor extend beyond end<br>|<br>| equals(…)<br>|<br>| intersect(…)<br>| Intersect two BlockIndex objects<br>|<br>| 【参数】<br>| ———-|<br>| 【返回值】<br>| ——-| intersection : BlockIndex<br>|<br>| lookup(…)<br>| Returns -1 if not found<br>|<br>| make_union(…)<br>| Combine together two BlockIndex objects, accepting indices if contained<br>| in one or the other<br>996<br>|<br>| 【参数】<br>| ———-| other : SparseIndex<br>|<br>| 【注意】<br>| —–| union is a protected keyword in Cython, hence make_union<br>|<br>| 【返回值】<br>| ——-| union : BlockIndex<br>|<br>| put(…)<br>|<br>| reindex(…)<br>|<br>| take(…)<br>|<br>| to_block_index(…)<br>|<br>| to_int_index(…)<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| blengths<br>|<br>| blocs<br>|<br>| length<br>|<br>| nblocks<br>|<br>| ngaps<br>|<br>| npoints<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| </strong>pyx_vtable<strong> = <capsule object="" null=""><br>class BlockIntersection(BlockMerge)<br>| not done yet<br>|<br>| 【方法排序】<br>| BlockIntersection<br>| BlockMerge<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| </capsule></strong>new<strong>(<em>args, *</em>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| ———————————————————————-<br>997<br>| 其他数据、属性定义：<br>|<br>| </strong>pyx_vtable<strong> = <capsule object="" null=""><br>|<br>| ———————————————————————-| Methods inherited from BlockMerge:<br>|<br>| </capsule></strong>init<strong>(self, /, <em>args, *</em>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>class BlockMerge(builtins.object)<br>| Object-oriented approach makes sharing state between recursive functions a<br>| lot easier and reduces code duplication<br>|<br>| 【方法定义】<br>|<br>| </strong>init<strong>(self, /, <em>args, *</em>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| </strong>new<strong>(<em>args, *</em>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| </strong>pyx_vtable<strong> = <capsule object="" null=""><br>class BlockUnion(BlockMerge)<br>| Object-oriented approach makes sharing state between recursive functions a<br>| lot easier and reduces code duplication<br>|<br>| 【方法排序】<br>| BlockUnion<br>| BlockMerge<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| </capsule></strong>new<strong>(<em>args, *</em>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| </strong>pyx_vtable<strong> = <capsule object="" null=""><br>|<br>| ———————————————————————-| Methods inherited from BlockMerge:<br>|<br>| </capsule></strong>init<strong>(self, /, <em>args, *</em>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>class IntIndex(SparseIndex)<br>| Object for holding exact integer sparse indexing information<br>|<br>| 【参数】<br>998<br>| ———-| length : integer<br>| indices : array-like<br>| Contains integers corresponding to<br>|<br>| 【方法排序】<br>| IntIndex<br>| SparseIndex<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| </strong>init<strong>(self, /, <em>args, *</em>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| </strong>new<strong>(<em>args, *</em>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| </strong>reduce<strong>(…)<br>| helper for pickle<br>|<br>| </strong>repr<strong>(self, /)<br>| Return repr(self).<br>|<br>| check_integrity(…)<br>| Only need be strictly ascending and nothing less than 0 or greater than<br>| totall ength<br>|<br>| equals(…)<br>|<br>| intersect(…)<br>|<br>| lookup(…)<br>|<br>| make_union(…)<br>|<br>| put(…)<br>|<br>| reindex(…)<br>|<br>| take(…)<br>|<br>| to_block_index(…)<br>|<br>| to_int_index(…)<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| indices<br>|<br>| length<br>|<br>| ngaps<br>|<br>| npoints<br>|<br>999<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| </strong>pyx_vtable<strong> = <capsule object="" null=""><br>class SparseIndex(builtins.object)<br>| Abstract superclass for sparse index types<br>|<br>| 【方法定义】<br>|<br>| </capsule></strong>init<strong>(self, /, <em>args, *</em>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| </strong>new<strong>(<em>args, *</em>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>【函数】<br>get_blocks(…)<br>get_reindexer(…)<br>reindex_integer(…)<br>sparse_add(…)<br>sparse_div(…)<br>sparse_floordiv(…)<br>sparse_mul(…)<br>sparse_nanadd(…)<br>sparse_nandiv(…)<br>sparse_nanfloordiv(…)<br>sparse_nanmul(…)<br>sparse_nanpow(…)<br>sparse_nanrdiv(…)<br>sparse_nanrfloordiv(…)<br>sparse_nanrpow(…)<br>sparse_nanrsub(…)<br>sparse_nanrtruediv = sparse_nanrdiv(…)<br>sparse_nansub(…)<br>sparse_nantruediv = sparse_nandiv(…)<br>sparse_pow(…)<br>1000<br>sparse_rdiv(…)<br>sparse_rfloordiv(…)<br>sparse_rpow(…)<br>sparse_rsub(…)<br>sparse_rtruediv = sparse_rdiv(…)<br>sparse_sub(…)<br>sparse_truediv = sparse_div(…)<br>【数据】
</strong>test<strong> = {}<br>【文件】 ： \pandas_sparse.cp35-win_amd64.pyd<br>_testing<br>所属模块：pandas._testing in pandas:<br>【名称】<br>pandas._testing<br>【函数】<br>assert_almost_equal(…)<br>Check that left and right objects are almost equal.<br>【参数】<br>———-a : object<br>b : object<br>check_less_precise : bool, default False<br>Specify comparison precision.<br>5 digits (False) or 3 digits (True) after decimal points are compared.<br>obj : str, default None<br>Specify object name being compared, internally used to show appropriate<br>assertion message<br>lobj : str, default None<br>Specify left object name being compared, internally used to show<br>appropriate assertion message<br>robj : str, default None<br>Specify right object name being compared, internally used to show<br>appropriate assertion message<br>assert_dict_equal(…)<br>1001<br>【数据】
</strong>test__ = {}<br>【文件】 ： \pandas_testing.cp35-win_amd64.pyd<br>_version<br>所属模块：pandas._version in pandas:<br>【名称】<br>pandas._version<br>【说明】</pandas.core.config.callabledynamicdoc></pandas.core.config.callabledynamicdoc></pandas.core.config.dictwrapper></pandas.core.config.callabledynamicdoc></pandas.core.config.callabledynamicdoc></class></pandas.core.indexing._indexslice></p>
<h1 id="This-file-was-generated-by-‘versioneer-py’-0-15-from"><a href="#This-file-was-generated-by-‘versioneer-py’-0-15-from" class="headerlink" title="This file was generated by ‘versioneer.py’ (0.15) from"></a>This file was generated by ‘versioneer.py’ (0.15) from</h1><h1 id="revision-control-system-data-or-from-the-parent-directory-name-of-an"><a href="#revision-control-system-data-or-from-the-parent-directory-name-of-an" class="headerlink" title="revision-control system data, or from the parent directory name of an"></a>revision-control system data, or from the parent directory name of an</h1><h1 id="unpacked-source-archive-Distribution-tarballs-contain-a-pre-generated-copy"><a href="#unpacked-source-archive-Distribution-tarballs-contain-a-pre-generated-copy" class="headerlink" title="unpacked source archive. Distribution tarballs contain a pre-generated copy"></a>unpacked source archive. Distribution tarballs contain a pre-generated copy</h1><h1 id="of-this-file"><a href="#of-this-file" class="headerlink" title="of this file."></a>of this file.</h1><p>【函数】<br>get_versions()<br>【数据】<br>version_json = ‘\n{\n “dirty”: false,\n “error”: null,\n “full-revis…..<br>【文件】 ： \pandas_version.py<br>algos<br>所属模块：pandas.algos in pandas:<br>【名称】<br>pandas.algos<br>【类型】<br>【内置对象】<br>IndexableSkiplist<br>Infinity<br>NegInfinity<br>Node<br>1002<br>class IndexableSkiplist(builtins.object)<br>| Sorted collection supporting O(lg n) insertion, removal, and<br>| lookup by rank.<br>|<br>| 【方法定义】<br>|<br>| <strong>getitem</strong>(self, key, /)<br>| Return self[key].<br>|<br>| <strong>init</strong>(self, /, <em>args, **kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>len</strong>(self, /)<br>| Return len(self).<br>|<br>| <strong>new</strong>(</em>args, <strong>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| get(…)<br>|<br>| insert(…)<br>|<br>| remove(…)<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| <strong>pyx_vtable</strong> = <capsule object="" null=""><br>class Infinity(builtins.object)<br>| 【方法定义】<br>|<br>| <strong>cmp</strong> = lambda(…)<br>|<br>| <strong>eq</strong> = lambda(…)<br>|<br>| <strong>ge</strong> = lambda1(…)<br>|<br>| <strong>gt</strong> = lambda1(…)<br>|<br>| <strong>le</strong> = lambda(…)<br>|<br>| <strong>lt</strong> = lambda(…)<br>|<br>| <strong>ne</strong> = lambda1(…)<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>1003<br>|<br>| <strong>hash</strong> = None<br>class NegInfinity(builtins.object)<br>| 【方法定义】<br>|<br>| <strong>cmp</strong> = lambda1(…)<br>|<br>| <strong>eq</strong> = lambda(…)<br>|<br>| <strong>ge</strong> = lambda(…)<br>|<br>| <strong>gt</strong> = lambda(…)<br>|<br>| <strong>le</strong> = lambda1(…)<br>|<br>| <strong>lt</strong> = lambda1(…)<br>|<br>| <strong>ne</strong> = lambda1(…)<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| <strong>hash</strong> = None<br>class Node(builtins.object)<br>| 【方法定义】<br>|<br>| <strong>init</strong>(self, /, *args, </capsule></strong>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>new</strong>(<em>args, <em>*kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| next<br>|<br>| value<br>|<br>| width<br>【函数】<br>arrmap_bool(…)<br>arrmap_float32(…)<br>1004<br>arrmap_float64(…)<br>arrmap_int32(…)<br>arrmap_int64(…)<br>arrmap_object(…)<br>backfill_2d_inplace_bool(…)<br>backfill_2d_inplace_float32(…)<br>backfill_2d_inplace_float64(…)<br>backfill_2d_inplace_int32(…)<br>backfill_2d_inplace_int64(…)<br>backfill_2d_inplace_object(…)<br>backfill_bool(…)<br>backfill_float32(…)<br>backfill_float64(…)<br>backfill_inplace_bool(…)<br>backfill_inplace_float32(…)<br>backfill_inplace_float64(…)<br>backfill_inplace_int32(…)<br>backfill_inplace_int64(…)<br>backfill_inplace_object(…)<br>backfill_int32(…)<br>backfill_int64(…)<br>backfill_object(…)<br>diff_2d_float32(…)<br>diff_2d_float64(…)<br>diff_2d_int16(…)<br>diff_2d_int32(…)<br>diff_2d_int64(…)<br>diff_2d_int8(…)<br>ensure_float32(…)<br>1005<br>ensure_float64(…)<br>ensure_int16(…)<br>ensure_int32(…)<br>ensure_int64(…)<br>ensure_int8(…)<br>ensure_object(…)<br>ensure_platform_int(…)<br>ewma(…)<br>Compute exponentially-weighted moving average using center-of-mass.<br>【参数】<br>———-input : ndarray (float64 type)<br>com : float64<br>adjust: int<br>ignore_na: int<br>minp: int<br>【返回值】<br>——-y : ndarray<br>ewmcov(…)<br>Compute exponentially-weighted moving variance using center-of-mass.<br>【参数】<br>———-input_x : ndarray (float64 type)<br>input_y : ndarray (float64 type)<br>com : float64<br>adjust: int<br>ignore_na: int<br>minp: int<br>bias: int<br>【返回值】<br>——-y : ndarray<br>ffill_by_group(…)<br>ffill_indexer(…)<br>full_outer_join(…)<br>group_add_float32(…)<br>Only aggregates on axis=0<br>group_add_float64(…)<br>1006<br>Only aggregates on axis=0<br>group_cumprod_float64(…)<br>Only transforms on axis=0<br>group_cumsum(out, values, labels, accum)<br>Only transforms on axis=0<br>group_labels(…)<br>Compute label vector from input values and associated useful data<br>【返回值】<br>——-group_last_bin_object(…)<br>Only aggregates on axis=0<br>group_last_float32(…)<br>Only aggregates on axis=0<br>group_last_float64(…)<br>Only aggregates on axis=0<br>group_last_int64(…)<br>Only aggregates on axis=0<br>group_last_object(…)<br>Only aggregates on axis=0<br>group_max_float32(…)<br>Only aggregates on axis=0<br>group_max_float64(…)<br>Only aggregates on axis=0<br>group_max_int64(…)<br>Only aggregates on axis=0<br>group_mean_float32(…)<br>group_mean_float64(…)<br>group_median_float64(…)<br>Only aggregates on axis=0<br>group_min_float32(…)<br>Only aggregates on axis=0<br>group_min_float64(…)<br>Only aggregates on axis=0<br>group_min_int64(…)<br>Only aggregates on axis=0<br>group_nth_bin_object(…)<br>Only aggregates on axis=0<br>1007<br>group_nth_float32(…)<br>Only aggregates on axis=0<br>group_nth_float64(…)<br>Only aggregates on axis=0<br>group_nth_int64(…)<br>Only aggregates on axis=0<br>group_nth_object(…)<br>Only aggregates on axis=0<br>group_ohlc_float32(…)<br>Only aggregates on axis=0<br>group_ohlc_float64(…)<br>Only aggregates on axis=0<br>group_prod_float32(…)<br>Only aggregates on axis=0<br>group_prod_float64(…)<br>Only aggregates on axis=0<br>group_shift_indexer(…)<br>group_var_float32(…)<br>group_var_float64(…)<br>groupby_bool(…)<br>groupby_float32(…)<br>groupby_float64(…)<br>groupby_indices(…)<br>groupby_int32(…)<br>groupby_int64(…)<br>groupby_object(…)<br>groupsort_indexer(…)<br>inner_join(…)<br>inner_join_indexer_float32(…)<br>Two-pass algorithm for monotonic indexes. Handles many-to-one merges<br>inner_join_indexer_float64(…)<br>Two-pass algorithm for monotonic indexes. Handles many-to-one merges<br>inner_join_indexer_int32(…)<br>Two-pass algorithm for monotonic indexes. Handles many-to-one merges<br>1008<br>inner_join_indexer_int64(…)<br>Two-pass algorithm for monotonic indexes. Handles many-to-one merges<br>inner_join_indexer_object(…)<br>Two-pass algorithm for monotonic indexes. Handles many-to-one merges<br>is_lexsorted(…)<br>is_monotonic_bool(…)<br>【返回值】<br>——-is_monotonic_inc, is_monotonic_dec<br>is_monotonic_float32(…)<br>【返回值】<br>——-is_monotonic_inc, is_monotonic_dec<br>is_monotonic_float64(…)<br>【返回值】<br>——-is_monotonic_inc, is_monotonic_dec<br>is_monotonic_int32(…)<br>【返回值】<br>——-is_monotonic_inc, is_monotonic_dec<br>is_monotonic_int64(…)<br>【返回值】<br>——-is_monotonic_inc, is_monotonic_dec<br>is_monotonic_object(…)<br>【返回值】<br>——-is_monotonic_inc, is_monotonic_dec<br>kth_smallest(a, k)<br>left_join_indexer_float32(…)<br>Two-pass algorithm for monotonic indexes. Handles many-to-one merges<br>left_join_indexer_float64(…)<br>Two-pass algorithm for monotonic indexes. Handles many-to-one merges<br>left_join_indexer_int32(…)<br>Two-pass algorithm for monotonic indexes. Handles many-to-one merges<br>left_join_indexer_int64(…)<br>Two-pass algorithm for monotonic indexes. Handles many-to-one merges<br>left_join_indexer_object(…)<br>Two-pass algorithm for monotonic indexes. Handles many-to-one merges<br>left_join_indexer_unique_float32(…)<br>1009<br>left_join_indexer_unique_float64(…)<br>left_join_indexer_unique_int32(…)<br>left_join_indexer_unique_int64(…)<br>left_join_indexer_unique_object(…)<br>left_outer_join(…)<br>map_indices_bool(…)<br>Produce a dict mapping the values of the input array to their respective<br>locations.<br>Example:<br>array([‘hi’, ‘there’]) –&gt; {‘hi’ : 0 , ‘there’ : 1}<br>Better to do this with Cython because of the enormous speed boost.<br>map_indices_float32(…)<br>Produce a dict mapping the values of the input array to their respective<br>locations.<br>Example:<br>array([‘hi’, ‘there’]) –&gt; {‘hi’ : 0 , ‘there’ : 1}<br>Better to do this with Cython because of the enormous speed boost.<br>map_indices_float64(…)<br>Produce a dict mapping the values of the input array to their respective<br>locations.<br>Example:<br>array([‘hi’, ‘there’]) –&gt; {‘hi’ : 0 , ‘there’ : 1}<br>Better to do this with Cython because of the enormous speed boost.<br>map_indices_int32(…)<br>Produce a dict mapping the values of the input array to their respective<br>locations.<br>Example:<br>array([‘hi’, ‘there’]) –&gt; {‘hi’ : 0 , ‘there’ : 1}<br>Better to do this with Cython because of the enormous speed boost.<br>map_indices_int64(…)<br>Produce a dict mapping the values of the input array to their respective<br>locations.<br>Example:<br>array([‘hi’, ‘there’]) –&gt; {‘hi’ : 0 , ‘there’ : 1}<br>Better to do this with Cython because of the enormous speed boost.<br>map_indices_object(…)<br>Produce a dict mapping the values of the input array to their respective<br>1010<br>locations.<br>Example:<br>array([‘hi’, ‘there’]) –&gt; {‘hi’ : 0 , ‘there’ : 1}<br>Better to do this with Cython because of the enormous speed boost.<br>max_subseq(…)<br>median(arr)<br>A faster median<br>min_subseq(…)<br>nancorr(…)<br>nancorr_spearman(…)<br>outer_join_indexer_float32(…)<br>outer_join_indexer_float64(…)<br>outer_join_indexer_int32(…)<br>outer_join_indexer_int64(…)<br>outer_join_indexer_object(…)<br>pad_2d_inplace_bool(…)<br>pad_2d_inplace_float32(…)<br>pad_2d_inplace_float64(…)<br>pad_2d_inplace_int32(…)<br>pad_2d_inplace_int64(…)<br>pad_2d_inplace_object(…)<br>pad_bool(…)<br>pad_float32(…)<br>pad_float64(…)<br>pad_inplace_bool(…)<br>pad_inplace_float32(…)<br>pad_inplace_float64(…)<br>pad_inplace_int32(…)<br>pad_inplace_int64(…)<br>pad_inplace_object(…)<br>1011<br>pad_int32(…)<br>pad_int64(…)<br>pad_object(…)<br>random(…) method of random.Random instance<br>random() -&gt; x in the interval [0, 1).<br>rank_1d_float64(…)<br>Fast NaN-friendly version of scipy.stats.rankdata<br>rank_1d_generic(…)<br>Fast NaN-friendly version of scipy.stats.rankdata<br>rank_1d_int64(…)<br>Fast NaN-friendly version of scipy.stats.rankdata<br>rank_2d_float64(…)<br>Fast NaN-friendly version of scipy.stats.rankdata<br>rank_2d_generic(…)<br>Fast NaN-friendly version of scipy.stats.rankdata<br>rank_2d_int64(…)<br>Fast NaN-friendly version of scipy.stats.rankdata<br>roll_generic(…)<br>roll_kurt(…)<br>roll_max(…)<br>Moving max of 1d array of dtype=float64 along axis=0 ignoring NaNs.<br>roll_mean(…)<br>roll_median_c(…)<br>roll_min(…)<br>Moving min of 1d array of dtype=float64 along axis=0 ignoring NaNs.<br>roll_quantile(…)<br>O(N log(window)) implementation using skip list<br>roll_skew(…)<br>roll_sum(…)<br>roll_var(…)<br>Numerically stable implementation using Welford’s method.<br>roll_window(…)<br>Assume len(weights) &lt;&lt; len(input)<br>take_1d_bool_bool(…)<br>1012<br>take_1d_bool_object(…)<br>take_1d_float32_float32(…)<br>take_1d_float32_float64(…)<br>take_1d_float64_float64(…)<br>take_1d_int16_float64(…)<br>take_1d_int16_int16(…)<br>take_1d_int16_int32(…)<br>take_1d_int16_int64(…)<br>take_1d_int32_float64(…)<br>take_1d_int32_int32(…)<br>take_1d_int32_int64(…)<br>take_1d_int64_float64(…)<br>take_1d_int64_int64(…)<br>take_1d_int8_float64(…)<br>take_1d_int8_int32(…)<br>take_1d_int8_int64(…)<br>take_1d_int8_int8(…)<br>take_1d_object_object(…)<br>take_2d_axis0_bool_bool(…)<br>take_2d_axis0_bool_object(…)<br>take_2d_axis0_float32_float32(…)<br>take_2d_axis0_float32_float64(…)<br>take_2d_axis0_float64_float64(…)<br>take_2d_axis0_int16_float64(…)<br>take_2d_axis0_int16_int16(…)<br>take_2d_axis0_int16_int32(…)<br>take_2d_axis0_int16_int64(…)<br>take_2d_axis0_int32_float64(…)<br>take_2d_axis0_int32_int32(…)<br>1013<br>take_2d_axis0_int32_int64(…)<br>take_2d_axis0_int64_float64(…)<br>take_2d_axis0_int64_int64(…)<br>take_2d_axis0_int8_float64(…)<br>take_2d_axis0_int8_int32(…)<br>take_2d_axis0_int8_int64(…)<br>take_2d_axis0_int8_int8(…)<br>take_2d_axis0_object_object(…)<br>take_2d_axis1_bool_bool(…)<br>take_2d_axis1_bool_object(…)<br>take_2d_axis1_float32_float32(…)<br>take_2d_axis1_float32_float64(…)<br>take_2d_axis1_float64_float64(…)<br>take_2d_axis1_int16_float64(…)<br>take_2d_axis1_int16_int16(…)<br>take_2d_axis1_int16_int32(…)<br>take_2d_axis1_int16_int64(…)<br>take_2d_axis1_int32_float64(…)<br>take_2d_axis1_int32_int32(…)<br>take_2d_axis1_int32_int64(…)<br>take_2d_axis1_int64_float64(…)<br>take_2d_axis1_int64_int64(…)<br>take_2d_axis1_int8_float64(…)<br>take_2d_axis1_int8_int32(…)<br>take_2d_axis1_int8_int64(…)<br>take_2d_axis1_int8_int8(…)<br>take_2d_axis1_object_object(…)<br>take_2d_multi_bool_bool(…)<br>1014<br>take_2d_multi_bool_object(…)<br>take_2d_multi_float32_float32(…)<br>take_2d_multi_float32_float64(…)<br>take_2d_multi_float64_float64(…)<br>take_2d_multi_int16_float64(…)<br>take_2d_multi_int16_int16(…)<br>take_2d_multi_int16_int32(…)<br>take_2d_multi_int16_int64(…)<br>take_2d_multi_int32_float64(…)<br>take_2d_multi_int32_int32(…)<br>take_2d_multi_int32_int64(…)<br>take_2d_multi_int64_float64(…)<br>take_2d_multi_int64_int64(…)<br>take_2d_multi_int8_float64(…)<br>take_2d_multi_int8_int32(…)<br>take_2d_multi_int8_int64(…)<br>take_2d_multi_int8_int8(…)<br>take_2d_multi_object_object(…)<br>【数据】<br>NIL = <pandas.algos.node object=""><br><strong>test</strong> = {}<br>float16 = dtype(‘float16’)<br>float32 = dtype(‘float32’)<br>float64 = dtype(‘float64’)<br>int16 = dtype(‘int16’)<br>int32 = dtype(‘int32’)<br>int64 = dtype(‘int64’)<br>int8 = dtype(‘int8’)<br>isnan = <ufunc 'isnan'=""><br>tiebreakers = {‘average’: 0, ‘dense’: 5, ‘first’: 3, ‘max’: 2, ‘min’: …<br>【文件】 ： \pandas\algos.cp35-win_amd64.pyd<br>1015<br>bdate_range<br>函数 bdate_range 模块所属：pandas.tseries.index:<br>bdate_range(start=None, end=None, periods=None, freq=’B’, tz=None, normalize=True, name=None, closed=None, </ufunc></pandas.algos.node></em></em>kwargs)<br>Return a fixed frequency datetime index, with business day as the default<br>frequency<br>【参数】<br>———-start : string or datetime-like, default None<br>Left bound for generating dates<br>end : string or datetime-like, default None<br>Right bound for generating dates<br>periods : integer or None, default None<br>If None, must specify start and end<br>freq : string or DateOffset, default ‘B’ (business daily)<br>Frequency strings can have multiples, e.g. ‘5H’<br>tz : string or None<br>Time zone name for returning localized DatetimeIndex, for example<br>Asia/Beijing<br>normalize : bool, default False<br>Normalize start/end dates to midnight before generating date range<br>name : str, default None<br>Name for the resulting index<br>closed : string or None, default None<br>Make the interval closed with respect to the given frequency to<br>the ‘left’, ‘right’, or both sides (None)<br>【注意】<br>—–2 of start, end, or periods must be specified<br>【返回值】<br>——-rng : DatetimeIndex<br>compat<br>模块包所属：pandas.compat in pandas:<br>【名称】<br>pandas.compat<br>【说明】<br>compat</p>
<h1 id="1016"><a href="#1016" class="headerlink" title="1016"></a>1016</h1><p>Cross-compatible functions for Python 2 and 3.<br>Key items to import for 2/3 compatible code:</p>
<ul>
<li>iterators: range(), map(), zip(), filter(), reduce()</li>
<li>lists: lrange(), lmap(), lzip(), lfilter()</li>
<li>unicode: u() [u”” is a syntax error in Python 3.0-3.2]</li>
<li>longs: long (int in Python 3)</li>
<li>callable</li>
<li>iterable method compatibility: iteritems, iterkeys, itervalues</li>
<li>Uses the original method if available, otherwise uses items, keys, values.</li>
<li>types:</li>
<li>text_type: unicode in Python 2, str in Python 3</li>
<li>binary_type: str in Python 2, bytes in Python 3</li>
<li>string_types: basestring in Python 2, str in Python 3</li>
<li>bind_method: binds functions to classes</li>
<li>add_metaclass(metaclass) - class decorator that recreates class with with the<br>given metaclass instead (and avoids intermediary class creation)<br>Python 2.6 compatibility:</li>
<li>OrderedDict</li>
<li>Counter<br>Other items:</li>
<li>OrderedDefaultDict</li>
<li>platform checker<br>【模块包·内容】<br>chainmap<br>chainmap_impl<br>openpyxl_compat<br>pickle_compat<br>【类型】<br>collections.OrderedDict(builtins.dict)<br>OrderedDefaultdict<br>class OrderedDefaultdict(collections.OrderedDict)<br>| Dictionary that remembers insertion order<br>|<br>| 【方法排序】<br>| OrderedDefaultdict<br>| collections.OrderedDict<br>| builtins.dict<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>init</strong>(self, <em>args, **kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>missing</strong>(self, key)<br>|<br>| <strong>reduce</strong>(self)<br>| Return state information for pickling<br>|<br>1017<br>| ———————————————————————-| Methods inherited from collections.OrderedDict:<br>|<br>| <strong>delitem</strong>(self, key, /)<br>| Delete self[key].<br>|<br>| <strong>eq</strong>(self, value, /)<br>| Return self==value.<br>|<br>| <strong>ge</strong>(self, value, /)<br>| Return self&gt;=value.<br>|<br>| <strong>gt</strong>(self, value, /)<br>| Return self&gt;value.<br>|<br>| <strong>iter</strong>(self, /)<br>| Implement iter(self).<br>|<br>| <strong>le</strong>(self, value, /)<br>| Return self&lt;=value.<br>|<br>| <strong>lt</strong>(self, value, /)<br>| Return self&lt;value.<br>|<br>| <strong>ne</strong>(self, value, /)<br>| Return self!=value.<br>|<br>| <strong>new</strong>(</em>args, <strong>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| <strong>repr</strong>(self, /)<br>| Return repr(self).<br>|<br>| <strong>reversed</strong>(…)<br>| od.<strong>reversed</strong>() &lt;==&gt; reversed(od)<br>|<br>| <strong>setitem</strong>(self, key, value, /)<br>| Set self[key] to value.<br>|<br>| <strong>sizeof</strong>(…)<br>| D.<strong>sizeof</strong>() -&gt; size of D in memory, in bytes<br>|<br>| clear(…)<br>| od.clear() -&gt; None. Remove all items from od.<br>|<br>| copy(…)<br>| od.copy() -&gt; a shallow copy of od<br>|<br>| fromkeys(…) from builtins.type<br>| OD.fromkeys(S[, v]) -&gt; New ordered dictionary with keys from S.<br>| If not specified, the value defaults to None.<br>|<br>| items(…)<br>| D.items() -&gt; a set-like object providing a view on D’s items<br>|<br>| keys(…)<br>| D.keys() -&gt; a set-like object providing a view on D’s keys<br>1018<br>|<br>| move_to_end(…)<br>| Move an existing element to the end (or beginning if last==False).<br>|<br>| Raises KeyError if the element does not exist.<br>| When last=True, acts like a fast version of self[key]=self.pop(key).<br>|<br>| pop(…)<br>| od.pop(k[,d]) -&gt; v, remove specified key and return the corresponding<br>| value. If key is not found, d is returned if given, otherwise KeyError<br>| is raised.<br>|<br>| popitem(…)<br>| od.popitem() -&gt; (k, v), return and remove a (key, value) pair.<br>| Pairs are returned in LIFO order if last is true or FIFO order if false.<br>|<br>| setdefault(…)<br>| od.setdefault(k[,d]) -&gt; od.get(k,d), also set od[k]=d if k not in od<br>|<br>| update(…)<br>| D.update([E, ]</strong>F) -&gt; None. Update D from dict/iterable E and F.<br>| If E is present and has a .keys() method, then does: for k in E: D[k] = E[k]<br>| If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v<br>| In either case, this is followed by: for k in F: D[k] = F[k]<br>|<br>| values(…)<br>| D.values() -&gt; an object providing a view on D’s values<br>|<br>| ———————————————————————-| Data descriptors inherited from collections.OrderedDict:<br>|<br>| <strong>dict</strong><br>|<br>| ———————————————————————-| Data and other attributes inherited from collections.OrderedDict:<br>|<br>| <strong>hash</strong> = None<br>|<br>| ———————————————————————-| Methods inherited from builtins.dict:<br>|<br>| <strong>contains</strong>(self, key, /)<br>| True if D has a key k, else False.<br>|<br>| <strong>getattribute</strong>(self, name, /)<br>| Return getattr(self, name).<br>|<br>| <strong>getitem</strong>(…)<br>| x.<strong>getitem</strong>(y) &lt;==&gt; x[y]<br>|<br>| <strong>len</strong>(self, /)<br>| Return len(self).<br>|<br>| get(…)<br>| D.get(k[,d]) -&gt; D[k] if k in D, else d. d defaults to None.<br>【函数】<br>1019<br>add_metaclass(metaclass)<br>Class decorator for creating a class with a metaclass.<br>bind_method(cls, name, func)<br>Bind a method to class, python 2 and python 3 compatible.<br>【参数】<br>———-cls : type<br>class to receive bound method<br>name : basestring<br>name of method on class instance<br>func : function<br>function to be bound as method<br>【返回值】<br>——-None<br>bytes_to_str(b, encoding=None)<br>callable(obj, /)<br>Return whether the object is callable (i.e., some kind of function).<br>Note that classes are callable, as are instances of classes with a<br><strong>call</strong>() method.<br>east_asian_len(data, encoding=None, ambiguous_width=1)<br>Calculate display width considering unicode East Asian Width<br>east_asian_width(chr, /)<br>Returns the east asian width assigned to the character chr as string.<br>is_platform_32bit()<br>is_platform_linux()<br>is_platform_mac()<br>is_platform_windows()<h1 id="https-github-com-pydata-pandas-pull-9123"><a href="#https-github-com-pydata-pandas-pull-9123" class="headerlink" title="https://github.com/pydata/pandas/pull/9123"></a><a href="https://github.com/pydata/pandas/pull/9123" target="_blank" rel="external">https://github.com/pydata/pandas/pull/9123</a></h1>isidentifier(s)<br>iteritems(obj, <strong>kwargs)<br>replacement for six’s iteritems for Python2/3 compat<br>uses ‘iteritems’ if available and otherwise uses ‘items’.<br>Passes kwargs to method.<br>iterkeys(obj, </strong>kwargs)<br>itervalues(obj, <strong>kwargs)<br>lfilter(*args, </strong>kwargs)<br>1020<br>lmap(<em>args, **kwargs)<br>lrange(</em>args, **kwargs)<h1 id="list-producing-versions-of-the-major-Python-iterating-functions"><a href="#list-producing-versions-of-the-major-Python-iterating-functions" class="headerlink" title="list-producing versions of the major Python iterating functions"></a>list-producing versions of the major Python iterating functions</h1>lzip(<em>args, *</em>kwargs)<br>raise_with_traceback(exc, traceback=Ellipsis)<br>Raise exception with existing traceback.<br>If traceback is not passed, uses sys.exc_info() to get traceback.<br>reduce(…)<br>reduce(function, sequence[, initial]) -&gt; value<br>Apply a function of two arguments cumulatively to the items of a sequence,<br>from left to right, so as to reduce the sequence to a single value.<br>For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates<br>((((1+2)+3)+4)+5). If initial is present, it is placed before the items<br>of the sequence in the calculation, and serves as a default when the<br>sequence is empty.<br>str_to_bytes(s, encoding=None)<br>strlen(data, encoding=None)<br>u(s)<br>u_safe(s)<br>unichr = chr(i, /)<br>Return a Unicode string of one character with ordinal i; 0 &lt;= i &lt;= 0x10ffff.<br>【数据】<br>PY2 = False<br>PY3 = True<br>PY35 = True<br>class_types = (<class 'type'="">,)<br>integer_types = (<class 'int'="">,)<br>string_and_binary_types = (<class 'str'="">, <class 'bytes'="">)<br>string_types = (<class 'str'="">,)<br>【文件】 ： \pandas\compat__init<strong>.py<br>computation<br>模块包所属：pandas.computation in pandas:<br>【名称】<br>1021<br>pandas.computation<br>【模块包·内容】<br>align<br>api<br>common<br>engines<br>eval<br>expr<br>expressions<br>ops<br>pytables<br>scope<br>tests (package)<br>【文件】 ： \pandas\computation\</strong>init<strong>.py<br>concat<br>函数 concat 模块所属：pandas.tools.merge:<br>concat(objs, axis=0, join=’outer’, join_axes=None, ignore_index=False, keys=None, levels=None, names=None,<br>verify_integrity=False, copy=True)<br>Concatenate pandas objects along a particular axis with optional set logic<br>along the other axes. Can also add a layer of hierarchical indexing on the<br>concatenation axis, which may be useful if the labels are the same (or<br>overlapping) on the passed axis number<br>【参数】<br>———-objs : a sequence or mapping of Series, DataFrame, or Panel objects<br>If a dict is passed, the sorted keys will be used as the <code>keys</code><br>argument, unless it is passed, in which case the values will be<br>selected (see below). Any None objects will be dropped silently unless<br>they are all None in which case a ValueError will be raised<br>axis : {0, 1, …}, default 0<br>The axis to concatenate along<br>join : {‘inner’, ‘outer’}, default ‘outer’<br>How to handle indexes on other axis(es)<br>join_axes : list of Index objects<br>Specific indexes to use for the other n - 1 axes instead of performing<br>inner/outer set logic<br>verify_integrity : boolean, default False<br>Check whether the new concatenated axis contains duplicates. This can<br>be very expensive relative to the actual data concatenation<br>keys : sequence, default None<br>If multiple levels passed, should contain tuples. Construct<br>hierarchical index using the passed keys as the outermost level<br>levels : list of sequences, default None<br>1022<br>Specific levels (unique values) to use for constructing a<br>MultiIndex. Otherwise they will be inferred from the keys<br>names : list, default None<br>Names for the levels in the resulting hierarchical index<br>ignore_index : boolean, default False<br>If True, do not use the index values along the concatenation axis. The<br>resulting axis will be labeled 0, …, n - 1. This is useful if you are<br>concatenating objects where the concatenation axis does not have<br>meaningful indexing information. Note the the index values on the other<br>axes are still respected in the join.<br>copy : boolean, default True<br>If False, do not copy data unnecessarily<br>【注意】<br>—–The keys, levels, and names arguments are all optional<br>【返回值】<br>——-concatenated : type of objects<br>core<br>模块包所属：pandas.core in pandas:<br>【名称】<br>pandas.core<br>【模块包·内容】<br>algorithms<br>api<br>base<br>categorical<br>common<br>config<br>config_init<br>convert<br>datetools<br>dtypes<br>format<br>frame<br>generic<br>groupby<br>index<br>indexing<br>internals<br>matrix<br>missing<br>nanops<br>ops<br>1023<br>panel<br>panel4d<br>panelnd<br>reshape<br>series<br>sparse<br>strings<br>style<br>【文件】 ： \pandas\core\</strong>init__.py<br>crosstab<br>函数 crosstab 模块所属：pandas.tools.pivot:<br>crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, dropna=True)<br>Compute a simple cross-tabulation of two (or more) factors. By default<br>computes a frequency table of the factors unless an array of values and an<br>aggregation function are passed<br>【参数】<br>———-index : array-like, Series, or list of arrays/Series<br>Values to group by in the rows<br>columns : array-like, Series, or list of arrays/Series<br>Values to group by in the columns<br>values : array-like, optional<br>Array of values to aggregate according to the factors<br>aggfunc : function, optional<br>If no values array is passed, computes a frequency table<br>rownames : sequence, default None<br>If passed, must match number of row arrays passed<br>colnames : sequence, default None<br>If passed, must match number of column arrays passed<br>margins : boolean, default False<br>Add row/column margins (subtotals)<br>dropna : boolean, default True<br>Do not include columns whose entries are all NaN<br>【注意】<br>—–Any Series passed will have their name attributes used unless row or column<br>names for the cross-tabulation are specified<br>【示例】<br>——–&gt;&gt;&gt; a<br>array([foo, foo, foo, foo, bar, bar,<br>bar, bar, foo, foo, foo], dtype=object)<br>1024<blockquote>
<blockquote>
<blockquote>
<p>b<br>array([one, one, one, two, one, one,<br>one, two, two, two, one], dtype=object)<br>c<br>array([dull, dull, shiny, dull, dull, shiny,<br>shiny, dull, shiny, shiny, shiny], dtype=object)<br>crosstab(a, [b, c], rownames=[‘a’], colnames=[‘b’, ‘c’])<br>b one two<br>c dull shiny dull shiny<br>a<br>bar 1 2 1 0<br>foo 2 2 1 2<br>【返回值】<br>——-crosstab : DataFrame<br>cut<br>函数 cut 模块所属：pandas.tools.tile:<br>cut(x, bins, right=True, labels=None, retbins=False, precision=3, include_lowest=False)<br>Return indices of half-open bins to which each value of <code>x</code> belongs.<br>【参数】<br>———-x : array-like<br>Input array to be binned. It has to be 1-dimensional.<br>bins : int or sequence of scalars<br>If <code>bins</code> is an int, it defines the number of equal-width bins in the<br>range of <code>x</code>. However, in this case, the range of <code>x</code> is extended<br>by .1% on each side to include the min or max values of <code>x</code>. If<br><code>bins</code> is a sequence it defines the bin edges allowing for<br>non-uniform bin width. No extension of the range of <code>x</code> is done in<br>this case.<br>right : bool, optional<br>Indicates whether the bins include the rightmost edge or not. If<br>right == True (the default), then the bins [1,2,3,4] indicate<br>(1,2], (2,3], (3,4].<br>labels : array or boolean, default None<br>Used as labels for the resulting bins. Must be of the same length as the resulting<br>bins. If False, return only integer indicators of the bins.<br>retbins : bool, optional<br>Whether to return the bins or not. Can be useful if bins is given<br>as a scalar.<br>precision : int<br>The precision at which to store and display the bins labels<br>include_lowest : bool<br>Whether the first interval should be left-inclusive or not.<br>1025<br>【返回值】<br>——-out : Categorical or Series or array of integers if labels is False<br>The return type (Categorical or Series) depends on the input: a Series of type category if<br>input is a Series else Categorical. Bins are represented as categories when categorical<br>data is returned.<br>bins : ndarray of floats<br>Returned only if <code>retbins</code> is True.<br>【注意】<br>—–The <code>cut</code> function can be useful for going from a continuous variable to<br>a categorical variable. For example, <code>cut</code> could convert ages to groups<br>of age ranges.<br>Any NA values will be NA in the result. Out of bounds values will be NA in<br>the resulting Categorical object<br>【示例】<br>——–&gt;&gt;&gt; pd.cut(np.array([.2, 1.4, 2.5, 6.2, 9.7, 2.1]), 3, retbins=True)<br>([(0.191, 3.367], (0.191, 3.367], (0.191, 3.367], (3.367, 6.533], (6.533, 9.7], (0.191, 3.367]]<br>Categories (3, object): [(0.191, 3.367] &lt; (3.367, 6.533] &lt; (6.533, 9.7]],<br>array([ 0.1905 , 3.36666667, 6.53333333, 9.7 ]))<br>pd.cut(np.array([.2, 1.4, 2.5, 6.2, 9.7, 2.1]), 3, labels=[“good”,”medium”,”bad”])<br>[good, good, good, medium, bad, good]<br>Categories (3, object): [good &lt; medium &lt; bad]<br>pd.cut(np.ones(5), 4, labels=False)<br>array([1, 1, 1, 1, 1], dtype=int64)<br>date_range<br>函数 date_range 模块所属：pandas.tseries.index:<br>date_range(start=None, end=None, periods=None, freq=’D’, tz=None, normalize=False, name=None, closed=None, <strong>kwargs)<br>Return a fixed frequency datetime index, with day (calendar) as the default<br>frequency<br>【参数】<br>———-start : string or datetime-like, default None<br>Left bound for generating dates<br>end : string or datetime-like, default None<br>Right bound for generating dates<br>periods : integer or None, default None<br>If None, must specify start and end<br>freq : string or DateOffset, default ‘D’ (calendar daily)<br>Frequency strings can have multiples, e.g. ‘5H’<br>1026<br>tz : string or None<br>Time zone name for returning localized DatetimeIndex, for example<br>Asia/Hong_Kong<br>normalize : bool, default False<br>Normalize start/end dates to midnight before generating date range<br>name : str, default None<br>Name of the resulting index<br>closed : string or None, default None<br>Make the interval closed with respect to the given frequency to<br>the ‘left’, ‘right’, or both sides (None)<br>【注意】<br>—–2 of start, end, or periods must be specified<br>【返回值】<br>——-rng : DatetimeIndex<br>datetime<br>datetime in module datetime:<br>类定义：datetime(date)<br>| datetime(year, month, day[, hour[, minute[, second[, microsecond[,tzinfo]]]]])<br>|<br>| The year, month and day arguments are required. tzinfo may be None, or an<br>| instance of a tzinfo subclass. The remaining arguments may be ints.<br>|<br>| 【方法排序】<br>| datetime<br>| date<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>add</strong>(self, value, /)<br>| Return self+value.<br>|<br>| <strong>eq</strong>(self, value, /)<br>| Return self==value.<br>|<br>| <strong>ge</strong>(self, value, /)<br>| Return self&gt;=value.<br>|<br>| <strong>getattribute</strong>(self, name, /)<br>| Return getattr(self, name).<br>|<br>| <strong>gt</strong>(self, value, /)<br>| Return self&gt;value.<br>1027<br>|<br>| <strong>hash</strong>(self, /)<br>| Return hash(self).<br>|<br>| <strong>le</strong>(self, value, /)<br>| Return self&lt;=value.<br>|<br>| <strong>lt</strong>(self, value, /)<br>| Return self&lt;value.<br>|<br>| <strong>ne</strong>(self, value, /)<br>| Return self!=value.<br>|<br>| <strong>new</strong>(*args, </strong>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| <strong>radd</strong>(self, value, /)<br>| Return value+self.<br>|<br>| <strong>reduce</strong>(…)<br>| <strong>reduce</strong>() -&gt; (cls, state)<br>|<br>| <strong>repr</strong>(self, /)<br>| Return repr(self).<br>|<br>| <strong>rsub</strong>(self, value, /)<br>| Return value-self.<br>|<br>| <strong>str</strong>(self, /)<br>| Return str(self).<br>|<br>| <strong>sub</strong>(self, value, /)<br>| Return self-value.<br>|<br>| astimezone(…)<br>| tz -&gt; convert to local time in new timezone tz<br>|<br>| combine(…) from builtins.type<br>| date, time -&gt; datetime with same date and time fields<br>|<br>| ctime(…)<br>| Return ctime() style string.<br>|<br>| date(…)<br>| Return date object with same year, month and day.<br>|<br>| dst(…)<br>| Return self.tzinfo.dst(self).<br>|<br>| fromtimestamp(…) from builtins.type<br>| timestamp[, tz] -&gt; tz’s local time from POSIX timestamp.<br>|<br>| isoformat(…)<br>| [sep] -&gt; string in ISO 8601 format, YYYY-MM-DDTHH:MM:SS[.mmmmmm][+HH:MM].<br>|<br>| sep is used to separate the year from the time, and defaults to ‘T’.<br>|<br>1028<br>| now(tz=None) from builtins.type<br>| Returns new datetime object representing current time local to tz.<br>|<br>| tz<br>| Timezone object.<br>|<br>| If no tz is specified, uses local timezone.<br>|<br>| replace(…)<br>| Return datetime with new specified fields.<br>|<br>| strptime(…) from builtins.type<br>| string, format -&gt; new datetime parsed from a string (like time.strptime()).<br>|<br>| time(…)<br>| Return time object with same time but with tzinfo=None.<br>|<br>| timestamp(…)<br>| Return POSIX timestamp as float.<br>|<br>| timetuple(…)<br>| Return time tuple, compatible with time.localtime().<br>|<br>| timetz(…)<br>| Return time object with same time and tzinfo.<br>|<br>| tzname(…)<br>| Return self.tzinfo.tzname(self).<br>|<br>| utcfromtimestamp(…) from builtins.type<br>| Construct a naive UTC datetime from a POSIX timestamp.<br>|<br>| utcnow(…) from builtins.type<br>| Return a new datetime representing UTC day and time.<br>|<br>| utcoffset(…)<br>| Return self.tzinfo.utcoffset(self).<br>|<br>| utctimetuple(…)<br>| Return UTC time tuple, compatible with time.localtime().<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| hour<br>|<br>| microsecond<br>|<br>| minute<br>|<br>| second<br>|<br>| tzinfo<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>1029<br>| max = datetime.datetime(9999, 12, 31, 23, 59, 59, 999999)<br>|<br>| min = datetime.datetime(1, 1, 1, 0, 0)<br>|<br>| resolution = datetime.timedelta(0, 0, 1)<br>|<br>| ———————————————————————-| Methods inherited from date:<br>|<br>| <strong>format</strong>(…)<br>| Formats self with strftime.<br>|<br>| fromordinal(…) from builtins.type<br>| int -&gt; date corresponding to a proleptic Gregorian ordinal.<br>|<br>| isocalendar(…)<br>| Return a 3-tuple containing ISO year, week number, and weekday.<br>|<br>| isoweekday(…)<br>| Return the day of the week represented by the date.<br>| Monday == 1 … Sunday == 7<br>|<br>| strftime(…)<br>| format -&gt; strftime() style string.<br>|<br>| today(…) from builtins.type<br>| Current date or datetime: same as self.<strong>class</strong>.fromtimestamp(time.time()).<br>|<br>| toordinal(…)<br>| Return proleptic Gregorian ordinal. January 1 of year 1 is day 1.<br>|<br>| weekday(…)<br>| Return the day of the week represented by the date.<br>| Monday == 0 … Sunday == 6<br>|<br>| ———————————————————————-| Data descriptors inherited from date:<br>|<br>| day<br>|<br>| month<br>|<br>| year<br>datetools<br>所属模块：pandas.core.datetools in pandas.core:<br>【名称】<br>pandas.core.datetools - A collection of random tools for dealing with dates in Python<br>1030<br>【函数】<br>callable(obj, /)<br>Return whether the object is callable (i.e., some kind of function).<br>Note that classes are callable, as are instances of classes with a<br><strong>call</strong>() method.<br>normalize_date(…)<br>Normalize datetime.datetime value to midnight. Returns datetime.date as a<br>datetime.datetime at midnight<br>【返回值】<br>——-normalized : datetime.datetime or Timestamp<br>【数据】<br>DAYS = [‘MON’, ‘TUE’, ‘WED’, ‘THU’, ‘FRI’, ‘SAT’, ‘SUN’]<br>MONTHS = [‘JAN’, ‘FEB’, ‘MAR’, ‘APR’, ‘MAY’, ‘JUN’, ‘JUL’, ‘AUG’, ‘SEP…<br>OLE_TIME_ZERO = datetime.datetime(1899, 12, 30, 0, 0)<br>bday = <businessday><br>bmonthBegin = <businessmonthbegin><br>bmonthEnd = <businessmonthend><br>bquarterEnd = <businessquarterend: startingmonth="3"><br>businessDay = <businessday><br>byearEnd = <businessyearend: month="12"><br>cbmonthBegin = <custombusinessmonthbegin><br>cbmonthEnd = <custombusinessmonthend><br>cday = <custombusinessday><br>customBusinessDay = <custombusinessday><br>customBusinessMonthBegin = <custombusinessmonthbegin><br>customBusinessMonthEnd = <custombusinessmonthend><br>day = <dateoffset><br>monthEnd = <monthend><br>need_suffix = [‘QS’, ‘BQ’, ‘BQS’, ‘AS’, ‘BA’, ‘BAS’]<br>opattern = re.compile(‘([-]?\d<em>)\s</em>([A-Za-z]+([-@][\dA-Za-z-]…<br>quarterEnd = <quarterend: startingmonth="3"><br>thisBMonthEnd = <0 *="" businessmonthends=""><br>thisBQuarterEnd = <0 *="" businessquarterends:="" startingmonth="3"><br>thisMonthEnd = <0 *="" monthends=""><br>thisQuarterEnd = <0 *="" quarterends:="" startingmonth="3"><br>thisYearBegin = <0 *="" yearbegins:="" month="1"><br>thisYearEnd = <0 *="" yearends:="" month="12"><br>week = <week: weekday="None"><br>yearBegin = <yearbegin: month="1"><br>yearEnd = <yearend: month="12"><br>【文件】 ： \pandas\core\datetools.py<br>1031<br>describe_option<br>CallableDynamicDoc 模块所属：pandas.core.config object:<br>类定义：CallableDynamicDoc(builtins.object)<br>| 【方法定义】<br>|<br>| <strong>call</strong>(self, <em>args, **kwds)<br>| Call self as a function.<br>|<br>| <strong>init</strong>(self, func, doc_tmpl)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>eval<br>函数 eval 模块所属：pandas.computation.eval:<br>eval(expr, parser=’pandas’, engine=’numexpr’, truediv=True, local_dict=None, global_dict=None, resolvers=(), level=0,<br>target=None)<br>Evaluate a Python expression as a string using various backends.<br>The following arithmetic operations are supported: <code>+</code>, <code>-</code>, ``</em><code>,</code>/<code>,</code>**<code>,</code>%<code>,</code>//<code>(python engine only) along with the following
boolean operations:</code>|<code>(or),</code>&amp;<code>(and), and</code>~<code>(not).
Additionally, the</code>‘pandas’<code>parser allows the use of :keyword:`and`,
:keyword:`or`, and :keyword:`not` with the same semantics as the
corresponding bitwise operators. :class:`~pandas.Series` and
:class:`~pandas.DataFrame` objects are supported and behave as they would
with plain ol&#39; Python evaluation.
【参数】
----------expr : str or unicode
The expression to evaluate. This string cannot contain any Python
`statements
&lt;http://docs.python.org/2/reference/simple_stmts.html#simple-statements&gt;`__,
only Python `expressions
1032
&lt;http://docs.python.org/2/reference/simple_stmts.html#expression-statements&gt;`__.
parser : string, default &#39;pandas&#39;, {&#39;pandas&#39;, &#39;python&#39;}
The parser to use to construct the syntax tree from the expression. The
default of</code>‘pandas’<code>parses code slightly different than standard
Python. Alternatively, you can parse an expression using the</code>‘python’<code>` parser to retain strict Python semantics. See the
:ref:</code>enhancing performance <enhancingperf.eval>` documentation for<br>more details.<br>engine : string, default ‘numexpr’, {‘python’, ‘numexpr’}<br>The engine used to evaluate the expression. Supported engines are</enhancingperf.eval></yearend:></yearbegin:></week:></0></0></0></0></0></0></quarterend:></monthend></dateoffset></custombusinessmonthend></custombusinessmonthbegin></custombusinessday></custombusinessday></custombusinessmonthend></custombusinessmonthbegin></businessyearend:></businessday></businessquarterend:></businessmonthend></businessmonthbegin></businessday></p>
</blockquote>
</blockquote>
</blockquote>
</class></class></class></class></class></li>
</ul>
<ul>
<li><code>&#39;numexpr&#39;</code>: This default engine evaluates pandas objects using<br>numexpr for large speed ups in complex expressions<br>with large frames.</li>
<li><code>&#39;python&#39;</code>: Performs operations as if you had <code>eval</code>‘d in top<br>level python. This engine is generally not that useful.<br>More backends may be available in the future.<br>truediv : bool, optional<br>Whether to use true division, like in Python &gt;= 3<br>local_dict : dict or None, optional<br>A dictionary of local variables, taken from locals() by default.<br>global_dict : dict or None, optional<br>A dictionary of global variables, taken from globals() by default.<br>resolvers : list of dict-like or None, optional<br>A list of objects implementing the <code>__getitem__</code> special method that<br>you can use to inject an additional collection of namespaces to use for<br>variable lookup. For example, this is used in the<br>:meth:<code>~pandas.DataFrame.query</code> method to inject the<br>:attr:<code>~pandas.DataFrame.index</code> and :attr:<code>~pandas.DataFrame.columns</code><br>variables that refer to their respective :class:<code>~pandas.DataFrame</code><br>instance attributes.<br>level : int, optional<br>The number of prior stack frames to traverse and add to the current<br>scope. Most users will <strong>not</strong> need to change this parameter.<br>target : a target object for assignment, optional, default is None<br>essentially this is a passed in resolver<br>【返回值】<br>——-ndarray, numeric scalar, DataFrame, Series<br>【注意】<br>—–The <code>dtype</code> of any objects involved in an arithmetic <code>%</code> operation are<br>recursively cast to <code>float64</code>.<br>See the :ref:<code>enhancing performance &lt;enhancingperf.eval&gt;</code> documentation for<br>more details.<br>【参见】<br>——–pandas.DataFrame.query<br>pandas.DataFrame.eval<br>1033<br>ewma<br>函数 ewma 模块所属：pandas.stats.moments:<br>ewma(arg, com=None, span=None, halflife=None, min_periods=0, freq=None, adjust=True, how=None, ignore_na=False)<br>Exponentially-weighted moving average<br>【参数】<br>———-arg : Series, DataFrame<br>com : float. optional<br>Center of mass: :math:<code>\alpha = 1 / (1 + com)</code>,<br>span : float, optional<br>Specify decay in terms of span, :math:<code>\alpha = 2 / (span + 1)</code><br>halflife : float, optional<br>Specify decay in terms of halflife, :math:<code>\alpha = 1 - exp(log(0.5) / halflife)</code><br>min_periods : int, default 0<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : None or string alias / date offset object, default=None<br>Frequency to conform to before computing statistic<br>adjust : boolean, default True<br>Divide by decaying adjustment factor in beginning periods to account for<br>imbalance in relative weightings (viewing EWMA as a moving average)<br>how : string, default ‘mean’<br>Method for down- or re-sampling<br>ignore_na : boolean, default False<br>Ignore missing values when calculating weights;<br>specify True to reproduce pre-0.15.0 behavior<br>【返回值】<br>——-y : type of input argument<br>【注意】<br>—–Either center of mass, span or halflife must be specified<br>EWMA is sometimes specified using a “span” parameter <code>s</code>, we have that the<br>decay parameter :math:<code>\alpha</code> is related to the span as<br>:math:<code>\alpha = 2 / (s + 1) = 1 / (1 + c)</code><br>where <code>c</code> is the center of mass. Given a span, the associated center of mass is<br>:math:<code>c = (s - 1) / 2</code><br>So a “20-day EWMA” would have center 9.5.<br>When adjust is True (default), weighted averages are calculated using weights<br>(1-alpha)<strong>(n-1), (1-alpha)</strong>(n-2), …, 1-alpha, 1.<br>1034<br>When adjust is False, weighted averages are calculated recursively as:<br>weighted_average[0] = arg[0];<br>weighted_average[i] = (1-alpha)<em>weighted_average[i-1] + alpha</em>arg[i].<br>When ignore_na is False (default), weights are based on absolute positions.<br>For example, the weights of x and y used in calculating the final weighted<br>average of [x, None, y] are (1-alpha)<strong>2 and 1 (if adjust is True), and<br>(1-alpha)</strong>2 and alpha (if adjust is False).<br>When ignore_na is True (reproducing pre-0.15.0 behavior), weights are based on<br>relative positions. For example, the weights of x and y used in calculating<br>the final weighted average of [x, None, y] are 1-alpha and 1 (if adjust is<br>True), and 1-alpha and alpha (if adjust is False).<br>More details can be found at<br><a href="http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-moment-functions" target="_blank" rel="external">http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-moment-functions</a><br>ewmcorr<br>函数 ewmcorr 模块所属：pandas.stats.moments:<br>ewmcorr(arg1, arg2=None, com=None, span=None, halflife=None, min_periods=0, freq=None, pairwise=None, how=None,<br>ignore_na=False, adjust=True)<br>Exponentially-weighted moving correlation<br>【参数】<br>———-arg1 : Series, DataFrame, or ndarray<br>arg2 : Series, DataFrame, or ndarray, optional<br>if not supplied then will default to arg1 and produce pairwise output<br>com : float. optional<br>Center of mass: :math:<code>\alpha = 1 / (1 + com)</code>,<br>span : float, optional<br>Specify decay in terms of span, :math:<code>\alpha = 2 / (span + 1)</code><br>halflife : float, optional<br>Specify decay in terms of halflife, :math:<code>\alpha = 1 - exp(log(0.5) / halflife)</code><br>min_periods : int, default 0<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : None or string alias / date offset object, default=None<br>Frequency to conform to before computing statistic<br>adjust : boolean, default True<br>Divide by decaying adjustment factor in beginning periods to account for<br>imbalance in relative weightings (viewing EWMA as a moving average)<br>how : string, default ‘mean’<br>Method for down- or re-sampling<br>ignore_na : boolean, default False<br>Ignore missing values when calculating weights;<br>specify True to reproduce pre-0.15.0 behavior<br>pairwise : bool, default False<br>1035<br>If False then only matching columns between arg1 and arg2 will be used and<br>the output will be a DataFrame.<br>If True then all pairwise combinations will be calculated and the output<br>will be a Panel in the case of DataFrame inputs. In the case of missing<br>elements, only complete pairwise observations will be used.<br>【返回值】<br>——-y : type of input argument<br>【注意】<br>—–Either center of mass, span or halflife must be specified<br>EWMA is sometimes specified using a “span” parameter <code>s</code>, we have that the<br>decay parameter :math:<code>\alpha</code> is related to the span as<br>:math:<code>\alpha = 2 / (s + 1) = 1 / (1 + c)</code><br>where <code>c</code> is the center of mass. Given a span, the associated center of mass is<br>:math:<code>c = (s - 1) / 2</code><br>So a “20-day EWMA” would have center 9.5.<br>When adjust is True (default), weighted averages are calculated using weights<br>(1-alpha)<strong>(n-1), (1-alpha)</strong>(n-2), …, 1-alpha, 1.<br>When adjust is False, weighted averages are calculated recursively as:<br>weighted_average[0] = arg[0];<br>weighted_average[i] = (1-alpha)<em>weighted_average[i-1] + alpha</em>arg[i].<br>When ignore_na is False (default), weights are based on absolute positions.<br>For example, the weights of x and y used in calculating the final weighted<br>average of [x, None, y] are (1-alpha)<strong>2 and 1 (if adjust is True), and<br>(1-alpha)</strong>2 and alpha (if adjust is False).<br>When ignore_na is True (reproducing pre-0.15.0 behavior), weights are based on<br>relative positions. For example, the weights of x and y used in calculating<br>the final weighted average of [x, None, y] are 1-alpha and 1 (if adjust is<br>True), and 1-alpha and alpha (if adjust is False).<br>More details can be found at<br><a href="http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-moment-functions" target="_blank" rel="external">http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-moment-functions</a><br>ewmcov<br>函数 ewmcov 模块所属：pandas.stats.moments:<br>ewmcov(arg1, arg2=None, com=None, span=None, halflife=None, min_periods=0, bias=False, freq=None, pairwise=None,<br>how=None, ignore_na=False, adjust=True)<br>Exponentially-weighted moving covariance<br>1036<br>【参数】<br>———-arg1 : Series, DataFrame, or ndarray<br>arg2 : Series, DataFrame, or ndarray, optional<br>if not supplied then will default to arg1 and produce pairwise output<br>com : float. optional<br>Center of mass: :math:<code>\alpha = 1 / (1 + com)</code>,<br>span : float, optional<br>Specify decay in terms of span, :math:<code>\alpha = 2 / (span + 1)</code><br>halflife : float, optional<br>Specify decay in terms of halflife, :math:<code>\alpha = 1 - exp(log(0.5) / halflife)</code><br>min_periods : int, default 0<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : None or string alias / date offset object, default=None<br>Frequency to conform to before computing statistic<br>adjust : boolean, default True<br>Divide by decaying adjustment factor in beginning periods to account for<br>imbalance in relative weightings (viewing EWMA as a moving average)<br>how : string, default ‘mean’<br>Method for down- or re-sampling<br>ignore_na : boolean, default False<br>Ignore missing values when calculating weights;<br>specify True to reproduce pre-0.15.0 behavior<br>pairwise : bool, default False<br>If False then only matching columns between arg1 and arg2 will be used and<br>the output will be a DataFrame.<br>If True then all pairwise combinations will be calculated and the output<br>will be a Panel in the case of DataFrame inputs. In the case of missing<br>elements, only complete pairwise observations will be used.<br>【返回值】<br>——-y : type of input argument<br>【注意】<br>—–Either center of mass, span or halflife must be specified<br>EWMA is sometimes specified using a “span” parameter <code>s</code>, we have that the<br>decay parameter :math:<code>\alpha</code> is related to the span as<br>:math:<code>\alpha = 2 / (s + 1) = 1 / (1 + c)</code><br>where <code>c</code> is the center of mass. Given a span, the associated center of mass is<br>:math:<code>c = (s - 1) / 2</code><br>So a “20-day EWMA” would have center 9.5.<br>When adjust is True (default), weighted averages are calculated using weights<br>(1-alpha)<strong>(n-1), (1-alpha)</strong>(n-2), …, 1-alpha, 1.<br>When adjust is False, weighted averages are calculated recursively as:<br>weighted_average[0] = arg[0];<br>weighted_average[i] = (1-alpha)<em>weighted_average[i-1] + alpha</em>arg[i].<br>When ignore_na is False (default), weights are based on absolute positions.<br>1037<br>For example, the weights of x and y used in calculating the final weighted<br>average of [x, None, y] are (1-alpha)<strong>2 and 1 (if adjust is True), and<br>(1-alpha)</strong>2 and alpha (if adjust is False).<br>When ignore_na is True (reproducing pre-0.15.0 behavior), weights are based on<br>relative positions. For example, the weights of x and y used in calculating<br>the final weighted average of [x, None, y] are 1-alpha and 1 (if adjust is<br>True), and 1-alpha and alpha (if adjust is False).<br>More details can be found at<br><a href="http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-moment-functions" target="_blank" rel="external">http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-moment-functions</a><br>ewmstd<br>函数 ewmstd 模块所属：pandas.stats.moments:<br>ewmstd(arg, com=None, span=None, halflife=None, min_periods=0, bias=False, ignore_na=False, adjust=True)<br>Exponentially-weighted moving std<br>【参数】<br>———-arg : Series, DataFrame<br>com : float. optional<br>Center of mass: :math:<code>\alpha = 1 / (1 + com)</code>,<br>span : float, optional<br>Specify decay in terms of span, :math:<code>\alpha = 2 / (span + 1)</code><br>halflife : float, optional<br>Specify decay in terms of halflife, :math:<code>\alpha = 1 - exp(log(0.5) / halflife)</code><br>min_periods : int, default 0<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : None or string alias / date offset object, default=None<br>Frequency to conform to before computing statistic<br>adjust : boolean, default True<br>Divide by decaying adjustment factor in beginning periods to account for<br>imbalance in relative weightings (viewing EWMA as a moving average)<br>how : string, default ‘mean’<br>Method for down- or re-sampling<br>ignore_na : boolean, default False<br>Ignore missing values when calculating weights;<br>specify True to reproduce pre-0.15.0 behavior<br>bias : boolean, default False<br>Use a standard estimation bias correction<br>【返回值】<br>——-y : type of input argument<br>【注意】</li>
</ul>
<hr>
<p>1038<br>Either center of mass, span or halflife must be specified<br>EWMA is sometimes specified using a “span” parameter <code>s</code>, we have that the<br>decay parameter :math:<code>\alpha</code> is related to the span as<br>:math:<code>\alpha = 2 / (s + 1) = 1 / (1 + c)</code><br>where <code>c</code> is the center of mass. Given a span, the associated center of mass is<br>:math:<code>c = (s - 1) / 2</code><br>So a “20-day EWMA” would have center 9.5.<br>When adjust is True (default), weighted averages are calculated using weights<br>(1-alpha)<strong>(n-1), (1-alpha)</strong>(n-2), …, 1-alpha, 1.<br>When adjust is False, weighted averages are calculated recursively as:<br>weighted_average[0] = arg[0];<br>weighted_average[i] = (1-alpha)<em>weighted_average[i-1] + alpha</em>arg[i].<br>When ignore_na is False (default), weights are based on absolute positions.<br>For example, the weights of x and y used in calculating the final weighted<br>average of [x, None, y] are (1-alpha)<strong>2 and 1 (if adjust is True), and<br>(1-alpha)</strong>2 and alpha (if adjust is False).<br>When ignore_na is True (reproducing pre-0.15.0 behavior), weights are based on<br>relative positions. For example, the weights of x and y used in calculating<br>the final weighted average of [x, None, y] are 1-alpha and 1 (if adjust is<br>True), and 1-alpha and alpha (if adjust is False).<br>More details can be found at<br><a href="http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-moment-functions" target="_blank" rel="external">http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-moment-functions</a><br>ewmvar<br>函数 ewmvar 模块所属：pandas.stats.moments:<br>ewmvar(arg, com=None, span=None, halflife=None, min_periods=0, bias=False, freq=None, how=None, ignore_na=False,<br>adjust=True)<br>Exponentially-weighted moving variance<br>【参数】<br>———-arg : Series, DataFrame<br>com : float. optional<br>Center of mass: :math:<code>\alpha = 1 / (1 + com)</code>,<br>span : float, optional<br>Specify decay in terms of span, :math:<code>\alpha = 2 / (span + 1)</code><br>halflife : float, optional<br>Specify decay in terms of halflife, :math:<code>\alpha = 1 - exp(log(0.5) / halflife)</code><br>min_periods : int, default 0<br>Minimum number of observations in window required to have a value<br>1039<br>(otherwise result is NA).<br>freq : None or string alias / date offset object, default=None<br>Frequency to conform to before computing statistic<br>adjust : boolean, default True<br>Divide by decaying adjustment factor in beginning periods to account for<br>imbalance in relative weightings (viewing EWMA as a moving average)<br>how : string, default ‘mean’<br>Method for down- or re-sampling<br>ignore_na : boolean, default False<br>Ignore missing values when calculating weights;<br>specify True to reproduce pre-0.15.0 behavior<br>bias : boolean, default False<br>Use a standard estimation bias correction<br>【返回值】<br>——-y : type of input argument<br>【注意】<br>—–Either center of mass, span or halflife must be specified<br>EWMA is sometimes specified using a “span” parameter <code>s</code>, we have that the<br>decay parameter :math:<code>\alpha</code> is related to the span as<br>:math:<code>\alpha = 2 / (s + 1) = 1 / (1 + c)</code><br>where <code>c</code> is the center of mass. Given a span, the associated center of mass is<br>:math:<code>c = (s - 1) / 2</code><br>So a “20-day EWMA” would have center 9.5.<br>When adjust is True (default), weighted averages are calculated using weights<br>(1-alpha)<strong>(n-1), (1-alpha)</strong>(n-2), …, 1-alpha, 1.<br>When adjust is False, weighted averages are calculated recursively as:<br>weighted_average[0] = arg[0];<br>weighted_average[i] = (1-alpha)<em>weighted_average[i-1] + alpha</em>arg[i].<br>When ignore_na is False (default), weights are based on absolute positions.<br>For example, the weights of x and y used in calculating the final weighted<br>average of [x, None, y] are (1-alpha)<strong>2 and 1 (if adjust is True), and<br>(1-alpha)</strong>2 and alpha (if adjust is False).<br>When ignore_na is True (reproducing pre-0.15.0 behavior), weights are based on<br>relative positions. For example, the weights of x and y used in calculating<br>the final weighted average of [x, None, y] are 1-alpha and 1 (if adjust is<br>True), and 1-alpha and alpha (if adjust is False).<br>More details can be found at<br><a href="http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-moment-functions" target="_blank" rel="external">http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-moment-functions</a><br>1040<br>ewmvol<br>函数 ewmstd 模块所属：pandas.stats.moments:<br>ewmstd(arg, com=None, span=None, halflife=None, min_periods=0, bias=False, ignore_na=False, adjust=True)<br>Exponentially-weighted moving std<br>【参数】<br>———-arg : Series, DataFrame<br>com : float. optional<br>Center of mass: :math:<code>\alpha = 1 / (1 + com)</code>,<br>span : float, optional<br>Specify decay in terms of span, :math:<code>\alpha = 2 / (span + 1)</code><br>halflife : float, optional<br>Specify decay in terms of halflife, :math:<code>\alpha = 1 - exp(log(0.5) / halflife)</code><br>min_periods : int, default 0<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : None or string alias / date offset object, default=None<br>Frequency to conform to before computing statistic<br>adjust : boolean, default True<br>Divide by decaying adjustment factor in beginning periods to account for<br>imbalance in relative weightings (viewing EWMA as a moving average)<br>how : string, default ‘mean’<br>Method for down- or re-sampling<br>ignore_na : boolean, default False<br>Ignore missing values when calculating weights;<br>specify True to reproduce pre-0.15.0 behavior<br>bias : boolean, default False<br>Use a standard estimation bias correction<br>【返回值】<br>——-y : type of input argument<br>【注意】<br>—–Either center of mass, span or halflife must be specified<br>EWMA is sometimes specified using a “span” parameter <code>s</code>, we have that the<br>decay parameter :math:<code>\alpha</code> is related to the span as<br>:math:<code>\alpha = 2 / (s + 1) = 1 / (1 + c)</code><br>where <code>c</code> is the center of mass. Given a span, the associated center of mass is<br>:math:<code>c = (s - 1) / 2</code><br>So a “20-day EWMA” would have center 9.5.<br>When adjust is True (default), weighted averages are calculated using weights<br>(1-alpha)<strong>(n-1), (1-alpha)</strong>(n-2), …, 1-alpha, 1.<br>When adjust is False, weighted averages are calculated recursively as:<br>1041<br>weighted_average[0] = arg[0];<br>weighted_average[i] = (1-alpha)<em>weighted_average[i-1] + alpha</em>arg[i].<br>When ignore_na is False (default), weights are based on absolute positions.<br>For example, the weights of x and y used in calculating the final weighted<br>average of [x, None, y] are (1-alpha)<strong>2 and 1 (if adjust is True), and<br>(1-alpha)</strong>2 and alpha (if adjust is False).<br>When ignore_na is True (reproducing pre-0.15.0 behavior), weights are based on<br>relative positions. For example, the weights of x and y used in calculating<br>the final weighted average of [x, None, y] are 1-alpha and 1 (if adjust is<br>True), and 1-alpha and alpha (if adjust is False).<br>More details can be found at<br><a href="http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-moment-functions" target="_blank" rel="external">http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-moment-functions</a><br>expanding_apply<br>函数 expanding_apply 模块所属：pandas.stats.moments:<br>expanding_apply(arg, func, min_periods=1, freq=None, args=(), kwargs={})<br>Generic expanding function application.<br>【参数】<br>———-arg : Series, DataFrame<br>func : function<br>Must produce a single value from an ndarray input<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>args : tuple<br>Passed on to func<br>kwargs : dict<br>Passed on to func<br>【返回值】<br>——-y : type of input argument<br>【注意】<br>—–The <code>freq</code> keyword is used to conform time series data to a specified<br>frequency by resampling the data. This is done with the default parameters<br>of :meth:<code>~pandas.Series.resample</code> (i.e. using the <code>mean</code>).<br>1042<br>expanding_corr<br>函数 expanding_corr 模块所属：pandas.stats.moments:<br>expanding_corr(arg1, arg2=None, min_periods=1, freq=None, pairwise=None)<br>Expanding sample correlation.<br>【参数】<br>———-arg1 : Series, DataFrame, or ndarray<br>arg2 : Series, DataFrame, or ndarray, optional<br>if not supplied then will default to arg1 and produce pairwise output<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>pairwise : bool, default False<br>If False then only matching columns between arg1 and arg2 will be used and<br>the output will be a DataFrame.<br>If True then all pairwise combinations will be calculated and the output<br>will be a Panel in the case of DataFrame inputs. In the case of missing<br>elements, only complete pairwise observations will be used.<br>【返回值】<br>——-y : type depends on inputs<br>DataFrame / DataFrame -&gt; DataFrame (matches on columns) or Panel (pairwise)<br>DataFrame / Series -&gt; Computes result for each column<br>Series / Series -&gt; Series<br>expanding_corr_pairwise<br>函数 expanding_corr_pairwise 模块所属：pandas.stats.moments:<br>expanding_corr_pairwise(df1, df2=None, min_periods=1, freq=None)<br>Deprecated. Use expanding_corr(…, pairwise=True) instead.<br>Pairwise expanding sample correlation<br>【参数】<br>———-df1 : DataFrame<br>1043<br>df2 : DataFrame<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>【返回值】<br>——-y : Panel whose items are df1.index values<br>expanding_count<br>函数 expanding_count 模块所属：pandas.stats.moments:<br>expanding_count(arg, freq=None)<br>Expanding count of number of non-NaN observations.<br>【参数】<br>———-arg : DataFrame or numpy ndarray-like<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>【返回值】<br>——-expanding_count : type of caller<br>【注意】<br>—–The <code>freq</code> keyword is used to conform time series data to a specified<br>frequency by resampling the data. This is done with the default parameters<br>of :meth:<code>~pandas.Series.resample</code> (i.e. using the <code>mean</code>).<br>expanding_cov<br>函数 expanding_cov 模块所属：pandas.stats.moments:<br>expanding_cov(arg1, arg2=None, min_periods=1, freq=None, pairwise=None, ddof=1)<br>Unbiased expanding covariance.<br>1044<br>【参数】<br>———-arg1 : Series, DataFrame, or ndarray<br>arg2 : Series, DataFrame, or ndarray, optional<br>if not supplied then will default to arg1 and produce pairwise output<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>pairwise : bool, default False<br>If False then only matching columns between arg1 and arg2 will be used and<br>the output will be a DataFrame.<br>If True then all pairwise combinations will be calculated and the output<br>will be a Panel in the case of DataFrame inputs. In the case of missing<br>elements, only complete pairwise observations will be used.<br>ddof : int, default 1<br>Delta Degrees of Freedom. The divisor used in calculations<br>is <code>N - ddof</code>, where <code>N</code> represents the number of elements.<br>【返回值】<br>——-y : type depends on inputs<br>DataFrame / DataFrame -&gt; DataFrame (matches on columns) or Panel (pairwise)<br>DataFrame / Series -&gt; Computes result for each column<br>Series / Series -&gt; Series<br>expanding_kurt<br>函数 roll_kurt 模块所属：pandas.algos:<br>roll_kurt(…)<br>Unbiased expanding kurtosis.<br>【参数】<br>———-arg : Series, DataFrame<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>【返回值】<br>——-y : type of input argument<br>1045<br>expanding_max<br>函数 roll_max 模块所属：pandas.algos:<br>roll_max(…)<br>Moving max of 1d array of dtype=float64 along axis=0 ignoring NaNs.<br>Expanding maximum.<br>【参数】<br>———-arg : Series, DataFrame<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>【返回值】<br>——-y : type of input argument<br>expanding_mean<br>函数 roll_mean 模块所属：pandas.algos:<br>roll_mean(…)<br>Expanding mean.<br>【参数】<br>———-arg : Series, DataFrame<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>【返回值】<br>——-y : type of input argument<br>1046<br>expanding_median<br>函数 roll_median_c 模块所属：pandas.algos:<br>roll_median_c(…)<br>Expanding median.<br>【参数】<br>———-arg : Series, DataFrame<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>【返回值】<br>——-y : type of input argument<br>expanding_min<br>函数 roll_min 模块所属：pandas.algos:<br>roll_min(…)<br>Moving min of 1d array of dtype=float64 along axis=0 ignoring NaNs.<br>Expanding minimum.<br>【参数】<br>———-arg : Series, DataFrame<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>【返回值】<br>——-y : type of input argument<br>1047<br>expanding_quantile<br>函数 expanding_quantile 模块所属：pandas.stats.moments:<br>expanding_quantile(arg, quantile, min_periods=1, freq=None)<br>Expanding quantile.<br>【参数】<br>———-arg : Series, DataFrame<br>quantile : float<br>0 &lt;= quantile &lt;= 1<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>【返回值】<br>——-y : type of input argument<br>【注意】<br>—–The <code>freq</code> keyword is used to conform time series data to a specified<br>frequency by resampling the data. This is done with the default parameters<br>of :meth:<code>~pandas.Series.resample</code> (i.e. using the <code>mean</code>).<br>expanding_skew<br>函数 roll_skew 模块所属：pandas.algos:<br>roll_skew(…)<br>Unbiased expanding skewness.<br>【参数】<br>———-arg : Series, DataFrame<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>1048<br>as a frequency string or DateOffset object.<br>【返回值】<br>——-y : type of input argument<br>expanding_std<br>函数 <lambda> 模块所属：pandas.stats.moments:</lambda></p>
<p><lambda> lambda <em>a, *</em>kw<br>Expanding standard deviation.<br>【参数】<br>———-arg : Series, DataFrame<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>ddof : int, default 1<br>Delta Degrees of Freedom. The divisor used in calculations<br>is <code>N - ddof</code>, where <code>N</code> represents the number of elements.<br>【返回值】<br>——-y : type of input argument<br>expanding_sum<br>函数 roll_sum 模块所属：pandas.algos:<br>roll_sum(…)<br>Expanding sum.<br>【参数】<br>———-arg : Series, DataFrame<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>1049<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>【返回值】<br>——-y : type of input argument<br>expanding_var<br>函数 roll_var 模块所属：pandas.algos:<br>roll_var(…)<br>Numerically stable implementation using Welford’s method.<br>Expanding variance.<br>【参数】<br>———-arg : Series, DataFrame<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>ddof : int, default 1<br>Delta Degrees of Freedom. The divisor used in calculations<br>is <code>N - ddof</code>, where <code>N</code> represents the number of elements.<br>【返回值】<br>——-y : type of input argument<br>factorize<br>函数 factorize 模块所属：pandas.core.algorithms:<br>factorize(values, sort=False, order=None, na_sentinel=-1, size_hint=None)<br>Encode input values as an enumerated type or categorical variable</lambda></p>
<h2 id="【参数】"><a href="#【参数】" class="headerlink" title="【参数】"></a>【参数】</h2><p>1050<br>values : ndarray (1-d)<br>Sequence<br>sort : boolean, default False<br>Sort by values<br>order : deprecated<br>na_sentinel : int, default -1<br>Value to mark “not found”<br>size_hint : hint to the hashtable sizer<br>【返回值】<br>——-labels : the indexer to the original array<br>uniques : ndarray (1-d) or Index<br>the unique values. Index is returned when passed values is Index or Series<br>note: an array of Periods will ignore sort as it returns an always sorted PeriodIndex<br>fama_macbeth<br>函数 fama_macbeth 模块所属：pandas.stats.fama_macbeth:<br>fama_macbeth(**kwargs)<br>Runs Fama-MacBeth regression.<br>【参数】<br>———-Takes the same arguments as a panel OLS, in addition to:<br>nw_lags_beta: int<br>Newey-West adjusts the betas by the given lags<br>get_dummies<br>函数 get_dummies 模块所属：pandas.core.reshape:<br>get_dummies(data, prefix=None, prefix<em>sep=’</em>‘, dummy_na=False, columns=None, sparse=False)<br>Convert categorical variable into dummy/indicator variables<br>【参数】<br>———-data : array-like, Series, or DataFrame<br>prefix : string, list of strings, or dict of strings, default None<br>String to append DataFrame column names<br>1051<br>Pass a list with length equal to the number of columns<br>when calling get_dummies on a DataFrame. Alternativly, <code>prefix</code><br>can be a dictionary mapping column names to prefixes.<br>prefix<em>sep : string, default ‘</em>‘<br>If appending prefix, separator/delimiter to use. Or pass a<br>list or dictionary as with <code>prefix.</code><br>dummy_na : bool, default False<br>Add a column to indicate NaNs, if False NaNs are ignored.<br>columns : list-like, default None<br>Column names in the DataFrame to be encoded.<br>If <code>columns</code> is None then all the columns with<br><code>object</code> or <code>category</code> dtype will be converted.<br>sparse : bool, default False<br>Whether the dummy columns should be sparse or not. Returns<br>SparseDataFrame if <code>data</code> is a Series or if all columns are included.<br>Otherwise returns a DataFrame with some SparseBlocks.<br>.. versionadded:: 0.16.1<br>【返回值】<br>——-dummies : DataFrame or SparseDataFrame<br>【示例】<br>——–&gt;&gt;&gt; import pandas as pd</p>
<blockquote>
<blockquote>
<blockquote>
<p>s = pd.Series(list(‘abca’))<br>get_dummies(s)<br>a b c<br>0 1 0 0<br>1 0 1 0<br>2 0 0 1<br>3 1 0 0<br>s1 = [‘a’, ‘b’, np.nan]<br>get_dummies(s1)<br>a b<br>0 1 0<br>1 0 1<br>2 0 0<br>get_dummies(s1, dummy_na=True)<br>a b NaN<br>0 1 0 0<br>1 0 1 0<br>2 0 0 1<br>df = DataFrame({‘A’: [‘a’, ‘b’, ‘a’], ‘B’: [‘b’, ‘a’, ‘c’],<br>‘C’: [1, 2, 3]})<br>get_dummies(df, prefix=[‘col1’, ‘col2’]):<br>C col1_a col1_b col2_a col2_b col2_c<br>0 1 1 0 0 1 0<br>1 2 0 1 1 0 0<br>2 3 1 0 0 0 1<br>1052<br>参见：<code>Series.str.get_dummies</code>.<br>get_option<br>CallableDynamicDoc 模块所属：pandas.core.config object:<br>类定义：CallableDynamicDoc(builtins.object)<br>| 【方法定义】<br>|<br>| <strong>call</strong>(self, <em>args, <strong>kwds)<br>| Call self as a function.<br>|<br>| <strong>init</strong>(self, func, doc_tmpl)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>get_store<br>函数 get_store 模块所属：pandas.io.pytables:<br>get_store(path, </strong>kwargs)<br>Backwards compatible alias for <code>HDFStore</code><br>groupby<br>函数 groupby 模块所属：pandas.core.groupby:<br>1053<br>groupby(obj, by, *</em>kwds)<br>Class for grouping and aggregating relational data. See aggregate,<br>transform, and apply functions on this object.<br>It’s easiest to use obj.groupby(…) to use GroupBy, but you can also do:<br>::<br>grouped = groupby(obj, …)<br>【参数】<br>———-obj : pandas object<br>axis : int, default 0<br>level : int, default None<br>Level of MultiIndex<br>groupings : list of Grouping objects<br>Most users should ignore this<br>exclusions : array-like, optional<br>List of columns to exclude<br>name : string<br>Most users should ignore this<br>【注意】<br>—–After grouping, see aggregate, apply, and transform functions. Here are<br>some other brief notes about usage. When grouping by multiple groups, the<br>result index will be a MultiIndex (hierarchical) by default.<br>Iteration produces (key, group) tuples, i.e. chunking the data by group. So<br>you can write code like:<br>::<br>grouped = obj.groupby(keys, axis=axis)<br>for key, group in grouped:</p>
<h1 id="do-something-with-the-data"><a href="#do-something-with-the-data" class="headerlink" title="do something with the data"></a>do something with the data</h1><p>Function calls on GroupBy, if not specially implemented, “dispatch” to the<br>grouped data. So if you group a DataFrame and wish to invoke the std()<br>method on each group, you can simply do:<br>::<br>df.groupby(mapper).std()<br>rather than<br>::<br>df.groupby(mapper).aggregate(np.std)<br>You can pass arguments to these “wrapped” functions, too.<br>See the online documentation for full exposition on these topics and much<br>more<br>1054<br>【返回值】<br>——-<strong>Attributes</strong><br>groups : dict<br>{group name -&gt; group labels}<br>len(grouped) : int<br>Number of groups<br>hashtable<br>所属模块：pandas.hashtable in pandas:<br>【名称】<br>pandas.hashtable<br>【类型】<br>【内置对象】<br>Factorizer<br>Float64Vector<br>HashTable<br>Float64HashTable<br>Int64HashTable<br>PyObjectHashTable<br>StringHashTable<br>Int64Factorizer<br>Int64Vector<br>ObjectVector<br>class Factorizer(builtins.object)<br>| 【方法定义】<br>|<br>| <strong>init</strong>(self, /, <em>args, **kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>new</strong>(</em>args, <strong>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| factorize(…)<br>| Factorize values with nans replaced by na_sentinel<br>| &gt;&gt;&gt; factorize(np.array([1,2,np.nan], dtype=’O’), na_sentinel=20)<br>| array([ 0, 1, 20])<br>|<br>| get_count(…)<br>|<br>| unique(…)<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| count<br>1055<br>|<br>| table<br>|<br>| uniques<br>class Float64HashTable(HashTable)<br>| 【方法排序】<br>| Float64HashTable<br>| HashTable<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>contains</strong>(self, key, /)<br>| Return key in self.<br>|<br>| <strong>len</strong>(self, /)<br>| Return len(self).<br>|<br>| <strong>new</strong>(*args, </strong>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| factorize(…)<br>|<br>| get_item(…)<br>|<br>| get_labels(…)<br>|<br>| lookup(…)<br>|<br>| map_locations(…)<br>|<br>| set_item(…)<br>|<br>| unique(…)<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| <strong>pyx_vtable</strong> = <capsule object="" null=""><br>class Float64Vector(builtins.object)<br>| 【方法定义】<br>|<br>| <strong>len</strong>(self, /)<br>| Return len(self).<br>|<br>| <strong>new</strong>(<em>args, **kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| to_array(…)<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| <strong>pyx_vtable</strong> = <capsule object="" null=""><br>1056<br>class HashTable(builtins.object)<br>| 【方法定义】<br>|<br>| <strong>new</strong>(</capsule></em>args, <strong>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>class Int64Factorizer(builtins.object)<br>| 【方法定义】<br>|<br>| <strong>init</strong>(self, /, *args, </strong>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>new</strong>(<em>args, **kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| factorize(…)<br>|<br>| get_count(…)<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| count<br>|<br>| table<br>|<br>| uniques<br>class Int64HashTable(HashTable)<br>| 【方法排序】<br>| Int64HashTable<br>| HashTable<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>contains</strong>(self, key, /)<br>| Return key in self.<br>|<br>| <strong>len</strong>(self, /)<br>| Return len(self).<br>|<br>| <strong>new</strong>(</em>args, <strong>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| factorize(…)<br>|<br>| get_item(…)<br>|<br>| get_iter_test(…)<br>|<br>| get_labels(…)<br>|<br>| get_labels_groupby(…)<br>|<br>| lookup(…)<br>|<br>1057<br>| map(…)<br>|<br>| map_locations(…)<br>|<br>| set_item(…)<br>|<br>| unique(…)<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| <strong>pyx_vtable</strong> = <capsule object="" null=""><br>class Int64Vector(builtins.object)<br>| 【方法定义】<br>|<br>| <strong>len</strong>(self, /)<br>| Return len(self).<br>|<br>| <strong>new</strong>(*args, </capsule></strong>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| to_array(…)<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| <strong>pyx_vtable</strong> = <capsule object="" null=""><br>class ObjectVector(builtins.object)<br>| 【方法定义】<br>|<br>| <strong>len</strong>(self, /)<br>| Return len(self).<br>|<br>| <strong>new</strong>(<em>args, **kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| to_array(…)<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| <strong>pyx_vtable</strong> = <capsule object="" null=""><br>class PyObjectHashTable(HashTable)<br>| 【方法排序】<br>| PyObjectHashTable<br>| HashTable<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>contains</strong>(self, key, /)<br>| Return key in self.<br>|<br>1058<br>| <strong>init</strong>(self, /, </capsule></em>args, <strong>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>len</strong>(self, /)<br>| Return len(self).<br>|<br>| <strong>new</strong>(*args, </strong>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| destroy(…)<br>|<br>| get_item(…)<br>|<br>| get_iter_test(…)<br>|<br>| get_labels(…)<br>|<br>| lookup(…)<br>|<br>| map_locations(…)<br>|<br>| set_item(…)<br>|<br>| unique(…)<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| <strong>pyx_vtable</strong> = <capsule object="" null=""><br>class StringHashTable(HashTable)<br>| 【方法排序】<br>| StringHashTable<br>| HashTable<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>new</strong>(<em>args, **kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| factorize(…)<br>|<br>| get_indexer(…)<br>|<br>| get_item(…)<br>|<br>| get_iter_test(…)<br>|<br>| set_item(…)<br>|<br>| unique(…)<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| <strong>pyx_vtable</strong> = <capsule object="" null=""><br>1059<br>【函数】<br>duplicated_int64(…)<br>mode_int64(…)<br>mode_object(…)<br>unique_label_indices(…)<br>indices of the first occurrences of the unique labels
</capsule></em>excluding<em> -1. equivelent to:<br>np.unique(labels, return_index=True)[1]<br>value_count_object(…)<br>value_count_scalar64(values, dropna)<br>【数据】<br><strong>test</strong> = {‘Factorizer.factorize (line 811)’: ‘\n Factorize va…<br>nan = nan<br>【文件】 ： \pandas\hashtable.cp35-win_amd64.pyd<br>index<br>所属模块：pandas.index in pandas:<br>【名称】<br>pandas.index<br>【类型】<br>【内置对象】<br>IndexEngine<br>Float64Engine<br>Int64Engine<br>DatetimeEngine<br>TimedeltaEngine<br>ObjectEngine<br>class DatetimeEngine(Int64Engine)<br>| 【方法排序】<br>| DatetimeEngine<br>| Int64Engine<br>| IndexEngine<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>1060<br>| <strong>contains</strong>(self, key, /)<br>| Return key in self.<br>|<br>| <strong>new</strong>(</em>args, <strong>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| get_backfill_indexer(…)<br>|<br>| get_indexer(…)<br>|<br>| get_loc(…)<br>|<br>| get_pad_indexer(…)<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| <strong>pyx_vtable</strong> = <capsule object="" null=""><br>|<br>| ———————————————————————-| Methods inherited from IndexEngine:<br>|<br>| <strong>init</strong>(self, /, *args, </capsule></strong>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| clear_mapping(…)<br>|<br>| get_indexer_non_unique(…)<br>| return an indexer suitable for takng from a non unique index<br>| return the labels in the same order ast the target<br>| and a missing indexer into the targets (which correspond<br>| to the -1 indicies in the results<br>|<br>| get_value(…)<br>| arr : 1-dimensional ndarray<br>|<br>| set_value(…)<br>| arr : 1-dimensional ndarray<br>|<br>| ———————————————————————-| Data descriptors inherited from IndexEngine:<br>|<br>| is_monotonic_decreasing<br>|<br>| is_monotonic_increasing<br>|<br>| is_unique<br>|<br>| mapping<br>|<br>| over_size_threshold<br>|<br>| vgetter<br>class Float64Engine(IndexEngine)<br>| 【方法排序】<br>| Float64Engine<br>1061<br>| IndexEngine<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>new</strong>(<em>args, **kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| get_backfill_indexer(…)<br>|<br>| get_pad_indexer(…)<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| <strong>pyx_vtable</strong> = <capsule object="" null=""><br>|<br>| ———————————————————————-| Methods inherited from IndexEngine:<br>|<br>| <strong>contains</strong>(self, key, /)<br>| Return key in self.<br>|<br>| <strong>init</strong>(self, /, </capsule></em>args, <strong>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| clear_mapping(…)<br>|<br>| get_indexer(…)<br>|<br>| get_indexer_non_unique(…)<br>| return an indexer suitable for takng from a non unique index<br>| return the labels in the same order ast the target<br>| and a missing indexer into the targets (which correspond<br>| to the -1 indicies in the results<br>|<br>| get_loc(…)<br>|<br>| get_value(…)<br>| arr : 1-dimensional ndarray<br>|<br>| set_value(…)<br>| arr : 1-dimensional ndarray<br>|<br>| ———————————————————————-| Data descriptors inherited from IndexEngine:<br>|<br>| is_monotonic_decreasing<br>|<br>| is_monotonic_increasing<br>|<br>| is_unique<br>|<br>| mapping<br>|<br>| over_size_threshold<br>|<br>1062<br>| vgetter<br>class IndexEngine(builtins.object)<br>| 【方法定义】<br>|<br>| <strong>contains</strong>(self, key, /)<br>| Return key in self.<br>|<br>| <strong>init</strong>(self, /, *args, </strong>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>new</strong>(<em>args, **kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| clear_mapping(…)<br>|<br>| get_indexer(…)<br>|<br>| get_indexer_non_unique(…)<br>| return an indexer suitable for takng from a non unique index<br>| return the labels in the same order ast the target<br>| and a missing indexer into the targets (which correspond<br>| to the -1 indicies in the results<br>|<br>| get_loc(…)<br>|<br>| get_value(…)<br>| arr : 1-dimensional ndarray<br>|<br>| set_value(…)<br>| arr : 1-dimensional ndarray<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| is_monotonic_decreasing<br>|<br>| is_monotonic_increasing<br>|<br>| is_unique<br>|<br>| mapping<br>|<br>| over_size_threshold<br>|<br>| vgetter<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| <strong>pyx_vtable</strong> = <capsule object="" null=""><br>class Int64Engine(IndexEngine)<br>| 【方法排序】<br>| Int64Engine<br>| IndexEngine<br>| 【内置对象】<br>1063<br>|<br>| 【方法定义】<br>|<br>| <strong>new</strong>(</capsule></em>args, <strong>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| get_backfill_indexer(…)<br>|<br>| get_pad_indexer(…)<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| <strong>pyx_vtable</strong> = <capsule object="" null=""><br>|<br>| ———————————————————————-| Methods inherited from IndexEngine:<br>|<br>| <strong>contains</strong>(self, key, /)<br>| Return key in self.<br>|<br>| <strong>init</strong>(self, /, *args, </capsule></strong>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| clear_mapping(…)<br>|<br>| get_indexer(…)<br>|<br>| get_indexer_non_unique(…)<br>| return an indexer suitable for takng from a non unique index<br>| return the labels in the same order ast the target<br>| and a missing indexer into the targets (which correspond<br>| to the -1 indicies in the results<br>|<br>| get_loc(…)<br>|<br>| get_value(…)<br>| arr : 1-dimensional ndarray<br>|<br>| set_value(…)<br>| arr : 1-dimensional ndarray<br>|<br>| ———————————————————————-| Data descriptors inherited from IndexEngine:<br>|<br>| is_monotonic_decreasing<br>|<br>| is_monotonic_increasing<br>|<br>| is_unique<br>|<br>| mapping<br>|<br>| over_size_threshold<br>|<br>| vgetter<br>1064<br>class ObjectEngine(IndexEngine)<br>| 【方法排序】<br>| ObjectEngine<br>| IndexEngine<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>new</strong>(<em>args, **kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| get_backfill_indexer(…)<br>|<br>| get_pad_indexer(…)<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| <strong>pyx_vtable</strong> = <capsule object="" null=""><br>|<br>| ———————————————————————-| Methods inherited from IndexEngine:<br>|<br>| <strong>contains</strong>(self, key, /)<br>| Return key in self.<br>|<br>| <strong>init</strong>(self, /, </capsule></em>args, <strong>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| clear_mapping(…)<br>|<br>| get_indexer(…)<br>|<br>| get_indexer_non_unique(…)<br>| return an indexer suitable for takng from a non unique index<br>| return the labels in the same order ast the target<br>| and a missing indexer into the targets (which correspond<br>| to the -1 indicies in the results<br>|<br>| get_loc(…)<br>|<br>| get_value(…)<br>| arr : 1-dimensional ndarray<br>|<br>| set_value(…)<br>| arr : 1-dimensional ndarray<br>|<br>| ———————————————————————-| Data descriptors inherited from IndexEngine:<br>|<br>| is_monotonic_decreasing<br>|<br>| is_monotonic_increasing<br>|<br>| is_unique<br>|<br>| mapping<br>1065<br>|<br>| over_size_threshold<br>|<br>| vgetter<br>class TimedeltaEngine(DatetimeEngine)<br>| 【方法排序】<br>| TimedeltaEngine<br>| DatetimeEngine<br>| Int64Engine<br>| IndexEngine<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>new</strong>(*args, </strong>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| <strong>pyx_vtable</strong> = <capsule object="" null=""><br>|<br>| ———————————————————————-| Methods inherited from DatetimeEngine:<br>|<br>| <strong>contains</strong>(self, key, /)<br>| Return key in self.<br>|<br>| get_backfill_indexer(…)<br>|<br>| get_indexer(…)<br>|<br>| get_loc(…)<br>|<br>| get_pad_indexer(…)<br>|<br>| ———————————————————————-| Methods inherited from IndexEngine:<br>|<br>| <strong>init</strong>(self, /, <em>args, *</em>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| clear_mapping(…)<br>|<br>| get_indexer_non_unique(…)<br>| return an indexer suitable for takng from a non unique index<br>| return the labels in the same order ast the target<br>| and a missing indexer into the targets (which correspond<br>| to the -1 indicies in the results<br>|<br>| get_value(…)<br>| arr : 1-dimensional ndarray<br>|<br>| set_value(…)<br>| arr : 1-dimensional ndarray<br>|<br>1066<br>| ———————————————————————-| Data descriptors inherited from IndexEngine:<br>|<br>| is_monotonic_decreasing<br>|<br>| is_monotonic_increasing<br>|<br>| is_unique<br>|<br>| mapping<br>|<br>| over_size_threshold<br>|<br>| vgetter<br>【函数】<br>convert_scalar(…)<br>get_value_at(…)<br>set_value_at(…)<br>【数据】<br>UTC = <utc><br><strong>test</strong> = {}<br>have_pytz = True<br>【文件】 ： \pandas\index.cp35-win_amd64.pyd<br>infer_freq<br>函数 infer_freq 模块所属：pandas.tseries.frequencies:<br>infer_freq(index, warn=True)<br>Infer the most likely frequency given the input index. If the frequency is<br>uncertain, a warning will be printed.<br>【参数】<br>———-index : DatetimeIndex or TimedeltaIndex<br>if passed a Series will use the values of the series (NOT THE INDEX)<br>warn : boolean, default True<br>【返回值】<br>——-freq : string or None<br>None if no discernible frequency<br>TypeError if the index is not datetime-like<br>ValueError if there are less than three values.<br>1067<br>info<br>所属模块：pandas.info in pandas:<br>【名称】<br>pandas.info<br>【说明】</utc></capsule></capsule></capsule></capsule></p>
<h1 id="pandas-a-powerful-data-analysis-and-manipulation-library-for-Python-2"><a href="#pandas-a-powerful-data-analysis-and-manipulation-library-for-Python-2" class="headerlink" title="pandas - a powerful data analysis and manipulation library for Python"></a>pandas - a powerful data analysis and manipulation library for Python</h1><p>See <a href="http://pandas.pydata.org/" target="_blank" rel="external">http://pandas.pydata.org/</a> for full documentation. Otherwise, see the<br>docstrings of the various objects in the pandas namespace:<br>Series<br>DataFrame<br>Panel<br>Index<br>DatetimeIndex<br>HDFStore<br>bdate_range<br>date_range<br>read_csv<br>read_fwf<br>read_table<br>ols<br>【文件】 ： \pandas\info.py<br>io<br>模块包所属：pandas.io in pandas:<br>【名称】<br>pandas.io<br>【模块包·内容】<br>api<br>auth<br>clipboard<br>common<br>1068<br>data<br>date_converters<br>excel<br>ga<br>gbq<br>html<br>json<br>packers<br>parsers<br>pickle<br>pytables<br>sas<br>sql<br>stata<br>tests (package)<br>wb<br>【文件】 ： \pandas\io__init<strong>.py<br>isnull<br>函数 isnull 模块所属：pandas.core.common:<br>isnull(obj)<br>Detect missing values (NaN in numeric arrays, None/NaN in object arrays)<br>【参数】<br>———-arr : ndarray or object value<br>Object to check for null-ness<br>【返回值】<br>——-isnulled : array-like of bool or bool<br>Array or bool indicating whether an object is null or if an array is<br>given which of the element is null.<br>【参见】<br>——–pandas.notnull: boolean inverse of pandas.isnull<br>json<br>1069<br>module _pandasujson:<br>【名称】<br>_pandasujson<br>【函数】<br>decode(…)<br>Converts JSON as string to dict object structure. Use precise_float=True to use high precision float decoder.<br>dump(…)<br>Converts arbitrary object recursively into JSON file. Use ensure_ascii=false to output UTF-8. Pass in<br>double_precision to alter the maximum digit precision of doubles. Set encode_html_chars=True to encode &lt; &gt; &amp; as unicode<br>escape sequences.<br>dumps(…)<br>Converts arbitrary object recursivly into JSON. Use ensure_ascii=false to output UTF-8. Pass in double_precision to<br>alter the maximum digit precision of doubles. Set encode_html_chars=True to encode &lt; &gt; &amp; as unicode escape sequences.<br>encode(…)<br>Converts arbitrary object recursivly into JSON. Use ensure_ascii=false to output UTF-8. Pass in double_precision to<br>alter the maximum digit precision of doubles. Set encode_html_chars=True to encode &lt; &gt; &amp; as unicode escape sequences.<br>load(…)<br>Converts JSON as file to dict object structure. Use precise_float=True to use high precision float decoder.<br>loads(…)<br>Converts JSON as string to dict object structure. Use precise_float=True to use high precision float decoder.<br>【版本】<br>1.33<br>【文件】 ： \pandas\json.cp35-win_amd64.pyd<br>lib<br>所属模块：pandas.lib in pandas:<br>【名称】<br>pandas.lib<br>【类型】<br>builtins.Exception(builtins.BaseException)<br>InvalidApply<br>【内置对象】<br>AxisProperty<br>BlockPlacement<br>BlockSlider<br>Reducer<br>1070<br>SeriesBinGrouper<br>SeriesGrouper<br>Slider<br>cache_readonly<br>class AxisProperty(builtins.object)<br>| 【方法定义】<br>|<br>| </strong>delete<strong>(self, instance, /)<br>| Delete an attribute of instance.<br>|<br>| </strong>get<strong>(self, instance, owner, /)<br>| Return an attribute of instance, which is of type owner.<br>|<br>| </strong>init<strong>(self, /, <em>args, *</em>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| </strong>new<strong>(<em>args, *</em>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| </strong>set<strong>(self, instance, value, /)<br>| Set an attribute of instance to value.<br>class BlockPlacement(builtins.object)<br>| 【方法定义】<br>|<br>| </strong>getitem<strong>(self, key, /)<br>| Return self[key].<br>|<br>| </strong>init<strong>(self, /, <em>args, *</em>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| </strong>iter<strong>(self, /)<br>| Implement iter(self).<br>|<br>| </strong>len<strong>(self, /)<br>| Return len(self).<br>|<br>| </strong>new<strong>(<em>args, *</em>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| </strong>repr<strong> = </strong>str<strong>(self, /)<br>|<br>| </strong>str<strong>(self, /)<br>| Return str(self).<br>|<br>| add(…)<br>|<br>| append(…)<br>|<br>| delete(…)<br>|<br>| isin(…)<br>|<br>| sub(…)<br>|<br>| ———————————————————————-<br>1071<br>| Data descriptors defined here:<br>|<br>| as_array<br>|<br>| as_slice<br>|<br>| indexer<br>|<br>| is_slice_like<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| </strong>pyx_vtable<strong> = <capsule object="" null=""><br>class BlockSlider(builtins.object)<br>| Only capable of sliding on axis=0<br>|<br>| 【方法定义】<br>|<br>| </capsule></strong>init<strong>(self, /, <em>args, *</em>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| </strong>new<strong>(<em>args, *</em>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| move(…)<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| blocks<br>|<br>| dummy<br>|<br>| frame<br>|<br>| idx_slider<br>|<br>| index<br>|<br>| nblocks<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| </strong>pyx_vtable<strong> = <capsule object="" null=""><br>class InvalidApply(builtins.Exception)<br>| Common base class for all non-exit exceptions.<br>|<br>| 【方法排序】<br>| InvalidApply<br>| builtins.Exception<br>| builtins.BaseException<br>| 【内置对象】<br>|<br>1072<br>| Data descriptors defined here:<br>|<br>| </capsule></strong>weakref<strong><br>| list of weak references to the object (if defined)<br>|<br>| ———————————————————————-| Methods inherited from builtins.Exception:<br>|<br>| </strong>init<strong>(self, /, <em>args, *</em>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| </strong>new<strong>(<em>args, *</em>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| ———————————————————————-| Methods inherited from builtins.BaseException:<br>|<br>| </strong>delattr<strong>(self, name, /)<br>| Implement delattr(self, name).<br>|<br>| </strong>getattribute<strong>(self, name, /)<br>| Return getattr(self, name).<br>|<br>| </strong>reduce<strong>(…)<br>| helper for pickle<br>|<br>| </strong>repr<strong>(self, /)<br>| Return repr(self).<br>|<br>| </strong>setattr<strong>(self, name, value, /)<br>| Implement setattr(self, name, value).<br>|<br>| </strong>setstate<strong>(…)<br>|<br>| </strong>str<strong>(self, /)<br>| Return str(self).<br>|<br>| with_traceback(…)<br>| Exception.with_traceback(tb) –| set self.</strong>traceback<strong> to tb and return self.<br>|<br>| ———————————————————————-| Data descriptors inherited from builtins.BaseException:<br>|<br>| </strong>cause<strong><br>| exception cause<br>|<br>| </strong>context<strong><br>| exception context<br>|<br>| </strong>dict<strong><br>|<br>| </strong>suppress_context<strong><br>|<br>| </strong>traceback<strong><br>|<br>| args<br>1073<br>class Reducer(builtins.object)<br>| Performs generic reduction operation on a C or Fortran-contiguous ndarray<br>| while avoiding ndarray construction overhead<br>|<br>| 【方法定义】<br>|<br>| </strong>init<strong>(self, /, <em>args, *</em>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| </strong>new<strong>(<em>args, *</em>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| get_result(…)<br>class SeriesBinGrouper(builtins.object)<br>| Performs grouping operation according to bin edges, rather than labels<br>|<br>| 【方法定义】<br>|<br>| </strong>init<strong>(self, /, <em>args, *</em>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| </strong>new<strong>(<em>args, *</em>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| get_result(…)<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| arr<br>|<br>| bins<br>|<br>| dummy_arr<br>|<br>| dummy_index<br>|<br>| f<br>|<br>| index<br>|<br>| ityp<br>|<br>| name<br>|<br>| typ<br>|<br>| values<br>class SeriesGrouper(builtins.object)<br>| Performs generic grouping operation while avoiding ndarray construction<br>| overhead<br>|<br>| 【方法定义】<br>|<br>1074<br>| </strong>init<strong>(self, /, <em>args, *</em>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| </strong>new<strong>(<em>args, *</em>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| get_result(…)<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| arr<br>|<br>| dummy_arr<br>|<br>| dummy_index<br>|<br>| f<br>|<br>| index<br>|<br>| ityp<br>|<br>| labels<br>|<br>| name<br>|<br>| typ<br>|<br>| values<br>class Slider(builtins.object)<br>| Only handles contiguous data for now<br>|<br>| 【方法定义】<br>|<br>| </strong>init<strong>(self, /, <em>args, *</em>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| </strong>new<strong>(<em>args, *</em>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| advance(…)<br>|<br>| reset(…)<br>|<br>| set_length(…)<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| </strong>pyx_vtable<strong> = <capsule object="" null=""><br>class cache_readonly(builtins.object)<br>| 【方法定义】<br>|<br>| </capsule></strong>call<strong>(self, /, <em>args, *</em>kwargs)<br>1075<br>| Call self as a function.<br>|<br>| </strong>delete<strong>(self, instance, /)<br>| Delete an attribute of instance.<br>|<br>| </strong>get<strong>(self, instance, owner, /)<br>| Return an attribute of instance, which is of type owner.<br>|<br>| </strong>init<strong>(self, /, <em>args, *</em>kwargs)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| </strong>new<strong>(<em>args, *</em>kwargs) from builtins.type<br>| Create and return a new object. See help(type) for accurate signature.<br>|<br>| </strong>set__(self, instance, value, /)<br>| Set an attribute of instance to value.<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| allow_setting<br>|<br>| func<br>|<br>| name<br>【函数】<br>apply_frame_axis0(…)<br>array_equivalent_object(…)<br>perform an element by element comparion on 1-d object arrays<br>taking into account nan positions<br>array_to_timestamp(…)<br>arrmap(…)<br>astype_intsafe(…)<br>astype_str(…)<br>astype_unicode(…)<br>checknull(…)<br>checknull_old(…)<br>clean_index_list(…)<br>Utility used in pandas.core.index._ensure_index<br>convert_sql_column(…)<br>convert_timestamps(…)<br>count_level_2d(…)<br>dicts_to_array(…)<br>1076<br>duplicated(…)<br>fast_multiget(…)<br>fast_unique(…)<br>fast_unique_multiple(…)<br>fast_unique_multiple_list(…)<br>fast_unique_multiple_list_gen(…)<br>fast_zip(…)<br>For zipping multiple ndarrays into an ndarray of tuples<br>fast_zip_fillna(…)<br>For zipping multiple ndarrays into an ndarray of tuples<br>generate_bins_dt64(…)<br>Int64 (datetime64) version of generic python version in groupby.py<br>generate_slices(…)<br>get_blkno_indexers(…)<br>Enumerate contiguous runs of integers in ndarray.<br>Iterate over elements of <code>blknos</code> yielding <code>(blkno, slice(start, stop))</code><br>pairs for each contiguous run found.<br>If <code>group</code> is True and there is more than one run for a certain blkno,<br><code>(blkno, array)</code> with an array containing positions of all elements equal<br>to blkno.<br>【返回值】<br>——-iter : iterator of (int, slice or array)<br>get_level_sorter(…)<br>argsort for a single level of a multi-index, keeping the order of higher<br>levels unchanged. <code>starts</code> points to starts of same-key indices w.r.t<br>to leading levels; equivalent to:<br>np.hstack([label[starts[i]:starts[i+1]].argsort(kind=’mergesort’)</p>
<ul>
<li>starts[i] for i in range(len(starts) - 1)])<br>get_reverse_indexer(…)<br>Reverse indexing operation.<br>Given <code>indexer</code>, make <code>indexer_inv</code> of it, such that::<br>indexer_inv[indexer[x]] = x<br>.. note:: If indexer is not unique, only first occurrence is accounted.<br>group_count(…)<br>has_infs_f4(…)<br>1077<br>has_infs_f8(…)<br>indexer_as_slice(…)<br>indices_fast(…)<br>infer_dtype(…)<br>we are coercing to an ndarray here<br>is_bool(…)<br>is_bool_array(…)<br>is_bytes_array(…)<br>is_complex(…)<br>is_date_array(…)<br>is_datetime64_array(…)<br>is_datetime_array(…)<br>is_float(…)<br>is_float_array(…)<br>is_integer(…)<br>is_integer_array(…)<br>is_integer_float_array(…)<br>is_lexsorted(…)<br>is_period(…)<br>is_period_array(…)<br>is_possible_datetimelike_array(…)<br>is_string_array(…)<br>is_time_array(…)<br>is_timedelta64_array(…)<br>is_timedelta_array(…)<br>is_timedelta_or_timedelta64_array(…)<br>infer with timedeltas and/or nat/none<br>is_unicode_array(…)<br>ismember(…)<br>Checks whether<br>1078<br>【参数】<br>———-arr : ndarray<br>values : set<br>【返回值】<br>——-ismember : ndarray (boolean dtype)<br>ismember_int64(…)<br>Checks whether<br>【参数】<br>———-arr : ndarray of int64<br>values : set<br>【返回值】<br>——-ismember : ndarray (boolean dtype)<br>ismember_nans(…)<br>isneginf_scalar(…)<br>isnullobj(…)<br>isnullobj2d(…)<br>isnullobj2d_old(…)<br>isnullobj_old(…)<br>isposinf_scalar(…)<br>isscalar(…)<br>Return True if given value is scalar.<br>This includes:</li>
</ul>
<ul>
<li>numpy array scalar (e.g. np.int64)</li>
<li>Python builtin numerics</li>
<li>Python builtin byte arrays and strings</li>
<li>None</li>
<li>instances of datetime.datetime</li>
<li>instances of datetime.timedelta</li>
<li>Period<br>item_from_zerodim(…)<br>If the value is a zerodim array, return the item it contains.<br>【示例】<br>——–&gt;&gt;&gt; item_from_zerodim(1)<br>1<br>item_from_zerodim(‘foobar’)<br>‘foobar’<br>1079<br>item_from_zerodim(np.array(1))<br>1<br>item_from_zerodim(np.array([1]))<br>array([1])<br>list_to_object_array(…)<br>Convert list to object ndarray. Seriously can’t believe I had to write this<br>function<br>lookup_values(…)<br>map_indices_list(…)<br>Produce a dict mapping the values of the input array to their respective<br>locations.<br>Example:<br>array([‘hi’, ‘there’]) –&gt; {‘hi’ : 0 , ‘there’ : 1}<br>Better to do this with Cython because of the enormous speed boost.<br>map_infer(…)<br>Substitute for np.vectorize with pandas-friendly dtype inference<br>【参数】<br>———-arr : ndarray<br>f : function<br>【返回值】<br>——-mapped : ndarray<br>map_infer_mask(…)<br>Substitute for np.vectorize with pandas-friendly dtype inference<br>【参数】<br>———-arr : ndarray<br>f : function<br>【返回值】<br>——-mapped : ndarray<br>max_len_string_array(arr)<br>return the maximum size of elements in a 1-dim string array<br>maybe_booleans_to_slice(…)<br>maybe_convert_bool(…)<br>maybe_convert_numeric(…)<br>Type inference function– convert strings to numeric (potentially) and<br>convert to proper dtype array<br>maybe_convert_objects(…)<br>Type inference function– convert object array to proper dtype<br>1080<br>maybe_indices_to_slice(…)<br>memory_usage_of_objects(…)<br>return the memory usage of an object array in bytes,<br>does not include the actual bytes of the pointers<br>reduce(…)<br>Paramaters<br>———–arr : NDFrame object<br>f : function<br>axis : integer axis<br>dummy : type of reduced output (series)<br>labels : Index or None<br>row_bool_subset(…)<br>row_bool_subset_object(…)<br>sanitize_objects(…)<br>scalar_binop(…)<br>scalar_compare(…)<br>slice_canonize(…)<br>Convert slice to canonical bounded form.<br>slice_get_indices_ex(…)<br>Get (start, stop, step, length) tuple for a slice.<br>If <code>objlen</code> is not specified, slice must be bounded, otherwise the result<br>will be wrong.<br>slice_getitem(…)<br>slice_len(…)<br>Get length of a bounded slice.<br>The slice must not have any “open” bounds that would create dependency on<br>container size, i.e.:</li>
<li>if <code>s.step is None or s.step &gt; 0</code>, <code>s.stop</code> is not <code>None</code></li>
<li>if <code>s.step &lt; 0</code>, <code>s.start</code> is not <code>None</code><br>Otherwise, the result is unreliable.<br>string_array_replace_from_nan_rep(…)<br>replace the values in the array with replacement if they are nan_rep; return the same array<br>time64_to_datetime(…)<br>to_datetime(…)<br>to_object_array(…)<br>to_object_array_tuples(…)<br>1081<br>to_timestamp(…)<br>try_parse_date_and_time(…)<br>try_parse_dates(…)<br>try_parse_datetime_components(…)<br>try_parse_year_month_day(…)<br>tuples_to_object_array(…)<br>values_from_object(…)<br>return my values or the object if we are say an ndarray<br>vec_binop(…)<br>vec_compare(…)<br>write_csv_rows(…)<br>【数据】<br>NaT = NaT<br><strong>pyx_capi</strong> = {‘is_null_datetimelike’: &lt;capsule object “int (PyObject…<br><strong>test</strong> = {‘item_from_zerodim (line 322)’: ‘\n If the value is a z…<br>iNaT = -9223372036854775808<br>is_numpy_prior_1_6_2 = False<br>isnan = <ufunc 'isnan'=""><br>pandas_null = <pandas.lib._pandasnull object=""><br>【文件】 ： \pandas\lib.cp35-win_amd64.pyd<br>lreshape<br>函数 lreshape 模块所属：pandas.core.reshape:<br>lreshape(data, groups, dropna=True, label=None)<br>Reshape long-format data to wide. Generalized inverse of DataFrame.pivot<br>【参数】<br>———-data : DataFrame<br>groups : dict<br>{new_name : list_of_columns}<br>dropna : boolean, default True<br>【示例】</pandas.lib._pandasnull></ufunc></li>
</ul>
<hr>
<p>1082<br>import pandas as pd<br>data = pd.DataFrame({‘hr1’: [514, 573], ‘hr2’: [545, 526],<br>… ‘team’: [‘Red Sox’, ‘Yankees’],<br>… ‘year1’: [2007, 2008], ‘year2’: [2008, 2008]})<br>data<br>hr1 hr2 team year1 year2<br>0 514 545 Red Sox 2007 2008<br>1 573 526 Yankees 2007 2008<br>pd.lreshape(data, {‘year’: [‘year1’, ‘year2’], ‘hr’: [‘hr1’, ‘hr2’]})<br>team hr year<br>0 Red Sox 514 2007<br>1 Yankees 573 2007<br>2 Red Sox 545 2008<br>3 Yankees 526 2008<br>【返回值】<br>——-reshaped : DataFrame<br>match<br>函数 match 模块所属：pandas.core.algorithms:<br>match(to_match, values, na_sentinel=-1)<br>Compute locations of to_match into values<br>【参数】<br>———-to_match : array-like<br>values to find positions of<br>values : array-like<br>Unique set of values<br>na_sentinel : int, default -1<br>Value to mark “not found”<br>【示例】<br>——–【返回值】<br>——-match : ndarray of integers<br>1083<br>melt<br>函数 melt 模块所属：pandas.core.reshape:<br>melt(frame, id_vars=None, value_vars=None, var_name=None, value_name=’value’, col_level=None)<br>“Unpivots” a DataFrame from wide format to long format, optionally leaving<br>identifier variables set.<br>This function is useful to massage a DataFrame into a format where one<br>or more columns are identifier variables (<code>id_vars</code>), while all other<br>columns, considered measured variables (<code>value_vars</code>), are “unpivoted” to<br>the row axis, leaving just two non-identifier columns, ‘variable’ and<br>‘value’.<br>【参数】<br>———-frame : DataFrame<br>id_vars : tuple, list, or ndarray, optional<br>Column(s) to use as identifier variables.<br>value_vars : tuple, list, or ndarray, optional<br>Column(s) to unpivot. If not specified, uses all columns that<br>are not set as <code>id_vars</code>.<br>var_name : scalar<br>Name to use for the ‘variable’ column. If None it uses<br><code>frame.columns.name</code> or ‘variable’.<br>value_name : scalar, default ‘value’<br>Name to use for the ‘value’ column.<br>col_level : int or string, optional<br>If columns are a MultiIndex then use this level to melt.<br>【参见】<br>——–pivot_table<br>DataFrame.pivot<br>【示例】<br>——–&gt;&gt;&gt; import pandas as pd<br>df = pd.DataFrame({‘A’: {0: ‘a’, 1: ‘b’, 2: ‘c’},<br>… ‘B’: {0: 1, 1: 3, 2: 5},<br>… ‘C’: {0: 2, 1: 4, 2: 6}})<br>df<br>A B C<br>0 a 1 2<br>1 b 3 4<br>2 c 5 6<br>pd.melt(df, id_vars=[‘A’], value_vars=[‘B’])<br>A variable value<br>0 a B 1<br>1 b B 3<br>2 c B 5<br>1084<br>pd.melt(df, id_vars=[‘A’], value_vars=[‘B’, ‘C’])<br>A variable value<br>0 a B 1<br>1 b B 3<br>2 c B 5<br>3 a C 2<br>4 b C 4<br>5 c C 6<br>The names of ‘variable’ and ‘value’ columns can be customized:<br>pd.melt(df, id_vars=[‘A’], value_vars=[‘B’],<br>… var_name=’myVarname’, value_name=’myValname’)<br>A myVarname myValname<br>0 a B 1<br>1 b B 3<br>2 c B 5<br>If you have multi-index columns:<br>df.columns = [list(‘ABC’), list(‘DEF’)]<br>df<br>A B C<br>D E F<br>0 a 1 2<br>1 b 3 4<br>2 c 5 6<br>pd.melt(df, col_level=0, id_vars=[‘A’], value_vars=[‘B’])<br>A variable value<br>0 a B 1<br>1 b B 3<br>2 c B 5<br>pd.melt(df, id_vars=[(‘A’, ‘D’)], value_vars=[(‘B’, ‘E’)])<br>(A, D) variable_0 variable_1 value<br>0 a B E 1<br>1 b B E 3<br>2 c B E 5<br>merge<br>函数 merge 模块所属：pandas.tools.merge:<br>merge(left, right, how=’inner’, on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False,<br>suffixes=(‘_x’, ‘_y’), copy=True, indicator=False)<br>Merge DataFrame objects by performing a database-style join operation by<br>columns or indexes.<br>If joining columns on columns, the DataFrame indexes <em>will be<br>ignored</em>. Otherwise if joining indexes on indexes or indexes on a column or<br>1085<br>columns, the index will be passed on.<br>【参数】<br>———-left : DataFrame<br>right : DataFrame<br>how : {‘left’, ‘right’, ‘outer’, ‘inner’}, default ‘inner’</p>
<ul>
<li>left: use only keys from left frame (SQL: left outer join)</li>
<li>right: use only keys from right frame (SQL: right outer join)</li>
<li>outer: use union of keys from both frames (SQL: full outer join)</li>
<li>inner: use intersection of keys from both frames (SQL: inner join)<br>on : label or list<br>Field names to join on. Must be found in both DataFrames. If on is<br>None and not merging on indexes, then it merges on the intersection of<br>the columns by default.<br>left_on : label or list, or array-like<br>Field names to join on in left DataFrame. Can be a vector or list of<br>vectors of the length of the DataFrame to use a particular vector as<br>the join key instead of columns<br>right_on : label or list, or array-like<br>Field names to join on in right DataFrame or vector/list of vectors per<br>left_on docs<br>left_index : boolean, default False<br>Use the index from the left DataFrame as the join key(s). If it is a<br>MultiIndex, the number of keys in the other DataFrame (either the index<br>or a number of columns) must match the number of levels<br>right_index : boolean, default False<br>Use the index from the right DataFrame as the join key. Same caveats as<br>left_index<br>sort : boolean, default False<br>Sort the join keys lexicographically in the result DataFrame<br>suffixes : 2-length sequence (tuple, list, …)<br>Suffix to apply to overlapping column names in the left and right<br>side, respectively<br>copy : boolean, default True<br>If False, do not copy data unnecessarily<br>indicator : boolean or string, default False<br>If True, adds a column to output DataFrame called “_merge” with<br>information on the source of each row.<br>If string, column with information on source of each row will be added to<br>output DataFrame, and column will be named value of string.<br>Information column is Categorical-type and takes on a value of “left_only”<br>for observations whose merge key only appears in ‘left’ DataFrame,<br>“right_only” for observations whose merge key only appears in ‘right’<br>DataFrame, and “both” if the observation’s merge key is found in both.<br>.. versionadded:: 0.17.0<br>【示例】<br>——–&gt;&gt;&gt; A &gt;&gt;&gt; B<br>lkey value rkey value<br>0 foo 1 0 foo 5<br>1 bar 2 1 bar 6<br>2 baz 3 2 qux 7<br>3 foo 4 3 bar 8<br>1086<br>merge(A, B, left_on=’lkey’, right_on=’rkey’, how=’outer’)<br>lkey value_x rkey value_y<br>0 foo 1 foo 5<br>1 foo 4 foo 5<br>2 bar 2 bar 6<br>3 bar 2 bar 8<br>4 baz 3 NaN NaN<br>5 NaN NaN qux 7<br>【返回值】<br>——-merged : DataFrame<br>The output type will the be same as ‘left’, if it is a subclass<br>of DataFrame.<br>msgpack<br>模块包所属：pandas.msgpack in pandas:<br>【名称】<br>pandas.msgpack - # coding: utf-8<br>【模块包·内容】<br>_packer<br>_unpacker<br>_version<br>exceptions<br>【类型】<br>ExtType(builtins.tuple)<br>ExtType<br>class ExtType(ExtType)<br>| ExtType represents ext type in msgpack.<br>|<br>| 【方法排序】<br>| ExtType<br>| ExtType<br>| builtins.tuple<br>| 【内置对象】<br>|<br>| Static methods defined here:<br>|<br>| <strong>new</strong>(cls, code, data)<br>| Create new instance of ExtType(code, data)<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>1087<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| ———————————————————————-| Methods inherited from ExtType:<br>|<br>| <strong>getnewargs</strong>(self)<br>| Return self as a plain tuple. Used by copy and pickle.<br>|<br>| <strong>repr</strong>(self)<br>| Return a nicely formatted representation string<br>|<br>| _asdict(self)<br>| Return a new OrderedDict which maps field names to their values.<br>|<br>| _replace(_self, <strong>kwds)<br>| Return a new ExtType object replacing specified fields with new values<br>|<br>| ———————————————————————-| Class methods inherited from ExtType:<br>|<br>| _make(iterable, new=<built-in method="" __new__="" of="" type="" object="" at="" 0x000000006408c530="">, len=<built-in function="" len="">)<br>from builtins.type<br>| Make a new ExtType object from a sequence or iterable<br>|<br>| ———————————————————————-| Data descriptors inherited from ExtType:<br>|<br>| code<br>| Alias for field number 0<br>|<br>| data<br>| Alias for field number 1<br>|<br>| ———————————————————————-| Data and other attributes inherited from ExtType:<br>|<br>| _fields = (‘code’, ‘data’)<br>|<br>| _source = “from builtins import property as _property, tupl…_itemget…<br>|<br>| ———————————————————————-| Methods inherited from builtins.tuple:<br>|<br>| <strong>add</strong>(self, value, /)<br>| Return self+value.<br>|<br>| <strong>contains</strong>(self, key, /)<br>| Return key in self.<br>|<br>| <strong>eq</strong>(self, value, /)<br>| Return self==value.<br>|<br>| <strong>ge</strong>(self, value, /)<br>| Return self&gt;=value.<br>|<br>| <strong>getattribute</strong>(self, name, /)<br>1088<br>| Return getattr(self, name).<br>|<br>| <strong>getitem</strong>(self, key, /)<br>| Return self[key].<br>|<br>| <strong>gt</strong>(self, value, /)<br>| Return self&gt;value.<br>|<br>| <strong>hash</strong>(self, /)<br>| Return hash(self).<br>|<br>| <strong>iter</strong>(self, /)<br>| Implement iter(self).<br>|<br>| <strong>le</strong>(self, value, /)<br>| Return self&lt;=value.<br>|<br>| <strong>len</strong>(self, /)<br>| Return len(self).<br>|<br>| <strong>lt</strong>(self, value, /)<br>| Return self<value. |="" __mul__(self,="" value,="" )="" return="" self*value.n="" __ne__(self,="" self!="value." __rmul__(self,="" self*value.="" count(...)="" t.count(value)="" -=""> integer – return number of occurrences of value<br>|<br>| index(…)<br>| T.index(value, [start, [stop]]) -&gt; integer – return first index of value.<br>| Raises ValueError if the value is not present.<br>【函数】<br>dump = pack(o, stream, </value.></built-in></built-in></strong>kwargs)<br>Pack object <code>o</code> and write it to <code>stream</code><br>See :class:<code>Packer</code> for options.<br>dumps = packb(o, <strong>kwargs)<br>Pack object <code>o</code> and return packed bytes<br>See :class:<code>Packer</code> for options.<br>load = unpack(…)<br>unpack(stream, object_hook=None, list_hook=None, bool use_list=1, encoding=None, unicode_errors=’strict’,<br>object_pairs_hook=None)<br>Unpack an object from <code>stream</code>.<br>Raises <code>ValueError</code> when <code>stream</code> has extra bytes.<br>1089<br>See :class:<code>Unpacker</code> for options.<br>loads = unpackb(…)<br>unpackb(packed, object_hook=None, list_hook=None, bool use_list=1, encoding=None, unicode_errors=’strict’,<br>object_pairs_hook=None, ext_hook=ExtType, Py_ssize_t max_str_len=2147483647, Py_ssize_t max_bin_len=2147483647,<br>Py_ssize_t max_array_len=2147483647, Py_ssize_t max_map_len=2147483647, Py_ssize_t max_ext_len=2147483647)<br>Unpack packed_bytes to object. Returns an unpacked object.<br>Raises <code>ValueError</code> when <code>packed</code> contains extra bytes.<br>See :class:<code>Unpacker</code> for options.<br>pack(o, stream, </strong>kwargs)<br>Pack object <code>o</code> and write it to <code>stream</code><br>See :class:<code>Packer</code> for options.<br>packb(o, <strong>kwargs)<br>Pack object <code>o</code> and return packed bytes<br>See :class:<code>Packer</code> for options.<br>unpack(…)<br>unpack(stream, object_hook=None, list_hook=None, bool use_list=1, encoding=None, unicode_errors=’strict’,<br>object_pairs_hook=None)<br>Unpack an object from <code>stream</code>.<br>Raises <code>ValueError</code> when <code>stream</code> has extra bytes.<br>See :class:<code>Unpacker</code> for options.<br>unpackb(…)<br>unpackb(packed, object_hook=None, list_hook=None, bool use_list=1, encoding=None, unicode_errors=’strict’,<br>object_pairs_hook=None, ext_hook=ExtType, Py_ssize_t max_str_len=2147483647, Py_ssize_t max_bin_len=2147483647,<br>Py_ssize_t max_array_len=2147483647, Py_ssize_t max_map_len=2147483647, Py_ssize_t max_ext_len=2147483647)<br>Unpack packed_bytes to object. Returns an unpacked object.<br>Raises <code>ValueError</code> when <code>packed</code> contains extra bytes.<br>See :class:<code>Unpacker</code> for options.<br>【数据】<br>version = (0, 4, 6)<br>【文件】 ： \pandas\msgpack__init<strong>.py<br>1090<br>notnull<br>函数 notnull 模块所属：pandas.core.common:<br>notnull(obj)<br>Replacement for numpy.isfinite / -numpy.isnan which is suitable for use<br>on object arrays.<br>【参数】<br>———-arr : ndarray or object value<br>Object to check for <em>not</em>-null-ness<br>【返回值】<br>——-isnulled : array-like of bool or bool<br>Array or bool indicating whether an object is <em>not</em> null or if an array<br>is given which of the element is <em>not</em> null.<br>【参见】<br>——–pandas.isnull : boolean inverse of pandas.notnull<br>offsets<br>所属模块：pandas.tseries.offsets in pandas.tseries:<br>【名称】<br>pandas.tseries.offsets<br>【类型】<br>【内置对象】<br>DateOffset<br>Easter<br>FY5253<br>FY5253Quarter<br>LastWeekOfMonth<br>Week<br>WeekOfMonth<br>BusinessMixin(builtins.object)<br>BusinessDay(BusinessMixin, SingleConstructorOffset)<br>CustomBusinessDay<br>BusinessHour(BusinessMixin, SingleConstructorOffset)<br>CustomBusinessMonthBegin(BusinessMixin, MonthOffset)<br>CustomBusinessMonthEnd(BusinessMixin, MonthOffset)<br>MonthOffset(SingleConstructorOffset)<br>1091<br>BusinessMonthBegin<br>BusinessMonthEnd<br>CustomBusinessMonthBegin(BusinessMixin, MonthOffset)<br>CustomBusinessMonthEnd(BusinessMixin, MonthOffset)<br>MonthBegin<br>MonthEnd<br>QuarterOffset(DateOffset)<br>BQuarterBegin<br>BQuarterEnd<br>QuarterBegin<br>QuarterEnd<br>SingleConstructorOffset(DateOffset)<br>BusinessDay(BusinessMixin, SingleConstructorOffset)<br>CustomBusinessDay<br>BusinessHour(BusinessMixin, SingleConstructorOffset)<br>Tick(SingleConstructorOffset)<br>Day<br>Hour<br>Micro<br>Milli<br>Minute<br>Nano<br>Second<br>YearOffset(DateOffset)<br>BYearBegin<br>BYearEnd<br>YearBegin<br>YearEnd<br>BDay = class BusinessDay(BusinessMixin, SingleConstructorOffset)<br>| DateOffset subclass representing possibly n business days<br>|<br>| 【方法排序】<br>| BusinessDay<br>| BusinessMixin<br>| SingleConstructorOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| </strong>init__(self, n=1, normalize=False, </strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| apply(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>1092<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| isAnchored(self)<br>|<br>| onOffset(self, dt)<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| freqstr<br>|<br>| ———————————————————————-| Methods inherited from BusinessMixin:<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| ———————————————————————-| Data descriptors inherited from BusinessMixin:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>1093<br>| copy(self)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| name<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>BMonthBegin = class BusinessMonthBegin(MonthOffset)<br>| DateOffset of one business month at beginning<br>|<br>| 【方法排序】<br>| BusinessMonthBegin<br>| MonthOffset<br>| SingleConstructorOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| apply(self, other)<br>|<br>| onOffset(self, dt)<br>|<br>| ———————————————————————-| Data descriptors inherited from MonthOffset:<br>|<br>| name<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, <strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>1094<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| isAnchored(self)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| rule_code<br>|<br>1095<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>BMonthEnd = class BusinessMonthEnd(MonthOffset)<br>| DateOffset increments between business EOM dates<br>|<br>| 【方法排序】<br>| BusinessMonthEnd<br>| MonthOffset<br>| SingleConstructorOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| apply(self, other)<br>|<br>| isAnchored(self)<br>|<br>| ———————————————————————-| Data descriptors inherited from MonthOffset:<br>|<br>| name<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, </strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>1096<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| onOffset(self, dt)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class BQuarterBegin(QuarterOffset)<br>| Quarter representation - doesn’t call super<br>|<br>| 【方法排序】<br>| BQuarterBegin<br>| QuarterOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>1097<br>|<br>| apply(self, other)<br>|<br>| ———————————————————————-| Methods inherited from QuarterOffset:<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, <strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| isAnchored(self)<br>|<br>| ———————————————————————-| Data descriptors inherited from QuarterOffset:<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-<br>1098<br>| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| onOffset(self, dt)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class BQuarterEnd(QuarterOffset)<br>| DateOffset increments between business Quarter dates<br>| startingMonth = 1 corresponds to dates like 1/31/2007, 4/30/2007, …<br>| startingMonth = 2 corresponds to dates like 2/28/2007, 5/31/2007, …<br>| startingMonth = 3 corresponds to dates like 3/30/2007, 6/29/2007, …<br>|<br>| 【方法排序】<br>| BQuarterEnd<br>| QuarterOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| apply(self, other)<br>|<br>| onOffset(self, dt)<br>|<br>| ———————————————————————-| Methods inherited from QuarterOffset:<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, </strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>1099<br>|<br>| isAnchored(self)<br>|<br>| ———————————————————————-| Data descriptors inherited from QuarterOffset:<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>1100<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class BYearBegin(YearOffset)<br>| DateOffset increments between business year begin dates<br>|<br>| 【方法排序】<br>| BYearBegin<br>| YearOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| apply(self, other)<br>|<br>| ———————————————————————-| Methods inherited from YearOffset:<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, <strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| ———————————————————————-| Data descriptors inherited from YearOffset:<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>1101<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| isAnchored(self)<br>|<br>| onOffset(self, dt)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>1102<br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class BYearEnd(YearOffset)<br>| DateOffset increments between business EOM dates<br>|<br>| 【方法排序】<br>| BYearEnd<br>| YearOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| apply(self, other)<br>|<br>| ———————————————————————-| Methods inherited from YearOffset:<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, </strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| ———————————————————————-| Data descriptors inherited from YearOffset:<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>1103<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| isAnchored(self)<br>|<br>| onOffset(self, dt)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class BusinessDay(BusinessMixin, SingleConstructorOffset)<br>| DateOffset subclass representing possibly n business days<br>1104<br>|<br>| 【方法排序】<br>| BusinessDay<br>| BusinessMixin<br>| SingleConstructorOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, <strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| apply(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| isAnchored(self)<br>|<br>| onOffset(self, dt)<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| freqstr<br>|<br>| ———————————————————————-| Methods inherited from BusinessMixin:<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| ———————————————————————-| Data descriptors inherited from BusinessMixin:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>1105<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| copy(self)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| name<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class BusinessHour(BusinessMixin, SingleConstructorOffset)<br>| DateOffset subclass representing possibly n business days<br>|<br>| .. versionadded: 0.16.1<br>|<br>| 【方法排序】<br>| BusinessHour<br>| BusinessMixin<br>| SingleConstructorOffset<br>| DateOffset<br>| 【内置对象】<br>1106<br>|<br>| 【方法定义】<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, </strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| apply(self, other)<br>|<br>| onOffset(self, dt)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Methods inherited from BusinessMixin:<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| ———————————————————————-| Data descriptors inherited from BusinessMixin:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>1107<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| isAnchored(self)<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| freqstr<br>|<br>| name<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>CBMonthBegin = class CustomBusinessMonthBegin(BusinessMixin, MonthOffset)<br>| <strong>EXPERIMENTAL</strong> DateOffset of one custom business month<br>|<br>| .. warning:: EXPERIMENTAL<br>|<br>| This class is not officially supported and the API is likely to change<br>| in future versions. Use this at your own risk.<br>|<br>| 【参数】<br>| ———-| n : int, default 1<br>| offset : timedelta, default timedelta(0)<br>| normalize : bool, default False<br>| Normalize start/end dates to midnight before generating date range<br>| weekmask : str, Default ‘Mon Tue Wed Thu Fri’<br>| weekmask of valid business days, passed to <code>numpy.busdaycalendar</code><br>| holidays : list<br>| list/array of dates to exclude from the set of valid business days,<br>| passed to <code>numpy.busdaycalendar</code><br>| calendar : pd.HolidayCalendar or np.busdaycalendar<br>|<br>1108<br>| 【方法排序】<br>| CustomBusinessMonthBegin<br>| BusinessMixin<br>| MonthOffset<br>| SingleConstructorOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, weekmask=’Mon Tue Wed Thu Fri’, holidays=None, calendar=None, <strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| apply(self, other)<br>|<br>| ———————————————————————-| Methods inherited from BusinessMixin:<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| ———————————————————————-| Data descriptors inherited from BusinessMixin:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| ———————————————————————-| Data descriptors inherited from MonthOffset:<br>|<br>| name<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>1109<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| isAnchored(self)<br>|<br>| onOffset(self, dt)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| freqstr<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>CBMonthEnd = class CustomBusinessMonthEnd(BusinessMixin, MonthOffset)<br>| </strong>EXPERIMENTAL<strong> DateOffset of one custom business month<br>|<br>| .. warning:: EXPERIMENTAL<br>|<br>| This class is not officially supported and the API is likely to change<br>| in future versions. Use this at your own risk.<br>|<br>| 【参数】<br>| ———-| n : int, default 1<br>1110<br>| offset : timedelta, default timedelta(0)<br>| normalize : bool, default False<br>| Normalize start/end dates to midnight before generating date range<br>| weekmask : str, Default ‘Mon Tue Wed Thu Fri’<br>| weekmask of valid business days, passed to <code>numpy.busdaycalendar</code><br>| holidays : list<br>| list/array of dates to exclude from the set of valid business days,<br>| passed to <code>numpy.busdaycalendar</code><br>| calendar : pd.HolidayCalendar or np.busdaycalendar<br>|<br>| 【方法排序】<br>| CustomBusinessMonthEnd<br>| BusinessMixin<br>| MonthOffset<br>| SingleConstructorOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, weekmask=’Mon Tue Wed Thu Fri’, holidays=None, calendar=None, </strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| apply(self, other)<br>|<br>| ———————————————————————-| Methods inherited from BusinessMixin:<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| ———————————————————————-| Data descriptors inherited from BusinessMixin:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| ———————————————————————-| Data descriptors inherited from MonthOffset:<br>|<br>| name<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>1111<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| isAnchored(self)<br>|<br>| onOffset(self, dt)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| freqstr<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>CDay = class CustomBusinessDay(BusinessDay)<br>1112<br>| <strong>EXPERIMENTAL</strong> DateOffset subclass representing possibly n business days<br>| excluding holidays<br>|<br>| .. warning:: EXPERIMENTAL<br>|<br>| This class is not officially supported and the API is likely to change<br>| in future versions. Use this at your own risk.<br>|<br>| 【参数】<br>| ———-| n : int, default 1<br>| offset : timedelta, default timedelta(0)<br>| normalize : bool, default False<br>| Normalize start/end dates to midnight before generating date range<br>| weekmask : str, Default ‘Mon Tue Wed Thu Fri’<br>| weekmask of valid business days, passed to <code>numpy.busdaycalendar</code><br>| holidays : list<br>| list/array of dates to exclude from the set of valid business days,<br>| passed to <code>numpy.busdaycalendar</code><br>| calendar : pd.HolidayCalendar or np.busdaycalendar<br>|<br>| 【方法排序】<br>| CustomBusinessDay<br>| BusinessDay<br>| BusinessMixin<br>| SingleConstructorOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>getstate</strong>(self)<br>| Return a pickleable state<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, weekmask=’Mon Tue Wed Thu Fri’, holidays=None, calendar=None, <strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>setstate</strong>(self, state)<br>| Reconstruct an instance from a pickled state<br>|<br>| apply(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>1113<br>| get_calendar(self, weekmask, holidays, calendar)<br>| Generate busdaycalendar<br>|<br>| onOffset(self, dt)<br>|<br>| ———————————————————————-| Methods inherited from BusinessDay:<br>|<br>| isAnchored(self)<br>|<br>| ———————————————————————-| Data descriptors inherited from BusinessDay:<br>|<br>| freqstr<br>|<br>| ———————————————————————-| Methods inherited from BusinessMixin:<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| ———————————————————————-| Data descriptors inherited from BusinessMixin:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>1114<br>| <strong>sub</strong>(self, other)<br>|<br>| copy(self)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| name<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class CustomBusinessDay(BusinessDay)<br>| </strong>EXPERIMENTAL<strong> DateOffset subclass representing possibly n business days<br>| excluding holidays<br>|<br>| .. warning:: EXPERIMENTAL<br>|<br>| This class is not officially supported and the API is likely to change<br>| in future versions. Use this at your own risk.<br>|<br>| 【参数】<br>| ———-| n : int, default 1<br>| offset : timedelta, default timedelta(0)<br>| normalize : bool, default False<br>| Normalize start/end dates to midnight before generating date range<br>| weekmask : str, Default ‘Mon Tue Wed Thu Fri’<br>| weekmask of valid business days, passed to <code>numpy.busdaycalendar</code><br>| holidays : list<br>| list/array of dates to exclude from the set of valid business days,<br>| passed to <code>numpy.busdaycalendar</code><br>| calendar : pd.HolidayCalendar or np.busdaycalendar<br>|<br>| 【方法排序】<br>| CustomBusinessDay<br>| BusinessDay<br>| BusinessMixin<br>| SingleConstructorOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>getstate</strong>(self)<br>| Return a pickleable state<br>|<br>1115<br>| <strong>init</strong>(self, n=1, normalize=False, weekmask=’Mon Tue Wed Thu Fri’, holidays=None, calendar=None, </strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>setstate</strong>(self, state)<br>| Reconstruct an instance from a pickled state<br>|<br>| apply(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| get_calendar(self, weekmask, holidays, calendar)<br>| Generate busdaycalendar<br>|<br>| onOffset(self, dt)<br>|<br>| ———————————————————————-| Methods inherited from BusinessDay:<br>|<br>| isAnchored(self)<br>|<br>| ———————————————————————-| Data descriptors inherited from BusinessDay:<br>|<br>| freqstr<br>|<br>| ———————————————————————-| Methods inherited from BusinessMixin:<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| ———————————————————————-| Data descriptors inherited from BusinessMixin:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>1116<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| copy(self)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| name<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class DateOffset(builtins.object)<br>| Standard kind of date increment used for a date range.<br>|<br>| Works exactly like relativedelta in terms of the keyword args you<br>| pass in, use of the keyword n is discouraged– you would be better<br>| off specifying n in the keywords you use, but regardless it is<br>| there for you. n is needed for DateOffset subclasses.<br>|<br>| DateOffets work as follows. Each offset specify a set of dates<br>| that conform to the DateOffset. For example, Bday defines this<br>| set to be the set of dates that are weekdays (M-F). To test if a<br>| date is in the set of a DateOffset dateOffset we can use the<br>1117<br>| onOffset method: dateOffset.onOffset(date).<br>|<br>| If a date is not on a valid date, the rollback and rollforward<br>| methods can be used to roll the date to the nearest valid date<br>| before/after the date.<br>|<br>| DateOffsets can be created to move dates forward a given number of<br>| valid dates. For example, Bday(2) can be added to a date to move<br>| it two business days forward. If the date does not start on a<br>| valid date, first it is moved to a valid date. Thus psedo code<br>| is:<br>|<br>| def <strong>add</strong>(date):<br>| date = rollback(date) # does nothing if date is valid<br>| return date + <n number="" of="" periods=""><br>|<br>| When a date offset is created for a negitive number of periods,<br>| the date is first rolled forward. The pseudo code is:<br>|<br>| def <strong>add</strong>(date):<br>| date = rollforward(date) # does nothing is date is valid<br>| return date + <n number="" of="" periods=""><br>|<br>| Zero presents a problem. Should it roll forward or back? We<br>| arbitrarily have it rollforward:<br>|<br>| date + BDay(0) == BDay.rollforward(date)<br>|<br>| Since 0 is a bit weird, we suggest avoiding its use.<br>|<br>| 【方法定义】<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, <strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>1118<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| isAnchored(self)<br>|<br>| onOffset(self, dt)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| rule_code<br>|<br>| ———————————————————————-| 其他数据、属性定义：<br>|<br>| normalize = False<br>class Day(Tick)<br>1119<br>| Standard kind of date increment used for a date range.<br>|<br>| Works exactly like relativedelta in terms of the keyword args you<br>| pass in, use of the keyword n is discouraged– you would be better<br>| off specifying n in the keywords you use, but regardless it is<br>| there for you. n is needed for DateOffset subclasses.<br>|<br>| DateOffets work as follows. Each offset specify a set of dates<br>| that conform to the DateOffset. For example, Bday defines this<br>| set to be the set of dates that are weekdays (M-F). To test if a<br>| date is in the set of a DateOffset dateOffset we can use the<br>| onOffset method: dateOffset.onOffset(date).<br>|<br>| If a date is not on a valid date, the rollback and rollforward<br>| methods can be used to roll the date to the nearest valid date<br>| before/after the date.<br>|<br>| DateOffsets can be created to move dates forward a given number of<br>| valid dates. For example, Bday(2) can be added to a date to move<br>| it two business days forward. If the date does not start on a<br>| valid date, first it is moved to a valid date. Thus psedo code<br>| is:<br>|<br>| def <strong>add</strong>(date):<br>| date = rollback(date) # does nothing if date is valid<br>| return date + <n number="" of="" periods=""><br>|<br>| When a date offset is created for a negitive number of periods,<br>| the date is first rolled forward. The pseudo code is:<br>|<br>| def <strong>add</strong>(date):<br>| date = rollforward(date) # does nothing is date is valid<br>| return date + <n number="" of="" periods=""><br>|<br>| Zero presents a problem. Should it roll forward or back? We<br>| arbitrarily have it rollforward:<br>|<br>| date + BDay(0) == BDay.rollforward(date)<br>|<br>| Since 0 is a bit weird, we suggest avoiding its use.<br>|<br>| 【方法排序】<br>| Day<br>| Tick<br>| SingleConstructorOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| Methods inherited from Tick:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>ge</strong> = f(self, other)<br>|<br>1120<br>| <strong>gt</strong> = f(self, other)<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>le</strong> = f(self, other)<br>|<br>| <strong>lt</strong> = f(self, other)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| apply(self, other)<br>|<br>| isAnchored(self)<br>|<br>| ———————————————————————-| Data descriptors inherited from Tick:<br>|<br>| delta<br>|<br>| nanos<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, </n></n></strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>1121<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| onOffset(self, dt)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class Easter(DateOffset)<br>| DateOffset for the Easter holiday using<br>| logic defined in dateutil. Right now uses<br>| the revised method which is valid in years<br>| 1583-4099.<br>|<br>| 【方法排序】<br>| Easter<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>init</strong>(self, n=1, <strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| apply(self, other)<br>|<br>| onOffset(self, dt)<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>1122<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| isAnchored(self)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>1123<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class FY5253(DateOffset)<br>| Describes 52-53 week fiscal year. This is also known as a 4-4-5 calendar.<br>|<br>| It is used by companies that desire that their<br>| fiscal year always end on the same day of the week.<br>|<br>| It is a method of managing accounting periods.<br>| It is a common calendar structure for some industries,<br>| such as retail, manufacturing and parking industry.<br>|<br>| For more information see:<br>| <a href="http://en.wikipedia.org/wiki/4%E2%80%934%E2%80%935_calendar" target="_blank" rel="external">http://en.wikipedia.org/wiki/4%E2%80%934%E2%80%935_calendar</a><br>|<br>|<br>| The year may either:<br>| - end on the last X day of the Y month.<br>| - end on the last X day closest to the last day of the Y month.<br>|<br>| X is a specific day of the week.<br>| Y is a certain month of the year<br>|<br>| 【参数】<br>| ———-| n : int<br>| weekday : {0, 1, …, 6}<br>| 0: Mondays<br>| 1: Tuesdays<br>| 2: Wednesdays<br>| 3: Thursdays<br>| 4: Fridays<br>| 5: Saturdays<br>| 6: Sundays<br>| startingMonth : The month in which fiscal years end. {1, 2, … 12}<br>| variation : str<br>| {“nearest”, “last”} for “LastOfMonth” or “NearestEndMonth”<br>|<br>| 【方法排序】<br>| FY5253<br>| DateOffset<br>1124<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, </strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| apply(self, other)<br>|<br>| get_rule_code_suffix(self)<br>|<br>| get_target_month_end(self, dt)<br>|<br>| get_year_end(self, dt)<br>|<br>| isAnchored(self)<br>|<br>| onOffset(self, dt)<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply_index(self, i)<br>1125<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class FY5253Quarter(DateOffset)<br>| DateOffset increments between business quarter dates<br>| for 52-53 week fiscal year (also known as a 4-4-5 calendar).<br>|<br>| It is used by companies that desire that their<br>| fiscal year always end on the same day of the week.<br>|<br>| It is a method of managing accounting periods.<br>| It is a common calendar structure for some industries,<br>| such as retail, manufacturing and parking industry.<br>|<br>| For more information see:<br>| <a href="http://en.wikipedia.org/wiki/4%E2%80%934%E2%80%935_calendar" target="_blank" rel="external">http://en.wikipedia.org/wiki/4%E2%80%934%E2%80%935_calendar</a><br>|<br>| The year may either:<br>| - end on the last X day of the Y month.<br>| - end on the last X day closest to the last day of the Y month.<br>1126<br>|<br>| X is a specific day of the week.<br>| Y is a certain month of the year<br>|<br>| startingMonth = 1 corresponds to dates like 1/31/2007, 4/30/2007, …<br>| startingMonth = 2 corresponds to dates like 2/28/2007, 5/31/2007, …<br>| startingMonth = 3 corresponds to dates like 3/30/2007, 6/29/2007, …<br>|<br>| 【参数】<br>| ———-| n : int<br>| weekday : {0, 1, …, 6}<br>| 0: Mondays<br>| 1: Tuesdays<br>| 2: Wednesdays<br>| 3: Thursdays<br>| 4: Fridays<br>| 5: Saturdays<br>| 6: Sundays<br>| startingMonth : The month in which fiscal years end. {1, 2, … 12}<br>| qtr_with_extra_week : The quarter number that has the leap<br>| or 14 week when needed. {1,2,3,4}<br>| variation : str<br>| {“nearest”, “last”} for “LastOfMonth” or “NearestEndMonth”<br>|<br>| 【方法排序】<br>| FY5253Quarter<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, <strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| apply(self, other)<br>|<br>| get_weeks(self, dt)<br>|<br>| isAnchored(self)<br>|<br>| onOffset(self, dt)<br>|<br>| year_has_extra_week(self, dt)<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>1127<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>1128<br>| freqstr<br>|<br>| name<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class Hour(Tick)<br>| Standard kind of date increment used for a date range.<br>|<br>| Works exactly like relativedelta in terms of the keyword args you<br>| pass in, use of the keyword n is discouraged– you would be better<br>| off specifying n in the keywords you use, but regardless it is<br>| there for you. n is needed for DateOffset subclasses.<br>|<br>| DateOffets work as follows. Each offset specify a set of dates<br>| that conform to the DateOffset. For example, Bday defines this<br>| set to be the set of dates that are weekdays (M-F). To test if a<br>| date is in the set of a DateOffset dateOffset we can use the<br>| onOffset method: dateOffset.onOffset(date).<br>|<br>| If a date is not on a valid date, the rollback and rollforward<br>| methods can be used to roll the date to the nearest valid date<br>| before/after the date.<br>|<br>| DateOffsets can be created to move dates forward a given number of<br>| valid dates. For example, Bday(2) can be added to a date to move<br>| it two business days forward. If the date does not start on a<br>| valid date, first it is moved to a valid date. Thus psedo code<br>| is:<br>|<br>| def <strong>add</strong>(date):<br>| date = rollback(date) # does nothing if date is valid<br>| return date + <n number="" of="" periods=""><br>|<br>| When a date offset is created for a negitive number of periods,<br>| the date is first rolled forward. The pseudo code is:<br>|<br>| def <strong>add</strong>(date):<br>| date = rollforward(date) # does nothing is date is valid<br>| return date + <n number="" of="" periods=""><br>|<br>| Zero presents a problem. Should it roll forward or back? We<br>| arbitrarily have it rollforward:<br>|<br>| date + BDay(0) == BDay.rollforward(date)<br>|<br>| Since 0 is a bit weird, we suggest avoiding its use.<br>|<br>| 【方法排序】<br>| Hour<br>| Tick<br>| SingleConstructorOffset<br>| DateOffset<br>| 【内置对象】<br>1129<br>|<br>| Methods inherited from Tick:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>ge</strong> = f(self, other)<br>|<br>| <strong>gt</strong> = f(self, other)<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>le</strong> = f(self, other)<br>|<br>| <strong>lt</strong> = f(self, other)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| apply(self, other)<br>|<br>| isAnchored(self)<br>|<br>| ———————————————————————-| Data descriptors inherited from Tick:<br>|<br>| delta<br>|<br>| nanos<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, </n></n></strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>1130<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| onOffset(self, dt)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class LastWeekOfMonth(DateOffset)<br>| Describes monthly dates in last week of month like “the last Tuesday of each month”<br>|<br>| 【参数】<br>| ———-| n : int<br>| weekday : {0, 1, …, 6}<br>| 0: Mondays<br>| 1: Tuesdays<br>| 2: Wednesdays<br>| 3: Thursdays<br>| 4: Fridays<br>1131<br>| 5: Saturdays<br>| 6: Sundays<br>|<br>| 【方法排序】<br>| LastWeekOfMonth<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, <strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| apply(self, other)<br>|<br>| getOffsetOfMonth(self, dt)<br>|<br>| onOffset(self, dt)<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply_index(self, i)<br>1132<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| isAnchored(self)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class Micro(Tick)<br>| Standard kind of date increment used for a date range.<br>|<br>| Works exactly like relativedelta in terms of the keyword args you<br>| pass in, use of the keyword n is discouraged– you would be better<br>| off specifying n in the keywords you use, but regardless it is<br>| there for you. n is needed for DateOffset subclasses.<br>|<br>| DateOffets work as follows. Each offset specify a set of dates<br>| that conform to the DateOffset. For example, Bday defines this<br>| set to be the set of dates that are weekdays (M-F). To test if a<br>| date is in the set of a DateOffset dateOffset we can use the<br>| onOffset method: dateOffset.onOffset(date).<br>|<br>| If a date is not on a valid date, the rollback and rollforward<br>1133<br>| methods can be used to roll the date to the nearest valid date<br>| before/after the date.<br>|<br>| DateOffsets can be created to move dates forward a given number of<br>| valid dates. For example, Bday(2) can be added to a date to move<br>| it two business days forward. If the date does not start on a<br>| valid date, first it is moved to a valid date. Thus psedo code<br>| is:<br>|<br>| def <strong>add</strong>(date):<br>| date = rollback(date) # does nothing if date is valid<br>| return date + <n number="" of="" periods=""><br>|<br>| When a date offset is created for a negitive number of periods,<br>| the date is first rolled forward. The pseudo code is:<br>|<br>| def <strong>add</strong>(date):<br>| date = rollforward(date) # does nothing is date is valid<br>| return date + <n number="" of="" periods=""><br>|<br>| Zero presents a problem. Should it roll forward or back? We<br>| arbitrarily have it rollforward:<br>|<br>| date + BDay(0) == BDay.rollforward(date)<br>|<br>| Since 0 is a bit weird, we suggest avoiding its use.<br>|<br>| 【方法排序】<br>| Micro<br>| Tick<br>| SingleConstructorOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| Methods inherited from Tick:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>ge</strong> = f(self, other)<br>|<br>| <strong>gt</strong> = f(self, other)<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>le</strong> = f(self, other)<br>|<br>| <strong>lt</strong> = f(self, other)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| apply(self, other)<br>|<br>1134<br>| isAnchored(self)<br>|<br>| ———————————————————————-| Data descriptors inherited from Tick:<br>|<br>| delta<br>|<br>| nanos<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, </n></n></strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| onOffset(self, dt)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>1135<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class Milli(Tick)<br>| Standard kind of date increment used for a date range.<br>|<br>| Works exactly like relativedelta in terms of the keyword args you<br>| pass in, use of the keyword n is discouraged– you would be better<br>| off specifying n in the keywords you use, but regardless it is<br>| there for you. n is needed for DateOffset subclasses.<br>|<br>| DateOffets work as follows. Each offset specify a set of dates<br>| that conform to the DateOffset. For example, Bday defines this<br>| set to be the set of dates that are weekdays (M-F). To test if a<br>| date is in the set of a DateOffset dateOffset we can use the<br>| onOffset method: dateOffset.onOffset(date).<br>|<br>| If a date is not on a valid date, the rollback and rollforward<br>| methods can be used to roll the date to the nearest valid date<br>| before/after the date.<br>|<br>| DateOffsets can be created to move dates forward a given number of<br>| valid dates. For example, Bday(2) can be added to a date to move<br>| it two business days forward. If the date does not start on a<br>| valid date, first it is moved to a valid date. Thus psedo code<br>| is:<br>|<br>| def <strong>add</strong>(date):<br>| date = rollback(date) # does nothing if date is valid<br>| return date + <n number="" of="" periods=""><br>|<br>| When a date offset is created for a negitive number of periods,<br>| the date is first rolled forward. The pseudo code is:<br>|<br>| def <strong>add</strong>(date):<br>| date = rollforward(date) # does nothing is date is valid<br>| return date + <n number="" of="" periods=""><br>|<br>| Zero presents a problem. Should it roll forward or back? We<br>1136<br>| arbitrarily have it rollforward:<br>|<br>| date + BDay(0) == BDay.rollforward(date)<br>|<br>| Since 0 is a bit weird, we suggest avoiding its use.<br>|<br>| 【方法排序】<br>| Milli<br>| Tick<br>| SingleConstructorOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| Methods inherited from Tick:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>ge</strong> = f(self, other)<br>|<br>| <strong>gt</strong> = f(self, other)<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>le</strong> = f(self, other)<br>|<br>| <strong>lt</strong> = f(self, other)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| apply(self, other)<br>|<br>| isAnchored(self)<br>|<br>| ———————————————————————-| Data descriptors inherited from Tick:<br>|<br>| delta<br>|<br>| nanos<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, <strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>neg</strong>(self)<br>1137<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| onOffset(self, dt)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>1138<br>class Minute(Tick)<br>| Standard kind of date increment used for a date range.<br>|<br>| Works exactly like relativedelta in terms of the keyword args you<br>| pass in, use of the keyword n is discouraged– you would be better<br>| off specifying n in the keywords you use, but regardless it is<br>| there for you. n is needed for DateOffset subclasses.<br>|<br>| DateOffets work as follows. Each offset specify a set of dates<br>| that conform to the DateOffset. For example, Bday defines this<br>| set to be the set of dates that are weekdays (M-F). To test if a<br>| date is in the set of a DateOffset dateOffset we can use the<br>| onOffset method: dateOffset.onOffset(date).<br>|<br>| If a date is not on a valid date, the rollback and rollforward<br>| methods can be used to roll the date to the nearest valid date<br>| before/after the date.<br>|<br>| DateOffsets can be created to move dates forward a given number of<br>| valid dates. For example, Bday(2) can be added to a date to move<br>| it two business days forward. If the date does not start on a<br>| valid date, first it is moved to a valid date. Thus psedo code<br>| is:<br>|<br>| def <strong>add</strong>(date):<br>| date = rollback(date) # does nothing if date is valid<br>| return date + <n number="" of="" periods=""><br>|<br>| When a date offset is created for a negitive number of periods,<br>| the date is first rolled forward. The pseudo code is:<br>|<br>| def <strong>add</strong>(date):<br>| date = rollforward(date) # does nothing is date is valid<br>| return date + <n number="" of="" periods=""><br>|<br>| Zero presents a problem. Should it roll forward or back? We<br>| arbitrarily have it rollforward:<br>|<br>| date + BDay(0) == BDay.rollforward(date)<br>|<br>| Since 0 is a bit weird, we suggest avoiding its use.<br>|<br>| 【方法排序】<br>| Minute<br>| Tick<br>| SingleConstructorOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| Methods inherited from Tick:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>ge</strong> = f(self, other)<br>1139<br>|<br>| <strong>gt</strong> = f(self, other)<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>le</strong> = f(self, other)<br>|<br>| <strong>lt</strong> = f(self, other)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| apply(self, other)<br>|<br>| isAnchored(self)<br>|<br>| ———————————————————————-| Data descriptors inherited from Tick:<br>|<br>| delta<br>|<br>| nanos<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, </n></n></strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-<br>1140<br>| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| onOffset(self, dt)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class MonthBegin(MonthOffset)<br>| DateOffset of one month at beginning<br>|<br>| 【方法排序】<br>| MonthBegin<br>| MonthOffset<br>| SingleConstructorOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| apply(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>1141<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| onOffset(self, dt)<br>|<br>| ———————————————————————-| Data descriptors inherited from MonthOffset:<br>|<br>| name<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, <strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| copy(self)<br>|<br>| isAnchored(self)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>1142<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class MonthEnd(MonthOffset)<br>| DateOffset of one month end<br>|<br>| 【方法排序】<br>| MonthEnd<br>| MonthOffset<br>| SingleConstructorOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| apply(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| onOffset(self, dt)<br>|<br>| ———————————————————————-| Data descriptors inherited from MonthOffset:<br>|<br>| name<br>|<br>1143<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, </strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| copy(self)<br>|<br>| isAnchored(self)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| rule_code<br>1144<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class Nano(Tick)<br>| Standard kind of date increment used for a date range.<br>|<br>| Works exactly like relativedelta in terms of the keyword args you<br>| pass in, use of the keyword n is discouraged– you would be better<br>| off specifying n in the keywords you use, but regardless it is<br>| there for you. n is needed for DateOffset subclasses.<br>|<br>| DateOffets work as follows. Each offset specify a set of dates<br>| that conform to the DateOffset. For example, Bday defines this<br>| set to be the set of dates that are weekdays (M-F). To test if a<br>| date is in the set of a DateOffset dateOffset we can use the<br>| onOffset method: dateOffset.onOffset(date).<br>|<br>| If a date is not on a valid date, the rollback and rollforward<br>| methods can be used to roll the date to the nearest valid date<br>| before/after the date.<br>|<br>| DateOffsets can be created to move dates forward a given number of<br>| valid dates. For example, Bday(2) can be added to a date to move<br>| it two business days forward. If the date does not start on a<br>| valid date, first it is moved to a valid date. Thus psedo code<br>| is:<br>|<br>| def <strong>add</strong>(date):<br>| date = rollback(date) # does nothing if date is valid<br>| return date + <n number="" of="" periods=""><br>|<br>| When a date offset is created for a negitive number of periods,<br>| the date is first rolled forward. The pseudo code is:<br>|<br>| def <strong>add</strong>(date):<br>| date = rollforward(date) # does nothing is date is valid<br>| return date + <n number="" of="" periods=""><br>|<br>| Zero presents a problem. Should it roll forward or back? We<br>| arbitrarily have it rollforward:<br>|<br>| date + BDay(0) == BDay.rollforward(date)<br>|<br>| Since 0 is a bit weird, we suggest avoiding its use.<br>|<br>| 【方法排序】<br>| Nano<br>| Tick<br>| SingleConstructorOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| Methods inherited from Tick:<br>|<br>1145<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>ge</strong> = f(self, other)<br>|<br>| <strong>gt</strong> = f(self, other)<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>le</strong> = f(self, other)<br>|<br>| <strong>lt</strong> = f(self, other)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| apply(self, other)<br>|<br>| isAnchored(self)<br>|<br>| ———————————————————————-| Data descriptors inherited from Tick:<br>|<br>| delta<br>|<br>| nanos<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, <strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>1146<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| onOffset(self, dt)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class QuarterBegin(QuarterOffset)<br>| Quarter representation - doesn’t call super<br>|<br>| 【方法排序】<br>| QuarterBegin<br>| QuarterOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| apply(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>1147<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| isAnchored(self)<br>|<br>| ———————————————————————-| Methods inherited from QuarterOffset:<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, </strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| ———————————————————————-| Data descriptors inherited from QuarterOffset:<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>1148<br>|<br>| copy(self)<br>|<br>| onOffset(self, dt)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class QuarterEnd(QuarterOffset)<br>| DateOffset increments between business Quarter dates<br>| startingMonth = 1 corresponds to dates like 1/31/2007, 4/30/2007, …<br>| startingMonth = 2 corresponds to dates like 2/28/2007, 5/31/2007, …<br>| startingMonth = 3 corresponds to dates like 3/31/2007, 6/30/2007, …<br>|<br>| 【方法排序】<br>| QuarterEnd<br>| QuarterOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, <strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| apply(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-<br>1149<br>| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| isAnchored(self)<br>|<br>| onOffset(self, dt)<br>|<br>| ———————————————————————-| Data descriptors inherited from QuarterOffset:<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| copy(self)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>1150<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class Second(Tick)<br>| Standard kind of date increment used for a date range.<br>|<br>| Works exactly like relativedelta in terms of the keyword args you<br>| pass in, use of the keyword n is discouraged– you would be better<br>| off specifying n in the keywords you use, but regardless it is<br>| there for you. n is needed for DateOffset subclasses.<br>|<br>| DateOffets work as follows. Each offset specify a set of dates<br>| that conform to the DateOffset. For example, Bday defines this<br>| set to be the set of dates that are weekdays (M-F). To test if a<br>| date is in the set of a DateOffset dateOffset we can use the<br>| onOffset method: dateOffset.onOffset(date).<br>|<br>| If a date is not on a valid date, the rollback and rollforward<br>| methods can be used to roll the date to the nearest valid date<br>| before/after the date.<br>|<br>| DateOffsets can be created to move dates forward a given number of<br>| valid dates. For example, Bday(2) can be added to a date to move<br>| it two business days forward. If the date does not start on a<br>| valid date, first it is moved to a valid date. Thus psedo code<br>| is:<br>|<br>| def <strong>add</strong>(date):<br>| date = rollback(date) # does nothing if date is valid<br>| return date + <n number="" of="" periods=""><br>|<br>| When a date offset is created for a negitive number of periods,<br>| the date is first rolled forward. The pseudo code is:<br>|<br>| def <strong>add</strong>(date):<br>| date = rollforward(date) # does nothing is date is valid<br>| return date + <n number="" of="" periods=""><br>|<br>| Zero presents a problem. Should it roll forward or back? We<br>| arbitrarily have it rollforward:<br>|<br>| date + BDay(0) == BDay.rollforward(date)<br>|<br>| Since 0 is a bit weird, we suggest avoiding its use.<br>1151<br>|<br>| 【方法排序】<br>| Second<br>| Tick<br>| SingleConstructorOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| Methods inherited from Tick:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>ge</strong> = f(self, other)<br>|<br>| <strong>gt</strong> = f(self, other)<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>le</strong> = f(self, other)<br>|<br>| <strong>lt</strong> = f(self, other)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| apply(self, other)<br>|<br>| isAnchored(self)<br>|<br>| ———————————————————————-| Data descriptors inherited from Tick:<br>|<br>| delta<br>|<br>| nanos<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, </n></n></strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>1152<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| onOffset(self, dt)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class Week(DateOffset)<br>| Weekly offset<br>|<br>| 【参数】<br>| ———-<br>1153<br>| weekday : int, default None<br>| Always generate specific day of week. 0 for Monday<br>|<br>| 【方法排序】<br>| Week<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, <strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| apply(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| isAnchored(self)<br>|<br>| onOffset(self, dt)<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>1154<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| copy(self)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class WeekOfMonth(DateOffset)<br>| Describes monthly dates like “the Tuesday of the 2nd week of each month”<br>|<br>| 【参数】<br>| ———-| n : int<br>| week : {0, 1, 2, 3, …}<br>| 0 is 1st week of month, 1 2nd week, etc.<br>| weekday : {0, 1, …, 6}<br>| 0: Mondays<br>| 1: Tuesdays<br>| 2: Wednesdays<br>| 3: Thursdays<br>| 4: Fridays<br>| 5: Saturdays<br>| 6: Sundays<br>|<br>1155<br>| 【方法排序】<br>| WeekOfMonth<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, </strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| apply(self, other)<br>|<br>| getOffsetOfMonth(self, dt)<br>|<br>| onOffset(self, dt)<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>1156<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| copy(self)<br>|<br>| isAnchored(self)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class YearBegin(YearOffset)<br>| DateOffset increments between calendar year begin dates<br>|<br>| 【方法排序】<br>| YearBegin<br>| YearOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| apply(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>1157<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| onOffset(self, dt)<br>|<br>| ———————————————————————-| Methods inherited from YearOffset:<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, <strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| ———————————————————————-| Data descriptors inherited from YearOffset:<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| copy(self)<br>|<br>1158<br>| isAnchored(self)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>class YearEnd(YearOffset)<br>| DateOffset increments between calendar year ends<br>|<br>| 【方法排序】<br>| YearEnd<br>| YearOffset<br>| DateOffset<br>| 【内置对象】<br>|<br>| 【方法定义】<br>|<br>| apply(self, other)<br>|<br>| apply_index(self, i)<br>| Vectorized apply of DateOffset to DatetimeIndex,<br>| raises NotImplentedError for offsets without a<br>| vectorized implementation<br>|<br>| .. versionadded:: 0.17.0<br>|<br>| 【参数】<br>| ———-| i : DatetimeIndex<br>|<br>| 【返回值】<br>| ——-| y : DatetimeIndex<br>|<br>| onOffset(self, dt)<br>|<br>| ———————————————————————-<br>1159<br>| Methods inherited from YearOffset:<br>|<br>| <strong>init</strong>(self, n=1, normalize=False, </strong>kwds)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| ———————————————————————-| Data descriptors inherited from YearOffset:<br>|<br>| rule_code<br>|<br>| ———————————————————————-| Methods inherited from DateOffset:<br>|<br>| <strong>add</strong>(self, other)<br>|<br>| <strong>call</strong>(self, other)<br>| Call self as a function.<br>|<br>| <strong>eq</strong>(self, other)<br>| Return self==value.<br>|<br>| <strong>hash</strong>(self)<br>| Return hash(self).<br>|<br>| <strong>mul</strong>(self, someInt)<br>|<br>| <strong>ne</strong>(self, other)<br>| Return self!=value.<br>|<br>| <strong>neg</strong>(self)<br>|<br>| <strong>radd</strong>(self, other)<br>|<br>| <strong>repr</strong>(self)<br>| Return repr(self).<br>|<br>| <strong>rmul</strong>(self, someInt)<br>|<br>| <strong>rsub</strong>(self, other)<br>|<br>| <strong>sub</strong>(self, other)<br>|<br>| copy(self)<br>|<br>| isAnchored(self)<br>|<br>| rollback(self, dt)<br>| Roll provided date backward to next offset only if not on offset<br>|<br>| rollforward(self, dt)<br>| Roll provided date forward to next offset only if not on offset<br>|<br>| ———————————————————————-| Data descriptors inherited from DateOffset:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>1160<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>|<br>| freqstr<br>|<br>| name<br>|<br>| ———————————————————————-| Data and other attributes inherited from DateOffset:<br>|<br>| normalize = False<br>【数据】<br><strong>all</strong> = [‘Day’, ‘BusinessDay’, ‘BDay’, ‘CustomBusinessDay’, ‘CDay’, …<br>【文件】 ： \pandas\tseries\offsets.py<br>ols<br>函数 ols 模块所属：pandas.stats.interface:<br>ols(**kwargs)<br>Returns the appropriate OLS object depending on whether you need<br>simple or panel OLS, and a full-sample or rolling/expanding OLS.<br>Will be a normal linear regression or a (pooled) panel regression depending<br>on the type of the inputs:<br>y : Series, x : DataFrame -&gt; OLS<br>y : Series, x : dict of DataFrame -&gt; OLS<br>y : DataFrame, x : DataFrame -&gt; PanelOLS<br>y : DataFrame, x : dict of DataFrame/Panel -&gt; PanelOLS<br>y : Series with MultiIndex, x : Panel/DataFrame + MultiIndex -&gt; PanelOLS<br>【参数】<br>———-y: Series or DataFrame<br>See above for types<br>x: Series, DataFrame, dict of Series, dict of DataFrame, Panel<br>weights : Series or ndarray<br>The weights are presumed to be (proportional to) the inverse of the<br>variance of the observations. That is, if the variables are to be<br>transformed by 1/sqrt(W) you must supply weights = 1/W<br>intercept: bool<br>True if you want an intercept. Defaults to True.<br>nw_lags: None or int<br>Number of Newey-West lags. Defaults to None.<br>nw_overlap: bool<br>1161<br>Whether there are overlaps in the NW lags. Defaults to False.<br>window_type: {‘full sample’, ‘rolling’, ‘expanding’}<br>‘full sample’ by default<br>window: int<br>size of window (for rolling/expanding OLS). If window passed and no<br>explicit window_type, ‘rolling” will be used as the window_type<br>Panel OLS options:<br>pool: bool<br>Whether to run pooled panel regression. Defaults to true.<br>entity_effects: bool<br>Whether to account for entity fixed effects. Defaults to false.<br>time_effects: bool<br>Whether to account for time fixed effects. Defaults to false.<br>x_effects: list<br>List of x’s to account for fixed effects. Defaults to none.<br>dropped_dummies: dict<br>Key is the name of the variable for the fixed effect.<br>Value is the value of that variable for which we drop the dummy.<br>For entity fixed effects, key equals ‘entity’.<br>By default, the first dummy is dropped if no dummy is specified.<br>cluster: {‘time’, ‘entity’}<br>cluster variances<br>【示例】<br>——–# Run simple OLS.<br>result = ols(y=y, x=x)<h1 id="Run-rolling-simple-OLS-with-window-of-size-10"><a href="#Run-rolling-simple-OLS-with-window-of-size-10" class="headerlink" title="Run rolling simple OLS with window of size 10."></a>Run rolling simple OLS with window of size 10.</h1>result = ols(y=y, x=x, window_type=’rolling’, window=10)<br>print(result.beta)<br>result = ols(y=y, x=x, nw_lags=1)<h1 id="Set-up-LHS-and-RHS-for-data-across-all-items"><a href="#Set-up-LHS-and-RHS-for-data-across-all-items" class="headerlink" title="Set up LHS and RHS for data across all items"></a>Set up LHS and RHS for data across all items</h1>y = A<br>x = {‘B’ : B, ‘C’ : C}<h1 id="Run-panel-OLS"><a href="#Run-panel-OLS" class="headerlink" title="Run panel OLS."></a>Run panel OLS.</h1>result = ols(y=y, x=x)<h1 id="Run-expanding-panel-OLS-with-window-10-and-entity-clustering"><a href="#Run-expanding-panel-OLS-with-window-10-and-entity-clustering" class="headerlink" title="Run expanding panel OLS with window 10 and entity clustering."></a>Run expanding panel OLS with window 10 and entity clustering.</h1>result = ols(y=y, x=x, cluster=’entity’, window_type=’expanding’, window=10)<br>【返回值】<br>——-The appropriate OLS object, which allows you to obtain betas and various<br>statistics, such as std err, t-stat, etc.<br>1162<br>option_context<br>option_context 模块所属：pandas.core.config:<br>类定义：option_context(builtins.object)<br>| Context manager to temporarily set options in the <code>with</code> statement context.<br>|<br>| You need to invoke as <code>option_context(pat, val, [(pat, val), ...])</code>.<br>|<br>| 【示例】<br>| ——–|<br>| &gt;&gt;&gt; with option_context(‘display.max_rows’, 10, ‘display.max_columns’, 5):<br>| …<br>|<br>| 【方法定义】<br>|<br>| <strong>enter</strong>(self)<br>|<br>| <strong>exit</strong>(self, <em>args)<br>|<br>| <strong>init</strong>(self, </em>args)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>options<br>ordered_merge<br>函数 ordered_merge 模块所属：pandas.tools.merge:<br>ordered_merge(left, right, on=None, left_by=None, right_by=None, left_on=None, right_on=None, fill_method=None,<br>1163<br>suffixes=(‘_x’, ‘_y’))<br>Perform merge with optional filling/interpolation designed for ordered<br>data like time series data. Optionally perform group-wise merge (see<br>examples)<br>【参数】<br>———-left : DataFrame<br>right : DataFrame<br>fill_method : {‘ffill’, None}, default None<br>Interpolation method for data<br>on : label or list<br>Field names to join on. Must be found in both DataFrames.<br>left_on : label or list, or array-like<br>Field names to join on in left DataFrame. Can be a vector or list of<br>vectors of the length of the DataFrame to use a particular vector as<br>the join key instead of columns<br>right_on : label or list, or array-like<br>Field names to join on in right DataFrame or vector/list of vectors per<br>left_on docs<br>left_by : column name or list of column names<br>Group left DataFrame by group columns and merge piece by piece with<br>right DataFrame<br>right_by : column name or list of column names<br>Group right DataFrame by group columns and merge piece by piece with<br>left DataFrame<br>suffixes : 2-length sequence (tuple, list, …)<br>Suffix to apply to overlapping column names in the left and right<br>side, respectively<br>【示例】<br>——–&gt;&gt;&gt; A &gt;&gt;&gt; B<br>key lvalue group key rvalue<br>0 a 1 a 0 b 1<br>1 c 2 a 1 c 2<br>2 e 3 a 2 d 3<br>3 a 1 b<br>4 c 2 b<br>5 e 3 b<br>ordered_merge(A, B, fill_method=’ffill’, left_by=’group’)<br>key lvalue group rvalue<br>0 a 1 a NaN<br>1 b 1 a 1<br>2 c 2 a 2<br>3 d 2 a 3<br>4 e 3 a 3<br>5 f 3 a 4<br>6 a 1 b NaN<br>7 b 1 b 1<br>8 c 2 b 2<br>9 d 2 b 3<br>10 e 3 b 3<br>11 f 3 b 4<br>【返回值】<br>1164<br>——-merged : DataFrame<br>The output type will the be same as ‘left’, if it is a subclass<br>of DataFrame.<br>pandas<br>package pandas:<br>【名称】<br>pandas<br>【说明】<h1 id="pandas-a-powerful-data-analysis-and-manipulation-library-for-Python-3"><a href="#pandas-a-powerful-data-analysis-and-manipulation-library-for-Python-3" class="headerlink" title="pandas - a powerful data analysis and manipulation library for Python"></a>pandas - a powerful data analysis and manipulation library for Python</h1>See <a href="http://pandas.pydata.org/" target="_blank" rel="external">http://pandas.pydata.org/</a> for full documentation. Otherwise, see the<br>docstrings of the various objects in the pandas namespace:<br>Series<br>DataFrame<br>Panel<br>Index<br>DatetimeIndex<br>HDFStore<br>bdate_range<br>date_range<br>read_csv<br>read_fwf<br>read_table<br>ols<br>【模块包·内容】<br>_period<br>_sparse<br>_testing<br>_version<br>algos<br>compat (package)<br>computation (package)<br>core (package)<br>hashtable<br>index<br>info<br>io (package)<br>json<br>lib<br>msgpack (package)<br>parser<br>rpy (package)<br>1165<br>sandbox (package)<br>sparse (package)<br>stats (package)<br>tests (package)<br>tools (package)<br>tseries (package)<br>tslib<br>util (package)<br>【子模块】<br>datetools<br>offsets<br>【数据】<br>IndexSlice = <pandas.core.indexing._indexslice object=""><br>NaT = NaT<br><strong>docformat</strong> = ‘restructuredtext’<br><strong>warningregistry</strong> = {‘version’: 7, (r’bad escape \s’, <class 'deprec...="" describe_option="<pandas.core.config.CallableDynamicDoc" object="">
get_option = <pandas.core.config.callabledynamicdoc object="">
options = <pandas.core.config.dictwrapper object="">
plot_params = {'xaxis.compat': False}
reset_option = <pandas.core.config.callabledynamicdoc object="">
set_option = <pandas.core.config.callabledynamicdoc object="">
【版本】
0.17.1
【文件】 ： \pandas\__init__.py
parser
所属模块：pandas.parser in pandas:
【名称】
pandas.parser
【类型】
builtins.Exception(builtins.BaseException)
CParserError
builtins.ValueError(builtins.Exception)
OverflowError
【内置对象】
TextReader
class CParserError(builtins.Exception)
| Common base class for all non-exit exceptions.
|
1166
| 【方法排序】
| CParserError
| builtins.Exception
| builtins.BaseException
| 【内置对象】
|
| Data descriptors defined here:
|
| __weakref__
| list of weak references to the object (if defined)
|
| ----------------------------------------------------------------------| Methods inherited from builtins.Exception:
|
| __init__(self, /, *args, **kwargs)
| Initialize self. See help(type(self)) for accurate signature.
|
| __new__(*args, **kwargs) from builtins.type
| Create and return a new object. See help(type) for accurate signature.
|
| ----------------------------------------------------------------------| Methods inherited from builtins.BaseException:
|
| __delattr__(self, name, /)
| Implement delattr(self, name).
|
| __getattribute__(self, name, /)
| Return getattr(self, name).
|
| __reduce__(...)
| helper for pickle
|
| __repr__(self, /)
| Return repr(self).
|
| __setattr__(self, name, value, /)
| Implement setattr(self, name, value).
|
| __setstate__(...)
|
| __str__(self, /)
| Return str(self).
|
| with_traceback(...)
| Exception.with_traceback(tb) --| set self.__traceback__ to tb and return self.
|
| ----------------------------------------------------------------------| Data descriptors inherited from builtins.BaseException:
|
| __cause__
| exception cause
|
| __context__
| exception context
|
| __dict__
1167
|
| __suppress_context__
|
| __traceback__
|
| args
class OverflowError(builtins.ValueError)
| Inappropriate argument value (of correct type).
|
| 【方法排序】
| OverflowError
| builtins.ValueError
| builtins.Exception
| builtins.BaseException
| 【内置对象】
|
| Data descriptors defined here:
|
| __weakref__
| list of weak references to the object (if defined)
|
| ----------------------------------------------------------------------| Methods inherited from builtins.ValueError:
|
| __init__(self, /, *args, **kwargs)
| Initialize self. See help(type(self)) for accurate signature.
|
| __new__(*args, **kwargs) from builtins.type
| Create and return a new object. See help(type) for accurate signature.
|
| ----------------------------------------------------------------------| Methods inherited from builtins.BaseException:
|
| __delattr__(self, name, /)
| Implement delattr(self, name).
|
| __getattribute__(self, name, /)
| Return getattr(self, name).
|
| __reduce__(...)
| helper for pickle
|
| __repr__(self, /)
| Return repr(self).
|
| __setattr__(self, name, value, /)
| Implement setattr(self, name, value).
|
| __setstate__(...)
|
| __str__(self, /)
| Return str(self).
|
| with_traceback(...)
| Exception.with_traceback(tb) --| set self.__traceback__ to tb and return self.
1168
|
| ----------------------------------------------------------------------| Data descriptors inherited from builtins.BaseException:
|
| __cause__
| exception cause
|
| __context__
| exception context
|
| __dict__
|
| __suppress_context__
|
| __traceback__
|
| args
class TextReader(builtins.object)
| # source: StringIO or file object
|
| 【方法定义】
|
| __init__(self, /, *args, **kwargs)
| Initialize self. See help(type(self)) for accurate signature.
|
| __new__(*args, **kwargs) from builtins.type
| Create and return a new object. See help(type) for accurate signature.
|
| debug_print(...)
|
| read(...)
| rows=None --> read all rows
|
| remove_noconvert(...)
|
| set_error_bad_lines(...)
|
| set_noconvert(...)
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| allow_leading_cols
|
| as_recarray
|
| buffer_lines
|
| compact_ints
|
| compression
|
| converters
|
| delim_whitespace
|
1169
| delimiter
|
| dtype
|
| encoding
|
| header
|
| header_end
|
| header_start
|
| index_col
|
| leading_cols
|
| low_memory
|
| mangle_dupe_cols
|
| memory_map
|
| na_values
|
| names
|
| noconvert
|
| orig_header
|
| skip_footer
|
| skiprows
|
| table_width
|
| tupleize_cols
|
| use_unsigned
|
| usecols
|
| ----------------------------------------------------------------------| 其他数据、属性定义：
|
| __pyx_vtable__ = <capsule object="" null="">
【函数】
downcast_int64(...)
【数据】
DEFAULT_CHUNKSIZE = 262144
__test__ = {}
na_values = {<class 'numpy.int64'="">: -9223372036854775808, <class 3="" 1170="" 1171="" 'nump...="" 【文件】="" ：="" \pandas\parser.cp35-win_amd64.pyd="" period_range="" 函数="" 模块所属：pandas.tseries.period:="" period_range(start="None," end="None," periods="None," freq="D" ,="" name="None)" return="" a="" fixed="" frequency="" datetime="" index,="" with="" day="" (calendar)="" as="" the="" default 【参数】="" ----------start="" :="" starting="" value,="" period-like,="" optional="" ending="" int,="" none="" number="" of="" in="" index="" str="" dateoffset,="" 'd'="" alias="" str,="" for="" resulting="" periodindex="" 【返回值】="" -------prng="" pivot="" pivot_simple="" 模块所属：pandas.core.reshape:="" pivot_simple(index,="" columns,="" values)="" produce="" 'pivot'="" table="" based="" on="" columns="" this="" dataframe.="" uses="" unique="" values="" from="" and="" fills="" values.="" ----------index="" ndarray="" labels="" to="" use="" make="" new="" frame's="" populating="" 【注意】="" -----obviously,="" all="" input="" arguments="" must="" have="" same="" length="" -------dataframe="" pivot_table="" 模块所属：pandas.tools.pivot:="" pivot_table(data,="" aggfunc="mean" fill_value="None," margins="False," dropna="True," margins_name="All" )="" create="" spreadsheet-style="" levels="" will="" be="" stored="" multiindex="" objects="" (hierarchical="" indexes)="" result="" dataframe="" ----------data="" column="" aggregate,="" column,="" grouper,="" array="" which="" has="" data,="" or="" list="" them.="" keys="" group="" by="" index.="" if="" an="" is="" passed,="" it="" being="" used="" manner="" column.="" function,="" numpy.mean,="" functions="" hierarchical="" whose="" top="" level="" are="" function="" names="" (inferred="" themselves)="" scalar,="" value="" replace="" missing="" boolean,="" false="" add="" row="" (e.g.="" subtotal="" grand="" totals)="" true="" do="" not="" include="" entries="" nan="" string,="" 'all'="" that="" contain="" totals="" when="" true.="" 【示例】="" --------="">>> df
A B C D
0 foo one small 1
1 foo one large 2
2 foo one large 2
3 foo two small 3
4 foo two small 3
1172
5 bar one large 4
6 bar one small 5
7 bar two small 6
8 bar two large 7
table = pivot_table(df, values='D', index=['A', 'B'],
... columns=['C'], aggfunc=np.sum)
table
small large
foo one 1 4
two 6 NaN
bar one 5 4
two 6 7
【返回值】
-------table : DataFrame
plot_params
_Options 模块所属：pandas.tools.plotting object:
类定义：_Options(builtins.dict)
| Stores pandas plotting options.
| Allows for parameter aliasing so you can just use parameter names that are
| the same as the plot function parameters, but is stored in a canonical
| format that makes it easy to breakdown into groups later
|
| 【方法排序】
| _Options
| builtins.dict
| 【内置对象】
|
| 【方法定义】
|
| __contains__(self, key)
| True if D has a key k, else False.
|
| __delitem__(self, key)
| Delete self[key].
|
| __getitem__(self, key)
| x.__getitem__(y) <==> x[y]
|
| __init__(self)
| Initialize self. See help(type(self)) for accurate signature.
|
| __setitem__(self, key, value)
| Set self[key] to value.
|
1173
| reset(self)
| Reset the option store to its initial state
|
| 【返回值】
| -------| None
|
| use(self, key, value)
| Temporarily set a parameter value using the with statement.
| Aliasing allowed.
|
| ----------------------------------------------------------------------| Data descriptors defined here:
|
| __dict__
| dictionary for instance variables (if defined)
|
| __weakref__
| list of weak references to the object (if defined)
|
| ----------------------------------------------------------------------| Methods inherited from builtins.dict:
|
| __eq__(self, value, /)
| Return self==value.
|
| __ge__(self, value, /)
| Return self>=value.
|
| __getattribute__(self, name, /)
| Return getattr(self, name).
|
| __gt__(self, value, /)
| Return self>value.
|
| __iter__(self, /)
| Implement iter(self).
|
| __le__(self, value, /)
| Return self<=value. 1174="" |="" __len__(self,="" )="" return="" len(self).="" __lt__(self,="" value,="" self<value.="" __ne__(self,="" self!="value." __new__(*args,="" **kwargs)="" from="" builtins.type="" create="" and="" a="" new="" object.="" see="" help(type)="" for="" accurate="" signature.="" __repr__(self,="" repr(self).="" __sizeof__(...)="" d.__sizeof__()="" -=""> size of D in memory, in bytes
|
| clear(...)
| D.clear() -> None. Remove all items from D.
|
| copy(...)
| D.copy() -> a shallow copy of D
|
| fromkeys(iterable, value=None, /) from builtins.type
| Returns a new dict with keys from iterable and values equal to value.
|
| get(...)
| D.get(k[,d]) -> D[k] if k in D, else d. d defaults to None.
|
| items(...)
| D.items() -> a set-like object providing a view on D's items
|
| keys(...)
| D.keys() -> a set-like object providing a view on D’s keys<br>|<br>| pop(…)<br>| D.pop(k[,d]) -&gt; v, remove specified key and return the corresponding value.<br>| If key is not found, d is returned if given, otherwise KeyError is raised<br>|<br>| popitem(…)<br>| D.popitem() -&gt; (k, v), remove and return some (key, value) pair as a<br>| 2-tuple; but raise KeyError if D is empty.<br>|<br>| setdefault(…)<br>| D.setdefault(k[,d]) -&gt; D.get(k,d), also set D[k]=d if k not in D<br>|<br>| update(…)<br>| D.update([E, ]<strong>F) -&gt; None. Update D from dict/iterable E and F.<br>| If E is present and has a .keys() method, then does: for k in E: D[k] = E[k]<br>| If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v<br>| In either case, this is followed by: for k in F: D[k] = F[k]<br>|<br>| values(…)<br>| D.values() -&gt; an object providing a view on D’s values<br>|<br>| ———————————————————————-| Data and other attributes inherited from builtins.dict:<br>|<br>| <strong>hash</strong> = None<br>pnow<br>函数 pnow 模块所属：pandas.tseries.period:<br>pnow(freq=None)<br>1175<br>qcut<br>函数 qcut 模块所属：pandas.tools.tile:<br>qcut(x, q, labels=None, retbins=False, precision=3)<br>Quantile-based discretization function. Discretize variable into<br>equal-sized buckets based on rank or based on sample quantiles. For example<br>1000 values for 10 quantiles would produce a Categorical object indicating<br>quantile membership for each data point.<br>【参数】<br>———-x : ndarray or Series<br>q : integer or array of quantiles<br>Number of quantiles. 10 for deciles, 4 for quartiles, etc. Alternately<br>array of quantiles, e.g. [0, .25, .5, .75, 1.] for quartiles<br>labels : array or boolean, default None<br>Used as labels for the resulting bins. Must be of the same length as the resulting<br>bins. If False, return only integer indicators of the bins.<br>retbins : bool, optional<br>Whether to return the bins or not. Can be useful if bins is given<br>as a scalar.<br>precision : int<br>The precision at which to store and display the bins labels<br>【返回值】<br>——-out : Categorical or Series or array of integers if labels is False<br>The return type (Categorical or Series) depends on the input: a Series of type category if<br>input is a Series else Categorical. Bins are represented as categories when categorical<br>data is returned.<br>bins : ndarray of floats<br>Returned only if <code>retbins</code> is True.<br>【注意】<br>—–Out of bounds values will be NA in the resulting Categorical object<br>【示例】<br>——–&gt;&gt;&gt; pd.qcut(range(5), 4)<br>[[0, 1], [0, 1], (1, 2], (2, 3], (3, 4]]<br>Categories (4, object): [[0, 1] &lt; (1, 2] &lt; (2, 3] &lt; (3, 4]]<br>pd.qcut(range(5), 3, labels=[“good”,”medium”,”bad”])<br>[good, good, medium, bad, bad]<br>Categories (3, object): [good &lt; medium &lt; bad]<br>pd.qcut(range(5), 4, labels=False)<br>array([0, 0, 1, 2, 3], dtype=int64)<br>1176<br>read_clipboard<br>函数 read_clipboard 模块所属：pandas.io.clipboard:<br>read_clipboard(</strong>kwargs)<br>Read text from clipboard and pass to read_table. See read_table for the<br>full argument list<br>If unspecified, <code>sep</code> defaults to ‘\s+’<br>【返回值】<br>——-parsed : DataFrame<br>read_csv<br>函数 read_csv 模块所属：pandas.io.parsers:<br>read_csv(filepath_or_buffer, sep=’,’, dialect=None, compression=’infer’, doublequote=True, escapechar=None, quotechar=’”‘,<br>quoting=0, skipinitialspace=False, lineterminator=None, header=’infer’, index_col=None, names=None, prefix=None,<br>skiprows=None, skipfooter=None, skip_footer=0, na_values=None, true_values=None, false_values=None, delimiter=None,<br>converters=None, dtype=None, usecols=None, engine=None, delim_whitespace=False, as_recarray=False, na_filter=True,<br>compact_ints=False, use_unsigned=False, low_memory=True, buffer_lines=None, warn_bad_lines=True, error_bad_lines=True,<br>keep_default_na=True, thousands=None, comment=None, decimal=b’.’, parse_dates=False, keep_date_col=False,<br>dayfirst=False, date_parser=None, memory_map=False, float_precision=None, nrows=None, iterator=False, chunksize=None,<br>verbose=False, encoding=None, squeeze=False, mangle_dupe_cols=True, tupleize_cols=False, infer_datetime_format=False,<br>skip_blank<em>lines=True)<br>Read CSV (comma-separated) file into DataFrame<br>Also supports optionally iterating or breaking of the file<br>into chunks.<br>Additional help can be found in the <code>online docs for IO Tools
&lt;http://pandas.pydata.org/pandas-docs/stable/io.html&gt;</code></em>.<br>【参数】<br>———-filepath_or<em>buffer : string or file handle / StringIO<br>The string could be a URL. Valid URL schemes include<br>http, ftp, s3, and file. For file URLs, a<br>host is expected. For instance, a local file could be<br>file ://localhost/path/to/table.csv<br>sep : string, default ‘,’<br>Delimiter to use. If sep is None, will try to automatically determine<br>1177<br>this. Regular expressions are accepted.<br>engine : {‘c’, ‘python’}<br>Parser engine to use. The C engine is faster while the python engine is<br>currently more feature-complete.<br>lineterminator : string (length 1), default None<br>Character to break file into lines. Only valid with C parser<br>quotechar : string (length 1)<br>The character used to denote the start and end of a quoted item. Quoted<br>items can include the delimiter and it will be ignored.<br>quoting : int or csv.QUOTE</em><em> instance, default None<br>Control field quoting behavior per ``csv.QUOTE_</em><code>constants. Use one of
QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).
Default (None) results in QUOTE_MINIMAL behavior.
skipinitialspace : boolean, default False
Skip spaces after delimiter
escapechar : string (length 1), default None
One-character string used to escape delimiter when quoting is QUOTE_NONE.
dtype : Type name or dict of column -&gt; type, default None
Data type for data or columns. E.g. {&#39;a&#39;: np.float64, &#39;b&#39;: np.int32}
(Unsupported with engine=&#39;python&#39;)
compression : {&#39;gzip&#39;, &#39;bz2&#39;, &#39;infer&#39;, None}, default &#39;infer&#39;
For on-the-fly decompression of on-disk data. If &#39;infer&#39;, then use gzip or
bz2 if filepath_or_buffer is a string ending in &#39;.gz&#39; or &#39;.bz2&#39;,
respectively, and no decompression otherwise. Set to None for no
decompression.
dialect : string or csv.Dialect instance, default None
If None defaults to Excel dialect. Ignored if sep longer than 1 char
See csv.Dialect documentation for more details
header : int, list of ints, default &#39;infer&#39;
Row number(s) to use as the column names, and the start of the
data. Defaults to 0 if no</code>names<code>passed, otherwise</code>None<code>. Explicitly
pass</code>header=0<code>to be able to replace existing names. The header can be
a list of integers that specify row locations for a multi-index on the
columns E.g. [0,1,3]. Intervening rows that are not specified will be
skipped (e.g. 2 in this example are skipped). Note that this parameter
ignores commented lines and empty lines if</code>skip_blank_lines=True<code>, so header=0
denotes the first line of data rather than the first line of the file.
skiprows : list-like or integer, default None
Line numbers to skip (0-indexed) or number of lines to skip (int)
at the start of the file
index_col : int or sequence or False, default None
Column to use as the row labels of the DataFrame. If a sequence is given, a
MultiIndex is used. If you have a malformed file with delimiters at the end
of each line, you might consider index_col=False to force pandas to _not_
use the first column as the index (row names)
names : array-like, default None
List of column names to use. If file contains no header row, then you
should explicitly pass header=None
prefix : string, default None
Prefix to add to column numbers when no header, e.g &#39;X&#39; for X0, X1, ...
na_values : str, list-like or dict, default None
Additional strings to recognize as NA/NaN. If dict passed, specific
per-column NA values
true_values : list, default None
Values to consider as True
false_values : list, default None
Values to consider as False
1178
keep_default_na : bool, default True
If na_values are specified and keep_default_na is False the default NaN
values are overridden, otherwise they&#39;re appended to
parse_dates : boolean, list of ints or names, list of lists, or dict, default False
If True -&gt; try parsing the index.
If [1, 2, 3] -&gt; try parsing columns 1, 2, 3 each as a separate date column.
If [[1, 3]] -&gt; combine columns 1 and 3 and parse as a single date column.
{&#39;foo&#39; : [1, 3]} -&gt; parse columns 1, 3 as date and call result &#39;foo&#39;
A fast-path exists for iso8601-formatted dates.
keep_date_col : boolean, default False
If True and parse_dates specifies combining multiple columns then
keep the original columns.
date_parser : function, default None
Function to use for converting a sequence of string columns to an
array of datetime instances. The default uses dateutil.parser.parser
to do the conversion. Pandas will try to call date_parser in three different
ways, advancing to the next if an exception occurs: 1) Pass one or more arrays
(as defined by parse_dates) as arguments; 2) concatenate (row-wise) the string
values from the columns defined by parse_dates into a single array and pass
that; and 3) call date_parser once for each row using one or more strings
(corresponding to the columns defined by parse_dates) as arguments.
dayfirst : boolean, default False
DD/MM format dates, international and European format
thousands : str, default None
Thousands separator
comment : str, default None
Indicates remainder of line should not be parsed. If found at the
beginning of a line, the line will be ignored altogether. This parameter
must be a single character. Like empty lines (as long as</code>skip_blank_lines=True<code>),
fully commented lines are ignored by the parameter `header`
but not by `skiprows`. For example, if comment=&#39;#&#39;, parsing
&#39;#empty\na,b,c\n1,2,3&#39; with `header=0` will result in &#39;a,b,c&#39; being
treated as the header.
decimal : str, default &#39;.&#39;
Character to recognize as decimal point. E.g. use &#39;,&#39; for European data
nrows : int, default None
Number of rows of file to read. Useful for reading pieces of large files
iterator : boolean, default False
Return TextFileReader object for iteration or getting chunks with</code>get<em>chunk()<code>`.
chunksize : int, default None
Return TextFileReader object for iteration.</code>See IO Tools docs for more<br>information<br><a href="http://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking" target="_blank" rel="external">http://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking</a>`</em> on<br><code>iterator</code> and <code>chunksize</code>.<br>skipfooter : int, default 0<br>Number of lines at bottom of file to skip (Unsupported with engine=’c’)<br>converters : dict, default None<br>Dict of functions for converting values in certain columns. Keys can either<br>be integers or column labels<br>verbose : boolean, default False<br>Indicate number of NA values placed in non-numeric columns<br>delimiter : string, default None<br>Alternative argument name for sep. Regular expressions are accepted.<br>encoding : string, default None<br>Encoding to use for UTF when reading/writing (ex. ‘utf-8’). <code>List of Python
standard encodings
&lt;https://docs.python.org/3/library/codecs.html#standard-encodings&gt;</code>_<br>1179<br>squeeze : boolean, default False<br>If the parsed data only contains one column then return a Series<br>na_filter : boolean, default True<br>Detect missing value markers (empty strings and the value of na_values). In<br>data without any NAs, passing na_filter=False can improve the performance<br>of reading a large file<br>usecols : array-like, default None<br>Return a subset of the columns.<br>Results in much faster parsing time and lower memory usage.<br>mangle_dupe_cols : boolean, default True<br>Duplicate columns will be specified as ‘X.0’…’X.N’, rather than ‘X’…’X’<br>tupleize_cols : boolean, default False<br>Leave a list of tuples on columns as is (default is to convert to<br>a Multi Index on the columns)<br>error_bad_lines : boolean, default True<br>Lines with too many fields (e.g. a csv line with too many commas) will by<br>default cause an exception to be raised, and no DataFrame will be returned.<br>If False, then these “bad lines” will dropped from the DataFrame that is<br>returned. (Only valid with C parser)<br>warn_bad_lines : boolean, default True<br>If error_bad_lines is False, and warn_bad_lines is True, a warning for each<br>“bad line” will be output. (Only valid with C parser).<br>infer_datetime_format : boolean, default False<br>If True and parse_dates is enabled for a column, attempt to infer<br>the datetime format to speed up the processing<br>skip_blank_lines : boolean, default True<br>If True, skip over blank lines rather than interpreting as NaN values<br>【返回值】<br>——-result : DataFrame or TextParser<br>read_excel<br>函数 read_excel 模块所属：pandas.io.excel:<br>read_excel(io, sheetname=0, header=0, skiprows=None, skip_footer=0, index_col=None, parse_cols=None, parse_dates=False,<br>date_parser=None, na_values=None, thousands=None, convert_float=True, has_index_names=None, converters=None,<br>engine=None, **kwds)<br>Read an Excel table into a pandas DataFrame<br>【参数】<br>———-io : string, file-like object, pandas ExcelFile, or xlrd workbook.<br>The string could be a URL. Valid URL schemes include http, ftp, s3,<br>and file. For file URLs, a host is expected. For instance, a local<br>file could be file://localhost/path/to/workbook.xlsx<br>sheetname : string, int, mixed list of strings/ints, or None, default 0<br>Strings are used for sheet names, Integers are used in zero-indexed sheet<br>1180<br>positions.<br>Lists of strings/integers are used to request multiple sheets.<br>Specify None to get all sheets.<br>str|int -&gt; DataFrame is returned.<br>list|None -&gt; Dict of DataFrames is returned, with keys representing sheets.<br>Available Cases</=value.></==></class></class></capsule></pandas.core.config.callabledynamicdoc></pandas.core.config.callabledynamicdoc></pandas.core.config.dictwrapper></pandas.core.config.callabledynamicdoc></class></pandas.core.indexing._indexslice></n></n></n></n></n></n></li>
<li>Defaults to 0 -&gt; 1st sheet as a DataFrame</li>
<li>1 -&gt; 2nd sheet as a DataFrame</li>
<li>“Sheet1” -&gt; 1st sheet as a DataFrame</li>
<li>[0,1,”Sheet5”] -&gt; 1st, 2nd &amp; 5th sheet as a dictionary of DataFrames</li>
<li>None -&gt; All sheets as a dictionary of DataFrames<br>header : int, list of ints, default 0<br>Row (0-indexed) to use for the column labels of the parsed<br>DataFrame. If a list of integers is passed those row positions will<br>be combined into a <code>MultiIndex</code><br>skiprows : list-like<br>Rows to skip at the beginning (0-indexed)<br>skip_footer : int, default 0<br>Rows at the end to skip (0-indexed)<br>index_col : int, list of ints, default None<br>Column (0-indexed) to use as the row labels of the DataFrame.<br>Pass None if there is no such column. If a list is passed,<br>those columns will be combined into a <code>MultiIndex</code><br>converters : dict, default None<br>Dict of functions for converting values in certain columns. Keys can<br>either be integers or column labels, values are functions that take one<br>input argument, the Excel cell content, and return the transformed<br>content.<br>parse_cols : int or list, default None</li>
<li>If None then parse all columns,</li>
<li>If int then indicates last column to be parsed</li>
<li>If list of ints then indicates list of column numbers to be parsed</li>
<li>If string then indicates comma separated list of column names and<br>column ranges (e.g. “A:E” or “A,C,E:F”)<br>na_values : list-like, default None<br>List of additional strings to recognize as NA/NaN<br>thousands : str, default None<br>Thousands separator for parsing string columns to numeric. Note that<br>this parameter is only necessary for columns stored as TEXT in Excel,<br>any numeric columns will automatically be parsed, regardless of display<br>format.<br>keep_default_na : bool, default True<br>If na_values are specified and keep_default_na is False the default NaN<br>values are overridden, otherwise they’re appended to<br>verbose : boolean, default False<br>Indicate number of NA values placed in non-numeric columns<br>engine: string, default None<br>If io is not a buffer or path, this must be set to identify io.<br>Acceptable values are None or xlrd<br>convert_float : boolean, default True<br>convert integral floats to int (i.e., 1.0 –&gt; 1). If False, all numeric<br>1181<br>data will be read in as floats: Excel stores all numbers as floats<br>internally<br>has_index_names : boolean, default None<br>DEPRECATED: for version 0.17+ index names will be automatically inferred<br>based on index_col. To read Excel output from 0.16.2 and prior that<br>had saved index names, use True.<br>【返回值】<br>——-parsed : DataFrame or Dict of DataFrames<br>DataFrame from the passed in Excel file. See notes in sheetname argument<br>for more information on when a Dict of Dataframes is returned.<br>read_fwf<br>函数 read_fwf 模块所属：pandas.io.parsers:<br>read_fwf(filepath_or<em>buffer, colspecs=’infer’, widths=None, **kwds)<br>Read a table of fixed-width formatted lines into DataFrame<br>Also supports optionally iterating or breaking of the file<br>into chunks.<br>Additional help can be found in the <code>online docs for IO Tools
&lt;http://pandas.pydata.org/pandas-docs/stable/io.html&gt;</code></em>.<br>【参数】<br>———-filepath_or<em>buffer : string or file handle / StringIO<br>The string could be a URL. Valid URL schemes include<br>http, ftp, s3, and file. For file URLs, a<br>host is expected. For instance, a local file could be<br>file ://localhost/path/to/table.csv<br>colspecs : list of pairs (int, int) or ‘infer’. optional<br>A list of pairs (tuples) giving the extents of the fixed-width<br>fields of each line as half-open intervals (i.e., [from, to[ ).<br>String value ‘infer’ can be used to instruct the parser to try<br>detecting the column specifications from the first 100 rows of<br>the data (default=’infer’).<br>widths : list of ints. optional<br>A list of field widths which can be used instead of ‘colspecs’ if<br>the intervals are contiguous.<br>lineterminator : string (length 1), default None<br>Character to break file into lines. Only valid with C parser<br>quotechar : string (length 1)<br>The character used to denote the start and end of a quoted item. Quoted<br>items can include the delimiter and it will be ignored.<br>quoting : int or csv.QUOTE</em><em> instance, default None<br>Control field quoting behavior per ``csv.QUOTE_</em><code>constants. Use one of
1182
QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).
Default (None) results in QUOTE_MINIMAL behavior.
skipinitialspace : boolean, default False
Skip spaces after delimiter
escapechar : string (length 1), default None
One-character string used to escape delimiter when quoting is QUOTE_NONE.
dtype : Type name or dict of column -&gt; type, default None
Data type for data or columns. E.g. {&#39;a&#39;: np.float64, &#39;b&#39;: np.int32}
(Unsupported with engine=&#39;python&#39;)
compression : {&#39;gzip&#39;, &#39;bz2&#39;, &#39;infer&#39;, None}, default &#39;infer&#39;
For on-the-fly decompression of on-disk data. If &#39;infer&#39;, then use gzip or
bz2 if filepath_or_buffer is a string ending in &#39;.gz&#39; or &#39;.bz2&#39;,
respectively, and no decompression otherwise. Set to None for no
decompression.
dialect : string or csv.Dialect instance, default None
If None defaults to Excel dialect. Ignored if sep longer than 1 char
See csv.Dialect documentation for more details
header : int, list of ints, default &#39;infer&#39;
Row number(s) to use as the column names, and the start of the
data. Defaults to 0 if no</code>names<code>passed, otherwise</code>None<code>. Explicitly
pass</code>header=0<code>to be able to replace existing names. The header can be
a list of integers that specify row locations for a multi-index on the
columns E.g. [0,1,3]. Intervening rows that are not specified will be
skipped (e.g. 2 in this example are skipped). Note that this parameter
ignores commented lines and empty lines if</code>skip_blank_lines=True<code>, so header=0
denotes the first line of data rather than the first line of the file.
skiprows : list-like or integer, default None
Line numbers to skip (0-indexed) or number of lines to skip (int)
at the start of the file
index_col : int or sequence or False, default None
Column to use as the row labels of the DataFrame. If a sequence is given, a
MultiIndex is used. If you have a malformed file with delimiters at the end
of each line, you might consider index_col=False to force pandas to _not_
use the first column as the index (row names)
names : array-like, default None
List of column names to use. If file contains no header row, then you
should explicitly pass header=None
prefix : string, default None
Prefix to add to column numbers when no header, e.g &#39;X&#39; for X0, X1, ...
na_values : str, list-like or dict, default None
Additional strings to recognize as NA/NaN. If dict passed, specific
per-column NA values
true_values : list, default None
Values to consider as True
false_values : list, default None
Values to consider as False
keep_default_na : bool, default True
If na_values are specified and keep_default_na is False the default NaN
values are overridden, otherwise they&#39;re appended to
parse_dates : boolean, list of ints or names, list of lists, or dict, default False
If True -&gt; try parsing the index.
If [1, 2, 3] -&gt; try parsing columns 1, 2, 3 each as a separate date column.
If [[1, 3]] -&gt; combine columns 1 and 3 and parse as a single date column.
{&#39;foo&#39; : [1, 3]} -&gt; parse columns 1, 3 as date and call result &#39;foo&#39;
A fast-path exists for iso8601-formatted dates.
keep_date_col : boolean, default False
If True and parse_dates specifies combining multiple columns then
1183
keep the original columns.
date_parser : function, default None
Function to use for converting a sequence of string columns to an
array of datetime instances. The default uses dateutil.parser.parser
to do the conversion. Pandas will try to call date_parser in three different
ways, advancing to the next if an exception occurs: 1) Pass one or more arrays
(as defined by parse_dates) as arguments; 2) concatenate (row-wise) the string
values from the columns defined by parse_dates into a single array and pass
that; and 3) call date_parser once for each row using one or more strings
(corresponding to the columns defined by parse_dates) as arguments.
dayfirst : boolean, default False
DD/MM format dates, international and European format
thousands : str, default None
Thousands separator
comment : str, default None
Indicates remainder of line should not be parsed. If found at the
beginning of a line, the line will be ignored altogether. This parameter
must be a single character. Like empty lines (as long as</code>skip_blank_lines=True<code>),
fully commented lines are ignored by the parameter `header`
but not by `skiprows`. For example, if comment=&#39;#&#39;, parsing
&#39;#empty\na,b,c\n1,2,3&#39; with `header=0` will result in &#39;a,b,c&#39; being
treated as the header.
decimal : str, default &#39;.&#39;
Character to recognize as decimal point. E.g. use &#39;,&#39; for European data
nrows : int, default None
Number of rows of file to read. Useful for reading pieces of large files
iterator : boolean, default False
Return TextFileReader object for iteration or getting chunks with</code>get<em>chunk()<code>`.
chunksize : int, default None
Return TextFileReader object for iteration.</code>See IO Tools docs for more<br>information<br><a href="http://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking" target="_blank" rel="external">http://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking</a>`</em> on<br><code>iterator</code> and <code>chunksize</code>.<br>skipfooter : int, default 0<br>Number of lines at bottom of file to skip (Unsupported with engine=’c’)<br>converters : dict, default None<br>Dict of functions for converting values in certain columns. Keys can either<br>be integers or column labels<br>verbose : boolean, default False<br>Indicate number of NA values placed in non-numeric columns<br>delimiter : string, default None<br>Alternative argument name for sep. Regular expressions are accepted.<br>encoding : string, default None<br>Encoding to use for UTF when reading/writing (ex. ‘utf-8’). <code>List of Python
standard encodings
&lt;https://docs.python.org/3/library/codecs.html#standard-encodings&gt;</code>_<br>squeeze : boolean, default False<br>If the parsed data only contains one column then return a Series<br>na_filter : boolean, default True<br>Detect missing value markers (empty strings and the value of na_values). In<br>data without any NAs, passing na_filter=False can improve the performance<br>of reading a large file<br>usecols : array-like, default None<br>Return a subset of the columns.<br>Results in much faster parsing time and lower memory usage.<br>mangle_dupe_cols : boolean, default True<br>Duplicate columns will be specified as ‘X.0’…’X.N’, rather than ‘X’…’X’<br>1184<br>tupleize_cols : boolean, default False<br>Leave a list of tuples on columns as is (default is to convert to<br>a Multi Index on the columns)<br>error_bad_lines : boolean, default True<br>Lines with too many fields (e.g. a csv line with too many commas) will by<br>default cause an exception to be raised, and no DataFrame will be returned.<br>If False, then these “bad lines” will dropped from the DataFrame that is<br>returned. (Only valid with C parser)<br>warn_bad_lines : boolean, default True<br>If error_bad_lines is False, and warn_bad_lines is True, a warning for each<br>“bad line” will be output. (Only valid with C parser).<br>infer_datetime_format : boolean, default False<br>If True and parse_dates is enabled for a column, attempt to infer<br>the datetime format to speed up the processing<br>skip_blank_lines : boolean, default True<br>If True, skip over blank lines rather than interpreting as NaN values<br>【返回值】<br>——-result : DataFrame or TextParser<br>Also, ‘delimiter’ is used to specify the filler character of the<br>fields if it is not spaces (e.g., ‘~’).<br>read_gbq<br>函数 read_gbq 模块所属：pandas.io.gbq:<br>read_gbq(query, project_id=None, index_col=None, col_order=None, reauth=False, verbose=True)<br>Load data from Google BigQuery.<br>THIS IS AN EXPERIMENTAL LIBRARY<br>The main method a user calls to execute a Query in Google BigQuery and read results<br>into a pandas DataFrame using the v2 Google API client for Python. Documentation for<br>the API is available at <a href="https://developers.google.com/api-client-library/python/" target="_blank" rel="external">https://developers.google.com/api-client-library/python/</a>.<br>Authentication to the Google BigQuery service is via OAuth 2.0 using the product name<br>‘pandas GBQ’.<br>【参数】<br>———-query : str<br>SQL-Like Query to return data values<br>project_id : str<br>Google BigQuery Account project ID.<br>index_col : str (optional)<br>Name of result column to use for index in results DataFrame<br>col_order : list(str) (optional)<br>List of BigQuery column names in the desired order for results<br>1185<br>DataFrame<br>reauth : boolean (default False)<br>Force Google BigQuery to reauthenticate the user. This is useful<br>if multiple accounts are used.<br>verbose : boolean (default True)<br>Verbose output<br>【返回值】<br>——-df: DataFrame<br>DataFrame representing results of query<br>read_hdf<br>函数 read_hdf 模块所属：pandas.io.pytables:<br>read_hdf(path_or_buf, key=None, <strong>kwargs)<br>read from the store, close it if we opened it<br>Retrieve pandas object stored in file, optionally based on where<br>criteria<br>【参数】<br>———-path_or_buf : path (string), or buffer to read from<br>key : group identifier in the store. Can be omitted a HDF file contains<br>a single pandas object.<br>where : list of Term (or convertable) objects, optional<br>start : optional, integer (defaults to None), row number to start<br>selection<br>stop : optional, integer (defaults to None), row number to stop<br>selection<br>columns : optional, a list of columns that if not None, will limit the<br>return columns<br>iterator : optional, boolean, return an iterator, default False<br>chunksize : optional, nrows to include in iteration, return an iterator<br>【返回值】<br>——-The selected object<br>read_html<br>1186<br>函数 read_html 模块所属：pandas.io.html:<br>read_html(io, match=’.+’, flavor=None, header=None, index_col=None, skiprows=None, attrs=None, parse_dates=False,<br>tupleize_cols=False, thousands=’,’, encoding=None)<br>Read HTML tables into a <code>list</code> of <code>DataFrame</code> objects.<br>【参数】<br>———-io : str or file-like<br>A URL, a file-like object, or a raw string containing HTML. Note that<br>lxml only accepts the http, ftp and file url protocols. If you have a<br>URL that starts with <code>&#39;https&#39;</code> you might try removing the <code>&#39;s&#39;</code>.<br>match : str or compiled regular expression, optional<br>The set of tables containing text matching this regex or string will be<br>returned. Unless the HTML is extremely simple you will probably need to<br>pass a non-empty string here. Defaults to ‘.+’ (match any non-empty<br>string). The default value will return all tables contained on a page.<br>This value is converted to a regular expression so that there is<br>consistent behavior between Beautiful Soup and lxml.<br>flavor : str or None, container of strings<br>The parsing engine to use. ‘bs4’ and ‘html5lib’ are synonymous with<br>each other, they are both there for backwards compatibility. The<br>default of <code>None</code> tries to use <code>lxml</code> to parse and if that fails it<br>falls back on <code>bs4</code> + <code>html5lib</code>.<br>header : int or list-like or None, optional<br>The row (or list of rows for a :class:<code>~pandas.MultiIndex</code>) to use to<br>make the columns headers.<br>index_col : int or list-like or None, optional<br>The column (or list of columns) to use to create the index.<br>skiprows : int or list-like or slice or None, optional<br>0-based. Number of rows to skip after parsing the column integer. If a<br>sequence of integers or a slice is given, will skip the rows indexed by<br>that sequence. Note that a single element sequence means ‘skip the nth<br>row’ whereas an integer means ‘skip n rows’.<br>attrs : dict or None, optional<br>This is a dictionary of attributes that you can pass to use to identify<br>the table in the HTML. These are not checked for validity before being<br>passed to lxml or Beautiful Soup. However, these attributes must be<br>valid HTML table attributes to work correctly. For example, ::<br>attrs = {‘id’: ‘table’}<br>is a valid attribute dictionary because the ‘id’ HTML tag attribute is<br>a valid HTML attribute for <em>any</em> HTML tag as per <code>this document
&lt;http://www.w3.org/TR/html-markup/global-attributes.html&gt;</code><strong>. ::<br>attrs = {‘asdf’: ‘table’}<br>is <em>not</em> a valid attribute dictionary because ‘asdf’ is not a valid<br>HTML attribute even if it is a valid XML attribute. Valid HTML 4.01<br>table attributes can be found <code>here
1187
&lt;http://www.w3.org/TR/REC-html40/struct/tables.html#h-11.2&gt;</code></strong>. A<br>working draft of the HTML 5 spec can be found <code>here
&lt;http://www.w3.org/TR/html-markup/table.html&gt;</code>__. It contains the<br>latest information on table attributes for the modern web.<br>parse_dates : bool, optional<br>See :func:<code>~pandas.read_csv</code> for more details.<br>tupleize_cols : bool, optional<br>If <code>False</code> try to parse multiple header rows into a<br>:class:<code>~pandas.MultiIndex</code>, otherwise return raw tuples. Defaults to<br><code>False</code>.<br>thousands : str, optional<br>Separator to use to parse thousands. Defaults to <code>&#39;,&#39;</code>.<br>encoding : str or None, optional<br>The encoding used to decode the web page. Defaults to <code>None</code>.<code>None</code><br>preserves the previous encoding behavior, which depends on the<br>underlying parser library (e.g., the parser library will try to use<br>the encoding provided by the document).<br>【返回值】<br>——-dfs : list of DataFrames<br>【注意】<br>—–Before using this function you should read the :ref:<code>gotchas about the
HTML parsing libraries &lt;html-gotchas&gt;</code>.<br>Expect to do some cleanup after you call this function. For example, you<br>might need to manually assign column names if the column names are<br>converted to NaN when you pass the <code>header=0</code> argument. We try to assume as<br>little as possible about the structure of the table and push the<br>idiosyncrasies of the HTML contained in the table to the user.<br>This function searches for <code>&lt;table&gt;</code> elements and only for <code>&lt;tr&gt;</code><br>and <code>&lt;th&gt;</code> rows and <code>&lt;td&gt;</code> elements within each <code>&lt;tr&gt;</code> or <code>&lt;th&gt;</code><br>element in the table. <code>&lt;td&gt;</code> stands for “table data”.<br>Similar to :func:<code>~pandas.read_csv</code> the <code>header</code> argument is applied
</strong>after<em>* <code>skiprows</code> is applied.<br>This function will </em>always<em> return a list of :class:<code>DataFrame</code> </em>or<em><br>it will fail, e.g., it will </em>not* return an empty list.<br>【示例】<br>——–See the :ref:<code>read_html documentation in the IO section of the docs
&lt;io.read_html&gt;</code> for some examples of reading in HTML tables.<br>【参见】<br>——–pandas.read_csv<br>1188<br>read_json<br>函数 read_json 模块所属：pandas.io.json:<br>read_json(path_or_buf=None, orient=None, typ=’frame’, dtype=True, convert_axes=True, convert_dates=True,<br>keep_default_dates=True, numpy=False, precise_float=False, date_unit=None)<br>Convert a JSON string to pandas object<br>【参数】<br>———-path_or_buf : a valid JSON string or file-like, default: None<br>The string could be a URL. Valid URL schemes include http, ftp, s3, and<br>file. For file URLs, a host is expected. For instance, a local file<br>could be <code>file://localhost/path/to/table.json</code><br>orient</li>
<li><code>Series</code></li>
</ul>
<ul>
<li>default is <code>&#39;index&#39;</code></li>
<li>allowed values are: <code>{&#39;split&#39;,&#39;records&#39;,&#39;index&#39;}</code></li>
<li>The Series index must be unique for orient <code>&#39;index&#39;</code>.</li>
</ul>
<ul>
<li><code>DataFrame</code></li>
</ul>
<ul>
<li>default is <code>&#39;columns&#39;</code></li>
<li>allowed values are: {‘split’,’records’,’index’,’columns’,’values’}</li>
<li>The DataFrame index must be unique for orients ‘index’ and<br>‘columns’.</li>
<li>The DataFrame columns must be unique for orients ‘index’,<br>‘columns’, and ‘records’.</li>
</ul>
<ul>
<li>The format of the JSON string</li>
</ul>
<ul>
<li>split : dict like<br><code>{index -&gt; [index], columns -&gt; [columns], data -&gt; [values]}</code></li>
<li>records : list like<br><code>[{column -&gt; value}, ... , {column -&gt; value}]</code></li>
<li>index : dict like <code>{index -&gt; {column -&gt; value}}</code></li>
<li>columns : dict like <code>{column -&gt; {index -&gt; value}}</code></li>
<li>values : just the values array<br>typ : type of object to recover (series or frame), default ‘frame’<br>dtype : boolean or dict, default True<br>If True, infer dtypes, if a dict of column to dtype, then use those,<br>if False, then don’t infer dtypes at all, applies only to the data.<br>convert_axes : boolean, default True<br>Try to convert the axes to the proper dtypes.<br>convert_dates : boolean, default True<br>List of columns to parse for dates; If True, then try to parse<br>datelike columns default is True; a column label is datelike if<br>1189</li>
</ul>
<ul>
<li>it ends with <code>&#39;_at&#39;</code>,</li>
<li>it ends with <code>&#39;_time&#39;</code>,</li>
<li>it begins with <code>&#39;timestamp&#39;</code>,</li>
<li>it is <code>&#39;modified&#39;</code>, or</li>
<li>it is <code>&#39;date&#39;</code><br>keep_default_dates : boolean, default True<br>If parsing dates, then parse the default datelike columns<br>numpy : boolean, default False<br>Direct decoding to numpy arrays. Supports numeric data only, but<br>non-numeric column and index labels are supported. Note also that the<br>JSON ordering MUST be the same for each term if numpy=True.<br>precise_float : boolean, default False<br>Set to enable usage of higher precision (strtod) function when<br>decoding string to double values. Default (False) is to use fast but<br>less precise builtin functionality<br>date_unit : string, default None<br>The timestamp unit to detect if converting dates. The default behaviour<br>is to try and detect the correct precision, but if this is not desired<br>then pass one of ‘s’, ‘ms’, ‘us’ or ‘ns’ to force parsing only seconds,<br>milliseconds, microseconds or nanoseconds respectively.<br>【返回值】<br>——-result : Series or DataFrame<br>read_msgpack<br>函数 read_msgpack 模块所属：pandas.io.packers:<br>read_msgpack(path_or_buf, iterator=False, **kwargs)<br>Load msgpack pandas object from the specified<br>file path<br>THIS IS AN EXPERIMENTAL LIBRARY and the storage format<br>may not be stable until a future release.<br>【参数】<br>———-path_or_buf : string File path, BytesIO like or string<br>iterator : boolean, if True, return an iterator to the unpacker<br>(default is False)<br>【返回值】</li>
</ul>
<hr>
<p>1190<br>obj : type of object stored in file<br>read_pickle<br>函数 read_pickle 模块所属：pandas.io.pickle:<br>read_pickle(path)<br>Load pickled pandas object (or any other pickled object) from the specified<br>file path<br>Warning: Loading pickled data received from untrusted sources can be<br>unsafe. See: <a href="http://docs.python.org/2.7/library/pickle.html" target="_blank" rel="external">http://docs.python.org/2.7/library/pickle.html</a><br>【参数】<br>———-path : string<br>File path<br>【返回值】<br>——-unpickled : type of object stored in file<br>read_sas<br>函数 read_sas 模块所属：pandas.io.sas:<br>read_sas(filepath_or_buffer, format=’xport’, index=None, encoding=’ISO-8859-1’, chunksize=None, iterator=False)<br>Read a SAS file into a DataFrame.<br>【参数】<br>———-filepath_or_buffer : string or file-like object<br>Path to SAS file or object implementing binary read method.<br>format : string<br>File format, only <code>xport</code> is currently supported.<br>index : identifier of index column<br>Identifier of column that should be used as index of the DataFrame.<br>encoding : string<br>Encoding for text data.<br>chunksize : int<br>Read file <code>chunksize</code> lines at a time, returns iterator.<br>iterator : boolean, default False<br>Return XportReader object for reading file incrementally.<br>1191<br>【返回值】<br>——-DataFrame or XportReader<br>【示例】<br>——–Read a SAS Xport file:<br>df = pandas.read_sas(‘filename.XPT’)<br>Read a Xport file in 10,000 line chunks:<br>itr = pandas.read_sas(‘filename.XPT’, chunksize=10000)<br>for chunk in itr:<br>do_something(chunk)<br>.. versionadded:: 0.17.0<br>read_sql<br>函数 read_sql 模块所属：pandas.io.sql:<br>read_sql(sql, con, index_col=None, coerce_float=True, params=None, parse_dates=None, columns=None, chunksize=None)<br>Read SQL query or database table into a DataFrame.<br>【参数】<br>———-sql : string SQL query or SQLAlchemy Selectable (select or text object)<br>to be executed, or database table name.<br>con : SQLAlchemy connectable(engine/connection) or database string URI<br>or DBAPI2 connection (fallback mode)<br>Using SQLAlchemy makes it possible to use any DB supported by that<br>library.<br>If a DBAPI2 object, only sqlite3 is supported.<br>index_col : string or list of strings, optional, default: None<br>Column(s) to set as index(MultiIndex)<br>coerce_float : boolean, default True<br>Attempt to convert values to non-string, non-numeric objects (like<br>decimal.Decimal) to floating point, useful for SQL result sets<br>params : list, tuple or dict, optional, default: None<br>List of parameters to pass to execute method. The syntax used<br>to pass parameters is database driver dependent. Check your<br>database driver documentation for which of the five syntax styles,<br>described in PEP 249’s paramstyle, is supported.<br>Eg. for psycopg2, uses %(name)s so use params={‘name’ : ‘value’}<br>parse_dates : list or dict, default: None</p>
<ul>
<li>List of column names to parse as dates</li>
<li>Dict of <code>{column_name: format string}</code> where format string is<br>strftime compatible in case of parsing string times or is one of<br>1192<br>(D, s, ns, ms, us) in case of parsing integer timestamps</li>
<li>Dict of <code>{column_name: arg dict}</code>, where the arg dict corresponds<br>to the keyword arguments of :func:<code>pandas.to_datetime</code><br>Especially useful with databases without native Datetime support,<br>such as SQLite<br>columns : list, default: None<br>List of column names to select from sql table (only used when reading<br>a table).<br>chunksize : int, default None<br>If specified, return an iterator where <code>chunksize</code> is the<br>number of rows to include in each chunk.<br>【返回值】<br>——-DataFrame<br>【注意】<br>—–This function is a convenience wrapper around <code>read_sql_table</code> and<br><code>read_sql_query</code> (and for backward compatibility) and will delegate<br>to the specific function depending on the provided input (database<br>table name or sql query). The delegated function might have more specific<br>notes about their functionality not listed here.<br>【参见】<br>——–read_sql_table : Read SQL database table into a DataFrame<br>read_sql_query : Read SQL query into a DataFrame<br>read_sql_query<br>函数 read_sql_query 模块所属：pandas.io.sql:<br>read_sql_query(sql, con, index_col=None, coerce_float=True, params=None, parse_dates=None, chunksize=None)<br>Read SQL query into a DataFrame.<br>Returns a DataFrame corresponding to the result set of the query<br>string. Optionally provide an <code>index_col</code> parameter to use one of the<br>columns as the index, otherwise default integer index will be used.<br>【参数】<br>———-sql : string SQL query or SQLAlchemy Selectable (select or text object)<br>to be executed.<br>con : SQLAlchemy connectable(engine/connection) or database string URI<br>or sqlite3 DBAPI2 connection<br>Using SQLAlchemy makes it possible to use any DB supported by that<br>library.<br>If a DBAPI2 object, only sqlite3 is supported.<br>index_col : string or list of strings, optional, default: None<br>1193<br>Column(s) to set as index(MultiIndex)<br>coerce_float : boolean, default True<br>Attempt to convert values to non-string, non-numeric objects (like<br>decimal.Decimal) to floating point, useful for SQL result sets<br>params : list, tuple or dict, optional, default: None<br>List of parameters to pass to execute method. The syntax used<br>to pass parameters is database driver dependent. Check your<br>database driver documentation for which of the five syntax styles,<br>described in PEP 249’s paramstyle, is supported.<br>Eg. for psycopg2, uses %(name)s so use params={‘name’ : ‘value’}<br>parse_dates : list or dict, default: None</li>
<li>List of column names to parse as dates</li>
<li>Dict of <code>{column_name: format string}</code> where format string is<br>strftime compatible in case of parsing string times or is one of<br>(D, s, ns, ms, us) in case of parsing integer timestamps</li>
<li>Dict of <code>{column_name: arg dict}</code>, where the arg dict corresponds<br>to the keyword arguments of :func:<code>pandas.to_datetime</code><br>Especially useful with databases without native Datetime support,<br>such as SQLite<br>chunksize : int, default None<br>If specified, return an iterator where <code>chunksize</code> is the number of<br>rows to include in each chunk.<br>【返回值】<br>——-DataFrame<br>【注意】<br>—–Any datetime values with time zone information parsed via the <code>parse_dates</code><br>parameter will be converted to UTC<br>【参见】<br>——–read_sql_table : Read SQL database table into a DataFrame<br>read_sql<br>read_sql_table<br>函数 read_sql_table 模块所属：pandas.io.sql:<br>read_sql_table(table_name, con, schema=None, index_col=None, coerce_float=True, parse_dates=None, columns=None,<br>chunksize=None)<br>Read SQL database table into a DataFrame.<br>Given a table name and an SQLAlchemy connectable, returns a DataFrame.<br>This function does not support DBAPI connections.<br>【参数】</li>
</ul>
<hr>
<p>1194<br>table_name : string<br>Name of SQL table in database<br>con : SQLAlchemy connectable (or database string URI)<br>Sqlite DBAPI connection mode not supported<br>schema : string, default None<br>Name of SQL schema in database to query (if database flavor<br>supports this). If None, use default schema (default).<br>index_col : string or list of strings, optional, default: None<br>Column(s) to set as index(MultiIndex)<br>coerce_float : boolean, default True<br>Attempt to convert values to non-string, non-numeric objects (like<br>decimal.Decimal) to floating point. Can result in loss of Precision.<br>parse_dates : list or dict, default: None</p>
<ul>
<li>List of column names to parse as dates</li>
<li>Dict of <code>{column_name: format string}</code> where format string is<br>strftime compatible in case of parsing string times or is one of<br>(D, s, ns, ms, us) in case of parsing integer timestamps</li>
<li>Dict of <code>{column_name: arg dict}</code>, where the arg dict corresponds<br>to the keyword arguments of :func:<code>pandas.to_datetime</code><br>Especially useful with databases without native Datetime support,<br>such as SQLite<br>columns : list, default: None<br>List of column names to select from sql table<br>chunksize : int, default None<br>If specified, return an iterator where <code>chunksize</code> is the number of<br>rows to include in each chunk.<br>【返回值】<br>——-DataFrame<br>【注意】<br>—–Any datetime values with time zone information will be converted to UTC<br>【参见】<br>——–read_sql_query : Read SQL query into a DataFrame.<br>read_sql<br>read_stata<br>函数 read_stata 模块所属：pandas.io.stata:<br>read_stata(filepath_or_buffer, convert_dates=True, convert_categoricals=True, encoding=None, index=None,<br>convert_missing=False, preserve_dtypes=True, columns=None, order_categoricals=True, chunksize=None, iterator=False)<br>Read Stata file into DataFrame<br>【参数】</li>
</ul>
<hr>
<p>1195<br>filepath_or_buffer : string or file-like object<br>Path to .dta file or object implementing a binary read() functions<br>convert_dates : boolean, defaults to True<br>Convert date variables to DataFrame time values<br>convert_categoricals : boolean, defaults to True<br>Read value labels and convert columns to Categorical/Factor variables<br>encoding : string, None or encoding<br>Encoding used to parse the files. Note that Stata doesn’t<br>support unicode. None defaults to iso-8859-1.<br>index : identifier of index column<br>identifier of column that should be used as index of the DataFrame<br>convert_missing : boolean, defaults to False<br>Flag indicating whether to convert missing values to their Stata<br>representations. If False, missing values are replaced with nans.<br>If True, columns containing missing values are returned with<br>object data types and missing values are represented by<br>StataMissingValue objects.<br>preserve_dtypes : boolean, defaults to True<br>Preserve Stata datatypes. If False, numeric data are upcast to pandas<br>default types for foreign data (float64 or int64)<br>columns : list or None<br>Columns to retain. Columns will be returned in the given order. None<br>returns all columns<br>order_categoricals : boolean, defaults to True<br>Flag indicating whether converted categorical data are ordered.<br>chunksize : int, default None<br>Return StataReader object for iterations, returns chunks with<br>given number of lines<br>iterator : boolean, default False<br>Return StataReader object<br>【返回值】<br>——-DataFrame or StataReader<br>【示例】<br>——–Read a Stata dta file:<br>df = pandas.read_stata(‘filename.dta’)<br>Read a Stata dta file in 10,000 line chunks:<br>itr = pandas.read_stata(‘filename.dta’, chunksize=10000)<br>for chunk in itr:<br>do_something(chunk)<br>read_table<br>函数 read_table 模块所属：pandas.io.parsers:<br>read_table(filepath_or_buffer, sep=’\t’, dialect=None, compression=’infer’, doublequote=True, escapechar=None, quotechar=’”‘,<br>1196<br>quoting=0, skipinitialspace=False, lineterminator=None, header=’infer’, index_col=None, names=None, prefix=None,<br>skiprows=None, skipfooter=None, skip_footer=0, na_values=None, true_values=None, false_values=None, delimiter=None,<br>converters=None, dtype=None, usecols=None, engine=None, delim_whitespace=False, as_recarray=False, na_filter=True,<br>compact_ints=False, use_unsigned=False, low_memory=True, buffer_lines=None, warn_bad_lines=True, error_bad_lines=True,<br>keep_default_na=True, thousands=None, comment=None, decimal=b’.’, parse_dates=False, keep_date_col=False,<br>dayfirst=False, date_parser=None, memory_map=False, float_precision=None, nrows=None, iterator=False, chunksize=None,<br>verbose=False, encoding=None, squeeze=False, mangle_dupe_cols=True, tupleize_cols=False, infer_datetime_format=False,<br>skip_blank<em>lines=True)<br>Read general delimited file into DataFrame<br>Also supports optionally iterating or breaking of the file<br>into chunks.<br>Additional help can be found in the <code>online docs for IO Tools
&lt;http://pandas.pydata.org/pandas-docs/stable/io.html&gt;</code></em>.<br>【参数】<br>———-filepath_or<em>buffer : string or file handle / StringIO<br>The string could be a URL. Valid URL schemes include<br>http, ftp, s3, and file. For file URLs, a<br>host is expected. For instance, a local file could be<br>file ://localhost/path/to/table.csv<br>sep : string, default \t (tab-stop)<br>Delimiter to use. Regular expressions are accepted.<br>engine : {‘c’, ‘python’}<br>Parser engine to use. The C engine is faster while the python engine is<br>currently more feature-complete.<br>lineterminator : string (length 1), default None<br>Character to break file into lines. Only valid with C parser<br>quotechar : string (length 1)<br>The character used to denote the start and end of a quoted item. Quoted<br>items can include the delimiter and it will be ignored.<br>quoting : int or csv.QUOTE</em><em> instance, default None<br>Control field quoting behavior per ``csv.QUOTE_</em><code>constants. Use one of
QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).
Default (None) results in QUOTE_MINIMAL behavior.
skipinitialspace : boolean, default False
Skip spaces after delimiter
escapechar : string (length 1), default None
One-character string used to escape delimiter when quoting is QUOTE_NONE.
dtype : Type name or dict of column -&gt; type, default None
Data type for data or columns. E.g. {&#39;a&#39;: np.float64, &#39;b&#39;: np.int32}
(Unsupported with engine=&#39;python&#39;)
compression : {&#39;gzip&#39;, &#39;bz2&#39;, &#39;infer&#39;, None}, default &#39;infer&#39;
For on-the-fly decompression of on-disk data. If &#39;infer&#39;, then use gzip or
bz2 if filepath_or_buffer is a string ending in &#39;.gz&#39; or &#39;.bz2&#39;,
respectively, and no decompression otherwise. Set to None for no
decompression.
dialect : string or csv.Dialect instance, default None
If None defaults to Excel dialect. Ignored if sep longer than 1 char
See csv.Dialect documentation for more details
header : int, list of ints, default &#39;infer&#39;
Row number(s) to use as the column names, and the start of the
data. Defaults to 0 if no</code>names<code>passed, otherwise</code>None<code>. Explicitly
pass</code>header=0<code>to be able to replace existing names. The header can be
a list of integers that specify row locations for a multi-index on the
1197
columns E.g. [0,1,3]. Intervening rows that are not specified will be
skipped (e.g. 2 in this example are skipped). Note that this parameter
ignores commented lines and empty lines if</code>skip_blank_lines=True<code>, so header=0
denotes the first line of data rather than the first line of the file.
skiprows : list-like or integer, default None
Line numbers to skip (0-indexed) or number of lines to skip (int)
at the start of the file
index_col : int or sequence or False, default None
Column to use as the row labels of the DataFrame. If a sequence is given, a
MultiIndex is used. If you have a malformed file with delimiters at the end
of each line, you might consider index_col=False to force pandas to _not_
use the first column as the index (row names)
names : array-like, default None
List of column names to use. If file contains no header row, then you
should explicitly pass header=None
prefix : string, default None
Prefix to add to column numbers when no header, e.g &#39;X&#39; for X0, X1, ...
na_values : str, list-like or dict, default None
Additional strings to recognize as NA/NaN. If dict passed, specific
per-column NA values
true_values : list, default None
Values to consider as True
false_values : list, default None
Values to consider as False
keep_default_na : bool, default True
If na_values are specified and keep_default_na is False the default NaN
values are overridden, otherwise they&#39;re appended to
parse_dates : boolean, list of ints or names, list of lists, or dict, default False
If True -&gt; try parsing the index.
If [1, 2, 3] -&gt; try parsing columns 1, 2, 3 each as a separate date column.
If [[1, 3]] -&gt; combine columns 1 and 3 and parse as a single date column.
{&#39;foo&#39; : [1, 3]} -&gt; parse columns 1, 3 as date and call result &#39;foo&#39;
A fast-path exists for iso8601-formatted dates.
keep_date_col : boolean, default False
If True and parse_dates specifies combining multiple columns then
keep the original columns.
date_parser : function, default None
Function to use for converting a sequence of string columns to an
array of datetime instances. The default uses dateutil.parser.parser
to do the conversion. Pandas will try to call date_parser in three different
ways, advancing to the next if an exception occurs: 1) Pass one or more arrays
(as defined by parse_dates) as arguments; 2) concatenate (row-wise) the string
values from the columns defined by parse_dates into a single array and pass
that; and 3) call date_parser once for each row using one or more strings
(corresponding to the columns defined by parse_dates) as arguments.
dayfirst : boolean, default False
DD/MM format dates, international and European format
thousands : str, default None
Thousands separator
comment : str, default None
Indicates remainder of line should not be parsed. If found at the
beginning of a line, the line will be ignored altogether. This parameter
must be a single character. Like empty lines (as long as</code>skip_blank_lines=True<code>),
fully commented lines are ignored by the parameter `header`
but not by `skiprows`. For example, if comment=&#39;#&#39;, parsing
&#39;#empty\na,b,c\n1,2,3&#39; with `header=0` will result in &#39;a,b,c&#39; being
treated as the header.
1198
decimal : str, default &#39;.&#39;
Character to recognize as decimal point. E.g. use &#39;,&#39; for European data
nrows : int, default None
Number of rows of file to read. Useful for reading pieces of large files
iterator : boolean, default False
Return TextFileReader object for iteration or getting chunks with</code>get<em>chunk()<code>`.
chunksize : int, default None
Return TextFileReader object for iteration.</code>See IO Tools docs for more<br>information<br><a href="http://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking" target="_blank" rel="external">http://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking</a>`</em> on<br><code>iterator</code> and <code>chunksize</code>.<br>skipfooter : int, default 0<br>Number of lines at bottom of file to skip (Unsupported with engine=’c’)<br>converters : dict, default None<br>Dict of functions for converting values in certain columns. Keys can either<br>be integers or column labels<br>verbose : boolean, default False<br>Indicate number of NA values placed in non-numeric columns<br>delimiter : string, default None<br>Alternative argument name for sep. Regular expressions are accepted.<br>encoding : string, default None<br>Encoding to use for UTF when reading/writing (ex. ‘utf-8’). <code>List of Python
standard encodings
&lt;https://docs.python.org/3/library/codecs.html#standard-encodings&gt;</code>_<br>squeeze : boolean, default False<br>If the parsed data only contains one column then return a Series<br>na_filter : boolean, default True<br>Detect missing value markers (empty strings and the value of na_values). In<br>data without any NAs, passing na_filter=False can improve the performance<br>of reading a large file<br>usecols : array-like, default None<br>Return a subset of the columns.<br>Results in much faster parsing time and lower memory usage.<br>mangle_dupe_cols : boolean, default True<br>Duplicate columns will be specified as ‘X.0’…’X.N’, rather than ‘X’…’X’<br>tupleize_cols : boolean, default False<br>Leave a list of tuples on columns as is (default is to convert to<br>a Multi Index on the columns)<br>error_bad_lines : boolean, default True<br>Lines with too many fields (e.g. a csv line with too many commas) will by<br>default cause an exception to be raised, and no DataFrame will be returned.<br>If False, then these “bad lines” will dropped from the DataFrame that is<br>returned. (Only valid with C parser)<br>warn_bad_lines : boolean, default True<br>If error_bad_lines is False, and warn_bad_lines is True, a warning for each<br>“bad line” will be output. (Only valid with C parser).<br>infer_datetime_format : boolean, default False<br>If True and parse_dates is enabled for a column, attempt to infer<br>the datetime format to speed up the processing<br>skip_blank_lines : boolean, default True<br>If True, skip over blank lines rather than interpreting as NaN values<br>【返回值】<br>——-result : DataFrame or TextParser<br>1199<br>reset_option<br>CallableDynamicDoc 模块所属：pandas.core.config object:<br>类定义：CallableDynamicDoc(builtins.object)<br>| 【方法定义】<br>|<br>| <strong>call</strong>(self, <em>args, *</em>kwds)<br>| Call self as a function.<br>|<br>| <strong>init</strong>(self, func, doc_tmpl)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>rolling_apply<br>函数 rolling_apply 模块所属：pandas.stats.moments:<br>rolling_apply(arg, window, func, min_periods=None, freq=None, center=False, args=(), kwargs={})<br>Generic moving function application.<br>【参数】<br>———-arg : Series, DataFrame<br>window : int<br>Size of the moving window. This is the number of observations used for<br>calculating the statistic.<br>func : function<br>Must produce a single value from an ndarray input<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>center : boolean, default False<br>1200<br>Whether the label should correspond with center of window<br>args : tuple<br>Passed on to func<br>kwargs : dict<br>Passed on to func<br>【返回值】<br>——-y : type of input argument<br>【注意】<br>—–By default, the result is set to the right edge of the window. This can be<br>changed to the center of the window by setting <code>center=True</code>.<br>The <code>freq</code> keyword is used to conform time series data to a specified<br>frequency by resampling the data. This is done with the default parameters<br>of :meth:<code>~pandas.Series.resample</code> (i.e. using the <code>mean</code>).<br>rolling_corr<br>函数 rolling_corr 模块所属：pandas.stats.moments:<br>rolling_corr(arg1, arg2=None, window=None, min_periods=None, freq=None, center=False, pairwise=None, how=None)<br>Moving sample correlation.<br>【参数】<br>———-arg1 : Series, DataFrame, or ndarray<br>arg2 : Series, DataFrame, or ndarray, optional<br>if not supplied then will default to arg1 and produce pairwise output<br>window : int<br>Size of the moving window. This is the number of observations used for<br>calculating the statistic.<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>center : boolean, default False<br>Set the labels at the center of the window.<br>how : string, default ‘None’<br>Method for down- or re-sampling<br>pairwise : bool, default False<br>If False then only matching columns between arg1 and arg2 will be used and<br>the output will be a DataFrame.<br>If True then all pairwise combinations will be calculated and the output<br>will be a Panel in the case of DataFrame inputs. In the case of missing<br>elements, only complete pairwise observations will be used.<br>1201<br>【返回值】<br>——-y : type depends on inputs<br>DataFrame / DataFrame -&gt; DataFrame (matches on columns) or Panel (pairwise)<br>DataFrame / Series -&gt; Computes result for each column<br>Series / Series -&gt; Series<br>【注意】<br>—–By default, the result is set to the right edge of the window. This can be<br>changed to the center of the window by setting <code>center=True</code>.<br>The <code>freq</code> keyword is used to conform time series data to a specified<br>frequency by resampling the data. This is done with the default parameters<br>of :meth:<code>~pandas.Series.resample</code> (i.e. using the <code>mean</code>).<br>rolling_corr_pairwise<br>函数 rolling_corr_pairwise 模块所属：pandas.stats.moments:<br>rolling_corr_pairwise(df1, df2=None, window=None, min_periods=None, freq=None, center=False)<br>Deprecated. Use rolling_corr(…, pairwise=True) instead.<br>Pairwise moving sample correlation<br>【参数】<br>———-df1 : DataFrame<br>df2 : DataFrame<br>window : int<br>Size of the moving window. This is the number of observations used for<br>calculating the statistic.<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>center : boolean, default False<br>Set the labels at the center of the window.<br>how : string, default ‘None’<br>Method for down- or re-sampling<br>【返回值】<br>——-y : Panel whose items are df1.index values</p>
<h2 id="【注意】"><a href="#【注意】" class="headerlink" title="【注意】"></a>【注意】</h2><p>1202<br>By default, the result is set to the right edge of the window. This can be<br>changed to the center of the window by setting <code>center=True</code>.<br>The <code>freq</code> keyword is used to conform time series data to a specified<br>frequency by resampling the data. This is done with the default parameters<br>of :meth:<code>~pandas.Series.resample</code> (i.e. using the <code>mean</code>).<br>rolling_count<br>函数 rolling_count 模块所属：pandas.stats.moments:<br>rolling_count(arg, window, freq=None, center=False, how=None)<br>Rolling count of number of non-NaN observations inside provided window.<br>【参数】<br>———-arg : DataFrame or numpy ndarray-like<br>window : int<br>Size of the moving window. This is the number of observations used for<br>calculating the statistic.<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>center : boolean, default False<br>Whether the label should correspond with center of window<br>how : string, default ‘mean’<br>Method for down- or re-sampling<br>【返回值】<br>——-rolling_count : type of caller<br>【注意】<br>—–The <code>freq</code> keyword is used to conform time series data to a specified<br>frequency by resampling the data. This is done with the default parameters<br>of :meth:<code>~pandas.Series.resample</code> (i.e. using the <code>mean</code>).<br>rolling_cov<br>函数 rolling_cov 模块所属：pandas.stats.moments:<br>rolling_cov(arg1, arg2=None, window=None, min_periods=None, freq=None, center=False, pairwise=None, how=None,<br>1203<br>ddof=1)<br>Unbiased moving covariance.<br>【参数】<br>———-arg1 : Series, DataFrame, or ndarray<br>arg2 : Series, DataFrame, or ndarray, optional<br>if not supplied then will default to arg1 and produce pairwise output<br>window : int<br>Size of the moving window. This is the number of observations used for<br>calculating the statistic.<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>center : boolean, default False<br>Set the labels at the center of the window.<br>how : string, default ‘None’<br>Method for down- or re-sampling<br>pairwise : bool, default False<br>If False then only matching columns between arg1 and arg2 will be used and<br>the output will be a DataFrame.<br>If True then all pairwise combinations will be calculated and the output<br>will be a Panel in the case of DataFrame inputs. In the case of missing<br>elements, only complete pairwise observations will be used.<br>ddof : int, default 1<br>Delta Degrees of Freedom. The divisor used in calculations<br>is <code>N - ddof</code>, where <code>N</code> represents the number of elements.<br>【返回值】<br>——-y : type depends on inputs<br>DataFrame / DataFrame -&gt; DataFrame (matches on columns) or Panel (pairwise)<br>DataFrame / Series -&gt; Computes result for each column<br>Series / Series -&gt; Series<br>【注意】<br>—–By default, the result is set to the right edge of the window. This can be<br>changed to the center of the window by setting <code>center=True</code>.<br>The <code>freq</code> keyword is used to conform time series data to a specified<br>frequency by resampling the data. This is done with the default parameters<br>of :meth:<code>~pandas.Series.resample</code> (i.e. using the <code>mean</code>).<br>rolling_kurt<br>函数 roll_kurt 模块所属：pandas.algos:<br>1204<br>roll_kurt(…)<br>Unbiased moving kurtosis.<br>【参数】<br>———-arg : Series, DataFrame<br>window : int<br>Size of the moving window. This is the number of observations used for<br>calculating the statistic.<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>center : boolean, default False<br>Set the labels at the center of the window.<br>how : string, default ‘None’<br>Method for down- or re-sampling<br>【返回值】<br>——-y : type of input argument<br>【注意】<br>—–By default, the result is set to the right edge of the window. This can be<br>changed to the center of the window by setting <code>center=True</code>.<br>The <code>freq</code> keyword is used to conform time series data to a specified<br>frequency by resampling the data. This is done with the default parameters<br>of :meth:<code>~pandas.Series.resample</code> (i.e. using the <code>mean</code>).<br>rolling_max<br>函数 roll_max 模块所属：pandas.algos:<br>roll_max(…)<br>Moving max of 1d array of dtype=float64 along axis=0 ignoring NaNs.<br>Moving maximum.<br>【参数】<br>———-arg : Series, DataFrame<br>window : int<br>Size of the moving window. This is the number of observations used for<br>calculating the statistic.<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>1205<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>center : boolean, default False<br>Set the labels at the center of the window.<br>how : string, default ‘’max’<br>Method for down- or re-sampling<br>【返回值】<br>——-y : type of input argument<br>【注意】<br>—–By default, the result is set to the right edge of the window. This can be<br>changed to the center of the window by setting <code>center=True</code>.<br>The <code>freq</code> keyword is used to conform time series data to a specified<br>frequency by resampling the data. This is done with the default parameters<br>of :meth:<code>~pandas.Series.resample</code> (i.e. using the <code>mean</code>).<br>rolling_mean<br>函数 roll_mean 模块所属：pandas.algos:<br>roll_mean(…)<br>Moving mean.<br>【参数】<br>———-arg : Series, DataFrame<br>window : int<br>Size of the moving window. This is the number of observations used for<br>calculating the statistic.<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>center : boolean, default False<br>Set the labels at the center of the window.<br>how : string, default ‘None’<br>Method for down- or re-sampling<br>【返回值】<br>——-y : type of input argument<br>1206<br>【注意】<br>—–By default, the result is set to the right edge of the window. This can be<br>changed to the center of the window by setting <code>center=True</code>.<br>The <code>freq</code> keyword is used to conform time series data to a specified<br>frequency by resampling the data. This is done with the default parameters<br>of :meth:<code>~pandas.Series.resample</code> (i.e. using the <code>mean</code>).<br>rolling_median<br>函数 roll_median_c 模块所属：pandas.algos:<br>roll_median_c(…)<br>Moving median.<br>【参数】<br>———-arg : Series, DataFrame<br>window : int<br>Size of the moving window. This is the number of observations used for<br>calculating the statistic.<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>center : boolean, default False<br>Set the labels at the center of the window.<br>how : string, default ‘’median’<br>Method for down- or re-sampling<br>【返回值】<br>——-y : type of input argument<br>【注意】<br>—–By default, the result is set to the right edge of the window. This can be<br>changed to the center of the window by setting <code>center=True</code>.<br>The <code>freq</code> keyword is used to conform time series data to a specified<br>frequency by resampling the data. This is done with the default parameters<br>of :meth:<code>~pandas.Series.resample</code> (i.e. using the <code>mean</code>).<br>1207<br>rolling_min<br>函数 roll_min 模块所属：pandas.algos:<br>roll_min(…)<br>Moving min of 1d array of dtype=float64 along axis=0 ignoring NaNs.<br>Moving minimum.<br>【参数】<br>———-arg : Series, DataFrame<br>window : int<br>Size of the moving window. This is the number of observations used for<br>calculating the statistic.<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>center : boolean, default False<br>Set the labels at the center of the window.<br>how : string, default ‘’min’<br>Method for down- or re-sampling<br>【返回值】<br>——-y : type of input argument<br>【注意】<br>—–By default, the result is set to the right edge of the window. This can be<br>changed to the center of the window by setting <code>center=True</code>.<br>The <code>freq</code> keyword is used to conform time series data to a specified<br>frequency by resampling the data. This is done with the default parameters<br>of :meth:<code>~pandas.Series.resample</code> (i.e. using the <code>mean</code>).<br>rolling_quantile<br>函数 rolling_quantile 模块所属：pandas.stats.moments:<br>rolling_quantile(arg, window, quantile, min_periods=None, freq=None, center=False)<br>Moving quantile.<br>【参数】<br>1208<br>———-arg : Series, DataFrame<br>window : int<br>Size of the moving window. This is the number of observations used for<br>calculating the statistic.<br>quantile : float<br>0 &lt;= quantile &lt;= 1<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>center : boolean, default False<br>Whether the label should correspond with center of window<br>【返回值】<br>——-y : type of input argument<br>【注意】<br>—–By default, the result is set to the right edge of the window. This can be<br>changed to the center of the window by setting <code>center=True</code>.<br>The <code>freq</code> keyword is used to conform time series data to a specified<br>frequency by resampling the data. This is done with the default parameters<br>of :meth:<code>~pandas.Series.resample</code> (i.e. using the <code>mean</code>).<br>rolling_skew<br>函数 roll_skew 模块所属：pandas.algos:<br>roll_skew(…)<br>Unbiased moving skewness.<br>【参数】<br>———-arg : Series, DataFrame<br>window : int<br>Size of the moving window. This is the number of observations used for<br>calculating the statistic.<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>center : boolean, default False<br>Set the labels at the center of the window.<br>1209<br>how : string, default ‘None’<br>Method for down- or re-sampling<br>【返回值】<br>——-y : type of input argument<br>【注意】<br>—–By default, the result is set to the right edge of the window. This can be<br>changed to the center of the window by setting <code>center=True</code>.<br>The <code>freq</code> keyword is used to conform time series data to a specified<br>frequency by resampling the data. This is done with the default parameters<br>of :meth:<code>~pandas.Series.resample</code> (i.e. using the <code>mean</code>).<br>rolling_std<br>函数 <lambda> 模块所属：pandas.stats.moments:</lambda></p>
<p><lambda> lambda <em>a, <em>*kw<br>Moving standard deviation.<br>【参数】<br>———-arg : Series, DataFrame<br>window : int<br>Size of the moving window. This is the number of observations used for<br>calculating the statistic.<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>center : boolean, default False<br>Set the labels at the center of the window.<br>how : string, default ‘None’<br>Method for down- or re-sampling<br>ddof : int, default 1<br>Delta Degrees of Freedom. The divisor used in calculations<br>is <code>N - ddof</code>, where <code>N</code> represents the number of elements.<br>【返回值】<br>——-y : type of input argument<br>【注意】<br>—–By default, the result is set to the right edge of the window. This can be<br>1210<br>changed to the center of the window by setting <code>center=True</code>.<br>The <code>freq</code> keyword is used to conform time series data to a specified<br>frequency by resampling the data. This is done with the default parameters<br>of :meth:<code>~pandas.Series.resample</code> (i.e. using the <code>mean</code>).<br>rolling_sum<br>函数 roll_sum 模块所属：pandas.algos:<br>roll_sum(…)<br>Moving sum.<br>【参数】<br>———-arg : Series, DataFrame<br>window : int<br>Size of the moving window. This is the number of observations used for<br>calculating the statistic.<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>center : boolean, default False<br>Set the labels at the center of the window.<br>how : string, default ‘None’<br>Method for down- or re-sampling<br>【返回值】<br>——-y : type of input argument<br>【注意】<br>—–By default, the result is set to the right edge of the window. This can be<br>changed to the center of the window by setting <code>center=True</code>.<br>The <code>freq</code> keyword is used to conform time series data to a specified<br>frequency by resampling the data. This is done with the default parameters<br>of :meth:<code>~pandas.Series.resample</code> (i.e. using the <code>mean</code>).<br>1211<br>rolling_var<br>函数 roll_var 模块所属：pandas.algos:<br>roll_var(…)<br>Numerically stable implementation using Welford’s method.<br>Moving variance.<br>【参数】<br>———-arg : Series, DataFrame<br>window : int<br>Size of the moving window. This is the number of observations used for<br>calculating the statistic.<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>center : boolean, default False<br>Set the labels at the center of the window.<br>how : string, default ‘None’<br>Method for down- or re-sampling<br>ddof : int, default 1<br>Delta Degrees of Freedom. The divisor used in calculations<br>is <code>N - ddof</code>, where <code>N</code> represents the number of elements.<br>【返回值】<br>——-y : type of input argument<br>【注意】<br>—–By default, the result is set to the right edge of the window. This can be<br>changed to the center of the window by setting <code>center=True</code>.<br>The <code>freq</code> keyword is used to conform time series data to a specified<br>frequency by resampling the data. This is done with the default parameters<br>of :meth:<code>~pandas.Series.resample</code> (i.e. using the <code>mean</code>).<br>rolling_window<br>函数 rolling_window 模块所属：pandas.stats.moments:<br>1212<br>rolling_window(arg, window=None, win_type=None, min_periods=None, freq=None, center=False, mean=True, axis=0,<br>how=None, </em></em>kwargs)<br>Applies a moving window of type <code>window_type</code> and size <code>window</code><br>on the data.<br>【参数】<br>———-arg : Series, DataFrame<br>window : int or ndarray<br>Weighting window specification. If the window is an integer, then it is<br>treated as the window length and win_type is required<br>win_type : str, default None<br>Window type (see Notes)<br>min_periods : int, default None<br>Minimum number of observations in window required to have a value<br>(otherwise result is NA).<br>freq : string or DateOffset object, optional (default None)<br>Frequency to conform the data to before computing the statistic. Specified<br>as a frequency string or DateOffset object.<br>center : boolean, default False<br>Whether the label should correspond with center of window<br>mean : boolean, default True<br>If True computes weighted mean, else weighted sum<br>axis : {0, 1}, default 0<br>how : string, default ‘mean’<br>Method for down- or re-sampling<br>【返回值】<br>——-y : type of input argument<br>【注意】<br>—–The recognized window types are:</lambda></p>
<ul>
<li><code>boxcar</code></li>
<li><code>triang</code></li>
<li><code>blackman</code></li>
<li><code>hamming</code></li>
<li><code>bartlett</code></li>
<li><code>parzen</code></li>
<li><code>bohman</code></li>
<li><code>blackmanharris</code></li>
<li><code>nuttall</code></li>
<li><code>barthann</code></li>
<li><code>kaiser</code> (needs beta)</li>
<li><code>gaussian</code> (needs std)</li>
<li><code>general_gaussian</code> (needs power, width)</li>
<li><code>slepian</code> (needs width).<br>By default, the result is set to the right edge of the window. This can be<br>changed to the center of the window by setting <code>center=True</code>.<br>The <code>freq</code> keyword is used to conform time series data to a specified<br>frequency by resampling the data. This is done with the default parameters<br>of :meth:<code>~pandas.Series.resample</code> (i.e. using the <code>mean</code>).<br>1213<br>scatter_matrix<br>函数 scatter_matrix 模块所属：pandas.tools.plotting:<br>scatter_matrix(frame, alpha=0.5, figsize=None, ax=None, grid=False, diagonal=’hist’, marker=’.’, density_kwds=None,<br>hist_kwds=None, range_padding=0.05, <strong>kwds)<br>Draw a matrix of scatter plots.<br>【参数】<br>———-frame : DataFrame<br>alpha : float, optional<br>amount of transparency applied<br>figsize : (float,float), optional<br>a tuple (width, height) in inches<br>ax : Matplotlib axis object, optional<br>grid : bool, optional<br>setting this to True will show the grid<br>diagonal : {‘hist’, ‘kde’}<br>pick between ‘kde’ and ‘hist’ for<br>either Kernel Density Estimation or Histogram<br>plot in the diagonal<br>marker : str, optional<br>Matplotlib marker type, default ‘.’<br>hist_kwds : other plotting keyword arguments<br>To be passed to hist function<br>density_kwds : other plotting keyword arguments<br>To be passed to kernel density estimate plot<br>range_padding : float, optional<br>relative extension of axis range in x and y<br>with respect to (x_max - x_min) or (y_max - y_min),<br>default 0.05<br>kwds : other plotting keyword arguments<br>To be passed to scatter function<br>【示例】<br>——–&gt;&gt;&gt; df = DataFrame(np.random.randn(1000, 4), columns=[‘A’,’B’,’C’,’D’])<br>scatter_matrix(df, alpha=0.2)<br>set_eng_float_format<br>函数 set_eng_float_format 模块所属：pandas.core.format:<br>1214<br>set_eng_float_format(accuracy=3, use_eng_prefix=False)<br>Alter default behavior on how float is formatted in DataFrame.<br>Format float in engineering format. By accuracy, we mean the number of<br>decimal digits after the floating point.<br>参见：EngFormatter.<br>set_option<br>CallableDynamicDoc 模块所属：pandas.core.config object:<br>类定义：CallableDynamicDoc(builtins.object)<br>| 【方法定义】<br>|<br>| <strong>call</strong>(self, *args, </strong>kwds)<br>| Call self as a function.<br>|<br>| <strong>init</strong>(self, func, doc_tmpl)<br>| Initialize self. See help(type(self)) for accurate signature.<br>|<br>| ———————————————————————-| Data descriptors defined here:<br>|<br>| <strong>dict</strong><br>| dictionary for instance variables (if defined)<br>|<br>| <strong>weakref</strong><br>| list of weak references to the object (if defined)<br>show_versions<br>函数 show_versions 模块所属：pandas.util.print_versions:<br>show_versions(as_json=False)<br>1215<br>sparse<br>模块包所属：pandas.sparse in pandas:<br>【名称】<br>pandas.sparse<br>【模块包·内容】<br>api<br>array<br>frame<br>list<br>panel<br>scipy_sparse<br>series<br>tests (package)<br>【文件】 ： \pandas\sparse__init<strong>.py<br>stats<br>模块包所属：pandas.stats in pandas:<br>【名称】<br>pandas.stats<br>【模块包·内容】<br>api<br>common<br>fama_macbeth<br>interface<br>math<br>misc<br>moments<br>ols<br>plm<br>tests (package)<br>var<br>【文件】 ： \pandas\stats\</strong>init__.py<br>1216<br>timedelta_range<br>函数 timedelta_range 模块所属：pandas.tseries.tdi:<br>timedelta_range(start=None, end=None, periods=None, freq=’D’, name=None, closed=None)<br>Return a fixed frequency timedelta index, with day as the default<br>frequency<br>【参数】<br>———-start : string or timedelta-like, default None<br>Left bound for generating dates<br>end : string or datetime-like, default None<br>Right bound for generating dates<br>periods : integer or None, default None<br>If None, must specify start and end<br>freq : string or DateOffset, default ‘D’ (calendar daily)<br>Frequency strings can have multiples, e.g. ‘5H’<br>name : str, default None<br>Name of the resulting index<br>closed : string or None, default None<br>Make the interval closed with respect to the given frequency to<br>the ‘left’, ‘right’, or both sides (None)<br>【注意】<br>—–2 of start, end, or periods must be specified<br>【返回值】<br>——-rng : TimedeltaIndex<br>to_datetime<br>函数 to_datetime 模块所属：pandas.tseries.tools:<br>to_datetime(arg, errors=’raise’, dayfirst=False, yearfirst=False, utc=None, box=True, format=None, exact=True, coerce=None,<br>unit=’ns’, infer_datetime_format=False)<br>Convert argument to datetime.<br>【参数】<br>———-arg : string, datetime, array of strings (with possible NAs)<br>errors : {‘ignore’, ‘raise’, ‘coerce’}, default ‘raise’</li>
</ul>
<ul>
<li>If ‘raise’, then invalid parsing will raise an exception</li>
<li>If ‘coerce’, then invalid parsing will be set as NaT<br>1217</li>
<li>If ‘ignore’, then invalid parsing will return the input<br>dayfirst : boolean, default False<br>Specify a date parse order if <code>arg</code> is str or its list-likes.<br>If True, parses dates with the day first, eg 10/11/12 is parsed as 2012-11-10.<br>Warning: dayfirst=True is not strict, but will prefer to parse<br>with day first (this is a known bug, based on dateutil behavior).<br>yearfirst : boolean, default False<br>Specify a date parse order if <code>arg</code> is str or its list-likes.</li>
<li>If True parses dates with the year first, eg 10/11/12 is parsed as 2010-11-12.</li>
<li>If both dayfirst and yearfirst are True, yearfirst is preceded (same as dateutil).<br>Warning: yearfirst=True is not strict, but will prefer to parse<br>with year first (this is a known bug, based on dateutil beahavior).<br>.. versionadded: 0.16.1<br>utc : boolean, default None<br>Return UTC DatetimeIndex if True (converting any tz-aware<br>datetime.datetime objects as well).<br>box : boolean, default True</li>
<li>If True returns a DatetimeIndex</li>
<li>If False returns ndarray of values.<br>format : string, default None<br>strftime to parse time, eg “%d/%m/%Y”, note that “%f” will parse<br>all the way up to nanoseconds.<br>exact : boolean, True by default</li>
<li>If True, require an exact format match.</li>
<li>If False, allow the format to match anywhere in the target string.<br>unit : unit of the arg (D,s,ms,us,ns) denote the unit in epoch<br>(e.g. a unix timestamp), which is an integer/float number.<br>infer_datetime_format : boolean, default False<br>If no <code>format</code> is given, try to infer the format based on the first<br>datetime string. Provides a large speed-up in many cases.<br>【返回值】<br>——-ret : datetime if parsing succeeded.<br>Return type depends on input:</li>
<li>list-like: DatetimeIndex</li>
<li>Series: Series of datetime64 dtype</li>
<li>scalar: Timestamp<br>In case when it is not possible to return designated types (e.g. when<br>any element of input is before Timestamp.min or after Timestamp.max)<br>return will have datetime.datetime type (or correspoding array/Series).<br>【示例】<br>——–Take separate series and convert to datetime<br>import pandas as pd<br>i = pd.date_range(‘20000101’,periods=100)<br>df = pd.DataFrame(dict(year = i.year, month = i.month, day = i.day))<br>pd.to_datetime(df.year<em>10000 + df.month</em>100 + df.day, format=’%Y%m%d’)<br>0 2000-01-01<br>1 2000-01-02<br>…<br>1218<br>98 2000-04-08<br>99 2000-04-09<br>Length: 100, dtype: datetime64[ns]<br>Or from strings<br>df = df.astype(str)<br>pd.to_datetime(df.day + df.month + df.year, format=”%d%m%Y”)<br>0 2000-01-01<br>1 2000-01-02<br>…<br>98 2000-04-08<br>99 2000-04-09<br>Length: 100, dtype: datetime64[ns]<br>Date that does not meet timestamp limitations:<br>pd.to_datetime(‘13000101’, format=’%Y%m%d’)<br>datetime.datetime(1300, 1, 1, 0, 0)<br>pd.to_datetime(‘13000101’, format=’%Y%m%d’, errors=’coerce’)<br>NaT<br>to_msgpack<br>函数 to_msgpack 模块所属：pandas.io.packers:<br>to_msgpack(path_or_buf, <em>args, *</em>kwargs)<br>msgpack (serialize) object to input file path<br>THIS IS AN EXPERIMENTAL LIBRARY and the storage format<br>may not be stable until a future release.<br>【参数】<br>———-path_or_buf : string File path, buffer-like, or None<br>if None, return generated string<br>args : an object or objects to serialize<br>append : boolean whether to append to an existing msgpack<br>(default is False)<br>compress : type of compressor (zlib or blosc), default to None (no<br>compression)<br>to_numeric<br>1219<br>函数 to_numeric 模块所属：pandas.tools.util:<br>to_numeric(arg, errors=’raise’)<br>Convert argument to a numeric type.<br>【参数】<br>———-arg : list, tuple or array of objects, or Series<br>errors : {‘ignore’, ‘raise’, ‘coerce’}, default ‘raise’</li>
<li>If ‘raise’, then invalid parsing will raise an exception</li>
<li>If ‘coerce’, then invalid parsing will be set as NaN</li>
<li>If ‘ignore’, then invalid parsing will return the input<br>【返回值】<br>——-ret : numeric if parsing succeeded.<br>Return type depends on input. Series if Series, otherwise ndarray<br>【示例】<br>——–Take separate series and convert to numeric, coercing when told to<br>import pandas as pd<br>s = pd.Series([‘1.0’, ‘2’, -3])<br>pd.to_numeric(s)<br>s = pd.Series([‘apple’, ‘1.0’, ‘2’, -3])<br>pd.to_numeric(s, errors=’ignore’)<br>pd.to_numeric(s, errors=’coerce’)<br>to_pickle<br>函数 to_pickle 模块所属：pandas.io.pickle:<br>to_pickle(obj, path)<br>Pickle (serialize) object to input file path<br>【参数】<br>———-obj : any object<br>path : string<br>File path<br>to_timedelta<br>1220<br>函数 to_timedelta 模块所属：pandas.tseries.timedeltas:<br>to_timedelta(arg, unit=’ns’, box=True, errors=’raise’, coerce=None)<br>Convert argument to timedelta<br>【参数】<br>———-arg : string, timedelta, array of strings (with possible NAs)<br>unit : unit of the arg (D,h,m,s,ms,us,ns) denote the unit, which is an integer/float number<br>box : boolean, default True</li>
<li>If True returns a Timedelta/TimedeltaIndex of the results</li>
<li>if False returns a np.timedelta64 or ndarray of values of dtype timedelta64[ns]<br>errors : {‘ignore’, ‘raise’, ‘coerce’}, default ‘raise’</li>
<li>If ‘raise’, then invalid parsing will raise an exception</li>
<li>If ‘coerce’, then invalid parsing will be set as NaT</li>
<li>If ‘ignore’, then invalid parsing will return the input<br>【返回值】<br>——-ret : timedelta64/arrays of timedelta64 if parsing succeeded<br>tools<br>模块包所属：pandas.tools in pandas:<br>【名称】<br>pandas.tools<br>【模块包·内容】<br>merge<br>pivot<br>plotting<br>rplot<br>tests (package)<br>tile<br>util<br>【文件】 ： \pandas\tools__init<strong>.py<br>tseries<br>1221<br>模块包所属：pandas.tseries in pandas:<br>【名称】<br>pandas.tseries<br>【模块包·内容】<br>api<br>base<br>common<br>converter<br>frequencies<br>holiday<br>index<br>interval<br>offsets<br>period<br>plotting<br>resample<br>tdi<br>tests (package)<br>timedeltas<br>tools<br>util<br>【文件】 ： \pandas\tseries\</strong>init<strong>.py<br>tslib<br>所属模块：pandas.tslib in pandas:<br>【名称】<br>pandas.tslib<br>【数据】
</strong>all<strong> = []
</strong>pyx_capi<strong> = {‘_check_all_nulls’: &lt;capsule object “int (PyObject *)”…
</strong>test<strong> = {‘_get_rule_month (line 1826)’: “\n Return starting mont…<br>【文件】 ： \pandas\tslib.cp35-win_amd64.pyd<br>unique<br>1222<br>函数 unique 模块所属：pandas.core.algorithms:<br>unique(values)<br>Compute unique values (not necessarily sorted) efficiently from input array<br>of values<br>【参数】<br>———-values : array-like<br>【返回值】<br>——-uniques<br>util<br>模块包所属：pandas.util in pandas:<br>【名称】<br>pandas.util<br>【模块包·内容】<br>clipboard<br>decorators<br>doctools<br>misc<br>print_versions<br>terminal<br>testing<br>【文件】 ： \pandas\util\</strong>init__.py<br>value_counts<br>函数 value_counts 模块所属：pandas.core.algorithms:<br>value_counts(values, sort=True, ascending=False, normalize=False, bins=None, dropna=True)<br>Compute a histogram of the counts of non-null values.<br>【参数】</li>
</ul>
<hr>
<p>1223<br>values : ndarray (1-d)<br>sort : boolean, default True<br>Sort by values<br>ascending : boolean, default False<br>Sort in ascending order<br>normalize: boolean, default False<br>If True then compute a relative histogram<br>bins : integer, optional<br>Rather than count values, group them into half-open bins,<br>convenience for pd.cut, only works with numeric data<br>dropna : boolean, default True<br>Don’t include counts of NaN<br>【返回值】<br>——-value_counts : Series<br>wide_to_long<br>函数 wide_to_long 模块所属：pandas.core.reshape:<br>wide_to_long(df, stubnames, i, j)<br>Wide panel to long format. Less flexible but more user-friendly than melt.<br>【参数】<br>———-df : DataFrame<br>The wide-format DataFrame<br>stubnames : list<br>A list of stub names. The wide format variables are assumed to<br>start with the stub names.<br>i : str<br>The name of the id variable.<br>j : str<br>The name of the subobservation variable.<br>stubend : str<br>Regex to match for the end of the stubs.<br>【返回值】<br>——-DataFrame<br>A DataFrame that contains each stub name as a variable as well as<br>variables for i and j.<br>【示例】<br>——–&gt;&gt;&gt; import pandas as pd<br>import numpy as np<br>np.random.seed(123)<br>df = pd.DataFrame({“A1970” : {0 : “a”, 1 : “b”, 2 : “c”},<br>1224<br>… “A1980” : {0 : “d”, 1 : “e”, 2 : “f”},<br>… “B1970” : {0 : 2.5, 1 : 1.2, 2 : .7},<br>… “B1980” : {0 : 3.2, 1 : 1.3, 2 : .1},<br>… “X” : dict(zip(range(3), np.random.randn(3)))<br>… })<br>df[“id”] = df.index<br>df<br>A1970 A1980 B1970 B1980 X id<br>0 a d 2.5 3.2 -1.085631 0<br>1 b e 1.2 1.3 0.997345 1<br>2 c f 0.7 0.1 0.282978 2<br>wide_to_long(df, [“A”, “B”], i=”id”, j=”year”)<br>X A B<br>id year<br>0 1970 -1.085631 a 2.5<br>1 1970 0.997345 b 1.2<br>2 1970 0.282978 c 0.7<br>0 1980 -1.085631 d 3.2<br>1 1980 0.997345 e 1.3<br>2 1980 0.282978 f 0.1<br>【注意】<br>—–All extra variables are treated as extra id variables. This simply uses<br><code>pandas.melt</code> under the hood, but is hard-coded to “do the right thing”<br>in a typicaly case.</p>
</blockquote>
</blockquote>
</blockquote>

      

      
        <div class="page-reward">
          <a href="javascript:;" class="page-reward-btn tooltip-top">
            <div class="tooltip tooltip-east">
            <span class="tooltip-item">
              赏
            </span>
            <span class="tooltip-content">
              <span class="tooltip-text">
                <span class="tooltip-inner">
                  <p class="reward-p"><i class="icon icon-quo-left"></i>谢谢你请我吃糖果<i class="icon icon-quo-right"></i></p>
                  <div class="reward-box">
                    
                    
                  </div>
                </span>
              </span>
            </span>
          </div>
          </a>
        </div>
      
    </div>
    <div class="article-info article-info-index">
      
      
      

      

      
        
<div class="share-btn share-icons tooltip-left">
  <div class="tooltip tooltip-east">
    <span class="tooltip-item">
      <a href="javascript:;" class="share-sns share-outer">
        <i class="icon icon-share"></i>
      </a>
    </span>
    <span class="tooltip-content">
      <div class="share-wrap">
        <div class="share-icons">
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="icon icon-weibo"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="icon icon-weixin"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="icon icon-qq"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="icon icon-douban"></i>
          </a>
          <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a>
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="icon icon-facebook"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="icon icon-twitter"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="icon icon-google"></i>
          </a>
        </div>
      </div>
    </span>
  </div>
</div>

<div class="page-modal wx-share js-wx-box">
    <a class="close js-modal-close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="http://s.jiathis.com/qrcode.php?url=http://yoursite.com/2017/04/06/Pandas学习笔记/" alt="微信分享二维码">
    </div>
</div>

<div class="mask js-mask"></div>
      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

  
<nav id="article-nav">
  
  
    <a href="/2017/04/05/十分钟搞定Pandas/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title"></div>
      <i class="icon-circle-right"></i>
    </a>
  
</nav>






  
    <div class="duoshuo"></div>
  




          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2017 王信平
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    <script>
	var yiliaConfig = {
		mathjax: false,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		root: "/",
		innerArchive: true,
		showTags: false
	}
</script>

<script>!function(t){function n(r){if(e[r])return e[r].exports;var o=e[r]={exports:{},id:r,loaded:!1};return t[r].call(o.exports,o,o.exports,n),o.loaded=!0,o.exports}var e={};return n.m=t,n.c=e,n.p="./",n(0)}([function(t,n,e){"use strict";function r(t){return t&&t.__esModule?t:{default:t}}function o(t,n){var e=/\/|index.html/g;return t.replace(e,"")===n.replace(e,"")}function i(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,e=0,r=t.length;e<r;e++){var i=t[e];o(n,i.getAttribute("href"))&&(0,d.default)(i,"active")}}function u(t){for(var n=t.offsetLeft,e=t.offsetParent;null!==e;)n+=e.offsetLeft,e=e.offsetParent;return n}function f(t){for(var n=t.offsetTop,e=t.offsetParent;null!==e;)n+=e.offsetTop,e=e.offsetParent;return n}function c(t,n,e,r,o){var i=u(t),c=f(t)-n;if(c-e<=o){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,h.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(e||c)+"px",a.style.left=i+"px",a.style.zIndex=r||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");c(t,document.body.scrollTop,-63,2,0),c(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}function l(){x.default.versions.mobile&&window.screen.width<800&&(i(),s())}var p=e(71),d=r(p),v=e(72),y=(r(v),e(84)),h=r(y),b=e(69),x=r(b),m=e(75),g=r(m),w=e(70);l(),(0,w.addLoadEvent)(function(){g.default.init()}),t.exports={}},function(t,n){var e=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=e)},function(t,n){var e={}.hasOwnProperty;t.exports=function(t,n){return e.call(t,n)}},function(t,n,e){var r=e(49),o=e(15);t.exports=function(t){return r(o(t))}},function(t,n,e){t.exports=!e(8)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,e){var r=e(6),o=e(12);t.exports=e(4)?function(t,n,e){return r.f(t,n,o(1,e))}:function(t,n,e){return t[n]=e,t}},function(t,n,e){var r=e(10),o=e(30),i=e(24),u=Object.defineProperty;n.f=e(4)?Object.defineProperty:function(t,n,e){if(r(t),n=i(n,!0),r(e),o)try{return u(t,n,e)}catch(t){}if("get"in e||"set"in e)throw TypeError("Accessors not supported!");return"value"in e&&(t[n]=e.value),t}},function(t,n,e){var r=e(22)("wks"),o=e(13),i=e(1).Symbol,u="function"==typeof i,f=t.exports=function(t){return r[t]||(r[t]=u&&i[t]||(u?i:o)("Symbol."+t))};f.store=r},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,e){var r=e(35),o=e(16);t.exports=Object.keys||function(t){return r(t,o)}},function(t,n,e){var r=e(11);t.exports=function(t){if(!r(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var e=0,r=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++e+r).toString(36))}},function(t,n){var e=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=e)},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,e){var r=e(6).f,o=e(2),i=e(7)("toStringTag");t.exports=function(t,n,e){t&&!o(t=e?t:t.prototype,i)&&r(t,i,{configurable:!0,value:n})}},function(t,n,e){var r=e(22)("keys"),o=e(13);t.exports=function(t){return r[t]||(r[t]=o(t))}},function(t,n,e){var r=e(1),o="__core-js_shared__",i=r[o]||(r[o]={});t.exports=function(t){return i[t]||(i[t]={})}},function(t,n){var e=Math.ceil,r=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?r:e)(t)}},function(t,n,e){var r=e(11);t.exports=function(t,n){if(!r(t))return t;var e,o;if(n&&"function"==typeof(e=t.toString)&&!r(o=e.call(t)))return o;if("function"==typeof(e=t.valueOf)&&!r(o=e.call(t)))return o;if(!n&&"function"==typeof(e=t.toString)&&!r(o=e.call(t)))return o;throw TypeError("Can't convert object to primitive value")}},function(t,n,e){var r=e(1),o=e(14),i=e(18),u=e(26),f=e(6).f;t.exports=function(t){var n=o.Symbol||(o.Symbol=i?{}:r.Symbol||{});"_"==t.charAt(0)||t in n||f(n,t,{value:u.f(t)})}},function(t,n,e){n.f=e(7)},function(t,n,e){var r=e(1),o=e(14),i=e(46),u=e(5),f="prototype",c=function(t,n,e){var a,s,l,p=t&c.F,d=t&c.G,v=t&c.S,y=t&c.P,h=t&c.B,b=t&c.W,x=d?o:o[n]||(o[n]={}),m=x[f],g=d?r:v?r[n]:(r[n]||{})[f];d&&(e=n);for(a in e)s=!p&&g&&void 0!==g[a],s&&a in x||(l=s?g[a]:e[a],x[a]=d&&"function"!=typeof g[a]?e[a]:h&&s?i(l,r):b&&g[a]==l?function(t){var n=function(n,e,r){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,e)}return new t(n,e,r)}return t.apply(this,arguments)};return n[f]=t[f],n}(l):y&&"function"==typeof l?i(Function.call,l):l,y&&((x.virtual||(x.virtual={}))[a]=l,t&c.R&&m&&!m[a]&&u(m,a,l)))};c.F=1,c.G=2,c.S=4,c.P=8,c.B=16,c.W=32,c.U=64,c.R=128,t.exports=c},function(t,n){var e={}.toString;t.exports=function(t){return e.call(t).slice(8,-1)}},function(t,n,e){var r=e(11),o=e(1).document,i=r(o)&&r(o.createElement);t.exports=function(t){return i?o.createElement(t):{}}},function(t,n,e){t.exports=!e(4)&&!e(8)(function(){return 7!=Object.defineProperty(e(29)("div"),"a",{get:function(){return 7}}).a})},function(t,n,e){"use strict";var r=e(18),o=e(27),i=e(36),u=e(5),f=e(2),c=e(17),a=e(51),s=e(20),l=e(58),p=e(7)("iterator"),d=!([].keys&&"next"in[].keys()),v="@@iterator",y="keys",h="values",b=function(){return this};t.exports=function(t,n,e,x,m,g,w){a(e,n,x);var O,S,_,j=function(t){if(!d&&t in A)return A[t];switch(t){case y:return function(){return new e(this,t)};case h:return function(){return new e(this,t)}}return function(){return new e(this,t)}},P=n+" Iterator",E=m==h,M=!1,A=t.prototype,T=A[p]||A[v]||m&&A[m],L=T||j(m),N=m?E?j("entries"):L:void 0,C="Array"==n?A.entries||T:T;if(C&&(_=l(C.call(new t)),_!==Object.prototype&&(s(_,P,!0),r||f(_,p)||u(_,p,b))),E&&T&&T.name!==h&&(M=!0,L=function(){return T.call(this)}),r&&!w||!d&&!M&&A[p]||u(A,p,L),c[n]=L,c[P]=b,m)if(O={values:E?L:j(h),keys:g?L:j(y),entries:N},w)for(S in O)S in A||i(A,S,O[S]);else o(o.P+o.F*(d||M),n,O);return O}},function(t,n,e){var r=e(10),o=e(55),i=e(16),u=e(21)("IE_PROTO"),f=function(){},c="prototype",a=function(){var t,n=e(29)("iframe"),r=i.length,o="<",u=">";for(n.style.display="none",e(48).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write(o+"script"+u+"document.F=Object"+o+"/script"+u),t.close(),a=t.F;r--;)delete a[c][i[r]];return a()};t.exports=Object.create||function(t,n){var e;return null!==t?(f[c]=r(t),e=new f,f[c]=null,e[u]=t):e=a(),void 0===n?e:o(e,n)}},function(t,n,e){var r=e(35),o=e(16).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return r(t,o)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,e){var r=e(2),o=e(3),i=e(45)(!1),u=e(21)("IE_PROTO");t.exports=function(t,n){var e,f=o(t),c=0,a=[];for(e in f)e!=u&&r(f,e)&&a.push(e);for(;n.length>c;)r(f,e=n[c++])&&(~i(a,e)||a.push(e));return a}},function(t,n,e){t.exports=e(5)},function(t,n,e){var r=e(15);t.exports=function(t){return Object(r(t))}},function(t,n,e){t.exports={default:e(41),__esModule:!0}},function(t,n,e){t.exports={default:e(42),__esModule:!0}},function(t,n,e){"use strict";function r(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var o=e(39),i=r(o),u=e(38),f=r(u),c="function"==typeof f.default&&"symbol"==typeof i.default?function(t){return typeof t}:function(t){return t&&"function"==typeof f.default&&t.constructor===f.default&&t!==f.default.prototype?"symbol":typeof t};n.default="function"==typeof f.default&&"symbol"===c(i.default)?function(t){return"undefined"==typeof t?"undefined":c(t)}:function(t){return t&&"function"==typeof f.default&&t.constructor===f.default&&t!==f.default.prototype?"symbol":"undefined"==typeof t?"undefined":c(t)}},function(t,n,e){e(65),e(63),e(66),e(67),t.exports=e(14).Symbol},function(t,n,e){e(64),e(68),t.exports=e(26).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,e){var r=e(3),o=e(61),i=e(60);t.exports=function(t){return function(n,e,u){var f,c=r(n),a=o(c.length),s=i(u,a);if(t&&e!=e){for(;a>s;)if(f=c[s++],f!=f)return!0}else for(;a>s;s++)if((t||s in c)&&c[s]===e)return t||s||0;return!t&&-1}}},function(t,n,e){var r=e(43);t.exports=function(t,n,e){if(r(t),void 0===n)return t;switch(e){case 1:return function(e){return t.call(n,e)};case 2:return function(e,r){return t.call(n,e,r)};case 3:return function(e,r,o){return t.call(n,e,r,o)}}return function(){return t.apply(n,arguments)}}},function(t,n,e){var r=e(9),o=e(34),i=e(19);t.exports=function(t){var n=r(t),e=o.f;if(e)for(var u,f=e(t),c=i.f,a=0;f.length>a;)c.call(t,u=f[a++])&&n.push(u);return n}},function(t,n,e){t.exports=e(1).document&&document.documentElement},function(t,n,e){var r=e(28);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==r(t)?t.split(""):Object(t)}},function(t,n,e){var r=e(28);t.exports=Array.isArray||function(t){return"Array"==r(t)}},function(t,n,e){"use strict";var r=e(32),o=e(12),i=e(20),u={};e(5)(u,e(7)("iterator"),function(){return this}),t.exports=function(t,n,e){t.prototype=r(u,{next:o(1,e)}),i(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,e){var r=e(9),o=e(3);t.exports=function(t,n){for(var e,i=o(t),u=r(i),f=u.length,c=0;f>c;)if(i[e=u[c++]]===n)return e}},function(t,n,e){var r=e(13)("meta"),o=e(11),i=e(2),u=e(6).f,f=0,c=Object.isExtensible||function(){return!0},a=!e(8)(function(){return c(Object.preventExtensions({}))}),s=function(t){u(t,r,{value:{i:"O"+ ++f,w:{}}})},l=function(t,n){if(!o(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!i(t,r)){if(!c(t))return"F";if(!n)return"E";s(t)}return t[r].i},p=function(t,n){if(!i(t,r)){if(!c(t))return!0;if(!n)return!1;s(t)}return t[r].w},d=function(t){return a&&v.NEED&&c(t)&&!i(t,r)&&s(t),t},v=t.exports={KEY:r,NEED:!1,fastKey:l,getWeak:p,onFreeze:d}},function(t,n,e){var r=e(6),o=e(10),i=e(9);t.exports=e(4)?Object.defineProperties:function(t,n){o(t);for(var e,u=i(n),f=u.length,c=0;f>c;)r.f(t,e=u[c++],n[e]);return t}},function(t,n,e){var r=e(19),o=e(12),i=e(3),u=e(24),f=e(2),c=e(30),a=Object.getOwnPropertyDescriptor;n.f=e(4)?a:function(t,n){if(t=i(t),n=u(n,!0),c)try{return a(t,n)}catch(t){}if(f(t,n))return o(!r.f.call(t,n),t[n])}},function(t,n,e){var r=e(3),o=e(33).f,i={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],f=function(t){try{return o(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==i.call(t)?f(t):o(r(t))}},function(t,n,e){var r=e(2),o=e(37),i=e(21)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=o(t),r(t,i)?t[i]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,e){var r=e(23),o=e(15);t.exports=function(t){return function(n,e){var i,u,f=String(o(n)),c=r(e),a=f.length;return c<0||c>=a?t?"":void 0:(i=f.charCodeAt(c),i<55296||i>56319||c+1===a||(u=f.charCodeAt(c+1))<56320||u>57343?t?f.charAt(c):i:t?f.slice(c,c+2):(i-55296<<10)+(u-56320)+65536)}}},function(t,n,e){var r=e(23),o=Math.max,i=Math.min;t.exports=function(t,n){return t=r(t),t<0?o(t+n,0):i(t,n)}},function(t,n,e){var r=e(23),o=Math.min;t.exports=function(t){return t>0?o(r(t),9007199254740991):0}},function(t,n,e){"use strict";var r=e(44),o=e(52),i=e(17),u=e(3);t.exports=e(31)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,e=this._i++;return!t||e>=t.length?(this._t=void 0,o(1)):"keys"==n?o(0,e):"values"==n?o(0,t[e]):o(0,[e,t[e]])},"values"),i.Arguments=i.Array,r("keys"),r("values"),r("entries")},function(t,n){},function(t,n,e){"use strict";var r=e(59)(!0);e(31)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,e=this._i;return e>=n.length?{value:void 0,done:!0}:(t=r(n,e),this._i+=t.length,{value:t,done:!1})})},function(t,n,e){"use strict";var r=e(1),o=e(2),i=e(4),u=e(27),f=e(36),c=e(54).KEY,a=e(8),s=e(22),l=e(20),p=e(13),d=e(7),v=e(26),y=e(25),h=e(53),b=e(47),x=e(50),m=e(10),g=e(3),w=e(24),O=e(12),S=e(32),_=e(57),j=e(56),P=e(6),E=e(9),M=j.f,A=P.f,T=_.f,L=r.Symbol,N=r.JSON,C=N&&N.stringify,k="prototype",F=d("_hidden"),q=d("toPrimitive"),I={}.propertyIsEnumerable,B=s("symbol-registry"),D=s("symbols"),W=s("op-symbols"),H=Object[k],K="function"==typeof L,R=r.QObject,J=!R||!R[k]||!R[k].findChild,U=i&&a(function(){return 7!=S(A({},"a",{get:function(){return A(this,"a",{value:7}).a}})).a})?function(t,n,e){var r=M(H,n);r&&delete H[n],A(t,n,e),r&&t!==H&&A(H,n,r)}:A,G=function(t){var n=D[t]=S(L[k]);return n._k=t,n},$=K&&"symbol"==typeof L.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof L},z=function(t,n,e){return t===H&&z(W,n,e),m(t),n=w(n,!0),m(e),o(D,n)?(e.enumerable?(o(t,F)&&t[F][n]&&(t[F][n]=!1),e=S(e,{enumerable:O(0,!1)})):(o(t,F)||A(t,F,O(1,{})),t[F][n]=!0),U(t,n,e)):A(t,n,e)},Y=function(t,n){m(t);for(var e,r=b(n=g(n)),o=0,i=r.length;i>o;)z(t,e=r[o++],n[e]);return t},Q=function(t,n){return void 0===n?S(t):Y(S(t),n)},X=function(t){var n=I.call(this,t=w(t,!0));return!(this===H&&o(D,t)&&!o(W,t))&&(!(n||!o(this,t)||!o(D,t)||o(this,F)&&this[F][t])||n)},V=function(t,n){if(t=g(t),n=w(n,!0),t!==H||!o(D,n)||o(W,n)){var e=M(t,n);return!e||!o(D,n)||o(t,F)&&t[F][n]||(e.enumerable=!0),e}},Z=function(t){for(var n,e=T(g(t)),r=[],i=0;e.length>i;)o(D,n=e[i++])||n==F||n==c||r.push(n);return r},tt=function(t){for(var n,e=t===H,r=T(e?W:g(t)),i=[],u=0;r.length>u;)!o(D,n=r[u++])||e&&!o(H,n)||i.push(D[n]);return i};K||(L=function(){if(this instanceof L)throw TypeError("Symbol is not a constructor!");var t=p(arguments.length>0?arguments[0]:void 0),n=function(e){this===H&&n.call(W,e),o(this,F)&&o(this[F],t)&&(this[F][t]=!1),U(this,t,O(1,e))};return i&&J&&U(H,t,{configurable:!0,set:n}),G(t)},f(L[k],"toString",function(){return this._k}),j.f=V,P.f=z,e(33).f=_.f=Z,e(19).f=X,e(34).f=tt,i&&!e(18)&&f(H,"propertyIsEnumerable",X,!0),v.f=function(t){return G(d(t))}),u(u.G+u.W+u.F*!K,{Symbol:L});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),et=0;nt.length>et;)d(nt[et++]);for(var nt=E(d.store),et=0;nt.length>et;)y(nt[et++]);u(u.S+u.F*!K,"Symbol",{for:function(t){return o(B,t+="")?B[t]:B[t]=L(t)},keyFor:function(t){if($(t))return h(B,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){J=!0},useSimple:function(){J=!1}}),u(u.S+u.F*!K,"Object",{create:Q,defineProperty:z,defineProperties:Y,getOwnPropertyDescriptor:V,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),N&&u(u.S+u.F*(!K||a(function(){var t=L();return"[null]"!=C([t])||"{}"!=C({a:t})||"{}"!=C(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!$(t)){for(var n,e,r=[t],o=1;arguments.length>o;)r.push(arguments[o++]);return n=r[1],"function"==typeof n&&(e=n),!e&&x(n)||(n=function(t,n){if(e&&(n=e.call(this,t,n)),!$(n))return n}),r[1]=n,C.apply(N,r)}}}),L[k][q]||e(5)(L[k],q,L[k].valueOf),l(L,"Symbol"),l(Math,"Math",!0),l(r.JSON,"JSON",!0)},function(t,n,e){e(25)("asyncIterator")},function(t,n,e){e(25)("observable")},function(t,n,e){e(62);for(var r=e(1),o=e(5),i=e(17),u=e(7)("toStringTag"),f=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],c=0;c<5;c++){var a=f[c],s=r[a],l=s&&s.prototype;l&&!l[u]&&o(l,u,a),i[a]=i.Array}},function(t,n){"use strict";var e={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&t.indexOf("KHTML")==-1,mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:t.indexOf("Safari")==-1,weixin:t.indexOf("MicroMessenger")==-1}}()};t.exports=e},function(t,n,e){"use strict";function r(t){return t&&t.__esModule?t:{default:t}}var o=e(40),i=r(o),u=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):o[t]||t}function n(t){return l[t]}var e=/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,r=/['<> "&]/g,o={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},f=/\u00a0/g,c=/<br\s*\/?>/gi,a=/\r?\n/g,s=/\s/g,l={};for(var p in o)l[o[p]]=p;return o["&apos;"]="'",l["'"]="&#39;",{encode:function(t){return t?(""+t).replace(r,n).replace(a,"<br/>").replace(s,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(c,"\n").replace(e,t).replace(f," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],e=0,r=t.length;r>e;e++)n.push(t.charCodeAt(e).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],e=0,r=t.length;r>e;e++)n.push(t.charCodeAt(e).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],e=0,r=t.length;r>e;e+=2)n.push(String.fromCharCode("0x"+t.slice(e,e+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,e=t.length;e>n;n++)t[n]=u.encodeObject(t[n]);else if("object"==("undefined"==typeof t?"undefined":(0,i.default)(t)))for(var r in t)t[r]=u.encodeObject(t[r]);else if("string"==typeof t)return u.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=u},function(t,n){function e(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=e},function(t,n){function e(t,n){if(t.classList)t.classList.remove(n);else{var e=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(e," ")}}t.exports=e},,,function(t,n){"use strict";function e(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">&laquo; Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next &raquo;</a>'),yiliaConfig&&yiliaConfig.open_in_new){var n=document.querySelectorAll(".article-entry a:not(.article-more-a)");n.forEach(function(t){t.setAttribute("target","_blank")})}var e=document.querySelector("#js-aboutme");e&&0!==e.length&&(e.innerHTML=e.innerText)}t.exports={init:e}},,,,,,,,,function(t,n){function e(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var e=t.nextSibling;return e?t.parentNode.insertBefore(n,e):t.parentNode.appendChild(n)}t.exports=e}])</script><script src="/./main.234bc0.js"></script><script>!function(){var e=function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)};e("/slider.885efe.js")}()</script>


    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">所有文章</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'friends')"><a href="javascript:void(0)" q-class="active:friends">友链</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">英语</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">python</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">十分钟搞定Pandas</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">心有猛虎</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">Chan</a>
              </li>
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br/>1、在博客根目录（注意不是yilia根目录）执行以下命令：<br/> npm i hexo-generator-json-content --save<br/><br/>
            2、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: true
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    
    	<section class="tools-section tools-section-friends" q-show="friends">
  		
        <ul class="search-ul">
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接1</a>
            </li>
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接2</a>
            </li>
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接3</a>
            </li>
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接4</a>
            </li>
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接5</a>
            </li>
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接6</a>
            </li>
          
        </ul>
  		
    	</section>
    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">很惭愧&lt;br&gt;&lt;br&gt;只做了一点微小的工作&lt;br&gt;谢谢大家&lt;br/&gt;一线软件程序猿，精通J2EE,JS,HTML5&lt;br/&gt;QQ=759949947 , Email=xpws2006@163.com</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
</body>
</html>